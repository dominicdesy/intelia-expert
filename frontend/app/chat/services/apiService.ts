// app/chat/services/apiService.ts - VERSION AGENT: Streaming LLM + Agent Callbacks
//

import { getSupabaseClient } from '@/lib/supabase/singleton'

// Types enrichis pour les callbacks de streaming Agent
type StreamCallbacks = {
  onDelta?: (text: string) => void;
  onFinal?: (full: string) => void;
  onFollowup?: (msg: string) => void;
  
  // üÜï NOUVEAUX CALLBACKS AGENT
  onAgentStart?: (complexity: string, subQueriesCount: number) => void;
  onAgentThinking?: (decisions: string[]) => void;
  onChunk?: (content: string, confidence: number, source?: string) => void;
  onAgentEnd?: (synthesisMethod: string, sourcesUsed: number) => void;
  onAgentError?: (error: string) => void;
  onAgentProgress?: (step: string, progress: number) => void;
};

// Configuration API pour le backend m√©tier (stats, billing, etc.)
const getApiConfig = () => {
  const baseUrl = process.env.NEXT_PUBLIC_API_BASE_URL
  const version = process.env.NEXT_PUBLIC_API_VERSION || 'v1'
  
  const cleanBaseUrl = baseUrl?.replace(/\/api\/?$/, '') || ''
  const finalUrl = `${cleanBaseUrl}/api/${version}`
  
  return finalUrl
}

const API_BASE_URL = getApiConfig()

// üîß FIX: Stockage direct des session IDs sans d√©pendance externe
function storeRecentSessionId(sessionId: string): void {
  try {
    const STORAGE_KEY = 'recent_session_ids';
    const MAX_SESSIONS = 50;
    
    // R√©cup√©rer les sessions existantes
    const existing = JSON.parse(localStorage.getItem(STORAGE_KEY) || '[]');
    
    // √âviter les doublons
    if (existing.includes(sessionId)) {
      console.log('[apiService] Session ID d√©j√† stock√©:', sessionId.substring(0, 8) + '...');
      return;
    }
    
    // Ajouter en t√™te de liste
    const updated = [sessionId, ...existing];
    
    // Limiter le nombre de sessions
    const limited = updated.slice(0, MAX_SESSIONS);
    
    // Sauvegarder
    localStorage.setItem(STORAGE_KEY, JSON.stringify(limited));
    
    console.log('[apiService] ‚úÖ Session ID stock√©:', sessionId.substring(0, 8) + '...', 'Total:', limited.length);
    
  } catch (error) {
    console.error('[apiService] Erreur stockage session ID:', error);
  }
}

// Fonction d'authentification pour le backend m√©tier (conserv√©e)
const getAuthToken = async (): Promise<string | null> => {
  console.log('[apiService] R√©cup√©ration token auth...');
  
  try {
    // M√©thode 1: R√©cup√©rer depuis intelia-expert-auth (PRIORIT√â)
    const authData = localStorage.getItem('intelia-expert-auth');
    if (authData) {
      const parsed = JSON.parse(authData);
      if (parsed.access_token) {
        console.log('[apiService] Token r√©cup√©r√© depuis intelia-expert-auth');
        
        // V√©rifier que le token n'est pas expir√©
        try {
          const tokenParts = parsed.access_token.split('.');
          if (tokenParts.length === 3) {
            const payload = JSON.parse(atob(tokenParts[1]));
            const now = Math.floor(Date.now() / 1000);
            const isExpired = payload.exp < now;
            
            if (!isExpired) {
              return parsed.access_token;
            }
          }
        } catch (decodeError) {
          return parsed.access_token;
        }
      }
    }
    
    // M√©thode 2: Fallback vers Supabase store
    const supabaseStore = localStorage.getItem('supabase-auth-store');
    if (supabaseStore) {
      const parsed = JSON.parse(supabaseStore);
      const possibleTokens = [
        parsed.state?.session?.access_token,
        parsed.state?.user?.access_token,
        parsed.access_token
      ];
      
      for (const token of possibleTokens) {
        if (token && typeof token === 'string' && token.length > 20) {
          return token;
        }
      }
    }
    
    console.error('[apiService] Aucun token trouv√©');
    return null;
    
  } catch (error) {
    console.error('[apiService] Erreur r√©cup√©ration token:', error);
    return null;
  }
}

// Headers pour les appels au backend m√©tier
const getAuthHeaders = async (): Promise<Record<string, string>> => {
  const headers: Record<string, string> = {
    'Content-Type': 'application/json',
    'Origin': 'https://expert.intelia.com',
  }

  const authToken = await getAuthToken()
  if (authToken) {
    headers['Authorization'] = `Bearer ${authToken}`
  }

  return headers
}

// G√©n√©ration UUID (conserv√©e)
const generateUUID = (): string => {
  if (typeof crypto !== 'undefined' && crypto.randomUUID) {
    return crypto.randomUUID()
  }
  
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    const r = Math.random() * 16 | 0
    const v = c === 'x' ? r : (r & 0x3 | 0x8)
    return v.toString(16)
  })
}

// Formatage heure locale (conserv√©e)
export const formatToLocalTime = (utcTimestamp: string): string => {
  try {
    const date = new Date(utcTimestamp);
    const options: Intl.DateTimeFormatOptions = {
      year: 'numeric',
      month: '2-digit', 
      day: '2-digit',
      hour: '2-digit',
      minute: '2-digit',
      second: '2-digit',
      timeZone: Intl.DateTimeFormat().resolvedOptions().timeZone,
      hour12: false
    };
    return date.toLocaleString('fr-CA', options);
  } catch (error) {
    console.warn('Erreur formatage date:', error);
    return utcTimestamp;
  }
}

export const simpleLocalTime = (utcTimestamp: string): string => {
  try {
    return new Date(utcTimestamp).toLocaleString('fr-CA', {
      year: 'numeric',
      month: '2-digit', 
      day: '2-digit',
      hour: '2-digit',
      minute: '2-digit',
      hour12: false
    });
  } catch (error) {
    console.warn('Erreur formatage date simple:', error);
    return utcTimestamp;
  }
}

// Interface pour les r√©ponses Agent (adapt√©e au streaming enrichi)
interface EnhancedAIResponse {
  response: string
  conversation_id: string
  language: string
  timestamp: string
  mode: 'streaming'
  source: 'llm_backend'
  final_response: string
  
  // Propri√©t√©s compatibles avec l'ancien format
  type?: 'answer' | 'clarification' | 'partial_answer' | 'validation_rejected'
  requires_clarification?: boolean
  clarification_questions?: string[]
  clarification_result?: any
  response_versions?: {
    ultra_concise?: string
    concise?: string
    standard?: string
    detailed?: string
  }
  full_text?: string
  rag_used?: boolean
  sources?: any[]
  confidence_score?: number
  note?: string
  
  // üÜï NOUVELLES PROPRI√âT√âS AGENT
  agent_metadata?: {
    complexity: string
    sub_queries_count: number
    synthesis_method: string
    sources_used: number
    processing_time?: number
    decisions?: string[]
  }
}

/**
 * ü§ñ FONCTION STREAMING SSE AGENT - VERSION ENRICHIE
 * G√®re l'appel vers /api/chat/stream avec support complet des √©v√©nements Agent
 */
async function streamAIResponseInternal(
  tenant_id: string,
  lang: string,
  message: string,
  conversation_id: string,
  user_context?: any,
  callbacks?: StreamCallbacks
): Promise<string> {
  
  const payload = {
    tenant_id,
    lang,
    message,
    conversation_id,
    user_context
  };

  console.log('[apiService] ü§ñ Streaming Agent vers /api/chat/stream:', {
    tenant_id,
    lang,
    message_preview: message.substring(0, 50) + '...',
    has_callbacks: !!callbacks,
    agent_callbacks: !!(callbacks?.onAgentStart || callbacks?.onAgentThinking)
  });

  // Headers SSE complets avec Cache-Control
  const response = await fetch('/api/chat/stream', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Accept': 'text/event-stream',
      'Cache-Control': 'no-cache'
    },
    body: JSON.stringify(payload)
  });

  if (!response.ok) {
    let errorInfo: any = null;
    try { 
      const text = await response.text();
      errorInfo = JSON.parse(text); 
    } catch { 
      errorInfo = { error: `http_${response.status}`, message: `Erreur HTTP ${response.status}` };
    }
    
    console.error('[apiService] Erreur streaming Agent:', errorInfo);
    throw new Error(errorInfo?.message || `Erreur ${response.status}`);
  }

  if (!response.body) {
    throw new Error("Pas de flux de donn√©es re√ßu");
  }

  // Traitement du flux SSE avec callbacks Agent enrichis
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let finalAnswer = "";
  let buffer = "";
  
  // Variables de suivi Agent
  let agentMetadata = {
    complexity: 'simple',
    sub_queries_count: 0,
    synthesis_method: 'direct',
    sources_used: 0,
    processing_time: Date.now(),
    decisions: [] as string[]
  };

  try {
    while (true) {
      const { value, done } = await reader.read();
      
      if (done) {
        // Calculer le temps de traitement final
        agentMetadata.processing_time = Date.now() - agentMetadata.processing_time;
        console.log('[apiService] ü§ñ Stream Agent termin√©:', {
          final_length: finalAnswer.length,
          agent_metadata: agentMetadata
        });
        break;
      }

      buffer += decoder.decode(value, { stream: true });

      // Traitement ligne par ligne (format SSE)
      let newlineIndex: number;
      while ((newlineIndex = buffer.indexOf("\n")) >= 0) {
        const line = buffer.slice(0, newlineIndex).trim();
        buffer = buffer.slice(newlineIndex + 1);
        
        if (!line || !line.startsWith("data:")) {
          continue;
        }
        
        const jsonStr = line.slice(5).trim();
        if (!jsonStr || jsonStr === "[DONE]") {
          continue;
        }
        
        try {
          const event = JSON.parse(jsonStr);
          
          // ü§ñ GESTION DES NOUVEAUX √âV√âNEMENTS AGENT
          switch (event.type) {
            case "agent_start":
              console.log('[apiService] ü§ñ Agent d√©marr√©:', event.complexity, 'sous-requ√™tes:', event.sub_queries_count);
              agentMetadata.complexity = event.complexity || 'simple';
              agentMetadata.sub_queries_count = event.sub_queries_count || 0;
              callbacks?.onAgentStart?.(event.complexity, event.sub_queries_count);
              break;
              
            case "agent_thinking":
              console.log('[apiService] üß† Agent r√©flexion:', event.decisions?.length || 0, 'd√©cisions');
              if (event.decisions && Array.isArray(event.decisions)) {
                agentMetadata.decisions.push(...event.decisions);
                callbacks?.onAgentThinking?.(event.decisions);
              }
              break;
              
            case "chunk":
              // Nouveau format chunk avec m√©tadonn√©es
              const chunkContent = event.content || event.text || '';
              const confidence = event.confidence || 0.8;
              const source = event.source || 'unknown';
              
              if (chunkContent) {
                finalAnswer += chunkContent;
                callbacks?.onChunk?.(chunkContent, confidence, source);
                // Fallback vers onDelta pour compatibilit√©
                callbacks?.onDelta?.(chunkContent);
              }
              break;
              
            case "agent_progress":
              console.log('[apiService] üìä Agent progression:', event.step, event.progress + '%');
              callbacks?.onAgentProgress?.(event.step, event.progress);
              break;
              
            case "agent_end":
              console.log('[apiService] üèÅ Agent termin√©:', event.synthesis_method, 'sources:', event.sources_used);
              agentMetadata.synthesis_method = event.synthesis_method || 'direct';
              agentMetadata.sources_used = event.sources_used || 0;
              callbacks?.onAgentEnd?.(event.synthesis_method, event.sources_used);
              break;
              
            case "agent_error":
              console.error('[apiService] ‚ùå Erreur Agent:', event.error);
              callbacks?.onAgentError?.(event.error);
              break;
              
            // üì¶ √âV√âNEMENTS LEGACY MAINTENUS
            case "delta":
              if (typeof event.text === "string" && event.text) {
                finalAnswer += event.text;
                callbacks?.onDelta?.(event.text);
              }
              break;
              
            case "final":
              if (event.answer) {
                finalAnswer = event.answer;
                callbacks?.onFinal?.(finalAnswer);
              }
              break;
              
            case "proactive_followup":
              if (event.answer) {
                console.log('[apiService] üîÑ Relance proactive re√ßue:', event.answer);
                callbacks?.onFollowup?.(event.answer);
              }
              break;
              
            case "error":
              console.error('[apiService] ‚ùå Erreur dans le stream:', event);
              throw new Error(event.message || 'Erreur de streaming');
              
            default:
              console.log('[apiService] üì° √âv√©nement SSE non g√©r√©:', event.type, event);
          }
          
        } catch (parseError) {
          // Ignore les lignes JSON malform√©es (chunks partiels)
          console.debug('[apiService] Ligne SSE malform√©e ignor√©e:', jsonStr.substring(0, 100));
        }
      }
    }
    
  } finally {
    try {
      reader.cancel();
    } catch {
      // Ignore les erreurs de cancel
    }
  }

  // Attacher les m√©tadonn√©es Agent √† la r√©ponse
  (finalAnswer as any).__agentMetadata = agentMetadata;

  return finalAnswer;
}

/**
 * ü§ñ NOUVELLE FONCTION generateAIResponse avec support Agent complet
 * Interface compatible avec l'ancien syst√®me + nouvelles capacit√©s Agent
 */
export const generateAIResponse = async (
  question: string,
  user: any,
  language: string = 'fr',
  conversationId?: string,
  concisionLevel: 'ultra_concise' | 'concise' | 'standard' | 'detailed' = 'concise',
  isClarificationResponse = false,
  originalQuestion?: string,
  clarificationEntities?: Record<string, any>,
  callbacks?: StreamCallbacks
): Promise<EnhancedAIResponse> => {
  
  if (!question || question.trim() === '') {
    throw new Error('Question requise')
  }

  if (!user || !user.id) {
    throw new Error('Utilisateur requis')
  }

  const finalConversationId = conversationId || generateUUID()

  console.log('[apiService] ü§ñ AGENT: G√©n√©ration AI avec streaming enrichi:', {
    question: question.substring(0, 50) + '...',
    session_id: finalConversationId.substring(0, 8) + '...',
    user_id: user.id,
    system: 'LLM Backend Agent',
    has_agent_callbacks: !!(callbacks?.onAgentStart || callbacks?.onAgentThinking)
  })

  try {
    // R√©cup√©ration du tenant_id depuis le profil utilisateur
    let tenant_id = 'ten_demo'; // Fallback
    
    // TODO: R√©cup√©rer le vrai tenant_id depuis Supabase
    // const supabase = getSupabaseClient()
    // const { data: profile } = await supabase
    //   .from('profiles')
    //   .select('tenant_id, organization_id')
    //   .eq('id', user.id)
    //   .single()
    // tenant_id = profile?.tenant_id || profile?.organization_id || 'ten_demo'

    // Enrichissement clarification (conserv√© de l'ancien syst√®me)
    let finalQuestion = question.trim()
    
    if (isClarificationResponse && originalQuestion) {
      console.log('[apiService] Mode clarification - enrichissement question')
      
      const breedMatch = finalQuestion.match(/(ross\s*308|cobb\s*500|hubbard)/i)
      const sexMatch = finalQuestion.match(/(male|m√¢le|femelle|female|mixte|mixed)/i)
      
      const breed = breedMatch ? breedMatch[0] : ''
      const sex = sexMatch ? sexMatch[0] : ''
      
      if (breed && sex) {
        finalQuestion = `${originalQuestion} pour ${breed} ${sex}`
        console.log('[apiService] Question enrichie:', finalQuestion)
      }
    }

    // ü§ñ Appel au service de streaming Agent avec callbacks enrichis
    const finalResponse = await streamAIResponseInternal(
      tenant_id,
      language,
      finalQuestion,
      finalConversationId,
      {
        user_id: user.id,
        concision_level: concisionLevel,
        ...(clarificationEntities && { clarification_entities: clarificationEntities })
      },
      callbacks  // <<< PROPAGATION DES CALLBACKS AGENT
    );

    // R√©cup√©ration des m√©tadonn√©es Agent
    const agentMetadata = (finalResponse as any).__agentMetadata || {
      complexity: 'simple',
      sub_queries_count: 0,
      synthesis_method: 'direct',
      sources_used: 0,
      processing_time: 0,
      decisions: []
    };

    console.log('[apiService] ü§ñ Streaming Agent termin√©:', {
      final_length: finalResponse.length,
      conversation_id: finalConversationId,
      agent_complexity: agentMetadata.complexity,
      agent_sources: agentMetadata.sources_used
    })

    // Enregistrement de la conversation via le backend m√©tier
    try {
      await saveConversationToBackend(finalConversationId, finalQuestion, finalResponse, user.id)
    } catch (saveError) {
      console.warn('[apiService] Erreur sauvegarde conversation:', saveError)
      // Ne pas faire √©chouer la r√©ponse pour une erreur de sauvegarde
    }

    // üîß FIX: Stockage du session ID pour l'historique
    storeRecentSessionId(finalConversationId)

    // Construction de la r√©ponse dans le format attendu par l'interface
    const processedResponse: EnhancedAIResponse = {
      response: finalResponse,
      conversation_id: finalConversationId,
      language: language,
      timestamp: new Date().toISOString(),
      mode: 'streaming',
      source: 'llm_backend',
      final_response: finalResponse,
      
      // Propri√©t√©s compatibles avec l'ancien format
      type: 'answer',
      requires_clarification: false,
      rag_used: true,
      sources: [],
      confidence_score: 0.9,
      note: 'G√©n√©r√© via streaming LLM Agent',
      full_text: finalResponse,
      
      // ü§ñ NOUVELLES M√âTADONN√âES AGENT
      agent_metadata: agentMetadata,
      
      // G√©n√©ration automatique des versions de r√©ponse
      response_versions: {
        ultra_concise: finalResponse.length > 200 ? 
          finalResponse.substring(0, 150) + '...' : finalResponse,
        concise: finalResponse.length > 400 ? 
          finalResponse.substring(0, 300) + '...' : finalResponse,
        standard: finalResponse,
        detailed: finalResponse
      }
    }

    console.log('[apiService] ü§ñ R√©ponse Agent trait√©e:', {
      response_length: processedResponse.response.length,
      conversation_id: processedResponse.conversation_id,
      agent_metadata: processedResponse.agent_metadata
    })

    return processedResponse

  } catch (error) {
    console.error('[apiService] Erreur g√©n√©ration AI Agent:', error)
    
    // Gestion des erreurs avec messages appropri√©s
    if (error instanceof Error) {
      throw error
    }
    
    throw new Error('Erreur de g√©n√©ration avec le service LLM Agent')
  }
}

/**
 * Sauvegarde de la conversation via le backend m√©tier
 * Utilise l'ancien endpoint pour maintenir la compatibilit√© des stats/billing
 */
async function saveConversationToBackend(
  conversationId: string,
  question: string,
  response: string,
  userId: string
): Promise<void> {
  
  try {
    const headers = await getAuthHeaders()
    
    const payload = {
      conversation_id: conversationId,
      question: question.trim(),
      response: response,
      user_id: userId,
      timestamp: new Date().toISOString(),
      source: 'llm_streaming_agent',
      metadata: {
        mode: 'streaming',
        backend: 'llm_backend_agent'
      }
    }

    const response_save = await fetch(`${API_BASE_URL}/conversations/save`, {
      method: 'POST',
      headers,
      body: JSON.stringify(payload)
    })

    if (!response_save.ok) {
      const errorText = await response_save.text()
      console.error('[apiService] Erreur sauvegarde conversation:', errorText)
      throw new Error(`Erreur sauvegarde: ${response_save.status}`)
    }

    console.log('[apiService] Conversation sauvegard√©e avec succ√®s')

  } catch (error) {
    console.error('[apiService] Erreur lors de la sauvegarde:', error)
    throw error
  }
}

/**
 * ü§ñ VERSION PUBLIQUE AGENT avec streaming (remplace l'ancienne)
 */
export const generateAIResponsePublic = async (
  question: string,
  language: string = 'fr',
  conversationId?: string,
  concisionLevel: 'ultra_concise' | 'concise' | 'standard' | 'detailed' = 'concise',
  callbacks?: StreamCallbacks
): Promise<EnhancedAIResponse> => {
  
  if (!question || question.trim() === '') {
    throw new Error('Question requise')
  }

  const finalConversationId = conversationId || generateUUID()

  console.log('[apiService] ü§ñ G√©n√©ration AI publique Agent:', {
    question: question.substring(0, 50) + '...',
    session_id: finalConversationId.substring(0, 8) + '...',
    has_agent_callbacks: !!(callbacks?.onAgentStart || callbacks?.onAgentThinking)
  })

  try {
    const finalResponse = await streamAIResponseInternal(
      'ten_public',
      language,
      question.trim(),
      finalConversationId,
      undefined,
      callbacks  // <<< PROPAGATION DES CALLBACKS AGENT
    );

    // R√©cup√©ration des m√©tadonn√©es Agent
    const agentMetadata = (finalResponse as any).__agentMetadata || {
      complexity: 'simple',
      sub_queries_count: 0,
      synthesis_method: 'direct',
      sources_used: 0,
      processing_time: 0,
      decisions: []
    };

    // üîß FIX: Stockage du session ID
    storeRecentSessionId(finalConversationId)

    return {
      response: finalResponse,
      conversation_id: finalConversationId,
      language: language,
      timestamp: new Date().toISOString(),
      mode: 'streaming',
      source: 'llm_backend',
      final_response: finalResponse,
      
      type: 'answer',
      requires_clarification: false,
      rag_used: true,
      sources: [],
      confidence_score: 0.9,
      note: 'G√©n√©r√© via streaming LLM Agent (public)',
      full_text: finalResponse,
      
      // ü§ñ M√âTADONN√âES AGENT
      agent_metadata: agentMetadata,
      
      response_versions: {
        ultra_concise: finalResponse.length > 200 ? 
          finalResponse.substring(0, 150) + '...' : finalResponse,
        concise: finalResponse.length > 400 ? 
          finalResponse.substring(0, 300) + '...' : finalResponse,
        standard: finalResponse,
        detailed: finalResponse
      }
    }

  } catch (error) {
    console.error('[apiService] Erreur g√©n√©ration AI publique Agent:', error)
    throw error
  }
}

// ===== FONCTIONS M√âTIER CONSERV√âES INT√âGRALEMENT (backend Digital Ocean) =====

/**
 * Chargement des conversations utilisateur (backend m√©tier)
 */
export const loadUserConversations = async (userId: string): Promise<any> => {
  if (!userId) {
    throw new Error('User ID requis')
  }

  console.log('[apiService] Chargement conversations:', userId)

  try {
    const headers = await getAuthHeaders()
    const url = `${API_BASE_URL}/conversations/user/${userId}`

    const response = await fetch(url, {
      method: 'GET',
      headers
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('[apiService] Erreur conversations:', errorText)
      
      if (response.status === 401) {
        throw new Error('Session expir√©e. Veuillez vous reconnecter.')
      }
      
      if (response.status === 405 || response.status === 404) {
        return {
          count: 0,
          conversations: [],
          user_id: userId,
          note: "Fonctionnalit√© en cours de d√©veloppement"
        }
      }
      
      throw new Error(`Erreur chargement conversations: ${response.status}`)
    }

    const data = await response.json()
    console.log('[apiService] Conversations charg√©es:', {
      count: data.count,
      conversations: data.conversations?.length || 0
    })

    return data

  } catch (error) {
    console.error('[apiService] Erreur chargement conversations:', error)
    
    if (error instanceof Error && error.message.includes('Failed to fetch')) {
      return {
        count: 0,
        conversations: [],
        user_id: userId,
        note: "Erreur de connexion - r√©essayez plus tard"
      }
    }
    
    throw error
  }
}

/**
 * ENVOI DE FEEDBACK (backend m√©tier)
 */
export const sendFeedback = async (
  conversationId: string,
  feedback: 1 | -1,
  comment?: string
): Promise<void> => {
  if (!conversationId) {
    throw new Error('ID de conversation requis')
  }

  console.log('[apiService] Envoi feedback:', feedback)

  try {
    const requestBody = {
      conversation_id: conversationId,
      rating: feedback === 1 ? 'positive' : 'negative',
      ...(comment && { comment: comment.trim() })
    }

    const headers = await getAuthHeaders()

    const response = await fetch(`${API_BASE_URL}/expert/feedback`, {
      method: 'POST',
      headers,
      body: JSON.stringify(requestBody)
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('[apiService] Erreur feedback:', errorText)
      
      if (response.status === 401) {
        throw new Error('Session expir√©e. Veuillez vous reconnecter.')
      }
      
      throw new Error(`Erreur envoi feedback: ${response.status}`)
    }

    console.log('[apiService] Feedback envoy√© avec succ√®s')

  } catch (error) {
    console.error('[apiService] Erreur feedback:', error)
    throw error
  }
}

/**
 * SUPPRESSION DE CONVERSATION (backend m√©tier)
 */
export const deleteConversation = async (conversationId: string): Promise<void> => {
  if (!conversationId) {
    throw new Error('ID de conversation requis')
  }

  console.log('[apiService] Suppression conversation:', conversationId)

  try {
    const headers = await getAuthHeaders()

    const response = await fetch(`${API_BASE_URL}/conversations/${conversationId}`, {
      method: 'DELETE',
      headers
    })

    if (!response.ok) {
      if (response.status === 404) {
        console.warn('[apiService] Conversation d√©j√† supprim√©e ou inexistante')
        return
      }
      
      const errorText = await response.text()
      console.error('[apiService] Erreur delete conversation:', errorText)
      
      if (response.status === 401) {
        throw new Error('Session expir√©e. Veuillez vous reconnecter.')
      }
      
      throw new Error(`Erreur suppression conversation: ${response.status}`)
    }

    const result = await response.json()
    console.log('[apiService] Conversation supprim√©e:', result.message || 'Succ√®s')

  } catch (error) {
    console.error('[apiService] Erreur suppression conversation:', error)
    throw error
  }
}

/**
 * SUPPRESSION DE TOUTES LES CONVERSATIONS (backend m√©tier)
 */
export const clearAllUserConversations = async (userId: string): Promise<void> => {
  if (!userId) {
    throw new Error('User ID requis')
  }

  console.log('[apiService] Suppression toutes conversations:', userId)

  try {
    const headers = await getAuthHeaders()

    const response = await fetch(`${API_BASE_URL}/conversations/user/${userId}`, {
      method: 'DELETE',
      headers
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('[apiService] Erreur clear all conversations:', errorText)
      
      if (response.status === 401) {
        throw new Error('Session expir√©e. Veuillez vous reconnecter.')
      }
      
      throw new Error(`Erreur suppression conversations: ${response.status}`)
    }

    const result = await response.json()
    console.log('[apiService] Toutes conversations supprim√©es:', {
      message: result.message,
      deleted_count: result.deleted_count || 0
    })

  } catch (error) {
    console.error('[apiService] Erreur suppression toutes conversations:', error)
    throw error
  }
}

/**
 * SUGGESTIONS DE SUJETS (backend m√©tier)
 */
export const getTopicSuggestions = async (language: string = 'fr'): Promise<string[]> => {
  console.log('[apiService] R√©cup√©ration suggestions sujets:', language)

  try {
    const headers = await getAuthHeaders()

    const response = await fetch(`${API_BASE_URL}/expert/topics?language=${language}`, {
      method: 'GET',
      headers
    })

    if (!response.ok) {
      console.warn('[apiService] Erreur r√©cup√©ration sujets:', response.status)
      
      return [
        "Probl√®mes de croissance poulets",
        "Conditions environnementales optimales",
        "Protocoles de vaccination",
        "Diagnostic probl√®mes de sant√©",
        "Nutrition et alimentation",
        "Gestion de la mortalit√©"
      ]
    }

    const data = await response.json()
    console.log('[apiService] Sujets r√©cup√©r√©s:', data.topics?.length || 0)

    return Array.isArray(data.topics) ? data.topics : []

  } catch (error) {
    console.error('[apiService] Erreur sujets:', error)
    
    return [
      "Probl√®mes de croissance poulets",
      "Conditions environnementales optimales", 
      "Protocoles de vaccination",
      "Diagnostic probl√®mes de sant√©",
      "Nutrition et alimentation",
      "Gestion de la mortalit√©"
    ]
  }
}

/**
 * HEALTH CHECK (backend m√©tier)
 */
export const checkAPIHealth = async (): Promise<boolean> => {
  try {
    const response = await fetch(`${API_BASE_URL}/system/health`, {
      method: 'GET',
      headers: {
        'Content-Type': 'application/json',
        'Origin': 'https://expert.intelia.com'
      }
    })

    const isHealthy = response.ok
    console.log('[apiService] API Health:', isHealthy ? 'OK' : 'KO')
    
    return isHealthy

  } catch (error) {
    console.error('[apiService] Erreur health check:', error)
    return false
  }
}

// ===== FONCTIONS UTILITAIRES CONSERV√âES =====

export const buildClarificationEntities = (
  clarificationAnswers: Record<string, string>,
  clarificationQuestions: string[]
): Record<string, any> => {
  const entities: Record<string, any> = {}
  
  Object.entries(clarificationAnswers).forEach(([index, answer]) => {
    if (answer && answer.trim()) {
      try {
        const questionIndex = parseInt(index)
        if (questionIndex >= 0 && questionIndex < clarificationQuestions.length) {
          const question = clarificationQuestions[questionIndex].toLowerCase()
          
          if (question.includes('race') || question.includes('breed') || question.includes('souche')) {
            entities.breed = answer.trim()
          } else if (question.includes('sexe') || question.includes('sex') || question.includes('male') || question.includes('femelle')) {
            entities.sex = answer.trim()
          } else if (question.includes('age') || question.includes('√¢ge') || question.includes('jour') || question.includes('semaine')) {
            entities.age = answer.trim()
          } else if (question.includes('poids') || question.includes('weight')) {
            entities.weight = answer.trim()
          } else if (question.includes('temperature') || question.includes('temp√©rature')) {
            entities.temperature = answer.trim()
          } else if (question.includes('nombre') || question.includes('quantite') || question.includes('effectif')) {
            entities.quantity = answer.trim()
          } else {
            entities[`answer_${questionIndex}`] = answer.trim()
          }
        }
      } catch {
        // Ignorer les index invalides
      }
    }
  })
  
  console.log('[apiService] Entit√©s construites:', entities)
  return entities
}

export const handleEnhancedNetworkError = (error: any): string => {
  if (error?.message?.includes('Failed to fetch')) {
    return 'Probl√®me de connexion. V√©rifiez votre connexion internet.'
  }
  
  if (error?.message?.includes('Session expir√©e')) {
    return 'Votre session a expir√©. Veuillez vous reconnecter.'
  }
  
  if (error?.message?.includes('Acc√®s non autoris√©')) {
    return 'Vous n\'avez pas l\'autorisation d\'effectuer cette action.'
  }
  
  return error?.message || 'Une erreur inattendue s\'est produite.'
}

// Export par d√©faut
export default generateAIResponse