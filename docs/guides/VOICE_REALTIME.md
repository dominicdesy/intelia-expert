# Voice Realtime - Documentation Compl√®te

## üìã Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture](#architecture)
3. [Fonctionnalit√©s](#fonctionnalit√©s)
4. [Contr√¥le d'acc√®s](#contr√¥le-dacc√®s)
5. [D√©tection de langue et vitesse](#d√©tection-de-langue-et-vitesse)
6. [Composants](#composants)
7. [Configuration](#configuration)
8. [Utilisation](#utilisation)
9. [D√©pannage](#d√©pannage)
10. [Historique des corrections](#historique-des-corrections)

---

## Vue d'ensemble

**Voice Realtime** est une fonctionnalit√© de conversation vocale en temps r√©el utilisant l'API OpenAI Realtime. Elle permet aux utilisateurs de parler directement avec l'assistant IA et de recevoir des r√©ponses audio en temps r√©el.

### Caract√©ristiques principales

- üé§ **Conversation vocale bidirectionnelle** en temps r√©el
- üåç **Support multilingue** (10 langues avec TTS)
- ‚ö° **Acc√©l√©ration automatique** pour le chinois (15% plus rapide)
- üîä **Audio optimis√©** sans clics ni coupures
- üéØ **Acc√®s contr√¥l√©** (Super admins + plan Intelia)
- üì± **Compatible mobile** avec bouton flottant

---

## Architecture

### Stack technique

```
User (Browser)
    ‚Üì WebSocket
Frontend (React + Next.js)
    ‚Üì WebSocket (/api/v1/ws/voice)
Backend (FastAPI)
    ‚Üì WebSocket
OpenAI Realtime API
```

### Flux de donn√©es

1. **Audio Input**: Microphone ‚Üí PCM16 (24kHz) ‚Üí Base64 ‚Üí WebSocket ‚Üí Backend ‚Üí OpenAI
2. **Audio Output**: OpenAI ‚Üí Base64 ‚Üí WebSocket ‚Üí Backend ‚Üí Frontend ‚Üí Web Audio API
3. **Transcription**: OpenAI transcrit automatiquement (Whisper)
4. **Langue**: Frontend d√©tecte langue ‚Üí Backend ajuste vitesse OpenAI

---

## Fonctionnalit√©s

### 1. Conversation vocale

- **Capture audio**: AudioContext + ScriptProcessorNode
- **Format**: PCM16 mono 24kHz (format natif OpenAI)
- **Streaming**: Audio envoy√© en temps r√©el (pas d'attente)
- **VAD (Voice Activity Detection)**: D√©tection automatique de la parole

### 2. Optimisations audio

#### Pr√©vention des clics audio
- **Gain node avec fade in/out** (3ms)
- **Pre-buffering** (2 chunks avant de jouer)
- **Seamless scheduling** avec `nextPlayTimeRef`

```typescript
// Fade in (3ms)
gainNode.gain.setValueAtTime(0, startTime);
gainNode.gain.linearRampToValueAtTime(1, startTime + 0.003);

// Fade out (3ms)
gainNode.gain.setValueAtTime(1, endTime - 0.003);
gainNode.gain.linearRampToValueAtTime(0, endTime);
```

#### Pr√©vention des overlaps
- **Flag isPlayingRef**: Emp√™che lecture simultan√©e
- **Queue syst√®me**: `audioQueueRef` pour g√©rer les chunks

### 3. Support multilingue

#### Langues support√©es (avec TTS)
- üá´üá∑ Fran√ßais
- üá¨üáß Anglais
- üá™üá∏ Espagnol
- üáµüáπ Portugais
- üá©üá™ Allemand
- üáÆüáπ Italien
- üá≥üá± N√©erlandais
- üáØüáµ Japonais
- üá®üá≥ Chinois
- üá∞üá∑ Cor√©en

#### Langues support√©es (sans TTS)
- üáπüá≠ Tha√Ø (transcription uniquement)
- üáÆüá≥ Hindi (transcription uniquement)

---

## Contr√¥le d'acc√®s

### Qui peut acc√©der?

Voice Realtime est accessible √†:
1. **Super admins** (`is_admin = true`)
2. **Utilisateurs avec plan Intelia** (`plan_name = 'intelia'`)

### Plan Intelia

Le plan Intelia est un plan sp√©cial pour les employ√©s:
- ‚úÖ Gratuit
- ‚úÖ Quota illimit√© (999,999 questions)
- ‚úÖ Acc√®s Voice Realtime
- ‚úÖ Support prioritaire
- ‚ùå Non visible publiquement
- ‚ùå Non auto-assignable

### Attribution du plan Intelia

#### Via SQL (recommand√©)

```sql
-- Pour un nouvel utilisateur
INSERT INTO user_billing_info (user_email, plan_name)
VALUES ('email@example.com', 'intelia');

-- Pour un utilisateur existant
UPDATE user_billing_info
SET plan_name = 'intelia'
WHERE user_email = 'email@example.com';
```

#### V√©rifier l'acc√®s

```sql
-- Voir tous les utilisateurs avec plan Intelia
SELECT u.email, u.full_name, ubi.plan_name, u.is_admin
FROM users u
LEFT JOIN user_billing_info ubi ON u.email = ubi.user_email
WHERE ubi.plan_name = 'intelia' OR u.is_admin = true;
```

### Impl√©mentation du contr√¥le d'acc√®s

#### Frontend (`useVoiceRealtime.ts`)

```typescript
const isSuperAdmin = user?.is_admin === true;
const hasInteliaPlan = user?.plan === "intelia";
const canUseVoiceRealtime = isSuperAdmin || hasInteliaPlan;

// Le bouton n'est affich√© que si canUseVoiceRealtime = true
if (!canUseVoiceRealtime) {
  return null; // Pas de bouton
}
```

#### Backend (`/auth/me`)

Le plan est charg√© depuis `user_billing_info` dans **tous les chemins de code**:
1. Chemin principal (Supabase profile)
2. Fallback (JWT uniquement)
3. Exception fallback

```python
# R√©cup√©ration du plan dans tous les cas
user_plan = "essential"  # Default
try:
    with psycopg2.connect(os.getenv("DATABASE_URL")) as conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT plan_name
                FROM user_billing_info
                WHERE user_email = %s
            """, (current_user.get("email"),))

            billing_row = cur.fetchone()
            if billing_row:
                user_plan = billing_row["plan_name"]
except Exception as e:
    logger.warning(f"Erreur r√©cup√©ration plan: {e}")

return {
    # ...
    "plan": user_plan,
    # ...
}
```

---

## D√©tection de langue et vitesse

### Probl√®me initial

Le chinois parl√© est souvent per√ßu comme "trop lent" par les locuteurs natifs. Solution: acc√©l√©rer de 15%.

### Approche c√¥t√© client (‚ùå √âCHEC)

**Ce qui a √©t√© essay√©:**
```typescript
// ‚ùå NE FONCTIONNE PAS
source.playbackRate.value = 1.15;
source.start(scheduledTime); // Le onended ne se d√©clenche jamais!
```

**Probl√®me:**
- Combinaison de `playbackRate` + `start(scheduledTime)` casse le callback `onended`
- Les chunks audio ne s'encha√Ænent plus
- Silence complet apr√®s le premier chunk

### Solution c√¥t√© serveur (‚úÖ FONCTIONNE)

**Impl√©mentation:**

1. **Frontend d√©tecte la langue** (Unicode regex)
```typescript
function detectLanguage(text: string): string {
  if (/[\u4e00-\u9fff]/.test(text)) return "zh"; // Chinois
  if (/[\u3040-\u309f\u30a0-\u30ff]/.test(text)) return "ja"; // Japonais
  if (/[\uac00-\ud7af]/.test(text)) return "ko"; // Cor√©en
  return "en";
}
```

2. **Frontend envoie au backend**
```typescript
ws.send(JSON.stringify({
  type: "language.detected",
  language: "zh"
}));
```

3. **Backend reconfigure OpenAI**
```python
async def configure_openai_session(self, language: Optional[str] = None):
    speed = 1.15 if language == "zh" else 1.0

    config = {
        "type": "session.update",
        "session": {
            # ... autres configs ...
            "temperature": 0.8,
            "max_response_output_tokens": 4096
        }
    }

    # Ajouter speed seulement si diff√©rent de 1.0
    if speed != 1.0:
        config["session"]["speed"] = speed
        logger.info(f"‚ö° Adjusting playback speed to {speed}x for language: {language}")

    await self.openai_ws.send(json.dumps(config))
```

**Avantages:**
- ‚úÖ Le param√®tre `speed` est natif dans l'API OpenAI
- ‚úÖ Aucun probl√®me avec `onended`
- ‚úÖ Audio s'encha√Æne parfaitement
- ‚úÖ Configuration dynamique (change en temps r√©el)

### Flux complet

```
1. User parle en chinois
2. OpenAI transcrit ‚Üí "‰Ω†Â•Ω"
3. Frontend d√©tecte "zh"
4. Frontend envoie {"type": "language.detected", "language": "zh"}
5. Backend re√ßoit message
6. Backend appelle configure_openai_session(language="zh")
7. OpenAI configure session avec speed=1.15
8. Toutes les r√©ponses suivantes sont 15% plus rapides
```

---

## Composants

### Frontend

#### 1. `useVoiceRealtime.ts` (Hook principal)

**Responsabilit√©s:**
- Gestion WebSocket client ‚Üî backend
- Capture microphone (PCM16 24kHz)
- Playback audio avec Web Audio API
- D√©tection de langue
- Gestion √©tats (idle/connecting/listening/speaking/error)

**√âtats:**
```typescript
type VoiceRealtimeState = "idle" | "connecting" | "listening" | "speaking" | "error";
```

**API publique:**
```typescript
const {
  state,              // √âtat actuel
  isConnected,        // WebSocket connect√©?
  isListening,        // En √©coute?
  isSpeaking,         // En train de parler?
  error,              // Erreur actuelle
  audioLevel,         // Niveau microphone (0-100)
  canUseVoiceRealtime, // Acc√®s autoris√©?
  startConversation,  // D√©marrer
  stopConversation,   // Arr√™ter
  interrupt,          // Interrompre r√©ponse
} = useVoiceRealtime();
```

#### 2. `VoiceRealtimeButton.tsx` (UI)

**Caract√©ristiques:**
- Bouton flottant en bas √† droite
- Position fixe avec `z-index: 9999`
- Compatible notch iOS (`env(safe-area-inset-*)`)
- R√©sistant au zoom (`transform: translate3d(0,0,0)`)
- Animations (pulse pour listening, ping pour speaking)
- Indicateur volume audio
- Messages d'erreur contextuels

**√âtats visuels:**
- **Idle**: Gris, ic√¥ne MicOff
- **Connecting**: Jaune, spinner
- **Listening**: Vert avec pulse, ic√¥ne Mic
- **Speaking**: Bleu avec animation, ic√¥ne Volume2
- **Error**: Rouge, ic√¥ne AlertCircle

### Backend

#### 1. `voice_realtime.py` (WebSocket endpoint)

**Endpoint:** `/api/v1/ws/voice`

**Classes principales:**
- `RateLimiter`: Limite 5 sessions/heure/user
- `WeaviateRAGService`: Pr√©-chargement contexte RAG
- `VoiceRealtimeSession`: Gestion session utilisateur

**Flux:**
```python
async def run(self):
    """Session lifecycle"""
    1. connect_openai()              # Connexion OpenAI
    2. configure_openai_session()    # Config initiale
    3. asyncio.gather(
         forward_client_to_openai(),  # Client ‚Üí OpenAI
         forward_openai_to_client(),  # OpenAI ‚Üí Client
         monitor_session_timeout()    # Timeout 10 min
       )
    4. cleanup()                     # Fermeture propre
```

**Messages WebSocket:**

| Type | Direction | Description |
|------|-----------|-------------|
| `auth` | Client ‚Üí Backend | Authentification JWT |
| `audio.input` | Client ‚Üí Backend | Chunk audio microphone |
| `language.detected` | Client ‚Üí Backend | Langue d√©tect√©e |
| `interrupt` | Client ‚Üí Backend | Annuler r√©ponse en cours |
| `response.audio.delta` | Backend ‚Üí Client | Chunk audio r√©ponse |
| `session.timeout` | Backend ‚Üí Client | Session expir√©e |

#### 2. Configuration OpenAI

```python
config = {
    "type": "session.update",
    "session": {
        "modalities": ["text", "audio"],
        "instructions": "You are a poultry farming expert...",
        "voice": "alloy",
        "input_audio_format": "pcm16",
        "output_audio_format": "pcm16",
        "input_audio_transcription": {
            "model": "whisper-1"
        },
        "turn_detection": {
            "type": "server_vad",
            "threshold": 0.5,
            "prefix_padding_ms": 300,
            "silence_duration_ms": 500
        },
        "temperature": 0.8,
        "max_response_output_tokens": 4096,
        "speed": 1.15  # Optionnel, pour chinois
    }
}
```

---

## Configuration

### Variables d'environnement

#### Backend (`.env`)

```bash
# Feature flag
ENABLE_VOICE_REALTIME=true

# OpenAI
OPENAI_API_KEY=sk-...

# Database
DATABASE_URL=postgresql://...

# Optional: Weaviate RAG
WEAVIATE_URL=https://...
WEAVIATE_API_KEY=...
```

#### Frontend (`.env.local`)

```bash
NEXT_PUBLIC_API_URL=https://expert.intelia.com
```

### Limites de s√©curit√©

```python
# backend/app/api/v1/voice_realtime.py
MAX_SESSION_DURATION = 600  # 10 minutes max
MAX_SESSIONS_PER_USER_PER_HOUR = 5
RATE_LIMIT_WINDOW = 3600  # 1 heure
```

---

## Utilisation

### Pour les d√©veloppeurs

#### Tester localement

1. **Backend:**
```bash
cd backend
export ENABLE_VOICE_REALTIME=true
export OPENAI_API_KEY=sk-...
uvicorn app.main:app --reload
```

2. **Frontend:**
```bash
cd frontend
npm run dev
```

3. **Donner acc√®s Intelia √† votre compte test:**
```sql
UPDATE user_billing_info
SET plan_name = 'intelia'
WHERE user_email = 'votre.email@test.com';
```

4. **Ouvrir:** http://localhost:3000/chat
5. **Cliquer** sur le bouton microphone en bas √† droite

#### Debug

**Frontend (console navigateur):**
```
üîå [Voice Realtime] Connecting to WebSocket
‚úÖ WebSocket connected
üé§ Microphone started
üìù Transcription: "Bonjour"
üåç Detected language: fr
üîä Received audio chunk
```

**Backend (logs):**
```
üîå Connecting to OpenAI Realtime API
‚úÖ OpenAI connected in 234.56ms
‚öôÔ∏è OpenAI session configured
üåç Language detected: zh
‚ö° Adjusting playback speed to 1.15x for language: zh
```

### Pour les utilisateurs finaux

1. **Se connecter** avec compte ayant plan Intelia ou admin
2. **Autoriser microphone** (popup navigateur)
3. **Cliquer** sur bouton flottant en bas √† droite
4. **Parler** naturellement dans votre langue
5. **√âcouter** la r√©ponse audio
6. **Double-cliquer** pour interrompre si n√©cessaire

---

## D√©pannage

### Probl√®me: Bouton Voice Realtime invisible

**Sympt√¥me:** Utilisateur avec plan Intelia ne voit pas le bouton

**Causes possibles:**

1. **Plan non charg√© correctement**
   - V√©rifier `/auth/me` retourne `"plan": "intelia"`
   - Logs backend: `[/auth/me] ‚úÖ Main path - Returning for ... with plan=intelia`

2. **Cache navigateur**
   - D√©connexion/reconnexion
   - Vider cache (Ctrl+Shift+Del)
   - Mode incognito pour tester

3. **Backend non red√©marr√©**
   - Apr√®s modification de `auth.py`, red√©marrer backend

**Solution:**
```sql
-- V√©rifier le plan dans la DB
SELECT u.email, u.full_name, ubi.plan_name, u.is_admin
FROM users u
LEFT JOIN user_billing_info ubi ON u.email = ubi.user_email
WHERE u.email = 'utilisateur@email.com';

-- Si plan incorrect, corriger:
UPDATE user_billing_info
SET plan_name = 'intelia'
WHERE user_email = 'utilisateur@email.com';
```

### Probl√®me: Audio avec clics

**Sympt√¥me:** Sons de "clic" entre les chunks audio

**Solution:** D√©j√† impl√©ment√©e (gain node avec fades)

**Si le probl√®me persiste:**
- V√©rifier que `isBufferingRef` fonctionne (pre-buffer 2 chunks)
- V√©rifier logs: `üîä Buffering... waiting for more chunks`

### Probl√®me: Audio ne s'encha√Æne pas

**Sympt√¥me:** Silence apr√®s le premier chunk

**Causes:**
1. `onended` ne se d√©clenche pas
2. `isPlayingRef` bloqu√© √† `true`

**Debug:**
```typescript
source.onended = () => {
  console.log("üîä Audio chunk finished playing"); // Ce log appara√Æt?
  isPlayingRef.current = false;
  // ...
};
```

### Probl√®me: Acc√©l√©ration chinoise ne fonctionne pas

**Sympt√¥me:** Audio chinois √† vitesse normale

**Debug:**

1. **V√©rifier d√©tection langue (frontend):**
```
Console: üåç Detected language: zh
```

2. **V√©rifier envoi au backend:**
```
Console: Sent language.detected message
```

3. **V√©rifier backend logs:**
```
Backend: üåç Language detected: zh
Backend: ‚ö° Adjusting playback speed to 1.15x for language: zh
```

4. **Tester avec texte chinois simple:**
   - Parler: "‰Ω†Â•Ω" (n«ê h«éo)
   - V√©rifier que regex d√©tecte bien: `/[\u4e00-\u9fff]/.test("‰Ω†Â•Ω")` = true

### Probl√®me: Microphone non accessible

**Sympt√¥me:** Erreur "Microphone access denied"

**Solutions:**
1. **V√©rifier permissions navigateur** (ic√¥ne cadenas dans URL)
2. **HTTPS requis** (localhost OK en d√©veloppement)
3. **Navigateur compatible** (Chrome, Firefox, Safari modernes)

---

## Historique des corrections

### 1. Overlapping audio (Voices multiples)

**Date:** Session 1
**Probl√®me:** Plusieurs voix parlaient simultan√©ment
**Cause:** `playAudioQueue()` appel√© en parall√®le
**Solution:** Flag `isPlayingRef` pour emp√™cher appels concurrents

```typescript
const isPlayingRef = useRef(false);

const playAudioQueue = async () => {
  if (isPlayingRef.current) return;
  isPlayingRef.current = true;
  // ... play audio ...
  source.onended = () => {
    isPlayingRef.current = false;
    playAudioQueue(); // Next chunk
  };
};
```

### 2. Clics audio ("griche")

**Date:** Session 1
**Probl√®me:** Sons de clic entre chunks audio
**Cause:** Transitions abruptes entre chunks
**Solution:** Gain node avec fade in/out + pre-buffering

```typescript
// Fade in/out (3ms)
gainNode.gain.setValueAtTime(0, startTime);
gainNode.gain.linearRampToValueAtTime(1, startTime + 0.003);
gainNode.gain.setValueAtTime(1, endTime - 0.003);
gainNode.gain.linearRampToValueAtTime(0, endTime);

// Pre-buffering
if (isBufferingRef.current && audioQueueRef.current.length < 2) {
  return; // Attendre plus de chunks
}
```

### 3. Plan Intelia non accessible

**Date:** Session 1
**Probl√®me:** Utilisateurs avec plan "intelia" ne voyaient pas le bouton
**Cause:** `/auth/me` ne chargeait le plan que dans le chemin principal (pas les fallbacks)
**Solution:** Ajouter r√©cup√©ration du plan dans tous les chemins

```python
# Ajout√© dans fallback ET exception handler
user_plan = "essential"
try:
    with psycopg2.connect(os.getenv("DATABASE_URL")) as conn:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT plan_name FROM user_billing_info
                WHERE user_email = %s
            """, (current_user.get("email"),))
            billing_row = cur.fetchone()
            if billing_row:
                user_plan = billing_row["plan_name"]
except Exception as e:
    logger.warning(f"Erreur r√©cup√©ration plan: {e}")
```

### 4. Acc√©l√©ration chinoise cassait l'audio

**Date:** Session 2
**Probl√®me:** Apr√®s impl√©mentation `playbackRate=1.15`, silence total
**Cause:** `source.start(scheduledTime)` + `playbackRate` casse `onended`
**Solution:** D√©placer l'acc√©l√©ration c√¥t√© serveur (param√®tre `speed` OpenAI)

```python
# Backend - server-side speed adjustment
speed = 1.15 if language == "zh" else 1.0
config["session"]["speed"] = speed
```

### 5. Bouton dispara√Æt lors du zoom

**Date:** Session 2
**Probl√®me:** Bouton Voice Realtime dispara√Æt quand user zoom
**Cause:** Position `fixed` sans optimisation pour zoom
**Solution:** Styles inline avec `transform: translate3d`

```typescript
style={{
  position: 'fixed',
  bottom: 'max(1.5rem, env(safe-area-inset-bottom, 1.5rem))',
  right: 'max(1.5rem, env(safe-area-inset-right, 1.5rem))',
  zIndex: 9999,
  transform: 'translate3d(0, 0, 0)',
  willChange: 'transform',
}}
```

---

## Am√©liorations futures

### Court terme
- [ ] Ajouter indicateur de connexion r√©seau
- [ ] Timeout configurable par plan
- [ ] Statistiques d'utilisation par utilisateur
- [ ] Support d'autres voix OpenAI (alloy, echo, fable, onyx, nova, shimmer)

### Moyen terme
- [ ] Mode "push-to-talk" en option
- [ ] Historique des conversations vocales
- [ ] Export audio des conversations
- [ ] Support TTS pour Thai et Hindi (quand disponible chez OpenAI)

### Long terme
- [ ] Mode hors ligne (avec models locaux)
- [ ] Personnalisation de la voix
- [ ] Support vid√©o en temps r√©el
- [ ] Traduction simultan√©e

---

## Ressources

### Documentation officielle
- [OpenAI Realtime API](https://platform.openai.com/docs/guides/realtime)
- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [WebSocket API](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)

### Code source
- Frontend: `frontend/lib/hooks/useVoiceRealtime.ts`
- Frontend UI: `frontend/components/VoiceRealtimeButton.tsx`
- Backend: `backend/app/api/v1/voice_realtime.py`
- Auth: `backend/app/api/v1/auth.py` (endpoint `/auth/me`)

### Tests
- Plan Intelia: `backend/sql/stripe/29_add_intelia_plan.sql`
- Billing: `backend/app/api/v1/billing.py`

---

**Derni√®re mise √† jour:** 2025-10-22
**Version:** 1.0
**Statut:** ‚úÖ Production
