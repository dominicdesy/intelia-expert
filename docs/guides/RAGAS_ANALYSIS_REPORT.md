# RAPPORT D'ANALYSE RAGAS - Post Follow-up Fixes

**Date**: 2025-10-08
**Tests**: 15 cas
**Score Global**: 23.50% (vs 21.17% pr√©c√©dent, +11%)

---

## üìä R√âSULTATS GLOBAUX

| M√©trique | Avant | Apr√®s | √âvolution | Cible |
|----------|-------|-------|-----------|-------|
| **Context Precision** | 1.59% | 2.06% | +30% üìà | 70%+ |
| **Context Recall** | 5.56% | 1.11% | -80% üìâ | 70%+ |
| **Faithfulness** | 26.39% | 31.27% | +18.5% üìà | 70%+ |
| **Answer Relevancy** | 51.15% | 59.57% | +16.5% üìà | 70%+ |
| **Score Global** | 21.17% | 23.50% | +11% üìà | 70%+ |

### Statut: ‚ö†Ô∏è INSUFFISANT (< 30%)

---

## üîç ANALYSE D√âTAILL√âE PAR PROBL√àME

### 1. üö® CONTEXT RECALL CRITIQUE (-80%)

**Probl√®me identifi√©**: **12 tests sur 15 (80%) retournent 0 documents de contexte**

#### Causes par Cat√©gorie:

**A) Queries Out-of-Domain (1 test - CORRECT):**
```json
{
  "query": "Qu'est-ce que la cryptomonnaie ?",
  "contexts": [],
  "raison": "OOD detector rejette correctement"
}
```
‚úÖ **Comportement attendu** - Pas de probl√®me

**B) Queries Incompl√®tes n√©cessitant Clarification (6+ tests - PROBL√àME):**
```json
{
  "query": "Quel est le poids d'un Ross 308 m√¢le ?",
  "entites_extraites": {"breed": "Ross 308", "sex": "male"},
  "entites_manquantes": ["age_days"],
  "contexts": [],
  "raison": "Retourne clarification SANS chercher contexte"
}
```
‚ùå **Probl√®me**: Le syst√®me demande l'√¢ge sans faire de recherche partielle

**C) Recherche Vectorielle D√©faillante (5+ tests - PROBL√àME MAJEUR):**
```json
{
  "query": "Quels sont les sympt√¥mes de Newcastle ?",
  "contexts": [
    "Litter disposal...",
    "Feed Clean-up Trends...",
    "Minimum Ventilation Calculation...",
    "Drinkers configuration..."
  ],
  "raison": "12 documents r√©cup√©r√©s mais AUCUN ne parle de Newcastle!"
}
```
‚ùå **Probl√®me**: Embeddings/chunking de mauvaise qualit√©

---

### 2. üî¥ CONTEXT PRECISION CATASTROPHIQUE (2.06%)

**D√©finition**: % de documents r√©cup√©r√©s qui sont r√©ellement pertinents

**Exemple concret** - Test "Sympt√¥mes Newcastle":
- **R√©cup√©r√©**: 12 documents
- **Pertinents**: ~0 (tous parlent de liti√®re, ventilation, alimentation)
- **Precision**: 0/12 = 0%

#### Causes Racines:

1. **Embeddings inadapt√©s au domaine m√©dical avicole**
   - Mots techniques (Newcastle, coccidiose, Gumboro) mal vectoris√©s
   - Similarit√© cosinus trouve documents avec mots g√©n√©riques similaires

2. **Chunking inappropri√©**
   - Chunks trop longs ‚Üí dilution du sens
   - Chunks sans contexte m√©dical clair

3. **Absence de filtrage s√©mantique post-r√©cup√©ration**
   - Aucun re-ranking
   - Aucune validation de pertinence

---

### 3. üü° FAITHFULNESS INSUFFISANT (31.27%)

**D√©finition**: % de la r√©ponse qui est fid√®le au contexte fourni

**Exemple concret** - Test calcul moul√©e:
```
Contexte: "0.0 kg d'aliment par poulet"
R√©ponse: "vous aurez besoin de 0.0 kg d'aliment"
R√©f√©rence attendue: "2.16 kg"
```

‚ùå **Probl√®me**: Le syst√®me suit fid√®lement un contexte ERRON√â (bug calculation)

#### Causes:

1. **Prompt permissif** - Ne force pas assez "use ONLY context"
2. **Contexte de mauvaise qualit√©** (voir Context Precision)
3. **Temp√©rature LLM trop √©lev√©e** ‚Üí Hallucinations

---

### 4. ‚úÖ ANSWER RELEVANCY EN PROGR√àS (59.57%)

**D√©finition**: % de pertinence de la r√©ponse vs question

**R√©sultat**: Seule m√©trique au-dessus de 50%

#### Points positifs:
- Les r√©ponses sont bien formul√©es
- Le ton est appropri√©
- La structure est coh√©rente

#### Point d'am√©lioration:
- Encore 40% de marge pour atteindre 70%+

---

## üéØ PLAN D'ACTION CORRECTIF

### PRIORIT√â 1 (Impact Imm√©diat - Critical Path)

#### 1.1. Activer recherche "best effort" pour queries incompl√®tes

**Probl√®me**: "Quel poids Ross 308?" ‚Üí 0 contextes au lieu de chercher infos g√©n√©rales

**Solution**:
```python
# Dans query_router.py, m√©thode route()
if route.destination == "needs_clarification":
    # üÜï NOUVEAU: Faire quand m√™me une recherche partielle
    partial_query = self._build_partial_query(
        original_query=query,
        known_entities=route.entities,
        missing_entities=route.missing_fields
    )

    # Chercher avec ce qu'on a (ex: "Ross 308 poids performance")
    fallback_docs = await weaviate_search(partial_query, limit=5)

    # Retourner clarification AVEC contexte partiel
    return clarification_with_context(
        message=clarification_message,
        partial_context=fallback_docs,
        missing=route.missing_fields
    )
```

**Impact attendu**: Context Recall +40-50% (tests B ne seront plus √† 0)

---

#### 1.2. Impl√©menter Re-Ranking S√©mantique

**Probl√®me**: "Newcastle?" ‚Üí Documents sur liti√®re/ventilation

**Solution - Cross-Encoder Re-Ranking**:
```python
# Nouveau fichier: llm/retrieval/semantic_reranker.py
from sentence_transformers import CrossEncoder

class SemanticReRanker:
    def __init__(self, model_name='cross-encoder/ms-marco-MiniLM-L-6-v2'):
        self.model = CrossEncoder(model_name)

    def rerank(self, query: str, documents: List[str], top_k: int = 5) -> List[Tuple[str, float]]:
        """
        Re-rank documents using cross-encoder

        Returns: List of (doc, score) tuples, filtered by score > 0.3
        """
        # Cr√©er paires (query, doc)
        pairs = [(query, doc) for doc in documents]

        # Scorer avec cross-encoder (plus pr√©cis que cosine similarity)
        scores = self.model.predict(pairs)

        # Filtrer scores faibles + trier
        results = [
            (doc, score)
            for doc, score in zip(documents, scores)
            if score > 0.3  # Seuil de pertinence
        ]
        results.sort(key=lambda x: x[1], reverse=True)

        return results[:top_k]
```

**Int√©gration dans standard_handler.py**:
```python
# Apr√®s r√©cup√©ration Weaviate
raw_docs = await weaviate_client.search(query, limit=20)  # R√©cup√©rer plus

# Re-rank pour garder les meilleurs
reranker = SemanticReRanker()
filtered_docs = reranker.rerank(
    query=query,
    documents=[d.content for d in raw_docs],
    top_k=5
)

# Utiliser seulement les documents pertinents
context_docs = [doc for doc, score in filtered_docs]
```

**Impact attendu**: Context Precision: 2% ‚Üí 40-50%

---

#### 1.3. Renforcer Prompts de G√©n√©ration

**Probl√®me**: Faithfulness 31% ‚Üí LLM ne suit pas assez le contexte

**Solution - Prompt Strict**:
```python
# Dans system_prompts.json, modifier "answer_generation"
STRICT_PROMPT = """Tu es un expert en production avicole.

R√àGLES CRITIQUES - √Ä SUIVRE ABSOLUMENT:

1. ‚úÖ R√©ponds UNIQUEMENT en te basant sur le contexte fourni ci-dessous
2. ‚ùå NE JAMAIS inventer de chiffres, dates, ou faits
3. ‚ùå Si le contexte ne contient pas la r√©ponse, dis: "Je n'ai pas assez d'informations dans ma base de donn√©es"
4. ‚úÖ Cite des extraits du contexte pour justifier ta r√©ponse
5. ‚úÖ Si le contexte est incomplet, indique ce qui manque

CONTEXTE FOURNI:
{context}

QUESTION:
{question}

R√âPONSE (bas√©e UNIQUEMENT sur le contexte):"""
```

**Baisser temp√©rature**:
```python
# Dans generators.py
response = await openai_client.chat.completions.create(
    model="gpt-4o",
    temperature=0.3,  # ‚¨áÔ∏è Baiss√© de 0.7 ‚Üí Plus factuel, moins cr√©atif
    messages=[...]
)
```

**Impact attendu**: Faithfulness: 31% ‚Üí 60-70%

---

### PRIORIT√â 2 (Moyen Terme - Optimisations)

#### 2.1. Am√©liorer Embeddings

**Options**:
1. **Fine-tuning** sur corpus avicole
   - Collecter 5000+ paires (question, document_pertinent)
   - Fine-tune `intfloat/multilingual-e5-large`

2. **Utiliser mod√®le sp√©cialis√© sciences**:
   ```python
   # Remplacer embedding actuel
   from sentence_transformers import SentenceTransformer
   model = SentenceTransformer('allenai/specter')  # Sp√©cialis√© sciences
   ```

**Impact**: Context Precision +10-20%

---

#### 2.2. Hybrid Search (BM25 + Vector)

**Probl√®me**: Recherche purement vectorielle rate des mots-cl√©s exacts

**Solution**:
```python
# Combiner recherche lexicale (mots-cl√©s) + s√©mantique
from rank_bm25 import BM25Okapi

class HybridSearcher:
    def search(self, query, documents):
        # 1. BM25 (lexical)
        bm25_scores = bm25.get_scores(query.split())

        # 2. Vector (semantic)
        vector_scores = cosine_similarity(query_embed, doc_embeds)

        # 3. Combiner (0.3 BM25 + 0.7 Vector)
        hybrid_scores = 0.3 * bm25_scores + 0.7 * vector_scores

        return top_k_docs(hybrid_scores)
```

**Impact**: Context Recall +15-20%

---

## üìã SYNTH√àSE EX√âCUTIVE

### Probl√®mes Critiques:

1. **80% des tests sans contexte** ‚Üí Queries incompl√®tes + OOD + mauvaise recherche
2. **98% des documents non pertinents** ‚Üí Embeddings/chunking inadapt√©s
3. **69% de non-fid√©lit√© au contexte** ‚Üí Prompts permissifs + temp√©rature √©lev√©e

### Actions Imm√©diates (1-2 jours):

‚úÖ **Quick Wins** (Impact: +30-40% score global):
1. Recherche partielle pour queries incompl√®tes
2. Re-ranking s√©mantique post-r√©cup√©ration
3. Prompts stricts + temp√©rature ‚Üì

### Actions Moyen Terme (1-2 semaines):

üîß **Optimisations** (Impact: +20-30% score global):
4. Fine-tune embeddings domaine avicole
5. Hybrid search BM25+Vector
6. Am√©liorer chunking (contexte m√©dical)

### Objectif Final:

üéØ **Score Global: 70%+**
- Context Precision: 70%
- Context Recall: 70%
- Faithfulness: 75%
- Answer Relevancy: 80%

---

## üìÅ FICHIERS √Ä MODIFIER

### Priorit√© 1:
1. `llm/core/query_router.py` ‚Üí Recherche partielle
2. `llm/retrieval/semantic_reranker.py` ‚Üí **NOUVEAU FICHIER** re-ranker
3. `llm/core/handlers/standard_handler.py` ‚Üí Int√©grer re-ranker
4. `llm/config/system_prompts.json` ‚Üí Prompts stricts
5. `llm/generation/generators.py` ‚Üí Temp√©rature ‚Üì

### Priorit√© 2:
6. `llm/config/embedding_config.json` ‚Üí **NOUVEAU** config embeddings
7. `llm/retrieval/hybrid_search.py` ‚Üí **NOUVEAU** BM25+Vector

---

## üß™ VALIDATION

Apr√®s chaque correction:
```bash
cd /c/intelia_gpt/intelia-expert/llm
python scripts/run_ragas_evaluation.py \
  --test-cases 15 \
  --output logs/ragas_post_corrections_v2.json
```

**Cible par it√©ration**:
- It√©ration 1 (P1.1): Context Recall 1% ‚Üí 40%
- It√©ration 2 (P1.2): Context Precision 2% ‚Üí 50%
- It√©ration 3 (P1.3): Faithfulness 31% ‚Üí 65%
- Final: Score global 23% ‚Üí 70%+

---

**Rapport g√©n√©r√© le**: 2025-10-08 21:35 UTC
**Prochaine √©tape**: Impl√©menter P1.1 (recherche partielle)
