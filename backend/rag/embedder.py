"""
RAG Embedder Complet - Version Finale Robuste
Corrige tous les problÃ¨mes de recherche et ajoute debug dÃ©taillÃ©
"""

import os
import time
import logging
import pickle
import traceback
from typing import Optional, List, Dict, Any

logger = logging.getLogger(__name__)

# VÃ©rification des dÃ©pendances avec fallback gracieux
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
    logger.info("âœ… sentence-transformers available")
except ImportError as e:
    logger.warning(f"âš ï¸ sentence-transformers not available: {e}")
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    SentenceTransformer = None

try:
    import faiss
    FAISS_AVAILABLE = True
    logger.info("âœ… faiss available")
except ImportError as e:
    logger.warning(f"âš ï¸ faiss not available: {e}")
    FAISS_AVAILABLE = False
    faiss = None

try:
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("âœ… numpy available")
except ImportError as e:
    logger.warning(f"âš ï¸ numpy not available: {e}")
    NUMPY_AVAILABLE = False
    np = None

class FastRAGEmbedder:
    """Version finale robuste du RAG Embedder avec debug complet"""
    
    def __init__(self, api_key: Optional[str] = None, **kwargs):
        """
        Constructeur avec vÃ©rifications complÃ¨tes
        
        Args:
            api_key: ClÃ© API (pour compatibilitÃ©)
            **kwargs: Autres paramÃ¨tres
        """
        logger.info("ğŸš€ Initializing FastRAGEmbedder...")
        
        # Configuration avec variables d'environnement
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        
        # Configuration modÃ¨le avec auto-dÃ©tection
        model_name = os.getenv('RAG_EMBEDDING_MODEL', 'all-MiniLM-L6-v2')
        self.model_name = model_name
        
        # Auto-dÃ©tection dimension selon le modÃ¨le
        if 'text-embedding-3-small' in model_name:
            self.dimension = 1536
        elif 'text-embedding-ada-002' in model_name:
            self.dimension = 1536
        elif 'all-MiniLM-L6-v2' in model_name:
            self.dimension = 384
        elif 'all-mpnet-base-v2' in model_name:
            self.dimension = 768
        else:
            self.dimension = int(os.getenv('RAG_DIMENSION', '384'))
        
        self.cache_size = int(os.getenv('RAG_EMBEDDING_CACHE_SIZE', '1000'))
        
        # Lazy loading attributes
        self._sentence_model = None
        self._faiss_index = None
        self._documents = []
        self._embeddings_cache = {}
        
        # Configuration performance
        self.lazy_loading = os.getenv('RAG_LAZY_LOADING', 'true').lower() == 'true'
        self.cache_enabled = os.getenv('RAG_CACHE_EMBEDDINGS', 'true').lower() == 'true'
        self.debug_enabled = os.getenv('RAG_DEBUG_SEARCH', 'false').lower() == 'true'
        
        # VÃ©rification disponibilitÃ©
        self.dependencies_available = (
            SENTENCE_TRANSFORMERS_AVAILABLE and 
            FAISS_AVAILABLE and 
            NUMPY_AVAILABLE
        )
        
        logger.info("âœ… FastRAGEmbedder initialized with compatible signature")
        logger.info(f"   Model: {self.model_name}")
        logger.info(f"   Dimension: {self.dimension}")
        logger.info(f"   Dependencies available: {self.dependencies_available}")
        logger.info(f"   Lazy loading: {self.lazy_loading}")
        logger.info(f"   Cache enabled: {self.cache_enabled}")
        logger.info(f"   Debug enabled: {self.debug_enabled}")
        
        if not self.dependencies_available:
            logger.warning("âš ï¸ Some dependencies missing - limited functionality")
    
    @property
    def sentence_model(self):
        """Lazy loading du modÃ¨le sentence-transformers avec vÃ©rifications complÃ¨tes"""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            logger.error("âŒ sentence-transformers not available")
            return None
            
        if self._sentence_model is None:
            try:
                start_time = time.time()
                logger.info(f"ğŸ”„ Loading sentence model: {self.model_name}")
                
                self._sentence_model = SentenceTransformer(self.model_name)
                
                load_time = time.time() - start_time
                logger.info(f"âœ… Model loaded in {load_time:.2f}s")
                
                # VÃ©rification dimension avec test embedding
                try:
                    test_embedding = self._sentence_model.encode(["test"])
                    actual_dim = test_embedding.shape[1]
                    
                    if actual_dim != self.dimension:
                        logger.warning(f"âš ï¸ Dimension mismatch: expected {self.dimension}, got {actual_dim}")
                        logger.info("ğŸ”„ Auto-correcting dimension...")
                        self.dimension = actual_dim
                        logger.info(f"âœ… Dimension corrected to: {self.dimension}")
                        
                except Exception as dim_error:
                    logger.error(f"âŒ Error checking dimension: {dim_error}")
                    
            except Exception as e:
                logger.error(f"âŒ Error loading model: {e}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                return None
        
        return self._sentence_model
    
    @property
    def faiss_index(self):
        """Lazy loading de l'index FAISS avec vÃ©rifications"""
        if not FAISS_AVAILABLE:
            logger.error("âŒ faiss not available")
            return None
            
        if self._faiss_index is None:
            try:
                logger.info(f"ğŸ”„ Creating FAISS index (dimension: {self.dimension})")
                
                # Index simple pour performance
                self._faiss_index = faiss.IndexFlatL2(self.dimension)
                
                logger.info("âœ… FAISS index created")
                
            except Exception as e:
                logger.error(f"âŒ Error creating FAISS index: {e}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                return None
        
        return self._faiss_index
    
    def load_index(self, index_path: str) -> bool:
        """Charger un index FAISS existant avec vÃ©rifications complÃ¨tes"""
        if not self.dependencies_available:
            logger.error("âŒ Dependencies not available for index loading")
            return False
            
        try:
            faiss_file = os.path.join(index_path, 'index.faiss')
            pkl_file = os.path.join(index_path, 'index.pkl')
            
            if not os.path.exists(faiss_file) or not os.path.exists(pkl_file):
                logger.warning(f"âŒ Index files missing in {index_path}")
                return False
            
            # Charger l'index FAISS
            logger.info(f"ğŸ”„ Loading FAISS index from {faiss_file}")
            self._faiss_index = faiss.read_index(faiss_file)
            
            # VÃ©rifier et corriger dimension si nÃ©cessaire
            if self._faiss_index.d != self.dimension:
                logger.warning(f"âš ï¸ Index dimension {self._faiss_index.d} != expected {self.dimension}")
                logger.info("ğŸ”„ Auto-correcting dimension to match index...")
                self.dimension = self._faiss_index.d
                logger.info(f"âœ… Dimension corrected to: {self.dimension}")
            
            # Charger les documents
            logger.info(f"ğŸ”„ Loading documents from {pkl_file}")
            with open(pkl_file, 'rb') as f:
                self._documents = pickle.load(f)
            
            # VÃ©rifications post-chargement
            vectors_count = self._faiss_index.ntotal
            docs_count = len(self._documents)
            
            logger.info(f"âœ… Index loaded successfully:")
            logger.info(f"   ğŸ“Š {vectors_count} vectors")
            logger.info(f"   ğŸ“š {docs_count} documents")
            logger.info(f"   ğŸ”¢ Dimension: {self._faiss_index.d}")
            
            # VÃ©rifier cohÃ©rence
            if vectors_count == 0:
                logger.warning("âš ï¸ Index has 0 vectors!")
                return False
            
            if docs_count == 0:
                logger.warning("âš ï¸ No documents loaded!")
                return False
            
            # Test de recherche basique
            try:
                test_vector = np.random.random((1, self.dimension)).astype('float32')
                test_scores, test_indices = self._faiss_index.search(test_vector, 1)
                logger.info(f"âœ… Index search test passed: found {len(test_indices[0])} results")
            except Exception as test_error:
                logger.error(f"âŒ Index search test failed: {test_error}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error loading index from {index_path}: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return False
    
    def has_search_engine(self) -> bool:
        """VÃ©rifier si le moteur de recherche est disponible"""
        has_deps = self.dependencies_available
        has_index = self._faiss_index is not None
        has_vectors = has_index and self._faiss_index.ntotal > 0
        has_docs = len(self._documents) > 0
        
        if self.debug_enabled:
            logger.info(f"ğŸ” DEBUG: Search engine check:")
            logger.info(f"   Dependencies: {has_deps}")
            logger.info(f"   Index: {has_index}")
            logger.info(f"   Vectors: {has_vectors}")
            logger.info(f"   Documents: {has_docs}")
        
        return has_deps and has_index and has_vectors and has_docs
    
    @property
    def search_engine(self) -> bool:
        """PropriÃ©tÃ© pour compatibilitÃ© avec l'ancien code"""
        return self.has_search_engine()
    
    def embed_text(self, text: str):
        """Embedding avec gestion d'erreurs complÃ¨te"""
        if self.debug_enabled:
            logger.info(f"ğŸ” DEBUG: Embedding text: '{text[:50]}...'")
            
        if not NUMPY_AVAILABLE:
            logger.error("âŒ numpy not available for embedding")
            return None
            
        if not text.strip():
            logger.warning("âš ï¸ Empty text, returning zero vector")
            return np.zeros(self.dimension)
        
        model = self.sentence_model
        if model is None:
            logger.error("âŒ Sentence model not available")
            return None
            
        try:
            # Cache check si activÃ©
            if self.cache_enabled:
                text_hash = hash(text)
                if text_hash in self._embeddings_cache:
                    if self.debug_enabled:
                        logger.info("ğŸ” DEBUG: Using cached embedding")
                    return self._embeddings_cache[text_hash]
            
            # Generate embedding
            if self.debug_enabled:
                logger.info("ğŸ” DEBUG: Generating new embedding...")
                
            embedding = model.encode([text])[0]
            
            if self.debug_enabled:
                logger.info(f"ğŸ” DEBUG: Generated embedding shape: {embedding.shape}")
            
            # Cache result si activÃ©
            if self.cache_enabled and len(self._embeddings_cache) < self.cache_size:
                self._embeddings_cache[text_hash] = embedding
                if self.debug_enabled:
                    logger.info("ğŸ” DEBUG: Embedding cached")
            
            return embedding
            
        except Exception as e:
            logger.error(f"âŒ Error embedding text: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return None
    
    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """Recherche robuste avec debug complet"""
        if self.debug_enabled:
            logger.info(f"ğŸ” DEBUG: Starting search for query: '{query}' with k={k}")
        
        if not query.strip():
            if self.debug_enabled:
                logger.info("ğŸ” DEBUG: Empty query, returning empty results")
            return []
        
        if not self.has_search_engine():
            logger.warning("âŒ Search engine not available - no documents indexed")
            return []
        
        try:
            # Debug info about index
            if self.debug_enabled:
                logger.info(f"ğŸ” DEBUG: Index has {self._faiss_index.ntotal} vectors and {len(self._documents)} documents")
            
            # Embed query
            if self.debug_enabled:
                logger.info(f"ğŸ” DEBUG: Embedding query...")
                
            query_embedding = self.embed_text(query)
            if query_embedding is None:
                logger.error("âŒ Failed to embed query")
                return []
                
            if self.debug_enabled:
                logger.info(f"ğŸ” DEBUG: Query embedding shape: {query_embedding.shape}")
                
            # PrÃ©parer pour FAISS
            query_embedding = query_embedding.reshape(1, -1).astype('float32')
            
            if self.debug_enabled:
                logger.info(f"ğŸ” DEBUG: Reshaped query embedding: {query_embedding.shape}")
            
            # Search FAISS
            if self.debug_enabled:
                logger.info(f"ğŸ” DEBUG: Performing FAISS search...")
                
            scores, indices = self._faiss_index.search(query_embedding, k)
            
            # Debug FAISS results
            if self.debug_enabled:
                logger.info(f"ğŸ” DEBUG: FAISS returned {len(scores[0])} results")
                logger.info(f"ğŸ” DEBUG: Raw scores: {scores[0].tolist()}")
                logger.info(f"ğŸ” DEBUG: Raw indices: {indices[0].tolist()}")
            
            # Traiter les rÃ©sultats
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if self.debug_enabled:
                    logger.info(f"ğŸ” DEBUG: Processing result {i}: score={score}, idx={idx}")
                
                # VÃ©rifier validitÃ© de l'index
                if idx < 0:
                    if self.debug_enabled:
                        logger.warning(f"ğŸ” DEBUG: Skipping invalid index {idx} (negative)")
                    continue
                    
                if idx >= len(self._documents):
                    if self.debug_enabled:
                        logger.warning(f"ğŸ” DEBUG: Skipping invalid index {idx} (>= {len(self._documents)})")
                    continue
                
                # RÃ©cupÃ©rer le document
                try:
                    doc_text = self._documents[idx]
                    
                    if self.debug_enabled:
                        logger.info(f"ğŸ” DEBUG: Valid result {i}: idx={idx}, score={score}")
                        logger.info(f"ğŸ” DEBUG: Document preview: '{doc_text[:100]}...'")
                    
                    results.append({
                        'text': doc_text,
                        'score': float(score),
                        'rank': i + 1,
                        'index': int(idx)
                    })
                    
                except Exception as doc_error:
                    logger.error(f"âŒ Error accessing document {idx}: {doc_error}")
                    continue
            
            # Log rÃ©sultats finaux
            if self.debug_enabled:
                logger.info(f"ğŸ” DEBUG: Final results count: {len(results)}")
                for i, result in enumerate(results[:3]):  # Log premiers rÃ©sultats
                    logger.info(f"ğŸ” DEBUG: Result {i}: score={result['score']:.4f}, text='{result['text'][:80]}...'")
            
            if len(results) == 0:
                logger.warning("âš ï¸ No valid results found after filtering")
            else:
                logger.info(f"âœ… Found {len(results)} valid results")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ Error during search: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return []
    
    def get_stats(self) -> Dict[str, Any]:
        """Statistiques complÃ¨tes du systÃ¨me"""
        return {
            'model_name': self.model_name,
            'dimension': self.dimension,
            'documents_count': len(self._documents),
            'cache_size': len(self._embeddings_cache),
            'index_size': self._faiss_index.ntotal if self._faiss_index else 0,
            'model_loaded': self._sentence_model is not None,
            'index_created': self._faiss_index is not None,
            'search_engine_available': self.has_search_engine(),
            'dependencies_available': self.dependencies_available,
            'sentence_transformers': SENTENCE_TRANSFORMERS_AVAILABLE,
            'faiss': FAISS_AVAILABLE,
            'numpy': NUMPY_AVAILABLE,
            'lazy_loading': self.lazy_loading,
            'cache_enabled': self.cache_enabled,
            'debug_enabled': self.debug_enabled
        }

# Alias pour compatibilitÃ©
class EnhancedDocumentEmbedder(FastRAGEmbedder):
    """Wrapper pour compatibilitÃ© avec l'ancien nom"""
    pass

class RAGEmbedder(FastRAGEmbedder):
    """Wrapper pour compatibilitÃ© avec RAGEmbedder"""
    pass

# Instance globale
_global_embedder: Optional[FastRAGEmbedder] = None

def get_embedder() -> FastRAGEmbedder:
    """Singleton pattern pour l'embedder"""
    global _global_embedder
    if _global_embedder is None:
        _global_embedder = FastRAGEmbedder()
    return _global_embedder