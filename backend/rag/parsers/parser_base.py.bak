"""Base classes for document parsers - Enhanced Version."""

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import logging
import re

# Enhanced imports for metadata enrichment
try:
    from .metadata_enrichment import MetadataEnricher, extract_hierarchical_metadata
except ImportError:
    # Fallback if metadata_enrichment not available
    def extract_hierarchical_metadata(file_path: str) -> Dict[str, str]:
        return {}
    
    class MetadataEnricher:
        @staticmethod
        def enrich_metadata(text: str, existing_metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
            return existing_metadata or {}

logger = logging.getLogger(__name__)


@dataclass
class ParserCapability:
    """Parser capability definition."""
    name: str
    supported_extensions: List[str]
    breed_types: List[str]
    data_types: List[str]
    quality_score: str
    description: str
    priority: int


@dataclass
class Document:
    """Document representation with metadata."""
    page_content: str
    metadata: Dict[str, Any]
    
    def __init__(self, page_content: str, metadata: Optional[Dict[str, Any]] = None):
        self.page_content = page_content
        self.metadata = metadata or {}


class BaseParser(ABC):
    """Base parser interface for all document parsers - Enhanced Version."""
    
    @property
    @abstractmethod
    def capability(self) -> ParserCapability:
        """Get parser capability information."""
        pass
    
    @abstractmethod
    def can_parse(self, file_path: str, content_sample: Optional[str] = None) -> float:
        """
        Check if parser can handle the given file.
        
        Args:
            file_path: Path to the file
            content_sample: Optional content sample for content-based detection
            
        Returns:
            Confidence score between 0.0 and 1.0
        """
        pass
    
    @abstractmethod
    def parse(self, file_path: str) -> List[Document]:
        """
        Parse file into list of documents.
        
        Args:
            file_path: Path to the file to parse
            
        Returns:
            List of Document objects
        """
        pass
    
    def create_base_metadata(self, file_path: str, additional_metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Create enhanced base metadata for document.
        
        Args:
            file_path: Path to the source file
            additional_metadata: Additional metadata to include
            
        Returns:
            Dictionary containing enriched metadata
        """
        path = Path(file_path)
        
        # Extract hierarchical metadata from file path
        hierarchical_metadata = extract_hierarchical_metadata(file_path)
        
        # Create base metadata
        base_metadata = {
            'source_file': str(path),
            'file_name': path.name,
            'file_stem': path.stem,
            'file_extension': path.suffix,
            'file_size': path.stat().st_size if path.exists() else 0,
            'parser_name': self.capability.name,
            'parser_priority': self.capability.priority,
            
            # Add hierarchical structure
            **hierarchical_metadata
        }
        
        # Add additional metadata if provided
        if additional_metadata:
            base_metadata.update(additional_metadata)
        
        return base_metadata
    
    def enrich_with_content_metadata(self, text: str, base_metadata: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enrich metadata with content-based analysis.
        
        Args:
            text: Document text content
            base_metadata: Existing metadata to enhance
            
        Returns:
            Enhanced metadata with content analysis
        """
        try:
            # Use MetadataEnricher to extract thematic tags
            enriched_metadata = MetadataEnricher.enrich_metadata(text, base_metadata)
            return enriched_metadata
        except Exception as e:
            logger.warning(f"Error enriching metadata: {e}")
            return base_metadata
    
    def split_by_section_headers(self, text: str, min_section_length: int = 100) -> List[Dict[str, str]]:
        """
        Split document by section headers for better chunking.
        
        Args:
            text: Document text to split
            min_section_length: Minimum length for a section to be valid
            
        Returns:
            List of sections with title and content
        """
        sections = []
        lines = text.split('\n')
        current_section = {'title': 'Introduction', 'content': ''}
        
        for line in lines:
            line_stripped = line.strip()
            if not line_stripped:
                current_section['content'] += '\n'
                continue
            
            # Check if line is a section header
            if self._is_section_header(line_stripped):
                # Save current section if it has enough content
                if len(current_section['content'].strip()) >= min_section_length:
                    sections.append(current_section)
                
                # Start new section
                current_section = {
                    'title': line_stripped,
                    'content': ''
                }
            else:
                current_section['content'] += line + '\n'
        
        # Add the last section
        if len(current_section['content'].strip()) >= min_section_length:
            sections.append(current_section)
        
        return sections
    
    def _is_section_header(self, line: str) -> bool:
        """
        Determine if a line is likely a section header.
        
        Args:
            line: Text line to analyze
            
        Returns:
            True if line appears to be a section header
        """
        line = line.strip()
        
        # Empty lines are not headers
        if not line:
            return False
        
        # Check for common header patterns
        header_patterns = [
            # All caps headers
            r'^[A-Z][A-Z\s\-\(\)]+$',
            
            # Title case headers (limited words)
            r'^[A-Z][a-z]+(\s+[A-Z][a-z]+){0,4}:?$',
            
            # Numbered sections
            r'^\d+\.?\s+[A-Z][a-z\s]+$',
            
            # Common poultry section headers
            r'^(Rearing|Production|Laying|Management|Nutrition|Health|Performance|Housing|Lighting|Water|Feed).*',
            
            # Headers ending with periods or colons
            r'^[A-Z][A-Za-z\s]+[:\.]$'
        ]
        
        # Check patterns
        for pattern in header_patterns:
            if re.match(pattern, line):
                return True
        
        # Additional heuristics
        word_count = len(line.split())
        
        # Very short lines with title case might be headers
        if word_count <= 5 and line[0].isupper() and not line.endswith('.'):
            # But exclude lines that are clearly not headers
            if not any(char.isdigit() for char in line[:10]):  # No numbers at start
                return True
        
        return False
    
    def create_enhanced_document(self, content: str, file_path: str, 
                               section_title: Optional[str] = None,
                               additional_metadata: Optional[Dict[str, Any]] = None) -> Document:
        """
        Create a Document with enhanced metadata including content analysis.
        
        Args:
            content: Document text content
            file_path: Source file path
            section_title: Optional section title
            additional_metadata: Additional metadata to include
            
        Returns:
            Document with enriched metadata
        """
        # Create base metadata with hierarchical info
        base_metadata = self.create_base_metadata(file_path, additional_metadata)
        
        # Add section information if provided
        if section_title:
            base_metadata['section_title'] = section_title
            base_metadata['is_section'] = True
        
        # Enrich with content-based metadata
        enriched_metadata = self.enrich_with_content_metadata(content, base_metadata)
        
        # Create and return document
        return Document(
            page_content=content,
            metadata=enriched_metadata
        )
    
    def get_supported_extensions(self) -> List[str]:
        """Get list of supported file extensions."""
        return self.capability.supported_extensions
    
    def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 100) -> List[str]:
        """
        Chunk text into smaller pieces with overlap.
        
        Args:
            text: Text to chunk
            chunk_size: Maximum size of each chunk
            overlap: Number of characters to overlap between chunks
            
        Returns:
            List of text chunks
        """
        if not text:
            return []
        
        chunks = []
        start = 0
        text_length = len(text)
        
        while start < text_length:
            end = start + chunk_size
            
            # Find a good breaking point (end of sentence, paragraph, etc.)
            if end < text_length:
                # Look for sentence end
                for sep in ['. ', '.\n', '\n\n', '\n', ' ']:
                    pos = text.rfind(sep, start + overlap, end)
                    if pos > start:
                        end = pos + len(sep) - 1
                        break
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            # Move start position
            start = end - overlap if end < text_length else text_length
            
            # Prevent infinite loop
            if start <= 0 and chunks:
                break
        
        return chunks
    
    def chunk_text_by_sections(self, text: str, max_chunk_size: int = 1500) -> List[Dict[str, Any]]:
        """
        Chunk text by sections with enhanced metadata.
        
        Args:
            text: Text to chunk
            max_chunk_size: Maximum size for each chunk
            
        Returns:
            List of dictionaries with content and section metadata
        """
        # First, split by sections
        sections = self.split_by_section_headers(text)
        
        chunks = []
        
        for section in sections:
            section_content = section['content'].strip()
            section_title = section['title']
            
            # If section is small enough, use as-is
            if len(section_content) <= max_chunk_size:
                chunks.append({
                    'content': section_content,
                    'section_title': section_title,
                    'is_complete_section': True,
                    'chunk_index': 0,
                    'total_chunks': 1
                })
            else:
                # Split large sections into smaller chunks
                text_chunks = self.chunk_text(section_content, max_chunk_size, 100)
                
                for i, chunk_content in enumerate(text_chunks):
                    chunks.append({
                        'content': chunk_content,
                        'section_title': section_title,
                        'is_complete_section': False,
                        'chunk_index': i,
                        'total_chunks': len(text_chunks)
                    })
        
        return chunks
    
    def create_documents_from_sections(self, file_path: str, sections_or_chunks: List[Dict[str, Any]]) -> List[Document]:
        """
        Create Document objects from sections or chunks with enhanced metadata.
        
        Args:
            file_path: Source file path
            sections_or_chunks: List of sections/chunks with metadata
            
        Returns:
            List of Document objects with enriched metadata
        """
        documents = []
        
        for i, section_data in enumerate(sections_or_chunks):
            content = section_data['content']
            
            if not content.strip():
                continue
            
            # Build additional metadata
            additional_metadata = {
                'section_index': i,
                'total_sections': len(sections_or_chunks)
            }
            
            # Add section-specific metadata
            for key in ['section_title', 'is_complete_section', 'chunk_index', 'total_chunks']:
                if key in section_data:
                    additional_metadata[key] = section_data[key]
            
            # Create enhanced document
            doc = self.create_enhanced_document(
                content=content,
                file_path=file_path,
                section_title=section_data.get('section_title'),
                additional_metadata=additional_metadata
            )
            
            documents.append(doc)
        
        return documents
    
    def __repr__(self) -> str:
        """String representation of parser."""
        return f"{self.__class__.__name__}(name='{self.capability.name}', extensions={self.capability.supported_extensions})"