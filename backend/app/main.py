# app/main.py - VERSION 4.0 AVEC SYST√àME DE CACHE STATISTIQUES INT√âGR√â
# ‚úÖ CONSERVATION INT√âGRALE DU CODE ORIGINAL + AJOUTS CACHE SAFE
# üöÄ NOUVEAU: Syst√®me de cache statistiques automatique
# üîß CORRECTION CORS POUR CREDENTIALS: 'INCLUDE' - VERSION FINALE CONSERV√âE
# üéØ FIX: Ajout du router stats_admin manquant + lifespan corrig√©

# tout en haut du fichier
import os
from pathlib import Path

def _rag_index_dir(name: str) -> str:
    """
    R√©sout le chemin de l'index RAG pour un espace donn√©.
    Priorit√©:
      1) ENV RAG_INDEX_DIR_<NAME> (ex: RAG_INDEX_DIR_GLOBAL)
      2) d√©faut /workspace/backend/rag_index/<name>
    """
    return os.getenv(f"RAG_INDEX_DIR_{name.upper()}", f"/workspace/backend/rag_index/{name}")

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List

from fastapi import FastAPI, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

# === LOGGING GLOBAL ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("app.main")

# === CONFIG CORS ===
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "https://expert.intelia.com,https://app.intelia.com,http://localhost:3000").split(",")

app = FastAPI(
    title="Intelia Expert API",
    version="4.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# === MIDDLEWARE CORS (conserv√©) ===
app.add_middleware(
    CORSMiddleware,
    allow_origins=[o.strip() for o in ALLOWED_ORIGINS if o.strip()],
    allow_credentials=True,      # üîß Important pour cookies/sessions
    allow_methods=["*"],
    allow_headers=["*"],
)

# === ROUTERS IMPORTS (inchang√©s) ===
try:
    from app.api.v1.auth import router as auth_router
    app.include_router(auth_router, prefix="/v1/auth", tags=["auth"])
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Router auth indisponible: {e}")

try:
    from app.api.v1.expert import router as expert_router
    app.include_router(expert_router, prefix="/v1/expert", tags=["expert"])
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Router expert indisponible: {e}")

try:
    from app.api.v1.stats import router as stats_router
    app.include_router(stats_router, prefix="/v1/stats", tags=["stats"])
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Router stats indisponible: {e}")

# Ajout du router d'admin statistiques si pr√©sent (conserv√©)
try:
    from app.api.v1.stats_admin import router as stats_admin_router
    app.include_router(stats_admin_router, prefix="/v1/stats-admin", tags=["stats-admin"])
except Exception as e:
    logger.info(f"‚ÑπÔ∏è Router stats-admin non charg√©: {e}")

# === D√âTECTION DU SYST√àME DE CACHE STATISTIQUES (conserv√©) ===
STATS_CACHE_AVAILABLE = False
try:
    from app.api.v1.stats_cache import get_stats_cache
    STATS_CACHE_AVAILABLE = True
except Exception as e:
    logger.info(f"‚ÑπÔ∏è Module cache statistiques indisponible: {e}")

# === OUTILS SUPPL√âMENTAIRES (inchang√©s) ===
def get_rag_paths() -> Dict[str, str]:
    """Conserve l'impl√©mentation originale pour ne rien casser ailleurs."""
    base_path = "/workspace/backend/rag_index"
    return {
        "global": f"{base_path}/global",
        "broiler": f"{base_path}/broiler",
        "layer": f"{base_path}/layer",
    }

# === T√ÇCHES P√âRIODIQUES (inchang√©es) ===
async def periodic_monitoring():
    while True:
        try:
            logger.debug("ü©∫ Healthcheck p√©riodique OK")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Monitoring error: {e}")
        await asyncio.sleep(60)

async def periodic_stats_update():
    while True:
        try:
            cache = get_stats_cache()
            cache.refresh_all()
            logger.info("‚ôªÔ∏è Cache statistiques r√©g√©n√©r√©")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è √âchec r√©g√©n√©ration cache stats: {e}")
        await asyncio.sleep(3600)

# === LIFESPAN CORRIG√â ===
from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ========== INITIALISATION AU D√âMARRAGE ==========
    logger.info("üöÄ D√©marrage de l'application Expert API avec syst√®me complet + cache statistiques")

    # ========== INITIALISATION DES SERVICES AM√âLIOR√âE (CONSERV√âE) ==========
    try:
        logger.info("üìä Initialisation des services analytics et facturation...")
        database_url = os.getenv("DATABASE_URL")
        if database_url:
            logger.info("‚úÖ DATABASE_URL configur√©e")

            # Analytics
            try:
                from app.api.v1.logging import get_analytics
                analytics_status = get_analytics()
                logger.info(f"‚úÖ Service analytics: {analytics_status.get('status', 'unknown')}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Service analytics partiellement disponible: {e}")

            # Billing
            try:
                from app.api.v1.billing import get_billing_manager
                billing = get_billing_manager()
                logger.info(f"‚úÖ Service billing: {len(billing.plans)} plans charg√©s")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Service billing partiellement disponible: {e}")

            # Cache statistiques (optionnel)
            try:
                if STATS_CACHE_AVAILABLE:
                    cache = get_stats_cache()
                    cache_stats = cache.get_cache_stats()
                    logger.info(f"‚úÖ Cache statistiques initialis√©: {cache_stats}")
                else:
                    logger.info("‚ÑπÔ∏è Cache statistiques non initialis√© (module absent)")
            except Exception as e:
                logger.info(f"‚ÑπÔ∏è Cache statistiques non initialis√©: {e}")

            # Nettoyage sessions
            try:
                from app.api.v1.pipeline.postgres_memory import PostgresMemory
                memory = PostgresMemory()
                cleaned = memory.cleanup_old_sessions(days_old=7)
                if cleaned > 0:
                    logger.info(f"üßπ {cleaned} anciennes sessions nettoy√©es")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Nettoyage sessions √©chou√©: {e}")
        else:
            logger.warning("‚ö†Ô∏è DATABASE_URL manquante - services analytics d√©sactiv√©s")
    except Exception as e:
        logger.error(f"‚åõ Erreur initialisation services: {e}")
        # ne pas bloquer le d√©marrage

    # ========== SUPABASE ==========
    app.state.supabase = None
    try:
        from supabase import create_client
        url, key = os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_ANON_KEY")
        if url and key:
            app.state.supabase = create_client(url, key)
            logger.info("‚úÖ Supabase pr√™t")
        else:
            logger.info("‚ÑπÔ∏è Supabase non configur√©")
    except Exception as e:
        logger.warning("‚ÑπÔ∏è Supabase indisponible: %s", e)

    # üöÄ CHARGEMENT DES 3 RAG (CONSERV√â INT√âGRALEMENT, AVEC FIX)
    app.state.rag = None
    app.state.rag_broiler = None
    app.state.rag_layer = None

    try:
        from rag.embedder import FastRAGEmbedder

        rag_paths = get_rag_paths()
        logger.info(f"üîç Chargement des 3 RAG: {list(rag_paths.keys())}")

        # Variables d'environnement (override si d√©finies)
        env_override = {
            "global": os.getenv("RAG_INDEX_GLOBAL"),
            "broiler": os.getenv("RAG_INDEX_BROILER"),
            "layer": os.getenv("RAG_INDEX_LAYER"),
        }
        for key, env_path in env_override.items():
            if env_path and os.path.exists(env_path):
                rag_paths[key] = env_path
                logger.info(f"üîß Override ENV pour {key}: {env_path}")

        def _log_loaded(name: str, path: str, emb) -> None:
            try:
                stats = emb.get_index_stats() if hasattr(emb, "get_index_stats") else {}
                n_docs = stats.get("n_docs")
                faiss_total = stats.get("faiss_total")
                chunks_loaded = stats.get("chunks_loaded", faiss_total)
                dim = stats.get("embedding_dim", "unknown")
                model = stats.get("model_name", "unknown")
                logger.info(
                    f"‚úÖ RAG {name.capitalize()} charg√©: {path} "
                    f"(docs={n_docs if n_docs is not None else 'unknown'}, "
                    f"chunks={chunks_loaded if chunks_loaded is not None else 'unknown'}, "
                    f"dim={dim}, model={model})"
                )
            except Exception:
                logger.info(f"‚úÖ RAG {name.capitalize()} charg√©: {path}")

        # üöÄ GLOBAL
        global_path = rag_paths["global"]
        logger.info(f"üîç Chargement RAG Global: {global_path}")
        if os.path.exists(global_path):
            global_embedder = FastRAGEmbedder(index_dir=global_path, debug=True, cache_embeddings=True, max_workers=2)
            if hasattr(global_embedder, "has_search_engine") and global_embedder.has_search_engine():
                app.state.rag = global_embedder
                _log_loaded("global", global_path, global_embedder)
            else:
                logger.error(f"‚åõ RAG Global: √âchec chargement depuis {global_path}")
        else:
            logger.error(f"‚åõ RAG Global: Chemin inexistant {global_path}")

        # üöÄ BROILER
        broiler_path = rag_paths["broiler"]
        logger.info(f"üîç Chargement RAG Broiler: {broiler_path}")
        if os.path.exists(broiler_path):
            try:
                broiler_embedder = FastRAGEmbedder(index_dir=broiler_path, debug=False, cache_embeddings=True, max_workers=2)
                if hasattr(broiler_embedder, "has_search_engine") and broiler_embedder.has_search_engine():
                    app.state.rag_broiler = broiler_embedder
                    _log_loaded("broiler", broiler_path, broiler_embedder)
                else:
                    logger.warning(f"‚ö†Ô∏è RAG Broiler: √âchec chargement depuis {broiler_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è RAG Broiler: Erreur {e}")
        else:
            logger.warning(f"‚ö†Ô∏è RAG Broiler: Chemin inexistant {broiler_path}")

        # üöÄ LAYER
        layer_path = rag_paths["layer"]
        logger.info(f"üîç Chargement RAG Layer: {layer_path}")
        if os.path.exists(layer_path):
            try:
                layer_embedder = FastRAGEmbedder(index_dir=layer_path, debug=False, cache_embeddings=True, max_workers=2)
                if hasattr(layer_embedder, "has_search_engine") and layer_embedder.has_search_engine():
                    app.state.rag_layer = layer_embedder
                    _log_loaded("layer", layer_path, layer_embedder)
                else:
                    logger.warning(f"‚ö†Ô∏è RAG Layer: √âchec chargement depuis {layer_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è RAG Layer: Erreur {e}")
        else:
            logger.warning(f"‚ö†Ô∏è RAG Layer: Chemin inexistant {layer_path}")

        # üìä R√©sum√© final des 3 RAG
        total_rags = sum(1 for rag in [app.state.rag, app.state.rag_broiler, app.state.rag_layer] if rag)

        rag_summary = {
            "global": "‚úÖ Actif" if app.state.rag else "‚åõ CRITIQUE",
            "broiler": "‚úÖ Actif" if app.state.rag_broiler else "‚åõ Absent",
            "layer": "‚úÖ Actif" if app.state.rag_layer else "‚åõ Absent",
            "total_loaded": total_rags
        }
        logger.info(f"üìä Status final des RAG: {rag_summary}")

        if total_rags == 3:
            logger.info("üéâ PARFAIT: Les 3 RAG sont charg√©s (Global + Broiler + Layer)")
        elif total_rags == 1:
            logger.warning("‚ö†Ô∏è Seulement 1 RAG charg√© - potentiel g√¢ch√©")
        else:
            logger.warning(f"‚ö†Ô∏è Seulement {total_rags}/3 RAG charg√©s")

    except Exception as e:
        logger.error("‚åõ Erreur critique initialisation RAG: %s", e)

    # ========== D√âMARRAGE DU MONITORING & SCHEDULER (inchang√©) ==========
    monitoring_task = None
    stats_scheduler_task = None
    
    try:
        monitoring_task = asyncio.create_task(periodic_monitoring())
        logger.info("üìä Monitoring p√©riodique d√©marr√©")
    except Exception as e:
        logger.error(f"‚åõ Erreur d√©marrage monitoring: {e}")

    if STATS_CACHE_AVAILABLE:
        try:
            stats_scheduler_task = asyncio.create_task(periodic_stats_update())
            logger.info("üîÑ Scheduler cache statistiques d√©marr√© (mise √† jour toutes les heures)")
        except Exception as e:
            logger.error(f"‚åõ Erreur d√©marrage scheduler cache: {e}")
    else:
        logger.info("‚ÑπÔ∏è Scheduler cache statistiques d√©sactiv√© (module non disponible)")

    # ========== L'APPLICATION D√âMARRE ==========
    system_features = []
    if STATS_CACHE_AVAILABLE:
        system_features.append("cache statistiques optimis√©")
    system_features.extend(["3 RAG", "monitoring", "analytics", "billing"])
    logger.info(f"üéØ Application Expert API pr√™te avec: {', '.join(system_features)}")
    yield  # --- L'APPLICATION FONCTIONNE ---

    # ========== NETTOYAGE ==========
    logger.info("üõë Arr√™t de l'application Expert API")
    if monitoring_task:
        try:
            monitoring_task.cancel()
            logger.info("üìä Monitoring p√©riodique arr√™t√©")
        except Exception as e:
            logger.error(f"‚åõ Erreur arr√™t monitoring: {e}")
    if stats_scheduler_task:
        try:
            stats_scheduler_task.cancel()
            logger.info("üîÑ Scheduler cache statistiques arr√™t√©")
        except Exception as e:
            logger.error(f"‚åõ Erreur arr√™t scheduler cache: {e}")

# === REGISTRATION DU LIFESPAN ===
app.router.lifespan_context = lifespan

# === ENDPOINT DE DEBUG RAG (conserv√©) ===
@app.get("/rag/debug")
def rag_debug():
    try:
        env_vars = {
            # nouveaux noms conseill√©s (d√©j√† support√©s par _rag_index_dir si tu les utilises)
            "RAG_INDEX_DIR_GLOBAL": os.getenv("RAG_INDEX_DIR_GLOBAL"),
            "RAG_INDEX_DIR_BROILER": os.getenv("RAG_INDEX_DIR_BROILER"),
            "RAG_INDEX_DIR_LAYER": os.getenv("RAG_INDEX_DIR_LAYER"),
            # compat h√©rit√©e
            "RAG_INDEX_GLOBAL": os.getenv("RAG_INDEX_GLOBAL"),
            "RAG_INDEX_BROILER": os.getenv("RAG_INDEX_BROILER"),
            "RAG_INDEX_LAYER": os.getenv("RAG_INDEX_LAYER"),
        }
        rag_status = {
            "global": bool(getattr(app.state, "rag", None)),
            "broiler": bool(getattr(app.state, "rag_broiler", None)),
            "layer": bool(getattr(app.state, "rag_layer", None)),
        }
        return {"env": env_vars, "status": rag_status}
    except Exception as e:
        return {"error": str(e)}

# === HEALTHCHECK (conserv√©) ===
@app.get("/health")
def health():
    return {"status": "ok", "time": datetime.utcnow().isoformat()}

# === MIDDLEWARE CORS FIX HEADERS (conserv√©) ===
@app.middleware("http")
async def add_cors_headers(request: Request, call_next):
    response: Response = await call_next(request)
    origin = request.headers.get("origin")
    allowed_origins = [o.strip() for o in ALLOWED_ORIGINS if o.strip()]

    if origin and origin in allowed_origins:
        response.headers["Access-Control-Allow-Origin"] = origin
        response.headers["Access-Control-Allow-Credentials"] = "true"
    else:
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Credentials"] = "false"
    
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Session-ID"

    return response

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host=os.getenv("HOST", "0.0.0.0"), port=int(os.getenv("PORT", "8000")))