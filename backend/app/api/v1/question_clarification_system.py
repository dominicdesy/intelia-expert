"""
app/api/v1/question_clarification_system.py - SYST√àME PRINCIPAL DE CLARIFICATION

Contient:
- EnhancedQuestionClarificationSystem (classe principale)
- Extraction d'entit√©s intelligente
- Analyse compl√®te des questions
- Interface publique + logging
- Identification des entit√©s critiques

COMPATIBLE: Pr√©serve tous les imports existants
"""

import os
import re
import json
import logging
import time
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime

# Imports des modules s√©par√©s
from .clarification_entities import (
    ExtractedEntities, ClarificationResult, ClarificationMode, ClarificationState
)
from .clarification_generators import QuestionGenerator

# Import des settings Intelia
try:
    from app.config.settings import settings
    SETTINGS_AVAILABLE = True
except ImportError:
    SETTINGS_AVAILABLE = False
    settings = None

# Import OpenAI s√©curis√©
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

logger = logging.getLogger(__name__)

# ==================== CONSTANTES ENTIT√âS CRITIQUES ====================

# Entit√©s consid√©r√©es comme critiques pour les r√©ponses v√©t√©rinaires
CRITICAL_ENTITIES = [
    "breed",        # Race/souche (essentiel pour protocoles sp√©cifiques)
    "age",          # √Çge (critique pour nutrition, vaccination, traitements)
    "sex",          # Sexe (important pour certains protocoles)
    "symptoms",     # Sympt√¥mes (essentiel pour diagnostic)
    "environment",  # Environnement (temp√©rature, humidit√©, logement)
    "feed",         # Alimentation (critique pour nutrition et performance)
    "flock_size",   # Taille du troupeau (important pour gestion)
    "mortality_rate" # Taux de mortalit√© (critique pour urgences)
]

# Mappage des entit√©s vers les attributs ExtractedEntities
ENTITY_ATTRIBUTE_MAPPING = {
    "breed": ["breed", "breed_type"],
    "age": ["age_days", "age_weeks"],
    "sex": ["sex"],
    "symptoms": ["symptoms"],
    "environment": ["temperature", "humidity", "housing_type"],
    "feed": ["feed_type"],
    "flock_size": ["flock_size"],
    "mortality_rate": ["mortality_rate"]
}

# Entit√©s critiques par type de question
CRITICAL_ENTITIES_BY_QUESTION_TYPE = {
    "growth": ["breed", "age", "feed"],
    "weight": ["breed", "age", "feed"],
    "mortality": ["breed", "age", "symptoms", "mortality_rate"],
    "health": ["breed", "age", "symptoms"],
    "temperature": ["age", "environment"],
    "feeding": ["breed", "age", "feed"],
    "environment": ["age", "environment"],
    "performance": ["breed", "age", "feed", "environment"],
    "laying": ["breed", "age", "feed", "environment"],
    "general": ["breed", "age"]
}

class EnhancedQuestionClarificationSystem:
    """
    Syst√®me de clarification intelligent AM√âLIOR√â avec validation GPT robuste int√©gr√©e + reconnaissance souches + entit√©s critiques
    """
    
    def __init__(self):
        """Initialise le syst√®me avec configuration am√©lior√©e"""
        
        if SETTINGS_AVAILABLE and settings:
            self.enabled = getattr(settings, 'clarification_system_enabled', True)
            self.model = getattr(settings, 'clarification_model', 'gpt-4o-mini')
            self.timeout = getattr(settings, 'clarification_timeout', 25)
            self.max_questions = getattr(settings, 'clarification_max_questions', 3)
            self.min_question_length = getattr(settings, 'clarification_min_length', 15)
            self.log_all_clarifications = getattr(settings, 'clarification_log_all', True)
            self.confidence_threshold = getattr(settings, 'clarification_confidence_threshold', 0.7)
            
            self.clarification_mode = ClarificationMode(getattr(settings, 'clarification_mode', 'adaptive'))
            self.smart_entity_extraction = getattr(settings, 'smart_entity_extraction', True)
            self.auto_reprocess_after_clarification = getattr(settings, 'auto_reprocess_after_clarification', True)
            self.adaptive_question_count = getattr(settings, 'adaptive_question_count', True)
            
            self.enable_semantic_dynamic = getattr(settings, 'enable_semantic_dynamic_clarification', True)
            self.semantic_dynamic_max_questions = getattr(settings, 'semantic_dynamic_max_questions', 4)
            
            # Configuration validation GPT robuste
            self.enable_question_validation = getattr(settings, 'enable_question_validation', True)
            self.validation_threshold = getattr(settings, 'validation_threshold', 0.5)
            self.enable_intelligent_fallback = getattr(settings, 'enable_intelligent_fallback', True)
            
            # Configuration reconnaissance souches
            self.enable_breed_normalization = getattr(settings, 'enable_breed_normalization', True)
            self.enable_sex_inference = getattr(settings, 'enable_sex_inference', True)
            
            # Configuration entit√©s critiques
            self.enable_critical_entity_analysis = getattr(settings, 'enable_critical_entity_analysis', True)
            self.critical_entities_threshold = getattr(settings, 'critical_entities_threshold', 0.8)
        else:
            self.enabled = os.getenv('ENABLE_CLARIFICATION_SYSTEM', 'true').lower() == 'true'
            self.model = os.getenv('CLARIFICATION_MODEL', 'gpt-4o-mini')
            self.timeout = int(os.getenv('CLARIFICATION_TIMEOUT', '25'))
            self.max_questions = int(os.getenv('CLARIFICATION_MAX_QUESTIONS', '3'))
            self.min_question_length = int(os.getenv('CLARIFICATION_MIN_LENGTH', '15'))
            self.log_all_clarifications = os.getenv('LOG_ALL_CLARIFICATIONS', 'true').lower() == 'true'
            self.confidence_threshold = float(os.getenv('CLARIFICATION_CONFIDENCE_THRESHOLD', '0.7'))
            
            self.clarification_mode = ClarificationMode(os.getenv('CLARIFICATION_MODE', 'adaptive'))
            self.smart_entity_extraction = os.getenv('SMART_ENTITY_EXTRACTION', 'true').lower() == 'true'
            self.auto_reprocess_after_clarification = os.getenv('AUTO_REPROCESS_AFTER_CLARIFICATION', 'true').lower() == 'true'
            self.adaptive_question_count = os.getenv('ADAPTIVE_QUESTION_COUNT', 'true').lower() == 'true'
            
            self.enable_semantic_dynamic = os.getenv('ENABLE_SEMANTIC_DYNAMIC_CLARIFICATION', 'true').lower() == 'true'
            self.semantic_dynamic_max_questions = int(os.getenv('SEMANTIC_DYNAMIC_MAX_QUESTIONS', '4'))
            
            # Configuration validation GPT robuste
            self.enable_question_validation = os.getenv('ENABLE_QUESTION_VALIDATION', 'true').lower() == 'true'
            self.validation_threshold = float(os.getenv('VALIDATION_THRESHOLD', '0.5'))
            self.enable_intelligent_fallback = os.getenv('ENABLE_INTELLIGENT_FALLBACK', 'true').lower() == 'true'
            
            # Configuration reconnaissance souches
            self.enable_breed_normalization = os.getenv('ENABLE_BREED_NORMALIZATION', 'true').lower() == 'true'
            self.enable_sex_inference = os.getenv('ENABLE_SEX_INFERENCE', 'true').lower() == 'true'
            
            # Configuration entit√©s critiques
            self.enable_critical_entity_analysis = os.getenv('ENABLE_CRITICAL_ENTITY_ANALYSIS', 'true').lower() == 'true'
            self.critical_entities_threshold = float(os.getenv('CRITICAL_ENTITIES_THRESHOLD', '0.8'))
        
        # Initialiser le g√©n√©rateur de questions
        self.question_generator = QuestionGenerator(
            model=self.model, 
            timeout=self.timeout, 
            max_questions=self.semantic_dynamic_max_questions
        )
        
        self._init_patterns()
        self._init_enhanced_prompts()
        self._init_clarification_logger()
        
        # Log de d√©marrage
        logger.info("‚úÖ [EnhancedQuestionClarificationSystem] READY: Agent de clarification op√©rationnel!")
        logger.info(f"üîß [Enhanced Clarification] Mode: {self.clarification_mode.value}")
        logger.info(f"üîß [Enhanced Clarification] Validation GPT robuste: {'‚úÖ' if self.enable_question_validation else '‚ùå'}")
        logger.info(f"üÜï [Breed Recognition] Normalisation souches: {'‚úÖ' if self.enable_breed_normalization else '‚ùå'}")
        logger.info(f"üéØ [Critical Entities] Analyse entit√©s critiques: {'‚úÖ' if self.enable_critical_entity_analysis else '‚ùå'}")
        logger.info(f"üìä [Critical Entities] Entit√©s critiques d√©finies: {len(CRITICAL_ENTITIES)} ({', '.join(CRITICAL_ENTITIES)})")

    def _init_patterns(self):
        """Patterns de d√©tection am√©lior√©s avec reconnaissance souches"""
        
        # Races sp√©cifiques avec nouvelles souches pondeuses
        self.specific_breed_patterns = {
            "fr": [
                # Poulets de chair
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro',
                
                # Poules pondeuses
                r'lohmann(?:\s*lsl)?(?:\s*-?\s*lite)?', r'lsl\s*-?\s*lite?',
                r'bovans\s*(?:brown|blanc|white)?', 
                r'hisex\s*(?:brown|blanc|white)?',
                r'isa\s*(?:brown|blanc|white)?',
                r'hyline\s*(?:brown|white)?'
            ],
            "en": [
                # Poulets de chair
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro',
                
                # Poules pondeuses
                r'lohmann(?:\s*lsl)?(?:\s*-?\s*lite)?', r'lsl\s*-?\s*lite?',
                r'bovans\s*(?:brown|white)?', 
                r'hisex\s*(?:brown|white)?',
                r'isa\s*(?:brown|white)?',
                r'hyline\s*(?:brown|white)?'
            ],
            "es": [
                # Poulets de chair
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro',
                
                # Poules pondeuses
                r'lohmann(?:\s*lsl)?(?:\s*-?\s*lite)?', r'lsl\s*-?\s*lite?',
                r'bovans\s*(?:brown|blanco|white)?', 
                r'hisex\s*(?:brown|blanco|white)?',
                r'isa\s*(?:brown|blanco|white)?',
                r'hyline\s*(?:brown|white)?'
            ]
        }
        
        # Patterns pour classification de type de question
        self.question_type_patterns = {
            "growth": [r'croissance', r'growth', r'crecimiento', r'grossissent?', r'growing', r'crecen'],
            "weight": [r'poids', r'weight', r'peso', r'p√®sent?', r'weigh', r'pesan', r'grammes?', r'grams?', r'gramos?'],
            "mortality": [r'mortalit√©', r'mortality', r'mortalidad', r'meurent', r'dying', r'mueren', r'dead', r'muerte'],
            "health": [r'maladie', r'disease', r'enfermedad', r'malade', r'sick', r'enfermo', r'sant√©', r'health', r'salud'],
            "temperature": [r'temp√©rature', r'temperature', r'temperatura', r'chaud', r'hot', r'caliente', r'froid', r'cold', r'fr√≠o'],
            "feeding": [r'alimentation', r'feeding', r'alimentaci√≥n', r'nourriture', r'food', r'comida', r'aliment'],
            "environment": [r'environnement', r'environment', r'ambiente', r'ventilation', r'humidity', r'humidit√©'],
            "performance": [r'performance', r'rendement', r'efficacit√©', r'efficiency', r'eficiencia', r'conversion'],
            "laying": [r'ponte', r'laying', r'puesta', r'oeufs?', r'eggs?', r'huevos?']
        }

    def _init_enhanced_prompts(self):
        """Prompts am√©lior√©s avec gestion du contexte et entit√©s critiques"""
        
        self.clarification_prompts = {
            "fr": """Tu es un expert v√©t√©rinaire sp√©cialis√© en aviculture. Analyse cette question et le contexte pour d√©terminer si des clarifications sont n√©cessaires.

Question: "{question}"
Type de question d√©tect√©: {question_type}
Entit√©s extraites: {extracted_entities}
Contexte conversationnel: {conversation_context}
Informations critiques manquantes: {missing_info}
Entit√©s critiques manquantes: {missing_critical_entities}

R√àGLES STRICTES:
1. Si TOUTES les informations critiques sont pr√©sentes ‚Üí r√©ponds "CLEAR"
2. Si des informations critiques manquent ‚Üí g√©n√®re des questions PR√âCISES
3. Priorise TOUJOURS les entit√©s critiques manquantes
4. Adapte le nombre de questions au nombre d'informations critiques manquantes
5. Pour {question_type}, ces entit√©s sont particuli√®rement importantes: {critical_entities_for_type}

Format: soit "CLEAR" soit liste de questions avec tirets.""",

            "en": """You are a veterinary expert specialized in poultry farming. Analyze this question and context to determine if clarifications are needed.

Question: "{question}"
Detected question type: {question_type}
Extracted entities: {extracted_entities}
Conversational context: {conversation_context}
Missing critical information: {missing_info}
Missing critical entities: {missing_critical_entities}

STRICT RULES:
1. If ALL critical information is present ‚Üí answer "CLEAR"
2. If critical information is missing ‚Üí generate PRECISE questions
3. ALWAYS prioritize missing critical entities
4. Adapt number of questions to missing critical information count
5. For {question_type}, these entities are particularly important: {critical_entities_for_type}

Format: either "CLEAR" or bulleted question list.""",

            "es": """Eres un experto veterinario especializado en avicultura. Analiza esta pregunta y contexto para determinar si se necesitan aclaraciones.

Pregunta: "{question}"
Tipo de pregunta detectado: {question_type}
Entidades extra√≠das: {extracted_entities}
Contexto conversacional: {conversation_context}
Informaci√≥n cr√≠tica faltante: {missing_info}
Entidades cr√≠ticas faltantes: {missing_critical_entities}

REGLAS ESTRICTAS:
1. Si TODA la informaci√≥n cr√≠tica est√° presente ‚Üí responde "CLEAR"
2. Si falta informaci√≥n cr√≠tica ‚Üí genera preguntas PRECISAS
3. Prioriza SIEMPRE las entidades cr√≠ticas faltantes
4. Adapta el n√∫mero de preguntas a la informaci√≥n cr√≠tica faltante
5. Para {question_type}, estas entidades son particularmente importantes: {critical_entities_for_type}

Formato: "CLEAR" o lista de preguntas con guiones."""
        }

    def _init_clarification_logger(self):
        """Initialise le logger sp√©cialis√© pour les clarifications"""
        self.clarification_logger = logging.getLogger("enhanced_question_clarification")
        self.clarification_logger.setLevel(logging.INFO)
        
        if not self.clarification_logger.handlers and self.log_all_clarifications:
            try:
                from logging.handlers import RotatingFileHandler
                
                log_dir = os.getenv('VALIDATION_LOGS_DIR', 'logs')
                os.makedirs(log_dir, exist_ok=True)
                
                log_file_path = os.path.join(log_dir, 'enhanced_question_clarifications.log')
                clarification_handler = RotatingFileHandler(
                    log_file_path,
                    maxBytes=int(os.getenv('VALIDATION_LOG_MAX_SIZE', '10485760')),
                    backupCount=int(os.getenv('VALIDATION_LOG_BACKUP_COUNT', '5'))
                )
                clarification_formatter = logging.Formatter(
                    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
                )
                clarification_handler.setFormatter(clarification_formatter)
                self.clarification_logger.addHandler(clarification_handler)
                
                logger.info(f"‚úÖ [Enhanced Clarification] Logger configur√©: {log_file_path}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Impossible de cr√©er le fichier de log: {e}")

    def classify_question_type(self, question: str, language: str) -> str:
        """Classifie le type de question"""
        
        question_lower = question.lower()
        
        for question_type, patterns in self.question_type_patterns.items():
            for pattern in patterns:
                if re.search(pattern, question_lower, re.IGNORECASE):
                    return question_type
        
        return "general"

    def analyze_critical_entities(self, extracted_entities: ExtractedEntities, question_type: str) -> Dict[str, Any]:
        """
        Analyse les entit√©s critiques manquantes selon le type de question
        
        Returns:
            Dict contenant:
            - missing_entities: Liste de toutes les entit√©s manquantes
            - missing_critical_entities: Liste des entit√©s critiques manquantes
            - clarification_required_critical: Boolean indiquant si une clarification critique est n√©cessaire
            - critical_entities_for_type: Entit√©s critiques sp√©cifiques au type de question
        """
        
        if not self.enable_critical_entity_analysis:
            return {
                "missing_entities": [],
                "missing_critical_entities": [],
                "clarification_required_critical": False,
                "critical_entities_for_type": []
            }
            
        # Obtenir les entit√©s critiques pour ce type de question
        critical_entities_for_type = CRITICAL_ENTITIES_BY_QUESTION_TYPE.get(
            question_type, 
            CRITICAL_ENTITIES_BY_QUESTION_TYPE["general"]
        )
        
        # Analyser toutes les entit√©s manquantes
        missing_entities = []
        missing_critical_entities = []
        
        entities_dict = extracted_entities.to_dict()
        
        for entity in CRITICAL_ENTITIES:
            # V√©rifier si l'entit√© est pr√©sente via son mapping
            entity_attributes = ENTITY_ATTRIBUTE_MAPPING.get(entity, [entity])
            entity_present = False
            
            for attr in entity_attributes:
                if attr in entities_dict and entities_dict[attr] is not None:
                    # V√©rifications sp√©ciales pour certains types
                    if attr == "breed_type" and entities_dict[attr] == "generic":
                        # Race g√©n√©rique = entit√© manquante (besoin de sp√©cificit√©)
                        continue
                    if attr == "symptoms" and isinstance(entities_dict[attr], list) and len(entities_dict[attr]) == 0:
                        # Liste vide de sympt√¥mes = entit√© manquante
                        continue
                    entity_present = True
                    break
            
            if not entity_present:
                missing_entities.append(entity)
                # V√©rifier si c'est critique pour ce type de question
                if entity in critical_entities_for_type:
                    missing_critical_entities.append(entity)
        
        # D√©terminer si une clarification critique est n√©cessaire
        clarification_required_critical = len(missing_critical_entities) > 0
        
        # Log de l'analyse
        logger.info(f"üéØ [Critical Entities] Type: {question_type}")
        logger.info(f"üéØ [Critical Entities] Critiques pour ce type: {critical_entities_for_type}")
        logger.info(f"‚ùå [Critical Entities] Manquantes: {missing_entities}")
        logger.info(f"üö® [Critical Entities] Critiques manquantes: {missing_critical_entities}")
        logger.info(f"‚ö†Ô∏è [Critical Entities] Clarification critique requise: {clarification_required_critical}")
        
        return {
            "missing_entities": missing_entities,
            "missing_critical_entities": missing_critical_entities,
            "clarification_required_critical": clarification_required_critical,
            "critical_entities_for_type": critical_entities_for_type
        }

    async def extract_entities_intelligent(self, question: str, language: str, conversation_context: Dict = None) -> ExtractedEntities:
        """Extraction intelligente d'entit√©s via OpenAI avec reconnaissance souches"""
        
        if not self.smart_entity_extraction or not OPENAI_AVAILABLE or not openai:
            logger.warning("‚ö†Ô∏è [Enhanced Clarification] Extraction intelligente d√©sactiv√©e ou OpenAI indisponible")
            return await self._extract_entities_fallback(question, language)
        
        try:
            # Construire le contexte pour l'extraction
            context_info = ""
            if conversation_context:
                context_info = f"\n\nContexte conversationnel disponible:\n{json.dumps(conversation_context, ensure_ascii=False, indent=2)}"
            
            # Prompt avec reconnaissance des souches pondeuses et focus sur entit√©s critiques
            extraction_prompt = f"""Tu es un expert en extraction d'informations pour l'aviculture. Extrait TOUTES les informations pertinentes de cette question et du contexte.

Question: "{question}"{context_info}

CONSIGNE: Extrait les informations sous format JSON strict. Utilise null pour les valeurs manquantes.

PRIORIT√â AUX ENTIT√âS CRITIQUES: {', '.join(CRITICAL_ENTITIES)}

IMPORTANT POUR LES RACES/SOUCHES:
- Reconna√Ætre les souches pondeuses: Lohmann LSL-Lite, Bovans Brown, Hisex Brown, ISA Brown, Hyline
- Reconna√Ætre les souches de chair: Ross 308, Cobb 500, Hubbard Flex, etc.
- Normaliser les noms (ex: "lohmann" ‚Üí "Lohmann LSL-Lite")
- Inf√©rer le sexe si possible (souches pondeuses = femelles)

```json
{{
  "breed": "race sp√©cifique (ex: Ross 308, Lohmann LSL-Lite) ou null",
  "breed_type": "specific/generic/null",
  "sex": "m√¢le/femelle/mixte ou null (inf√©rer si souche pondeuse)",
  "age_days": nombre_jours_ou_null,
  "age_weeks": nombre_semaines_ou_null,
  "weight_grams": poids_grammes_ou_null,
  "mortality_rate": taux_mortalit√©_pourcentage_ou_null,
  "temperature": temp√©rature_celsius_ou_null,
  "humidity": humidit√©_pourcentage_ou_null,
  "housing_type": "type_b√¢timent_ou_null",
  "feed_type": "type_alimentation_ou_null",
  "flock_size": nombre_poulets_ou_null,
  "symptoms": ["sympt√¥me1", "sympt√¥me2"] ou null,
  "duration_problem": "dur√©e_probl√®me_ou_null",
  "previous_treatments": ["traitement1"] ou null
}}
```"""

            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return await self._extract_entities_fallback(question, language)
            
            openai.api_key = api_key
            
            response = openai.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un extracteur d'entit√©s expert en aviculture avec reconnaissance des souches et focus sur les entit√©s critiques. R√©ponds uniquement avec du JSON valide."},
                    {"role": "user", "content": extraction_prompt}
                ],
                temperature=0.1,
                max_tokens=500,
                timeout=self.timeout
            )
            
            answer = response.choices[0].message.content.strip()
            
            # Extraire le JSON de la r√©ponse
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', answer, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_match = re.search(r'\{.*\}', answer, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    logger.warning("‚ö†Ô∏è [Enhanced Clarification] Pas de JSON trouv√© dans la r√©ponse")
                    return await self._extract_entities_fallback(question, language)
            
            # Parser le JSON
            try:
                extracted_data = json.loads(json_str)
                
                # Convertir en ExtractedEntities
                entities = ExtractedEntities(
                    breed=extracted_data.get("breed"),
                    breed_type=extracted_data.get("breed_type"),
                    sex=extracted_data.get("sex"),
                    age_days=extracted_data.get("age_days"),
                    age_weeks=extracted_data.get("age_weeks"),
                    weight_grams=extracted_data.get("weight_grams"),
                    mortality_rate=extracted_data.get("mortality_rate"),
                    temperature=extracted_data.get("temperature"),
                    humidity=extracted_data.get("humidity"),
                    housing_type=extracted_data.get("housing_type"),
                    feed_type=extracted_data.get("feed_type"),
                    flock_size=extracted_data.get("flock_size"),
                    symptoms=extracted_data.get("symptoms"),
                    duration_problem=extracted_data.get("duration_problem"),
                    previous_treatments=extracted_data.get("previous_treatments")
                )
                
                # Appliquer normalisation et inf√©rence
                if self.enable_breed_normalization or self.enable_sex_inference:
                    entities.normalize_and_infer()
                
                logger.info(f"ü§ñ [Enhanced Clarification] Entit√©s extraites intelligemment: {entities.to_dict()}")
                return entities
                
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Erreur parsing JSON: {e}")
                return await self._extract_entities_fallback(question, language)
        
        except Exception as e:
            logger.error(f"‚ùå [Enhanced Clarification] Erreur extraction intelligente: {e}")
            return await self._extract_entities_fallback(question, language)

    async def _extract_entities_fallback(self, question: str, language: str) -> ExtractedEntities:
        """Extraction d'entit√©s fallback avec reconnaissance souches (r√®gles basiques)"""
        
        entities = ExtractedEntities()
        question_lower = question.lower()
        
        # D√©tection race sp√©cifique avec nouvelles souches
        specific_patterns = self.specific_breed_patterns.get(language, self.specific_breed_patterns["fr"])
        for pattern in specific_patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                raw_breed = match.group(0).strip()
                entities.breed = raw_breed
                entities.breed_type = "specific"
                break
        
        # D√©tection race g√©n√©rique si pas sp√©cifique
        if not entities.breed:
            generic_patterns = [r'poulets?', r'volailles?', r'chickens?', r'poultry', r'pollos?', r'aves?', r'poules?']
            for pattern in generic_patterns:
                match = re.search(pattern, question_lower, re.IGNORECASE)
                if match:
                    entities.breed = match.group(0).strip()
                    entities.breed_type = "generic"
                    break
        
        # D√©tection sexe explicite
        sex_patterns = {
            "fr": [r'm√¢les?', r'femelles?', r'coqs?', r'poules?', r'poulettes?', r'mixte'],
            "en": [r'males?', r'females?', r'roosters?', r'hens?', r'pullets?', r'mixed'],
            "es": [r'machos?', r'hembras?', r'gallos?', r'gallinas?', r'pollas?', r'mixto']
        }
        
        patterns = sex_patterns.get(language, sex_patterns["fr"])
        for pattern in patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                sex_word = match.group(0).lower()
                if sex_word in ['m√¢le', 'm√¢les', 'male', 'males', 'macho', 'machos', 'coq', 'coqs', 'rooster', 'roosters', 'gallo', 'gallos']:
                    entities.sex = "m√¢le"
                elif sex_word in ['femelle', 'femelles', 'female', 'females', 'hembra', 'hembras', 'poule', 'poules', 'hen', 'hens', 'gallina', 'gallinas', 'poulette', 'poulettes', 'pullet', 'pullets', 'polla', 'pollas']:
                    entities.sex = "femelle"
                elif sex_word in ['mixte', 'mixed', 'mixto']:
                    entities.sex = "mixte"
                break
        
        # D√©tection √¢ge
        age_patterns = [
            r'(\d+)\s*jours?', r'(\d+)\s*days?', r'(\d+)\s*d√≠as?',
            r'(\d+)\s*semaines?', r'(\d+)\s*weeks?', r'(\d+)\s*semanas?',
            r'jour\s*(\d+)', r'day\s*(\d+)', r'd√≠a\s*(\d+)'
        ]
        
        for pattern in age_patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                value = int(match.group(1))
                if 'semaine' in pattern or 'week' in pattern or 'semana' in pattern:
                    entities.age_weeks = value
                    entities.age_days = value * 7
                else:
                    entities.age_days = value
                break
        
        # D√©tection poids
        weight_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:kg|gramm?es?|g|lbs?)',
            r'p√®sent?\s+(\d+(?:\.\d+)?)', r'weigh\s+(\d+(?:\.\d+)?)'
        ]
        
        for pattern in weight_patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                entities.weight_grams = float(match.group(1))
                break
        
        # Appliquer normalisation et inf√©rence m√™me en fallback
        if self.enable_breed_normalization or self.enable_sex_inference:
            entities.normalize_and_infer()
        
        return entities

    async def analyze_question_enhanced(
        self, 
        question: str, 
        language: str = "fr",
        user_id: str = "unknown",
        conversation_id: str = None,
        conversation_context: Dict = None,
        original_question: str = None,
        mode: str = None
    ) -> ClarificationResult:
        """
        ANALYSE AM√âLIOR√âE avec extraction intelligente, gestion du contexte et analyse des entit√©s critiques
        """
        
        start_time = time.time()
        
        if not self.enabled:
            logger.info(f"üîß [Enhanced Clarification] Syst√®me d√©sactiv√©")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="system_disabled",
                clarification_state=ClarificationState.NONE
            )
        
        if not question or len(question.strip()) < self.min_question_length:
            logger.info(f"‚ö†Ô∏è [Enhanced Clarification] Question trop courte: {len(question)}")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="question_too_short",
                clarification_state=ClarificationState.NONE
            )
        
        # Classification du type de question
        question_type = self.classify_question_type(question, language)
        logger.info(f"üè∑Ô∏è [Enhanced Clarification] Type de question: {question_type}")
        
        # Extraction intelligente d'entit√©s avec reconnaissance souches
        extracted_entities = await self.extract_entities_intelligent(
            question, 
            language, 
            conversation_context
        )
        
        logger.info(f"üîç [Enhanced Clarification] Analyse: '{question[:80]}...'")
        logger.info(f"üìä [Enhanced Clarification] Entit√©s extraites: {extracted_entities.to_dict()}")
        
        # Logging de reconnaissance automatique
        if extracted_entities.breed_normalized:
            logger.info(f"üîÑ [Breed Recognition] Souche normalis√©e automatiquement: {extracted_entities.breed}")
        if extracted_entities.sex_inferred:
            logger.info(f"üö∫ [Sex Inference] Sexe inf√©r√© automatiquement: {extracted_entities.sex}")
        
        # NOUVELLE FONCTIONNALIT√â: Analyse des entit√©s critiques
        critical_analysis = self.analyze_critical_entities(extracted_entities, question_type)
        
        # D√©terminer les informations critiques manquantes (ancien syst√®me)
        missing_critical_info = extracted_entities.get_missing_critical_info(question_type)
        
        logger.info(f"‚ùå [Enhanced Clarification] Informations critiques manquantes (ancien): {missing_critical_info}")
        logger.info(f"üéØ [Critical Analysis] R√©sultats: {critical_analysis}")
        
        # Gestion du mode s√©mantique dynamique avec validation robuste
        if (mode == "semantic_dynamic" or 
            self.clarification_mode == ClarificationMode.SEMANTIC_DYNAMIC) and \
           self.enable_semantic_dynamic:
            
            logger.info(f"üéØ [Semantic Dynamic] Mode activ√© pour: '{question[:50]}...'")
            
            # G√©n√©rer questions dynamiques avec m√©tadonn√©es de validation
            dynamic_questions, validation_metadata = self.question_generator.generate_dynamic_questions_with_validation(question, language)
            
            if dynamic_questions:
                processing_time_ms = int((time.time() - start_time) * 1000)
                
                result = ClarificationResult(
                    needs_clarification=True,
                    questions=dynamic_questions,
                    processing_time_ms=processing_time_ms,
                    reason="semantic_dynamic_clarification_generated",
                    model_used=f"{self.model}_semantic_dynamic",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=ClarificationMode.SEMANTIC_DYNAMIC,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    confidence_score=0.9,
                    original_question=original_question or question,
                    validation_score=validation_metadata.get("validation_score", 0.8),
                    validation_details=validation_metadata,
                    fallback_used=validation_metadata.get("fallback_used", False),
                    gpt_failed=not validation_metadata.get("gpt_success", False),
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
                
                logger.info(f"‚úÖ [Semantic Dynamic] {len(dynamic_questions)} questions g√©n√©r√©es dynamiquement")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            else:
                logger.warning("‚ö†Ô∏è [Semantic Dynamic] Aucune question g√©n√©r√©e, fallback vers mode normal")
        
        # Logique de clarification bas√©e sur les entit√©s critiques
        if critical_analysis["clarification_required_critical"]:
            logger.info(f"üö® [Critical Entities] Clarification critique requise - entit√©s manquantes: {critical_analysis['missing_critical_entities']}")
            
            # G√©n√©rer questions sp√©cifiques aux entit√©s critiques manquantes
            critical_questions = self.question_generator.generate_critical_entity_questions(
                language, 
                critical_analysis["missing_critical_entities"], 
                question_type
            )
            
            return ClarificationResult(
                needs_clarification=True,
                questions=critical_questions,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="critical_entities_missing",
                model_used="rule_based_critical_entities",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_mode=self.clarification_mode,
                clarification_state=ClarificationState.NEEDED,
                missing_critical_info=missing_critical_info,
                confidence_score=95.0,
                original_question=original_question or question,
                validation_score=0.9,
                fallback_used=False,
                gpt_failed=False,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=True
            )
        
        # Logique de clarification intelligente (ancien syst√®me am√©lior√©)
        if extracted_entities.breed_type == "generic":
            logger.info(f"üö® [Enhanced Clarification] Race g√©n√©rique d√©tect√©e - clarification obligatoire")
            
            generic_questions = self.question_generator.generate_adaptive_questions(
                language, missing_critical_info, question_type
            )
            
            return ClarificationResult(
                needs_clarification=True,
                questions=generic_questions,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="generic_breed_detected",
                model_used="rule_based_enhanced",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_mode=self.clarification_mode,
                clarification_state=ClarificationState.NEEDED,
                missing_critical_info=missing_critical_info,
                confidence_score=95.0,
                original_question=original_question or question,
                validation_score=0.9,
                fallback_used=False,
                gpt_failed=False,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=critical_analysis["clarification_required_critical"]
            )
        
        # Si race sp√©cifique + √¢ge pr√©sents = OK
        if extracted_entities.breed_type == "specific" and (extracted_entities.age_days or extracted_entities.age_weeks):
            logger.info(f"‚úÖ [Enhanced Clarification] Race sp√©cifique + √¢ge - question compl√®te")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="specific_breed_and_age_detected",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_state=ClarificationState.NONE,
                validation_score=1.0,
                fallback_used=False,
                gpt_failed=False,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=False
            )
        
        # Si pas d'informations critiques manquantes (ancien + nouveau syst√®me)
        if not missing_critical_info and not critical_analysis["clarification_required_critical"]:
            logger.info(f"‚úÖ [Enhanced Clarification] Toutes les informations critiques pr√©sentes")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="all_critical_info_present",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_state=ClarificationState.NONE,
                validation_score=1.0,
                fallback_used=False,
                gpt_failed=False,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=False
            )
        
        # Analyse via OpenAI pour les cas complexes (avec informations d'entit√©s critiques)
        if not OPENAI_AVAILABLE or not openai:
            logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] OpenAI non disponible - fallback vers questions adaptatives")
            
            adaptive_questions = self.question_generator.generate_adaptive_questions(
                language, missing_critical_info, question_type
            )
            
            return ClarificationResult(
                needs_clarification=True,
                questions=adaptive_questions,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="openai_unavailable_adaptive_fallback",
                model_used="rule_based_adaptive",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_mode=self.clarification_mode,
                clarification_state=ClarificationState.NEEDED,
                missing_critical_info=missing_critical_info,
                confidence_score=0.7,
                original_question=original_question or question,
                validation_score=0.8,
                fallback_used=True,
                gpt_failed=True,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=critical_analysis["clarification_required_critical"]
            )
        
        try:
            # Configuration OpenAI
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Cl√© API OpenAI manquante - fallback adaptatif")
                
                adaptive_questions = self.question_generator.generate_adaptive_questions(
                    language, missing_critical_info, question_type
                )
                
                return ClarificationResult(
                    needs_clarification=True,
                    questions=adaptive_questions,
                    processing_time_ms=int((time.time() - start_time) * 1000),
                    reason="openai_key_missing_adaptive_fallback",
                    model_used="rule_based_adaptive",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=self.clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    confidence_score=0.7,
                    original_question=original_question or question,
                    validation_score=0.8,
                    fallback_used=True,
                    gpt_failed=True,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
            
            openai.api_key = api_key
            
            # PROMPT ENRICHI avec toutes les informations + entit√©s critiques
            prompt_template = self.clarification_prompts.get(language.lower(), self.clarification_prompts["fr"])
            
            context_str = json.dumps(conversation_context, ensure_ascii=False) if conversation_context else "Aucun contexte"
            entities_str = json.dumps(extracted_entities.to_dict(), ensure_ascii=False)
            missing_info_str = ", ".join(missing_critical_info) if missing_critical_info else "Aucune"
            missing_critical_entities_str = ", ".join(critical_analysis["missing_critical_entities"]) if critical_analysis["missing_critical_entities"] else "Aucune"
            critical_entities_for_type_str = ", ".join(critical_analysis["critical_entities_for_type"])
            
            user_prompt = prompt_template.format(
                question=question,
                question_type=question_type,
                extracted_entities=entities_str,
                conversation_context=context_str,
                missing_info=missing_info_str,
                missing_critical_entities=missing_critical_entities_str,
                critical_entities_for_type=critical_entities_for_type_str
            )
            
            system_prompt = f"""Tu es un assistant expert qui d√©termine si une question d'aviculture n√©cessite des clarifications. 

Mode de clarification: {self.clarification_mode.value}
Questions adaptatives: {'activ√©es' if self.adaptive_question_count else 'd√©sactiv√©es'}
Analyse entit√©s critiques: {'activ√©e' if self.enable_critical_entity_analysis else 'd√©sactiv√©e'}

FOCUS PRIORITAIRE sur les entit√©s critiques: {', '.join(CRITICAL_ENTITIES)}

Sois tr√®s pr√©cis et utilise intelligemment le contexte conversationnel pour √©viter les questions redondantes."""
            
            # Appel OpenAI enrichi
            logger.info(f"ü§ñ [Enhanced Clarification] Appel GPT-4o-mini enrichi avec analyse entit√©s critiques...")
            
            response = openai.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=400,
                timeout=self.timeout
            )
            
            answer = response.choices[0].message.content.strip()
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            logger.info(f"ü§ñ [Enhanced Clarification] R√©ponse GPT-4o-mini ({processing_time_ms}ms): {answer[:100]}...")
            
            # Analyse de la r√©ponse
            if answer.upper().strip() in ["CLEAR", "CLEAR.", "CLEAR !"]:
                result = ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason="question_clear_by_gpt4o_mini_enhanced",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    validation_score=1.0,
                    fallback_used=False,
                    gpt_failed=False,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=False
                )
                
                logger.info(f"‚úÖ [Enhanced Clarification] Question claire selon GPT-4o-mini enrichi")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            
            # Extraire les questions de clarification
            clarification_questions = self._extract_questions(answer)
            
            # Limitation adaptative du nombre de questions
            if self.adaptive_question_count:
                max_questions = min(len(critical_analysis["missing_critical_entities"]) + 1, self.max_questions)
            else:
                max_questions = self.max_questions
            
            if clarification_questions and len(clarification_questions) > 0:
                limited_questions = clarification_questions[:max_questions]
                
                # Mode de clarification
                clarification_mode = self.clarification_mode
                if clarification_mode == ClarificationMode.ADAPTIVE:
                    clarification_mode = ClarificationMode.INTERACTIVE if len(limited_questions) == 1 else ClarificationMode.BATCH
                
                result = ClarificationResult(
                    needs_clarification=True,
                    questions=limited_questions,
                    processing_time_ms=processing_time_ms,
                    reason="clarification_needed_by_gpt4o_mini_enhanced",
                    model_used=self.model,
                    confidence_score=self._calculate_confidence_score_enhanced(question, limited_questions, extracted_entities, question_type),
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    original_question=original_question or question,
                    validation_score=0.8,
                    fallback_used=False,
                    gpt_failed=False,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
                
                logger.info(f"‚ùì [Enhanced Clarification] {len(limited_questions)} questions g√©n√©r√©es (mode: {clarification_mode.value})")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            else:
                logger.info(f"‚úÖ [Enhanced Clarification] Aucune question valide - question suffisante")
                return ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason="no_valid_questions_from_gpt4o_mini_enhanced",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    validation_score=1.0,
                    fallback_used=False,
                    gpt_failed=False,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
        
        except Exception as e:
            processing_time_ms = int((time.time() - start_time) * 1000)
            logger.error(f"‚ùå [Enhanced Clarification] Erreur GPT-4o-mini: {e}")
            
            # Fallback intelligent en cas d'erreur GPT
            if self.enable_intelligent_fallback:
                logger.info(f"üîÑ [Enhanced Clarification] Fallback intelligent activ√© suite √† erreur GPT")
                
                adaptive_questions = self.question_generator.generate_adaptive_questions(
                    language, missing_critical_info, question_type
                )
                
                return ClarificationResult(
                    needs_clarification=True,
                    questions=adaptive_questions,
                    processing_time_ms=processing_time_ms,
                    reason=f"gpt_error_intelligent_fallback: {str(e)}",
                    model_used="rule_based_adaptive_fallback",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=self.clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    confidence_score=0.6,
                    original_question=original_question or question,
                    validation_score=0.7,
                    fallback_used=True,
                    gpt_failed=True,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
            else:
                return ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason=f"error_gpt4o_mini_enhanced: {str(e)}",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    fallback_used=False,
                    gpt_failed=True,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )

    def _extract_questions(self, answer: str) -> List[str]:
        """Extrait les questions de clarification de la r√©ponse GPT"""
        questions = []
        lines = answer.splitlines()
        
        for line in lines:
            line = line.strip()
            if line and len(line) > 15:
                # Nettoyer les puces et formatage
                cleaned_line = re.sub(r'^[-‚Ä¢*]\s*', '', line)
                cleaned_line = re.sub(r'^\d+\.\s*', '', cleaned_line)
                cleaned_line = cleaned_line.strip()
                
                # V√©rifier que c'est une vraie question
                if cleaned_line and len(cleaned_line) > 20 and cleaned_line not in questions:
                    # Ajouter un point d'interrogation si manquant
                    if not cleaned_line.endswith('?') and not cleaned_line.endswith(' ?'):
                        if any(word in cleaned_line.lower() for word in ['quel', 'quelle', 'combien', 'comment', 'what', 'how', 'which', 'cu√°l', 'c√≥mo', 'cu√°nto']):
                            cleaned_line += ' ?'
                    
                    questions.append(cleaned_line)
        
        return questions

    def _calculate_confidence_score_enhanced(
        self, 
        original_question: str, 
        clarification_questions: List[str], 
        extracted_entities: ExtractedEntities,
        question_type: str
    ) -> float:
        """Score de confiance plus intelligent avec entit√©s critiques"""
        
        # Score de base
        base_score = min(len(clarification_questions) * 20, 70)
        
        # Bonus pour informations g√©n√©riques d√©tect√©es
        if extracted_entities.breed_type == "generic":
            base_score += 20
        
        # Bonus selon le type de question et informations manquantes
        critical_info_bonus = {
            "growth": 15 if not extracted_entities.age_days else 0,
            "weight": 15 if not extracted_entities.age_days else 0,
            "health": 10 if not extracted_entities.symptoms else 0,
            "mortality": 15 if not extracted_entities.mortality_rate else 0,
            "laying": 10 if not extracted_entities.age_days else 0
        }
        
        base_score += critical_info_bonus.get(question_type, 5)
        
        # NOUVEAU: Bonus pour entit√©s critiques manquantes
        if self.enable_critical_entity_analysis:
            critical_analysis = self.analyze_critical_entities(extracted_entities, question_type)
            critical_missing_count = len(critical_analysis["missing_critical_entities"])
            base_score += critical_missing_count * 10  # Bonus de 10 points par entit√© critique manquante
        
        # Malus si beaucoup d'informations d√©j√† pr√©sentes
        extracted_count = len([v for v in extracted_entities.to_dict().values() if v is not None])
        if extracted_count > 3:
            base_score -= 10
        
        # Bonus si reconnaissance automatique a fonctionn√©
        if extracted_entities.breed_normalized:
            base_score += 5
        if extracted_entities.sex_inferred:
            base_score += 5
        
        return min(base_score, 95.0)

    async def check_for_reprocessing(
        self,
        conversation_id: str,
        user_response: str,
        original_clarification_result: ClarificationResult
    ) -> Optional[ClarificationResult]:
        """
        V√©rifie si la question originale peut √™tre retrait√©e apr√®s clarification
        """
        
        if not self.auto_reprocess_after_clarification:
            return None
        
        if not original_clarification_result.original_question:
            return None
        
        logger.info(f"üîÑ [Enhanced Clarification] V√©rification retraitement apr√®s clarification")
        
        # Construire la question enrichie
        enriched_question = f"{original_clarification_result.original_question}\n\nInformation suppl√©mentaire: {user_response}"
        
        # R√©analyser avec le contexte enrichi
        reprocess_result = await self.analyze_question_enhanced(
            question=enriched_question,
            language="fr",
            conversation_id=conversation_id,
            original_question=original_clarification_result.original_question
        )
        
        if not reprocess_result.needs_clarification:
            reprocess_result.should_reprocess = True
            reprocess_result.clarification_state = ClarificationState.AWAITING_REPROCESS
            logger.info(f"‚úÖ [Enhanced Clarification] Question pr√™te pour retraitement")
            return reprocess_result
        
        logger.info(f"‚ö†Ô∏è [Enhanced Clarification] Clarification suppl√©mentaire encore n√©cessaire")
        return None

    def format_clarification_response_enhanced(
        self, 
        result: ClarificationResult,
        language: str
    ) -> str:
        """Formatage enrichi selon le mode de clarification avec mention des entit√©s critiques"""
        
        if not result.questions:
            return ""
        
        intros = {
            "fr": {
                ClarificationMode.BATCH: "‚ùì Pour vous donner la r√©ponse la plus pr√©cise possible, j'aurais besoin de quelques informations suppl√©mentaires :",
                ClarificationMode.INTERACTIVE: "‚ùì Pour vous aider au mieux, puis-je vous poser une question rapide :",
                ClarificationMode.ADAPTIVE: "‚ùì J'ai besoin d'une pr√©cision pour vous donner une r√©ponse adapt√©e :",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì Pour mieux comprendre votre situation et vous aider efficacement :"
            },
            "en": {
                ClarificationMode.BATCH: "‚ùì To give you the most accurate answer possible, I would need some additional information:",
                ClarificationMode.INTERACTIVE: "‚ùì To help you best, may I ask you a quick question:",
                ClarificationMode.ADAPTIVE: "‚ùì I need clarification to give you a tailored answer:",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì To better understand your situation and help you effectively:"
            },
            "es": {
                ClarificationMode.BATCH: "‚ùì Para darle la respuesta m√°s precisa posible, necesitar√≠a informaci√≥n adicional:",
                ClarificationMode.INTERACTIVE: "‚ùì Para ayudarle mejor, ¬øpuedo hacerle una pregunta r√°pida:",
                ClarificationMode.ADAPTIVE: "‚ùì Necesito una aclaraci√≥n para darle una respuesta adaptada:",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì Para entender mejor su situaci√≥n y ayudarle efectivamente:"
            }
        }
        
        outros = {
            "fr": {
                ClarificationMode.BATCH: "\n\nCes pr√©cisions m'aideront √† vous donner des conseils sp√©cifiques et adapt√©s √† votre situation ! üêî",
                ClarificationMode.INTERACTIVE: "\n\nMerci pour votre pr√©cision ! üêî",
                ClarificationMode.ADAPTIVE: "\n\nCela m'aidera √† vous donner une r√©ponse plus pr√©cise ! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\nCela me permettra de vous donner les conseils les plus pertinents ! üêî"
            },
            "en": {
                ClarificationMode.BATCH: "\n\nThese details will help me give you specific advice tailored to your situation! üêî",
                ClarificationMode.INTERACTIVE: "\n\nThank you for the clarification! üêî",
                ClarificationMode.ADAPTIVE: "\n\nThis will help me give you a more precise answer! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\nThis will allow me to give you the most relevant advice! üêî"
            },
            "es": {
                ClarificationMode.BATCH: "\n\n¬°Estos detalles me ayudar√°n a darle consejos espec√≠ficos adaptados a su situaci√≥n! üêî",
                ClarificationMode.INTERACTIVE: "\n\n¬°Gracias por la aclaraci√≥n! üêî",
                ClarificationMode.ADAPTIVE: "\n\n¬°Esto me ayudar√° a darle una respuesta m√°s precisa! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\n¬°Esto me permitir√° darle los consejos m√°s relevantes! üêî"
            }
        }
        
        mode = result.clarification_mode or ClarificationMode.BATCH
        intro = intros.get(language, intros["fr"]).get(mode, intros["fr"][ClarificationMode.BATCH])
        outro = outros.get(language, outros["fr"]).get(mode, outros["fr"][ClarificationMode.BATCH])
        
        # Ajouter une mention sp√©ciale si des entit√©s critiques sont manquantes
        critical_mention = ""
        if hasattr(result, 'clarification_required_critical') and result.clarification_required_critical:
            critical_mentions = {
                "fr": " (informations essentielles pour un diagnostic pr√©cis)",
                "en": " (essential information for accurate diagnosis)",
                "es": " (informaci√≥n esencial para un diagn√≥stico preciso)"
            }
            critical_mention = critical_mentions.get(language, critical_mentions["fr"])
        
        if mode == ClarificationMode.INTERACTIVE or len(result.questions) == 1:
            # Mode interactif ou une seule question
            return f"{intro}{critical_mention}\n\n{result.questions[0]}{outro}"
        else:
            # Mode batch - plusieurs questions
            formatted_questions = "\n".join([f"‚Ä¢ {q}" for q in result.questions])
            return f"{intro}{critical_mention}\n\n{formatted_questions}{outro}"

    async def _log_clarification_decision(
        self,
        question: str,
        language: str,
        user_id: str,
        conversation_id: str,
        result: ClarificationResult
    ):
        """Log d√©taill√© des d√©cisions de clarification enrichi avec entit√©s critiques"""
        
        clarification_data = {
            "timestamp": datetime.now().isoformat(),
            "conversation_id": conversation_id,
            "user_id": user_id,
            "question": question,
            "question_length": len(question),
            "language": language,
            "result": result.to_dict(),
            "system_config": {
                "enabled": self.enabled,
                "model": self.model,
                "max_questions": self.max_questions,
                "confidence_threshold": self.confidence_threshold,
                "clarification_mode": self.clarification_mode.value,
                "enable_semantic_dynamic": self.enable_semantic_dynamic,
                "enable_question_validation": self.enable_question_validation,
                "enable_breed_normalization": self.enable_breed_normalization,
                "enable_sex_inference": self.enable_sex_inference,
                "enable_critical_entity_analysis": self.enable_critical_entity_analysis,
                "critical_entities_threshold": self.critical_entities_threshold
            }
        }
        
        # Log structur√©
        self.clarification_logger.info(json.dumps(clarification_data, ensure_ascii=False))
        
        # Log standard enrichi avec entit√©s critiques
        if result.needs_clarification:
            critical_info = ""
            if hasattr(result, 'clarification_required_critical'):
                critical_status = "üö® CRITIQUE" if result.clarification_required_critical else "üìù Standard"
                critical_entities_count = len(getattr(result, 'missing_critical_entities', []))
                critical_info = f" | {critical_status} ({critical_entities_count} entit√©s critiques manquantes)"
            
            logger.info(
                f"‚ùì [Enhanced Clarification] CLARIFICATION - "
                f"User: {user_id[:8]} | Type: {result.question_type} | "
                f"Questions: {len(result.questions)} | Mode: {result.clarification_mode.value if result.clarification_mode else 'N/A'} | "
                f"Validation: {result.validation_score:.1f} | "
                f"Fallback: {'‚úÖ' if result.fallback_used else '‚ùå'} | "
                f"Temps: {result.processing_time_ms}ms{critical_info}"
            )
        else:
            logger.info(
                f"‚úÖ [Enhanced Clarification] CLEAR - "
                f"User: {user_id[:8]} | Type: {result.question_type} | "
                f"Raison: {result.reason} | "
                f"Temps: {result.processing_time_ms}ms"
            )

    def get_stats_enhanced(self) -> Dict:
        """Retourne les statistiques du syst√®me enrichi avec entit√©s critiques"""
        return {
            "enabled": self.enabled,
            "model": self.model,
            "max_questions": self.max_questions,
            "confidence_threshold": self.confidence_threshold,
            "openai_available": OPENAI_AVAILABLE,
            "clarification_mode": self.clarification_mode.value,
            "smart_entity_extraction": self.smart_entity_extraction,
            "semantic_dynamic_enabled": self.enable_semantic_dynamic,
            "question_validation_enabled": self.enable_question_validation,
            "breed_normalization_enabled": self.enable_breed_normalization,
            "sex_inference_enabled": self.enable_sex_inference,
            "critical_entity_analysis_enabled": self.enable_critical_entity_analysis,
            "critical_entities_threshold": self.critical_entities_threshold,
            "critical_entities": CRITICAL_ENTITIES,
            "critical_entities_count": len(CRITICAL_ENTITIES),
            "supported_question_types": list(self.question_type_patterns.keys()),
            "supported_languages": ["fr", "en", "es"],
            "critical_entities_by_question_type": CRITICAL_ENTITIES_BY_QUESTION_TYPE
        }


# ==================== INSTANCE GLOBALE ====================

# Instance singleton du syst√®me de clarification
enhanced_clarification_system = EnhancedQuestionClarificationSystem()

# ==================== FONCTIONS UTILITAIRES PUBLIQUES ====================

async def analyze_question_for_clarification_enhanced(
    question: str, 
    language: str = "fr",
    user_id: str = "unknown", 
    conversation_id: str = None,
    conversation_context: Dict = None,
    original_question: str = None
) -> ClarificationResult:
    """Fonction utilitaire pour analyser les questions avec le syst√®me am√©lior√©"""
    return await enhanced_clarification_system.analyze_question_enhanced(
        question, language, user_id, conversation_id, conversation_context, original_question
    )

async def analyze_question_for_clarification_semantic_dynamic(
    question: str, 
    language: str = "fr",
    user_id: str = "unknown", 
    conversation_id: str = None,
    conversation_context: Dict = None
) -> ClarificationResult:
    """Fonction utilitaire pour utiliser le mode s√©mantique dynamique directement"""
    return await enhanced_clarification_system.analyze_question_enhanced(
        question, language, user_id, conversation_id, conversation_context, mode="semantic_dynamic"
    )

def analyze_critical_entities_for_question(
    extracted_entities: ExtractedEntities, 
    question_type: str
) -> Dict[str, Any]:
    """Fonction utilitaire pour analyser les entit√©s critiques d'une question"""
    return enhanced_clarification_system.analyze_critical_entities(extracted_entities, question_type)

def get_critical_entities_for_question_type(question_type: str) -> List[str]:
    """Retourne les entit√©s critiques pour un type de question donn√©"""
    return CRITICAL_ENTITIES_BY_QUESTION_TYPE.get(question_type, CRITICAL_ENTITIES_BY_QUESTION_TYPE["general"])

def is_critical_entity_missing(entity_name: str, extracted_entities: ExtractedEntities) -> bool:
    """V√©rifie si une entit√© critique sp√©cifique est manquante"""
    if entity_name not in CRITICAL_ENTITIES:
        return False
    
    entity_attributes = ENTITY_ATTRIBUTE_MAPPING.get(entity_name, [entity_name])
    entities_dict = extracted_entities.to_dict()
    
    for attr in entity_attributes:
        if attr in entities_dict and entities_dict[attr] is not None:
            # V√©rifications sp√©ciales
            if attr == "breed_type" and entities_dict[attr] == "generic":
                continue
            if attr == "symptoms" and isinstance(entities_dict[attr], list) and len(entities_dict[attr]) == 0:
                continue
            return False
    
    return True

def format_clarification_response_enhanced(result: ClarificationResult, language: str) -> str:
    """Formate la r√©ponse de clarification avec le syst√®me am√©lior√©"""
    return enhanced_clarification_system.format_clarification_response_enhanced(result, language)

async def check_for_reprocessing_after_clarification(
    conversation_id: str,
    user_response: str,
    original_clarification_result: ClarificationResult
) -> Optional[ClarificationResult]:
    """V√©rifie si une question peut √™tre retrait√©e apr√®s clarification"""
    return await enhanced_clarification_system.check_for_reprocessing(
        conversation_id, user_response, original_clarification_result
    )

def get_enhanced_clarification_system_stats() -> Dict:
    """Retourne les statistiques du syst√®me am√©lior√©"""
    return enhanced_clarification_system.get_stats_enhanced()

def is_enhanced_clarification_system_enabled() -> bool:
    """V√©rifie si le syst√®me de clarification am√©lior√© est activ√©"""
    return enhanced_clarification_system.enabled

def build_enriched_question_enhanced(
    original_question: str, 
    clarification_answers: Dict[str, str], 
    clarification_questions: List[str]
) -> str:
    """Construit une question enrichie avec les r√©ponses de clarification"""
    enriched_question = original_question + "\n\nInformations suppl√©mentaires :"
    
    for index_str, answer in clarification_answers.items():
        if answer and answer.strip():
            try:
                index = int(index_str)
                if 0 <= index < len(clarification_questions):
                    question = clarification_questions[index]
                    enriched_question += f"\n- {question}: {answer.strip()}"
            except (ValueError, IndexError):
                continue
    
    return enriched_question

def get_missing_critical_entities_summary(result: ClarificationResult, language: str = "fr") -> str:
    """G√©n√®re un r√©sum√© des entit√©s critiques manquantes"""
    if not hasattr(result, 'missing_critical_entities') or not result.missing_critical_entities:
        return ""
    
    summaries = {
        "fr": {
            "breed": "race/souche",
            "age": "√¢ge",
            "sex": "sexe",
            "symptoms": "sympt√¥mes",
            "environment": "environnement",
            "feed": "alimentation",
            "flock_size": "taille du troupeau",
            "mortality_rate": "taux de mortalit√©"
        },
        "en": {
            "breed": "breed/strain",
            "age": "age",
            "sex": "sex",
            "symptoms": "symptoms",
            "environment": "environment",
            "feed": "feeding",
            "flock_size": "flock size",
            "mortality_rate": "mortality rate"
        },
        "es": {
            "breed": "raza/cepa",
            "age": "edad",
            "sex": "sexo",
            "symptoms": "s√≠ntomas",
            "environment": "ambiente",
            "feed": "alimentaci√≥n",
            "flock_size": "tama√±o del reba√±o",
            "mortality_rate": "tasa de mortalidad"
        }
    }
    
    entity_names = summaries.get(language, summaries["fr"])
    missing_names = [entity_names.get(entity, entity) for entity in result.missing_critical_entities]
    
    if len(missing_names) == 1:
        return missing_names[0]
    elif len(missing_names) == 2:
        conjunction = {"fr": " et ", "en": " and ", "es": " y "}.get(language, " et ")
        return conjunction.join(missing_names)
    else:
        conjunction = {"fr": " et ", "en": " and ", "es": " y "}.get(language, " et ")
        return ", ".join(missing_names[:-1]) + conjunction + missing_names[-1]

# ==================== EXTENSIONS DU QUESTION GENERATOR ====================

def extend_question_generator_with_critical_entities():
    """√âtend le g√©n√©rateur de questions avec le support des entit√©s critiques"""
    
    def generate_critical_entity_questions(self, language: str, missing_critical_entities: List[str], question_type: str) -> List[str]:
        """G√©n√®re des questions sp√©cifiques aux entit√©s critiques manquantes"""
        
        questions = []
        
        critical_entity_questions = {
            "fr": {
                "breed": [
                    "Quelle est la race ou souche exacte de vos volailles ? (ex: Ross 308, Cobb 500, Lohmann LSL-Lite)",
                    "Quel type de poulets √©levez-vous ? Pr√©cisez la souche si possible."
                ],
                "age": [
                    "Quel est l'√¢ge de vos volailles en jours ou en semaines ?",
                    "Depuis combien de temps vos volailles sont-elles n√©es ?"
                ],
                "sex": [
                    "S'agit-il de m√¢les, de femelles ou d'un troupeau mixte ?",
                    "Quel est le sexe de vos volailles ?"
                ],
                "symptoms": [
                    "Quels sympt√¥mes pr√©cis observez-vous chez vos volailles ?",
                    "Pouvez-vous d√©crire les signes cliniques que vous avez remarqu√©s ?"
                ],
                "environment": [
                    "Quelles sont les conditions d'√©levage ? (temp√©rature, humidit√©, type de b√¢timent)",
                    "Dans quel environnement vos volailles sont-elles √©lev√©es ?"
                ],
                "feed": [
                    "Quel type d'alimentation donnez-vous √† vos volailles ?",
                    "Pouvez-vous pr√©ciser le programme alimentaire utilis√© ?"
                ],
                "flock_size": [
                    "Combien de volailles avez-vous dans votre troupeau ?",
                    "Quelle est la taille de votre √©levage ?"
                ],
                "mortality_rate": [
                    "Quel est le taux de mortalit√© observ√© ? (nombre de morts / total)",
                    "Combien de volailles sont mortes et sur combien au total ?"
                ]
            },
            "en": {
                "breed": [
                    "What is the exact breed or strain of your poultry? (e.g., Ross 308, Cobb 500, Lohmann LSL-Lite)",
                    "What type of chickens are you raising? Please specify the strain if possible."
                ],
                "age": [
                    "What is the age of your poultry in days or weeks?",
                    "How long have your poultry been hatched?"
                ],
                "sex": [
                    "Are these males, females, or a mixed flock?",
                    "What is the sex of your poultry?"
                ],
                "symptoms": [
                    "What specific symptoms are you observing in your poultry?",
                    "Can you describe the clinical signs you have noticed?"
                ],
                "environment": [
                    "What are the housing conditions? (temperature, humidity, building type)",
                    "In what environment are your poultry being raised?"
                ],
                "feed": [
                    "What type of feed are you giving to your poultry?",
                    "Can you specify the feeding program used?"
                ],
                "flock_size": [
                    "How many poultry do you have in your flock?",
                    "What is the size of your operation?"
                ],
                "mortality_rate": [
                    "What is the observed mortality rate? (number of deaths / total)",
                    "How many poultry have died and out of how many total?"
                ]
            },
            "es": {
                "breed": [
                    "¬øCu√°l es la raza o cepa exacta de sus aves? (ej: Ross 308, Cobb 500, Lohmann LSL-Lite)",
                    "¬øQu√© tipo de pollos est√° criando? Especifique la cepa si es posible."
                ],
                "age": [
                    "¬øCu√°l es la edad de sus aves en d√≠as o semanas?",
                    "¬øHace cu√°nto tiempo nacieron sus aves?"
                ],
                "sex": [
                    "¬øSon machos, hembras o un reba√±o mixto?",
                    "¬øCu√°l es el sexo de sus aves?"
                ],
                "symptoms": [
                    "¬øQu√© s√≠ntomas espec√≠ficos observa en sus aves?",
                    "¬øPuede describir los signos cl√≠nicos que ha notado?"
                ],
                "environment": [
                    "¬øCu√°les son las condiciones de crianza? (temperatura, humedad, tipo de edificio)",
                    "¬øEn qu√© ambiente se est√°n criando sus aves?"
                ],
                "feed": [
                    "¬øQu√© tipo de alimentaci√≥n da a sus aves?",
                    "¬øPuede especificar el programa alimentario utilizado?"
                ],
                "flock_size": [
                    "¬øCu√°ntas aves tiene en su reba√±o?",
                    "¬øCu√°l es el tama√±o de su operaci√≥n?"
                ],
                "mortality_rate": [
                    "¬øCu√°l es la tasa de mortalidad observada? (n√∫mero de muertes / total)",
                    "¬øCu√°ntas aves han muerto y de cu√°ntas en total?"
                ]
            }
        }
        
        language_questions = critical_entity_questions.get(language, critical_entity_questions["fr"])
        
        # Prioriser selon le type de question
        priority_order = CRITICAL_ENTITIES_BY_QUESTION_TYPE.get(question_type, CRITICAL_ENTITIES)
        
        # Trier les entit√©s manquantes par priorit√©
        sorted_entities = [entity for entity in priority_order if entity in missing_critical_entities]
        remaining_entities = [entity for entity in missing_critical_entities if entity not in sorted_entities]
        sorted_entities.extend(remaining_entities)
        
        # G√©n√©rer les questions dans l'ordre de priorit√©
        for entity in sorted_entities[:self.max_questions]:
            if entity in language_questions:
                # Prendre la premi√®re question pour cette entit√©
                questions.append(language_questions[entity][0])
        
        return questions
    
    # Ajouter la m√©thode au g√©n√©rateur de questions
    QuestionGenerator.generate_critical_entity_questions = generate_critical_entity_questions

# Appliquer l'extension
extend_question_generator_with_critical_entities()

# ==================== LOGGING DE D√âMARRAGE ====================

logger.info("‚ùì [EnhancedQuestionClarificationSystem] Module MODULAIRE initialis√© avec ENTIT√âS CRITIQUES")
logger.info("‚úÖ [Clarification System] PR√äT - Toutes fonctionnalit√©s disponibles + analyse entit√©s critiques!")
logger.info(f"üéØ [Critical Entities] {len(CRITICAL_ENTITIES)} entit√©s critiques configur√©es")
logger.info(f"üìä [System Stats] {enhanced_clarification_system.get_stats_enhanced()}")