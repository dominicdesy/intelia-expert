"""
app/api/v1/question_clarification_system.py - VERSION COMPL√àTE AVEC VALIDATION GPT INT√âGR√âE

AM√âLIORATIONS MAJEURES:
1. ‚úÖ Extraction intelligente d'entit√©s via OpenAI avec raisonnement dynamique (CONSERV√â)
2. ‚úÖ Clarification multi-tour (interactive vs batch) (CONSERV√â)
3. ‚úÖ Retraitement automatique apr√®s clarification (CONSERV√â)
4. ‚úÖ Gestion avanc√©e du contexte conversationnel (CONSERV√â)
5. ‚úÖ Prompts plus intelligents pour donn√©es num√©riques (CONSERV√â)
6. ‚úÖ Clarification partielle adaptative (1 question si 1 info manque) (CONSERV√â)
7. üÜï Mode s√©mantique dynamique avec g√©n√©ration GPT de questions contextuelles (CONSERV√â)
8. üîß NOUVEAU: Validation automatique robuste des questions g√©n√©r√©es par GPT
9. üîß NOUVEAU: Filtrage avanc√© des questions non pertinentes
10. üîß NOUVEAU: Fallback intelligent si validation √©choue
11. üîß NOUVEAU: Fallback lisible si GPT √©choue compl√®tement
"""

import os
import re
import json
import logging
import time
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from datetime import datetime
from enum import Enum

# Import des settings Intelia
try:
    from app.config.settings import settings
    SETTINGS_AVAILABLE = True
except ImportError:
    SETTINGS_AVAILABLE = False
    settings = None

# Import OpenAI s√©curis√©
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

logger = logging.getLogger(__name__)

class ClarificationMode(Enum):
    """Modes de clarification disponibles"""
    BATCH = "batch"
    INTERACTIVE = "interactive"
    ADAPTIVE = "adaptive"
    SEMANTIC_DYNAMIC = "semantic_dynamic"

class ClarificationState(Enum):
    """√âtats de clarification"""
    NONE = "none"
    NEEDED = "needed"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    AWAITING_REPROCESS = "awaiting_reprocess"

@dataclass
class ExtractedEntities:
    """Entit√©s extraites intelligemment du contexte"""
    breed: Optional[str] = None
    breed_type: Optional[str] = None
    age_days: Optional[int] = None
    age_weeks: Optional[float] = None
    weight_grams: Optional[float] = None
    mortality_rate: Optional[float] = None
    temperature: Optional[float] = None
    humidity: Optional[float] = None
    housing_type: Optional[str] = None
    feed_type: Optional[str] = None
    flock_size: Optional[int] = None
    symptoms: Optional[List[str]] = None
    duration_problem: Optional[str] = None
    previous_treatments: Optional[List[str]] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire pour logs"""
        return {k: v for k, v in asdict(self).items() if v is not None}
    
    def get_missing_critical_info(self, question_type: str) -> List[str]:
        """D√©termine les informations critiques manquantes selon le type de question"""
        missing = []
        
        if not self.breed or self.breed_type == "generic":
            missing.append("breed")
        
        if question_type in ["growth", "weight", "performance"]:
            if not self.age_days and not self.age_weeks:
                missing.append("age")
        elif question_type in ["health", "mortality", "disease"]:
            if not self.age_days and not self.age_weeks:
                missing.append("age")
            if not self.symptoms:
                missing.append("symptoms")
        elif question_type in ["environment", "temperature", "housing"]:
            if not self.age_days and not self.age_weeks:
                missing.append("age")
        elif question_type in ["feeding", "nutrition"]:
            if not self.age_days and not self.age_weeks:
                missing.append("age")
        
        return missing

@dataclass
class ClarificationResult:
    """R√©sultat de l'analyse de clarification am√©lior√©"""
    needs_clarification: bool
    questions: Optional[List[str]] = None
    confidence_score: float = 0.0
    processing_time_ms: int = 0
    reason: Optional[str] = None
    model_used: Optional[str] = None
    extracted_entities: Optional[ExtractedEntities] = None
    question_type: Optional[str] = None
    clarification_mode: Optional[ClarificationMode] = None
    clarification_state: Optional[ClarificationState] = None
    missing_critical_info: Optional[List[str]] = None
    should_reprocess: bool = False
    original_question: Optional[str] = None
    validation_score: Optional[float] = None  # üîß NOUVEAU: Score de validation des questions
    validation_details: Optional[Dict[str, Any]] = None  # üîß NOUVEAU: D√©tails validation
    fallback_used: bool = False  # üîß NOUVEAU: Indicateur si fallback utilis√©
    gpt_failed: bool = False  # üîß NOUVEAU: Indicateur si GPT a √©chou√©
    
    def to_dict(self) -> Dict:
        """Convertit en dictionnaire pour les logs"""
        return {
            "needs_clarification": self.needs_clarification,
            "questions": self.questions,
            "questions_count": len(self.questions) if self.questions else 0,
            "confidence_score": self.confidence_score,
            "processing_time_ms": self.processing_time_ms,
            "reason": self.reason,
            "model_used": self.model_used,
            "extracted_entities": self.extracted_entities.to_dict() if self.extracted_entities else None,
            "question_type": self.question_type,
            "clarification_mode": self.clarification_mode.value if self.clarification_mode else None,
            "clarification_state": self.clarification_state.value if self.clarification_state else None,
            "missing_critical_info": self.missing_critical_info,
            "should_reprocess": self.should_reprocess,
            "original_question": self.original_question,
            "validation_score": self.validation_score,
            "validation_details": self.validation_details,
            "fallback_used": self.fallback_used,
            "gpt_failed": self.gpt_failed
        }

class EnhancedQuestionClarificationSystem:
    """
    Syst√®me de clarification intelligent AM√âLIOR√â avec validation GPT robuste int√©gr√©e
    """
    
    def __init__(self):
        """Initialise le syst√®me avec configuration am√©lior√©e"""
        
        if SETTINGS_AVAILABLE and settings:
            self.enabled = getattr(settings, 'clarification_system_enabled', True)
            self.model = getattr(settings, 'clarification_model', 'gpt-4o-mini')
            self.timeout = getattr(settings, 'clarification_timeout', 25)
            self.max_questions = getattr(settings, 'clarification_max_questions', 3)
            self.min_question_length = getattr(settings, 'clarification_min_length', 15)
            self.log_all_clarifications = getattr(settings, 'clarification_log_all', True)
            self.confidence_threshold = getattr(settings, 'clarification_confidence_threshold', 0.7)
            
            self.clarification_mode = ClarificationMode(getattr(settings, 'clarification_mode', 'adaptive'))
            self.smart_entity_extraction = getattr(settings, 'smart_entity_extraction', True)
            self.auto_reprocess_after_clarification = getattr(settings, 'auto_reprocess_after_clarification', True)
            self.adaptive_question_count = getattr(settings, 'adaptive_question_count', True)
            self.intelligent_missing_detection = getattr(settings, 'intelligent_missing_detection', True)
            
            self.enable_semantic_dynamic = getattr(settings, 'enable_semantic_dynamic_clarification', True)
            self.semantic_dynamic_max_questions = getattr(settings, 'semantic_dynamic_max_questions', 4)
            
            # üîß NOUVEAU: Configuration validation GPT robuste
            self.enable_question_validation = getattr(settings, 'enable_question_validation', True)
            self.validation_threshold = getattr(settings, 'validation_threshold', 0.5)
            self.enable_intelligent_fallback = getattr(settings, 'enable_intelligent_fallback', True)
        else:
            self.enabled = os.getenv('ENABLE_CLARIFICATION_SYSTEM', 'true').lower() == 'true'
            self.model = os.getenv('CLARIFICATION_MODEL', 'gpt-4o-mini')
            self.timeout = int(os.getenv('CLARIFICATION_TIMEOUT', '25'))
            self.max_questions = int(os.getenv('CLARIFICATION_MAX_QUESTIONS', '3'))
            self.min_question_length = int(os.getenv('CLARIFICATION_MIN_LENGTH', '15'))
            self.log_all_clarifications = os.getenv('LOG_ALL_CLARIFICATIONS', 'true').lower() == 'true'
            self.confidence_threshold = float(os.getenv('CLARIFICATION_CONFIDENCE_THRESHOLD', '0.7'))
            
            self.clarification_mode = ClarificationMode(os.getenv('CLARIFICATION_MODE', 'adaptive'))
            self.smart_entity_extraction = os.getenv('SMART_ENTITY_EXTRACTION', 'true').lower() == 'true'
            self.auto_reprocess_after_clarification = os.getenv('AUTO_REPROCESS_AFTER_CLARIFICATION', 'true').lower() == 'true'
            self.adaptive_question_count = os.getenv('ADAPTIVE_QUESTION_COUNT', 'true').lower() == 'true'
            self.intelligent_missing_detection = os.getenv('INTELLIGENT_MISSING_DETECTION', 'true').lower() == 'true'
            
            self.enable_semantic_dynamic = os.getenv('ENABLE_SEMANTIC_DYNAMIC_CLARIFICATION', 'true').lower() == 'true'
            self.semantic_dynamic_max_questions = int(os.getenv('SEMANTIC_DYNAMIC_MAX_QUESTIONS', '4'))
            
            # üîß NOUVEAU: Configuration validation GPT robuste
            self.enable_question_validation = os.getenv('ENABLE_QUESTION_VALIDATION', 'true').lower() == 'true'
            self.validation_threshold = float(os.getenv('VALIDATION_THRESHOLD', '0.5'))
            self.enable_intelligent_fallback = os.getenv('ENABLE_INTELLIGENT_FALLBACK', 'true').lower() == 'true'
        
           - Logs d√©taill√©s: m√©tadonn√©es validation + fallback + erreurs
logger.info("‚úÖ [EnhancedQuestionClarificationSystem] READY: Agent de clarification avec VALIDATION ROBUSTE + FALLBACK INTELLIGENT op√©rationnel!")(f"üîß [Enhanced Clarification] Mode: {self.clarification_mode.value}")
        logger.info(f"üîß [Enhanced Clarification] Extraction entit√©s: {'‚úÖ' if self.smart_entity_extraction else '‚ùå'}")
        logger.info(f"üîß [Enhanced Clarification] Auto-reprocess: {'‚úÖ' if self.auto_reprocess_after_clarification else '‚ùå'}")
        logger.info(f"üîß [Enhanced Clarification] Questions adaptatives: {'‚úÖ' if self.adaptive_question_count else '‚ùå'}")
        logger.info(f"üîß [Enhanced Clarification] Validation GPT robuste: {'‚úÖ' if self.enable_question_validation else '‚ùå'}")
        logger.info(f"üîß [Enhanced Clarification] Fallback intelligent: {'‚úÖ' if self.enable_intelligent_fallback else '‚ùå'}")
        logger.info(f"üÜï [Semantic Dynamic] Mode dynamique: {'‚úÖ' if self.enable_semantic_dynamic else '‚ùå'}")
        
        self._init_patterns()
        self._init_enhanced_prompts()
        self._init_clarification_logger()

    def _init_patterns(self):
        """Patterns de d√©tection am√©lior√©s"""
        
        # Races sp√©cifiques (identiques)
        self.specific_breed_patterns = {
            "fr": [
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro'
            ],
            "en": [
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro'
            ],
            "es": [
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro'
            ]
        }
        
        # ‚úÖ NOUVEAUX: Patterns pour classification de type de question
        self.question_type_patterns = {
            "growth": [r'croissance', r'growth', r'crecimiento', r'grossissent?', r'growing', r'crecen'],
            "weight": [r'poids', r'weight', r'peso', r'p√®sent?', r'weigh', r'pesan', r'grammes?', r'grams?', r'gramos?'],
            "mortality": [r'mortalit√©', r'mortality', r'mortalidad', r'meurent', r'dying', r'mueren', r'dead', r'muerte'],
            "health": [r'maladie', r'disease', r'enfermedad', r'malade', r'sick', r'enfermo', r'sant√©', r'health', r'salud'],
            "temperature": [r'temp√©rature', r'temperature', r'temperatura', r'chaud', r'hot', r'caliente', r'froid', r'cold', r'fr√≠o'],
            "feeding": [r'alimentation', r'feeding', r'alimentaci√≥n', r'nourriture', r'food', r'comida', r'aliment'],
            "environment": [r'environnement', r'environment', r'ambiente', r'ventilation', r'humidity', r'humidit√©'],
            "performance": [r'performance', r'rendement', r'efficacit√©', r'efficiency', r'eficiencia', r'conversion']
        }

    # üîß M√âTHODE COMPL√àTEMENT R√â√âCRITE: G√©n√©ration dynamique avec validation robuste int√©gr√©e
    def generate_dynamic_clarification_questions(self, user_question: str, language: str = "fr") -> Tuple[List[str], Dict[str, Any]]:
        """
        üÜï G√©n√®re jusqu'√† 4 questions de clarification via GPT avec validation robuste automatique
        üîß COMPL√àTEMENT R√â√âCRIT: Validation int√©gr√©e + fallback intelligent
        
        Returns:
            Tuple[List[str], Dict[str, Any]]: (questions_valid√©es, m√©tadonn√©es_validation)
        """
        
        validation_metadata = {
            "gpt_called": False,
            "gpt_success": False,
            "validation_performed": False,
            "validation_score": 0.0,
            "fallback_used": False,
            "fallback_reason": None,
            "questions_generated": 0,
            "questions_validated": 0
        }
        
        try:
            # Import dynamique du prompt template avec fallback
            try:
                from .prompt_templates import (
                    build_contextualization_prompt, 
                    validate_dynamic_questions,
                    get_dynamic_clarification_fallback_questions
                )
            except ImportError:
                logger.error("‚ùå [Semantic Dynamic] Impossible d'importer les templates - fallback direct")
                validation_metadata["fallback_used"] = True
                validation_metadata["fallback_reason"] = "import_error"
                fallback_questions = self._basic_fallback_questions(user_question, language)
                return fallback_questions, validation_metadata

            # V√©rifier disponibilit√© OpenAI
            if not OPENAI_AVAILABLE or not openai:
                logger.warning("‚ö†Ô∏è [Semantic Dynamic] OpenAI non disponible - fallback intelligent")
                validation_metadata["fallback_used"] = True
                validation_metadata["fallback_reason"] = "openai_unavailable"
                fallback_questions = get_dynamic_clarification_fallback_questions(user_question, language)
                return fallback_questions, validation_metadata

            # Configuration OpenAI
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                logger.warning("‚ö†Ô∏è [Semantic Dynamic] Cl√© API OpenAI manquante - fallback intelligent")
                validation_metadata["fallback_used"] = True
                validation_metadata["fallback_reason"] = "api_key_missing"
                fallback_questions = get_dynamic_clarification_fallback_questions(user_question, language)
                return fallback_questions, validation_metadata
            
            openai.api_key = api_key

            # Construire le prompt contextualis√© am√©lior√©
            prompt = build_contextualization_prompt(user_question, language)
            logger.info(f"ü§ñ [Clarification-Dynamique] Prompt g√©n√©r√© pour: '{user_question[:50]}...'")
            logger.debug(f"ü§ñ [Clarification-Dynamique] Prompt complet:\n{prompt}")

            # Appel GPT pour g√©n√©ration dynamique
            validation_metadata["gpt_called"] = True
            
            response = openai.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un expert en aviculture sp√©cialis√© dans la g√©n√©ration de questions pertinentes et pr√©cises."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=300,
                timeout=self.timeout
            )
            
            content = response.choices[0].message.content.strip()
            validation_metadata["gpt_success"] = True
            
            logger.info(f"ü§ñ [Clarification-Dynamique] R√©ponse brute re√ßue ({len(content)} chars)")
            logger.debug(f"ü§ñ [Clarification-Dynamique] Contenu: {content}")
            
            # Parser la r√©ponse JSON avec fallback am√©lior√©
            questions = []
            try:
                json_match = re.search(r'\{.*?\}', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                    data = json.loads(json_str)
                    questions = data.get("clarification_questions", [])
                    validation_metadata["questions_generated"] = len(questions)
                    
                    logger.info(f"ü§ñ [Clarification-Dynamique] {len(questions)} questions extraites du JSON")
                else:
                    logger.warning("‚ö†Ô∏è [Semantic Dynamic] Pas de JSON trouv√© - extraction texte libre")
                    questions = self._extract_questions_from_text(content, language)
                    validation_metadata["questions_generated"] = len(questions)
                    
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå [Semantic Dynamic] Erreur parsing JSON: {e}")
                logger.debug(f"Contenu probl√©matique: {content}")
                questions = self._extract_questions_from_text(content, language)
                validation_metadata["questions_generated"] = len(questions)
            
            # üîß NOUVEAU: Validation robuste des questions g√©n√©r√©es
            if self.enable_question_validation and questions:
                validation_metadata["validation_performed"] = True
                
                validation_result = validate_dynamic_questions(questions, user_question, language)
                validation_metadata["validation_score"] = validation_result.get("quality_score", 0.0)
                
                logger.info(f"üîß [Question Validation] Score qualit√©: {validation_metadata['validation_score']:.2f}")
                logger.info(f"üîß [Question Validation] Questions valides: {len(validation_result.get('valid_questions', []))}/{len(questions)}")
                
                # V√©rifier si validation √©choue
                if validation_metadata["validation_score"] < self.validation_threshold:
                    logger.warning(f"‚ö†Ô∏è [Question Validation] Score trop bas ({validation_metadata['validation_score']:.2f} < {self.validation_threshold})")
                    
                    valid_questions = validation_result.get("valid_questions", [])
                    if valid_questions and len(valid_questions) >= 1:
                        logger.info(f"üîß [Question Validation] Utilisation des {len(valid_questions)} questions valides")
                        questions = valid_questions[:self.semantic_dynamic_max_questions]
                        validation_metadata["questions_validated"] = len(questions)
                    else:
                        logger.warning("‚ö†Ô∏è [Question Validation] Aucune question valide - fallback intelligent")
                        if self.enable_intelligent_fallback:
                            validation_metadata["fallback_used"] = True
                            validation_metadata["fallback_reason"] = "validation_failed"
                            fallback_questions = get_dynamic_clarification_fallback_questions(user_question, language)
                            return fallback_questions, validation_metadata
                        else:
                            questions = []
                else:
                    # Validation r√©ussie - utiliser les questions valides
                    questions = validation_result.get("valid_questions", questions)[:self.semantic_dynamic_max_questions]
                    validation_metadata["questions_validated"] = len(questions)
                    
            else:
                # Pas de validation - nettoyage basique
                cleaned_questions = []
                for q in questions[:self.semantic_dynamic_max_questions]:
                    if isinstance(q, str) and len(q.strip()) > 10:
                        cleaned_q = q.strip()
                        if not cleaned_q.endswith('?'):
                            cleaned_q += ' ?'
                        cleaned_questions.append(cleaned_q)
                questions = cleaned_questions
                validation_metadata["questions_validated"] = len(questions)
            
            if questions:
                logger.info(f"‚úÖ [Semantic Dynamic] {len(questions)} questions g√©n√©r√©es et valid√©es avec succ√®s")
                return questions, validation_metadata
            else:
                logger.warning("‚ö†Ô∏è [Semantic Dynamic] Aucune question finale valide - fallback intelligent")
                if self.enable_intelligent_fallback:
                    validation_metadata["fallback_used"] = True
                    validation_metadata["fallback_reason"] = "no_final_questions"
                    fallback_questions = get_dynamic_clarification_fallback_questions(user_question, language)
                    return fallback_questions, validation_metadata
                else:
                    return [], validation_metadata
            
        except Exception as e:
            logger.error(f"‚ùå [Semantic Dynamic] Erreur g√©n√©ration questions de clarification: {e}")
            validation_metadata["fallback_used"] = True
            validation_metadata["fallback_reason"] = f"exception: {str(e)}"
            
            if self.enable_intelligent_fallback:
                try:
                    from .prompt_templates import get_dynamic_clarification_fallback_questions
                    fallback_questions = get_dynamic_clarification_fallback_questions(user_question, language)
                    return fallback_questions, validation_metadata
                except ImportError:
                    return self._basic_fallback_questions(user_question, language), validation_metadata
            else:
                return [], validation_metadata

    def _extract_questions_from_text(self, text: str, language: str) -> List[str]:
        """Extrait les questions depuis un texte libre si JSON parsing √©choue (AM√âLIOR√â)"""
        
        questions = []
        lines = text.split('\n')
        
        # Mots-cl√©s de questions par langue pour validation
        question_keywords = {
            "fr": ['quel', 'quelle', 'comment', 'combien', 'o√π', 'quand', 'pourquoi', 'depuis quand'],
            "en": ['what', 'how', 'which', 'where', 'when', 'why', 'how long', 'what type'],
            "es": ['qu√©', 'cu√°l', 'c√≥mo', 'd√≥nde', 'cu√°ndo', 'por qu√©', 'cu√°nto tiempo', 'qu√© tipo']
        }
        
        keywords = question_keywords.get(language, question_keywords["fr"])
        
        for line in lines:
            line = line.strip()
            
            # V√©rifier que la ligne ressemble √† une question
            if ('?' in line or 
                any(word in line.lower() for word in keywords)):
                
                # Nettoyer la ligne
                cleaned = re.sub(r'^[-‚Ä¢*\d]+\.?\s*', '', line)  # Supprimer puces/num√©ros
                cleaned = cleaned.strip()
                
                # V√©rifications de qualit√© am√©lior√©es
                if (len(cleaned) > 15 and 
                    len(cleaned) < 150 and 
                    len(questions) < self.semantic_dynamic_max_questions and
                    cleaned not in questions):
                    
                    # √âviter les questions trop g√©n√©riques
                    generic_words = ['exemple', 'example', 'ejemplo', 'etc', 'g√©n√©ralement', 'usually']
                    if not any(generic in cleaned.lower() for generic in generic_words):
                        if not cleaned.endswith('?'):
                            cleaned += ' ?'
                        questions.append(cleaned)
        
        logger.info(f"üìù [Semantic Dynamic] Questions extraites du texte libre: {len(questions)}")
        return questions

    def _basic_fallback_questions(self, user_question: str, language: str) -> List[str]:
        """Questions de fallback basiques si tout √©choue (NOUVEAU)"""
        
        basic_fallbacks = {
            "fr": [
                "Pouvez-vous pr√©ciser la race ou souche de vos volailles ?",
                "Quel √¢ge ont actuellement vos animaux ?", 
                "Dans quel contexte d'√©levage vous trouvez-vous ?"
            ],
            "en": [
                "Could you specify the breed or strain of your poultry?",
                "What age are your animals currently?",
                "What farming context are you in?"
            ],
            "es": [
                "¬øPodr√≠a especificar la raza o cepa de sus aves?",
                "¬øQu√© edad tienen actualmente sus animales?",
                "¬øEn qu√© contexto de cr√≠a se encuentra?"
            ]
        }
        
        questions = basic_fallbacks.get(language, basic_fallbacks["fr"])
        logger.info(f"üîÑ [Fallback Basique] Questions de base utilis√©es ({language}): {len(questions)}")
        return questions

    async def extract_entities_intelligent(self, question: str, language: str, conversation_context: Dict = None) -> ExtractedEntities:
        """‚úÖ NOUVEAU: Extraction intelligente d'entit√©s via OpenAI (CONSERV√â IDENTIQUE)"""
        
        if not self.smart_entity_extraction or not OPENAI_AVAILABLE or not openai:
            logger.warning("‚ö†Ô∏è [Enhanced Clarification] Extraction intelligente d√©sactiv√©e ou OpenAI indisponible")
            return await self._extract_entities_fallback(question, language)
        
        try:
            # Construire le contexte pour l'extraction
            context_info = ""
            if conversation_context:
                context_info = f"\n\nContexte conversationnel disponible:\n{json.dumps(conversation_context, ensure_ascii=False, indent=2)}"
            
            extraction_prompt = f"""Tu es un expert en extraction d'informations pour l'aviculture. Extrait TOUTES les informations pertinentes de cette question et du contexte.

Question: "{question}"{context_info}

CONSIGNE: Extrait les informations sous format JSON strict. Utilise null pour les valeurs manquantes.

```json
{{
  "breed": "race sp√©cifique (ex: Ross 308) ou null",
  "breed_type": "specific/generic/null",
  "age_days": nombre_jours_ou_null,
  "age_weeks": nombre_semaines_ou_null,
  "weight_grams": poids_grammes_ou_null,
  "mortality_rate": taux_mortalit√©_pourcentage_ou_null,
  "temperature": temp√©rature_celsius_ou_null,
  "humidity": humidit√©_pourcentage_ou_null,
  "housing_type": "type_b√¢timent_ou_null",
  "feed_type": "type_alimentation_ou_null",
  "flock_size": nombre_poulets_ou_null,
  "symptoms": ["sympt√¥me1", "sympt√¥me2"] ou null,
  "duration_problem": "dur√©e_probl√®me_ou_null",
  "previous_treatments": ["traitement1"] ou null
}}
```

IMPORTANT: 
- Si une race g√©n√©rique est mentionn√©e (poulet, volaille), breed_type = "generic"
- Si une race sp√©cifique est mentionn√©e (Ross 308), breed_type = "specific"
- Convertir les semaines en jours si n√©cessaire (1 semaine = 7 jours)
- √ätre tr√®s pr√©cis sur les valeurs num√©riques"""

            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return await self._extract_entities_fallback(question, language)
            
            openai.api_key = api_key
            
            response = openai.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un extracteur d'entit√©s expert en aviculture. R√©ponds uniquement avec du JSON valide."},
                    {"role": "user", "content": extraction_prompt}
                ],
                temperature=0.1,
                max_tokens=500,
                timeout=self.timeout
            )
            
            answer = response.choices[0].message.content.strip()
            
            # Extraire le JSON de la r√©ponse
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', answer, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Fallback: chercher directement du JSON
                json_match = re.search(r'\{.*\}', answer, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    logger.warning("‚ö†Ô∏è [Enhanced Clarification] Pas de JSON trouv√© dans la r√©ponse")
                    return await self._extract_entities_fallback(question, language)
            
            # Parser le JSON
            try:
                extracted_data = json.loads(json_str)
                
                # Convertir en ExtractedEntities
                entities = ExtractedEntities(
                    breed=extracted_data.get("breed"),
                    breed_type=extracted_data.get("breed_type"),
                    age_days=extracted_data.get("age_days"),
                    age_weeks=extracted_data.get("age_weeks"),
                    weight_grams=extracted_data.get("weight_grams"),
                    mortality_rate=extracted_data.get("mortality_rate"),
                    temperature=extracted_data.get("temperature"),
                    humidity=extracted_data.get("humidity"),
                    housing_type=extracted_data.get("housing_type"),
                    feed_type=extracted_data.get("feed_type"),
                    flock_size=extracted_data.get("flock_size"),
                    symptoms=extracted_data.get("symptoms"),
                    duration_problem=extracted_data.get("duration_problem"),
                    previous_treatments=extracted_data.get("previous_treatments")
                )
                
                logger.info(f"ü§ñ [Enhanced Clarification] Entit√©s extraites intelligemment: {entities.to_dict()}")
                return entities
                
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Erreur parsing JSON: {e}")
                return await self._extract_entities_fallback(question, language)
        
        except Exception as e:
            logger.error(f"‚ùå [Enhanced Clarification] Erreur extraction intelligente: {e}")
            return await self._extract_entities_fallback(question, language)

    async def _extract_entities_fallback(self, question: str, language: str) -> ExtractedEntities:
        """Extraction d'entit√©s fallback (r√®gles basiques) (CONSERV√â IDENTIQUE)"""
        
        entities = ExtractedEntities()
        question_lower = question.lower()
        
        # D√©tection race sp√©cifique
        specific_patterns = self.specific_breed_patterns.get(language, self.specific_breed_patterns["fr"])
        for pattern in specific_patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                entities.breed = match.group(0).strip()
                entities.breed_type = "specific"
                break
        
        # D√©tection race g√©n√©rique si pas sp√©cifique
        if not entities.breed:
            generic_patterns = [r'poulets?', r'volailles?', r'chickens?', r'poultry', r'pollos?', r'aves?']
            for pattern in generic_patterns:
                match = re.search(pattern, question_lower, re.IGNORECASE)
                if match:
                    entities.breed = match.group(0).strip()
                    entities.breed_type = "generic"
                    break
        
        # D√©tection √¢ge
        age_patterns = [
            r'(\d+)\s*jours?', r'(\d+)\s*days?', r'(\d+)\s*d√≠as?',
            r'(\d+)\s*semaines?', r'(\d+)\s*weeks?', r'(\d+)\s*semanas?',
            r'jour\s*(\d+)', r'day\s*(\d+)', r'd√≠a\s*(\d+)'
        ]
        
        for pattern in age_patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                value = int(match.group(1))
                if 'semaine' in pattern or 'week' in pattern or 'semana' in pattern:
                    entities.age_weeks = value
                    entities.age_days = value * 7
                else:
                    entities.age_days = value
                break
        
        # D√©tection poids
        weight_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:kg|gramm?es?|g|lbs?)',
            r'p√®sent?\s+(\d+(?:\.\d+)?)', r'weigh\s+(\d+(?:\.\d+)?)'
        ]
        
        for pattern in weight_patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                entities.weight_grams = float(match.group(1))
                break
        
        # D√©tection mortalit√©
        mortality_patterns = [
            r'mortalit√©\s+(?:de\s+)?(\d+(?:\.\d+)?)%?',
            r'mortality\s+(?:of\s+)?(\d+(?:\.\d+)?)%?',
            r'(\d+(?:\.\d+)?)%\s+mortalit[√©y]'
        ]
        
        for pattern in mortality_patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                entities.mortality_rate = float(match.group(1))
                break
        
        return entities

    def classify_question_type(self, question: str, language: str) -> str:
        """‚úÖ NOUVEAU: Classifie le type de question (CONSERV√â IDENTIQUE)"""
        
        question_lower = question.lower()
        
        for question_type, patterns in self.question_type_patterns.items():
            for pattern in patterns:
                if re.search(pattern, question_lower, re.IGNORECASE):
                    return question_type
        
        return "general"

    def _init_enhanced_prompts(self):
        """‚úÖ NOUVEAUX PROMPTS AM√âLIOR√âS avec gestion du contexte (CONSERV√â IDENTIQUE)"""
        
        self.clarification_prompts = {
            "fr": """Tu es un expert v√©t√©rinaire sp√©cialis√© en aviculture. Analyse cette question et le contexte pour d√©terminer si des clarifications sont n√©cessaires.

Question: "{question}"
Type de question d√©tect√©: {question_type}
Entit√©s extraites: {extracted_entities}
Contexte conversationnel: {conversation_context}
Informations critiques manquantes: {missing_info}

R√àGLES STRICTES:
1. Si TOUTES les informations critiques sont pr√©sentes ‚Üí r√©ponds "CLEAR"
2. Si des informations critiques manquent ‚Üí g√©n√®re des questions PR√âCISES
3. Adapte le nombre de questions au nombre d'informations manquantes
4. Priorise les informations les plus critiques pour ce type de question

INFORMATIONS CRITIQUES PAR TYPE:
- Questions de poids/croissance: race sp√©cifique + √¢ge OBLIGATOIRES
- Questions de sant√©/mortalit√©: race + √¢ge + sympt√¥mes
- Questions d'environnement: race + √¢ge + conditions actuelles
- Questions d'alimentation: race + √¢ge + type d'aliment actuel

Si clarification n√©cessaire, pose des questions TR√àS SP√âCIFIQUES:
- Pour la race: "Quelle race/lign√©e exacte (Ross 308, Cobb 500, etc.) ?"
- Pour l'√¢ge: "Quel √¢ge exact en jours ?"
- Pour les sympt√¥mes: "Quels sympt√¥mes pr√©cis observez-vous ?"

IMPORTANT: 
- Ne pose QUE les questions pour les informations vraiment manquantes
- Utilise le contexte conversationnel pour √©viter de redemander des infos d√©j√† connues
- Sois tr√®s pr√©cis dans tes questions

Format: soit "CLEAR" soit liste de questions avec tirets.""",

            "en": """You are a veterinary expert specialized in poultry farming. Analyze this question and context to determine if clarifications are needed.

Question: "{question}"
Detected question type: {question_type}
Extracted entities: {extracted_entities}
Conversational context: {conversation_context}
Missing critical information: {missing_info}

STRICT RULES:
1. If ALL critical information is present ‚Üí answer "CLEAR"
2. If critical information is missing ‚Üí generate PRECISE questions
3. Adapt number of questions to missing information count
4. Prioritize most critical information for this question type

CRITICAL INFORMATION BY TYPE:
- Weight/growth questions: specific breed + age MANDATORY
- Health/mortality questions: breed + age + symptoms
- Environment questions: breed + age + current conditions
- Feeding questions: breed + age + current feed type

If clarification needed, ask VERY SPECIFIC questions:
- For breed: "What exact breed/line (Ross 308, Cobb 500, etc.)?"
- For age: "What exact age in days?"
- For symptoms: "What specific symptoms do you observe?"

IMPORTANT:
- Only ask questions for truly missing information
- Use conversational context to avoid re-asking known information
- Be very precise in your questions

Format: either "CLEAR" or bulleted question list.""",

            "es": """Eres un experto veterinario especializado en avicultura. Analiza esta pregunta y contexto para determinar si se necesitan aclaraciones.

Pregunta: "{question}"
Tipo de pregunta detectado: {question_type}
Entidades extra√≠das: {extracted_entities}
Contexto conversacional: {conversation_context}
Informaci√≥n cr√≠tica faltante: {missing_info}

REGLAS ESTRICTAS:
1. Si TODA la informaci√≥n cr√≠tica est√° presente ‚Üí responde "CLEAR"
2. Si falta informaci√≥n cr√≠tica ‚Üí genera preguntas PRECISAS
3. Adapta el n√∫mero de preguntas a la informaci√≥n faltante
4. Prioriza la informaci√≥n m√°s cr√≠tica para este tipo de pregunta

INFORMACI√ìN CR√çTICA POR TIPO:
- Preguntas peso/crecimiento: raza espec√≠fica + edad OBLIGATORIAS
- Preguntas salud/mortalidad: raza + edad + s√≠ntomas
- Preguntas ambiente: raza + edad + condiciones actuales
- Preguntas alimentaci√≥n: raza + edad + tipo alimento actual

Si necesita aclaraci√≥n, haz preguntas MUY ESPEC√çFICAS:
- Para raza: "¬øQu√© raza/l√≠nea exacta (Ross 308, Cobb 500, etc.)?"
- Para edad: "¬øQu√© edad exacta en d√≠as?"
- Para s√≠ntomas: "¬øQu√© s√≠ntomas espec√≠ficos observa?"

IMPORTANTE:
- Solo pregunta por informaci√≥n realmente faltante
- Usa el contexto conversacional para evitar preguntar informaci√≥n ya conocida
- S√© muy preciso en tus preguntas

Formato: "CLEAR" o lista de preguntas con guiones."""
        }

    def _init_clarification_logger(self):
        """Initialise le logger sp√©cialis√© pour les clarifications (CONSERV√â IDENTIQUE)"""
        self.clarification_logger = logging.getLogger("enhanced_question_clarification")
        self.clarification_logger.setLevel(logging.INFO)
        
        if not self.clarification_logger.handlers and self.log_all_clarifications:
            try:
                from logging.handlers import RotatingFileHandler
                
                log_dir = os.getenv('VALIDATION_LOGS_DIR', 'logs')
                os.makedirs(log_dir, exist_ok=True)
                
                log_file_path = os.path.join(log_dir, 'enhanced_question_clarifications.log')
                clarification_handler = RotatingFileHandler(
                    log_file_path,
                    maxBytes=int(os.getenv('VALIDATION_LOG_MAX_SIZE', '10485760')),
                    backupCount=int(os.getenv('VALIDATION_LOG_BACKUP_COUNT', '5'))
                )
                clarification_formatter = logging.Formatter(
                    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
                )
                clarification_handler.setFormatter(clarification_formatter)
                self.clarification_logger.addHandler(clarification_handler)
                
                logger.info(f"‚úÖ [Enhanced Clarification] Logger configur√©: {log_file_path}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Impossible de cr√©er le fichier de log: {e}")

    async def analyze_question_enhanced(
        self, 
        question: str, 
        language: str = "fr",
        user_id: str = "unknown",
        conversation_id: str = None,
        conversation_context: Dict = None,
        original_question: str = None,
        mode: str = None
    ) -> ClarificationResult:
        """
        ‚úÖ ANALYSE AM√âLIOR√âE avec extraction intelligente et gestion du contexte
        üÜï NOUVEAU: Support mode s√©mantique dynamique
        üîß AM√âLIOR√â: Gestion compl√®te des erreurs avec validation robuste
        """
        
        start_time = time.time()
        
        if not self.enabled:
            logger.info(f"üîß [Enhanced Clarification] Syst√®me d√©sactiv√©")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="system_disabled",
                clarification_state=ClarificationState.NONE
            )
        
        if not question or len(question.strip()) < self.min_question_length:
            logger.info(f"‚ö†Ô∏è [Enhanced Clarification] Question trop courte: {len(question)}")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="question_too_short",
                clarification_state=ClarificationState.NONE
            )
        
        # ‚úÖ NOUVEAU: Classification du type de question
        question_type = self.classify_question_type(question, language)
        logger.info(f"üè∑Ô∏è [Enhanced Clarification] Type de question: {question_type}")
        
        # ‚úÖ NOUVEAU: Extraction intelligente d'entit√©s
        extracted_entities = await self.extract_entities_intelligent(
            question, 
            language, 
            conversation_context
        )
        
        logger.info(f"üîç [Enhanced Clarification] Analyse: '{question[:80]}...'")
        logger.info(f"üìä [Enhanced Clarification] Entit√©s extraites: {extracted_entities.to_dict()}")
        
        # üÜï NOUVEAU: Gestion du mode s√©mantique dynamique avec validation robuste
        if (mode == "semantic_dynamic" or 
            self.clarification_mode == ClarificationMode.SEMANTIC_DYNAMIC) and \
           self.enable_semantic_dynamic:
            
            logger.info(f"üéØ [Semantic Dynamic] Mode activ√© pour: '{question[:50]}...'")
            
            # G√©n√©rer questions dynamiques avec m√©tadonn√©es de validation
            dynamic_questions, validation_metadata = self.generate_dynamic_clarification_questions(question, language)
            
            if dynamic_questions:
                processing_time_ms = int((time.time() - start_time) * 1000)
                
                result = ClarificationResult(
                    needs_clarification=True,
                    questions=dynamic_questions,
                    processing_time_ms=processing_time_ms,
                    reason="semantic_dynamic_clarification_generated",
                    model_used=f"{self.model}_semantic_dynamic",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=ClarificationMode.SEMANTIC_DYNAMIC,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=["context_understanding"],
                    confidence_score=0.9,
                    original_question=original_question or question,
                    validation_score=validation_metadata.get("validation_score", 0.8),
                    validation_details=validation_metadata,
                    fallback_used=validation_metadata.get("fallback_used", False),
                    gpt_failed=not validation_metadata.get("gpt_success", False)
                )
                
                logger.info(f"‚úÖ [Semantic Dynamic] {len(dynamic_questions)} questions g√©n√©r√©es dynamiquement")
                logger.info(f"üîß [Validation Metadata] GPT: {'‚úÖ' if validation_metadata.get('gpt_success') else '‚ùå'}, " +
                           f"Validation: {'‚úÖ' if validation_metadata.get('validation_performed') else '‚ùå'}, " +
                           f"Fallback: {'‚úÖ' if validation_metadata.get('fallback_used') else '‚ùå'}")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            else:
                logger.warning("‚ö†Ô∏è [Semantic Dynamic] Aucune question g√©n√©r√©e, fallback vers mode normal")
        
        # ‚úÖ NOUVEAU: D√©terminer les informations critiques manquantes
        missing_critical_info = extracted_entities.get_missing_critical_info(question_type)
        logger.info(f"‚ùå [Enhanced Clarification] Informations critiques manquantes: {missing_critical_info}")
        
        # ‚úÖ NOUVEAU: Logique de clarification intelligente
        if extracted_entities.breed_type == "generic":
            logger.info(f"üö® [Enhanced Clarification] Race g√©n√©rique d√©tect√©e - clarification obligatoire")
            
            generic_questions = self._generate_adaptive_clarification_questions(
                language, missing_critical_info, question_type
            )
            
            return ClarificationResult(
                needs_clarification=True,
                questions=generic_questions,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="generic_breed_detected",
                model_used="rule_based_enhanced",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_mode=self.clarification_mode,
                clarification_state=ClarificationState.NEEDED,
                missing_critical_info=missing_critical_info,
                confidence_score=95.0,
                original_question=original_question or question,
                validation_score=0.9,
                fallback_used=False,
                gpt_failed=False
            )
        
        # ‚úÖ NOUVEAU: Si race sp√©cifique + √¢ge pr√©sents = OK
        if extracted_entities.breed_type == "specific" and (extracted_entities.age_days or extracted_entities.age_weeks):
            logger.info(f"‚úÖ [Enhanced Clarification] Race sp√©cifique + √¢ge - question compl√®te")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="specific_breed_and_age_detected",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_state=ClarificationState.NONE,
                validation_score=1.0,
                fallback_used=False,
                gpt_failed=False
            )
        
        # ‚úÖ NOUVEAU: Si pas d'informations critiques manquantes
        if not missing_critical_info:
            logger.info(f"‚úÖ [Enhanced Clarification] Toutes les informations critiques pr√©sentes")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="all_critical_info_present",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_state=ClarificationState.NONE,
                validation_score=1.0,
                fallback_used=False,
                gpt_failed=False
            )
        
        # ‚úÖ ANALYSE VIA OpenAI pour les cas complexes avec gestion d'erreur robuste
        if not OPENAI_AVAILABLE or not openai:
            logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] OpenAI non disponible - fallback vers questions adaptatives")
            
            adaptive_questions = self._generate_adaptive_clarification_questions(
                language, missing_critical_info, question_type
            )
            
            return ClarificationResult(
                needs_clarification=True,
                questions=adaptive_questions,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="openai_unavailable_adaptive_fallback",
                model_used="rule_based_adaptive",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_mode=self.clarification_mode,
                clarification_state=ClarificationState.NEEDED,
                missing_critical_info=missing_critical_info,
                confidence_score=0.7,
                original_question=original_question or question,
                validation_score=0.8,
                fallback_used=True,
                gpt_failed=True
            )
        
        try:
            # ‚úÖ Configuration OpenAI avec gestion d'erreur
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Cl√© API OpenAI manquante - fallback adaptatif")
                
                adaptive_questions = self._generate_adaptive_clarification_questions(
                    language, missing_critical_info, question_type
                )
                
                return ClarificationResult(
                    needs_clarification=True,
                    questions=adaptive_questions,
                    processing_time_ms=int((time.time() - start_time) * 1000),
                    reason="openai_key_missing_adaptive_fallback",
                    model_used="rule_based_adaptive",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=self.clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    confidence_score=0.7,
                    original_question=original_question or question,
                    validation_score=0.8,
                    fallback_used=True,
                    gpt_failed=True
                )
            
            openai.api_key = api_key
            
            # ‚úÖ PROMPT ENRICHI avec toutes les informations
            prompt_template = self.clarification_prompts.get(language.lower(), self.clarification_prompts["fr"])
            
            context_str = json.dumps(conversation_context, ensure_ascii=False) if conversation_context else "Aucun contexte"
            entities_str = json.dumps(extracted_entities.to_dict(), ensure_ascii=False)
            missing_info_str = ", ".join(missing_critical_info) if missing_critical_info else "Aucune"
            
            user_prompt = prompt_template.format(
                question=question,
                question_type=question_type,
                extracted_entities=entities_str,
                conversation_context=context_str,
                missing_info=missing_info_str
            )
            
            system_prompt = f"""Tu es un assistant expert qui d√©termine si une question d'aviculture n√©cessite des clarifications. 

Mode de clarification: {self.clarification_mode.value}
Questions adaptatives: {'activ√©es' if self.adaptive_question_count else 'd√©sactiv√©es'}

Sois tr√®s pr√©cis et utilise intelligemment le contexte conversationnel pour √©viter les questions redondantes."""
            
            # ‚úÖ Appel OpenAI enrichi
            logger.info(f"ü§ñ [Enhanced Clarification] Appel GPT-4o-mini enrichi...")
            
            response = openai.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=400,
                timeout=self.timeout
            )
            
            answer = response.choices[0].message.content.strip()
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            logger.info(f"ü§ñ [Enhanced Clarification] R√©ponse GPT-4o-mini ({processing_time_ms}ms): {answer[:100]}...")
            
            # Analyse de la r√©ponse
            if answer.upper().strip() in ["CLEAR", "CLEAR.", "CLEAR !"]:
                result = ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason="question_clear_by_gpt4o_mini_enhanced",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    validation_score=1.0,
                    fallback_used=False,
                    gpt_failed=False
                )
                
                logger.info(f"‚úÖ [Enhanced Clarification] Question claire selon GPT-4o-mini enrichi")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            
            # Extraire les questions de clarification
            clarification_questions = self._extract_questions(answer)
            
            # ‚úÖ NOUVEAU: Limitation adaptative du nombre de questions
            if self.adaptive_question_count:
                max_questions = min(len(missing_critical_info) + 1, self.max_questions)
            else:
                max_questions = self.max_questions
            
            if clarification_questions and len(clarification_questions) > 0:
                limited_questions = clarification_questions[:max_questions]
                
                # ‚úÖ NOUVEAU: Mode de clarification
                clarification_mode = self.clarification_mode
                if clarification_mode == ClarificationMode.ADAPTIVE:
                    clarification_mode = ClarificationMode.INTERACTIVE if len(limited_questions) == 1 else ClarificationMode.BATCH
                
                result = ClarificationResult(
                    needs_clarification=True,
                    questions=limited_questions,
                    processing_time_ms=processing_time_ms,
                    reason="clarification_needed_by_gpt4o_mini_enhanced",
                    model_used=self.model,
                    confidence_score=self._calculate_confidence_score_enhanced(question, limited_questions, extracted_entities, question_type),
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    original_question=original_question or question,
                    validation_score=0.8,  # Score par d√©faut pour questions GPT
                    fallback_used=False,
                    gpt_failed=False
                )
                
                logger.info(f"‚ùì [Enhanced Clarification] {len(limited_questions)} questions g√©n√©r√©es (mode: {clarification_mode.value})")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            else:
                logger.info(f"‚úÖ [Enhanced Clarification] Aucune question valide - question suffisante")
                return ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason="no_valid_questions_from_gpt4o_mini_enhanced",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    validation_score=1.0,
                    fallback_used=False,
                    gpt_failed=False
                )
        
        except Exception as e:
            processing_time_ms = int((time.time() - start_time) * 1000)
            logger.error(f"‚ùå [Enhanced Clarification] Erreur GPT-4o-mini: {e}")
            
            # üîß NOUVEAU: Fallback intelligent en cas d'erreur GPT
            if self.enable_intelligent_fallback:
                logger.info(f"üîÑ [Enhanced Clarification] Fallback intelligent activ√© suite √† erreur GPT")
                
                adaptive_questions = self._generate_adaptive_clarification_questions(
                    language, missing_critical_info, question_type
                )
                
                return ClarificationResult(
                    needs_clarification=True,
                    questions=adaptive_questions,
                    processing_time_ms=processing_time_ms,
                    reason=f"gpt_error_intelligent_fallback: {str(e)}",
                    model_used="rule_based_adaptive_fallback",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=self.clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    confidence_score=0.6,
                    original_question=original_question or question,
                    validation_score=0.7,
                    fallback_used=True,
                    gpt_failed=True
                )
            else:
                return ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason=f"error_gpt4o_mini_enhanced: {str(e)}",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    fallback_used=False,
                    gpt_failed=True
                )

    def _generate_adaptive_clarification_questions(
        self, 
        language: str, 
        missing_info: List[str], 
        question_type: str
    ) -> List[str]:
        """‚úÖ NOUVEAU: G√©n√®re des questions adaptatives selon les informations manquantes (CONSERV√â IDENTIQUE)"""
        
        question_templates = {
            "fr": {
                "breed": "Quelle est la race/lign√©e exacte de vos poulets (Ross 308, Cobb 500, Hubbard, etc.) ?",
                "age": "Quel √¢ge ont-ils actuellement (en jours pr√©cis) ?",
                "symptoms": "Quels sympt√¥mes sp√©cifiques observez-vous ?",
                "housing": "Dans quel type d'√©levage sont-ils log√©s (b√¢timent ferm√©, semi-ouvert, plein air) ?",
                "feed": "Quel type d'alimentation utilisez-vous actuellement ?",
                "duration": "Depuis combien de temps observez-vous ce probl√®me ?",
                "conditions": "Quelles sont les conditions environnementales actuelles (temp√©rature, humidit√©) ?"
            },
            "en": {
                "breed": "What is the exact breed/line of your chickens (Ross 308, Cobb 500, Hubbard, etc.)?",
                "age": "How old are they currently (in precise days)?",
                "symptoms": "What specific symptoms do you observe?",
                "housing": "What type of housing are they in (closed building, semi-open, free-range)?",
                "feed": "What type of feed are you currently using?",
                "duration": "How long have you been observing this problem?",
                "conditions": "What are the current environmental conditions (temperature, humidity)?"
            },
            "es": {
                "breed": "¬øCu√°l es la raza/l√≠nea exacta de sus pollos (Ross 308, Cobb 500, Hubbard, etc.)?",
                "age": "¬øQu√© edad tienen actualmente (en d√≠as precisos)?",
                "symptoms": "¬øQu√© s√≠ntomas espec√≠ficos observa?",
                "housing": "¬øEn qu√© tipo de alojamiento est√°n (edificio cerrado, semi-abierto, campo libre)?",
                "feed": "¬øQu√© tipo de alimentaci√≥n est√° usando actualmente?",
                "duration": "¬øDesde cu√°ndo observa este problema?",
                "conditions": "¬øCu√°les son las condiciones ambientales actuales (temperatura, humedad)?"
            }
        }
        
        templates = question_templates.get(language, question_templates["fr"])
        questions = []
        
        # Priorise selon le type de question
        priority_mapping = {
            "growth": ["breed", "age"],
            "weight": ["breed", "age"],
            "health": ["breed", "age", "symptoms"],
            "mortality": ["breed", "age", "symptoms", "duration"],
            "environment": ["breed", "age", "conditions"],
            "feeding": ["breed", "age", "feed"],
            "performance": ["breed", "age"]
        }
        
        priority_order = priority_mapping.get(question_type, ["breed", "age"])
        
        # Ajouter les questions dans l'ordre de priorit√©
        for info_type in priority_order:
            if info_type in missing_info and info_type in templates:
                questions.append(templates[info_type])
        
        # Ajouter les autres informations manquantes
        for info_type in missing_info:
            if info_type in templates and templates[info_type] not in questions:
                questions.append(templates[info_type])
        
        return questions[:self.max_questions]

    def _extract_questions(self, answer: str) -> List[str]:
        """Extrait les questions de clarification de la r√©ponse GPT (CONSERV√â IDENTIQUE)"""
        questions = []
        lines = answer.splitlines()
        
        for line in lines:
            line = line.strip()
            if line and len(line) > 15:
                # Nettoyer les puces et formatage
                cleaned_line = re.sub(r'^[-‚Ä¢*]\s*', '', line)
                cleaned_line = re.sub(r'^\d+\.\s*', '', cleaned_line)
                cleaned_line = cleaned_line.strip()
                
                # V√©rifier que c'est une vraie question
                if cleaned_line and len(cleaned_line) > 20 and cleaned_line not in questions:
                    # Ajouter un point d'interrogation si manquant
                    if not cleaned_line.endswith('?') and not cleaned_line.endswith(' ?'):
                        if any(word in cleaned_line.lower() for word in ['quel', 'quelle', 'combien', 'comment', 'what', 'how', 'which', 'cu√°l', 'c√≥mo', 'cu√°nto']):
                            cleaned_line += ' ?'
                    
                    questions.append(cleaned_line)
        
        return questions

    def _calculate_confidence_score_enhanced(
        self, 
        original_question: str, 
        clarification_questions: List[str], 
        extracted_entities: ExtractedEntities,
        question_type: str
    ) -> float:
        """‚úÖ AM√âLIOR√â: Score de confiance plus intelligent avec entit√©s (CONSERV√â IDENTIQUE)"""
        
        # Score de base
        base_score = min(len(clarification_questions) * 20, 70)
        
        # Bonus pour informations g√©n√©riques d√©tect√©es
        if extracted_entities.breed_type == "generic":
            base_score += 20
        
        # Bonus selon le type de question et informations manquantes
        critical_info_bonus = {
            "growth": 15 if not extracted_entities.age_days else 0,
            "weight": 15 if not extracted_entities.age_days else 0,
            "health": 10 if not extracted_entities.symptoms else 0,
            "mortality": 15 if not extracted_entities.mortality_rate else 0
        }
        
        base_score += critical_info_bonus.get(question_type, 5)
        
        # Malus si beaucoup d'informations d√©j√† pr√©sentes
        extracted_count = len([v for v in extracted_entities.to_dict().values() if v is not None])
        if extracted_count > 3:
            base_score -= 10
        
        return min(base_score, 95.0)

    async def check_for_reprocessing(
        self,
        conversation_id: str,
        user_response: str,
        original_clarification_result: ClarificationResult
    ) -> Optional[ClarificationResult]:
        """
        ‚úÖ NOUVEAU: V√©rifie si la question originale peut √™tre retrait√©e apr√®s clarification (CONSERV√â IDENTIQUE)
        """
        
        if not self.auto_reprocess_after_clarification:
            return None
        
        if not original_clarification_result.original_question:
            return None
        
        logger.info(f"üîÑ [Enhanced Clarification] V√©rification retraitement apr√®s clarification")
        
        # Construire la question enrichie
        enriched_question = f"{original_clarification_result.original_question}\n\nInformation suppl√©mentaire: {user_response}"
        
        # R√©analyser avec le contexte enrichi
        reprocess_result = await self.analyze_question_enhanced(
            question=enriched_question,
            language="fr",  # √Ä am√©liorer: r√©cup√©rer la langue du contexte
            conversation_id=conversation_id,
            original_question=original_clarification_result.original_question
        )
        
        if not reprocess_result.needs_clarification:
            reprocess_result.should_reprocess = True
            reprocess_result.clarification_state = ClarificationState.AWAITING_REPROCESS
            logger.info(f"‚úÖ [Enhanced Clarification] Question pr√™te pour retraitement")
            return reprocess_result
        
        logger.info(f"‚ö†Ô∏è [Enhanced Clarification] Clarification suppl√©mentaire encore n√©cessaire")
        return None

    def format_clarification_response_enhanced(
        self, 
        result: ClarificationResult,
        language: str
    ) -> str:
        """‚úÖ NOUVEAU: Formatage enrichi selon le mode de clarification (CONSERV√â IDENTIQUE)"""
        
        if not result.questions:
            return ""
        
        intros = {
            "fr": {
                ClarificationMode.BATCH: "‚ùì Pour vous donner la r√©ponse la plus pr√©cise possible, j'aurais besoin de quelques informations suppl√©mentaires :",
                ClarificationMode.INTERACTIVE: "‚ùì Pour vous aider au mieux, puis-je vous poser une question rapide :",
                ClarificationMode.ADAPTIVE: "‚ùì J'ai besoin d'une pr√©cision pour vous donner une r√©ponse adapt√©e :",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì Pour mieux comprendre votre situation et vous aider efficacement :"
            },
            "en": {
                ClarificationMode.BATCH: "‚ùì To give you the most accurate answer possible, I would need some additional information:",
                ClarificationMode.INTERACTIVE: "‚ùì To help you best, may I ask you a quick question:",
                ClarificationMode.ADAPTIVE: "‚ùì I need clarification to give you a tailored answer:",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì To better understand your situation and help you effectively:"
            },
            "es": {
                ClarificationMode.BATCH: "‚ùì Para darle la respuesta m√°s precisa posible, necesitar√≠a informaci√≥n adicional:",
                ClarificationMode.INTERACTIVE: "‚ùì Para ayudarle mejor, ¬øpuedo hacerle una pregunta r√°pida:",
                ClarificationMode.ADAPTIVE: "‚ùì Necesito una aclaraci√≥n para darle una respuesta adaptada:",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì Para entender mejor su situaci√≥n y ayudarle efectivamente:"
            }
        }
        
        outros = {
            "fr": {
                ClarificationMode.BATCH: "\n\nCes pr√©cisions m'aideront √† vous donner des conseils sp√©cifiques et adapt√©s √† votre situation ! üêî",
                ClarificationMode.INTERACTIVE: "\n\nMerci pour votre pr√©cision ! üêî",
                ClarificationMode.ADAPTIVE: "\n\nCela m'aidera √† vous donner une r√©ponse plus pr√©cise ! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\nCela me permettra de vous donner les conseils les plus pertinents ! üêî"
            },
            "en": {
                ClarificationMode.BATCH: "\n\nThese details will help me give you specific advice tailored to your situation! üêî",
                ClarificationMode.INTERACTIVE: "\n\nThank you for the clarification! üêî",
                ClarificationMode.ADAPTIVE: "\n\nThis will help me give you a more precise answer! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\nThis will allow me to give you the most relevant advice! üêî"
            },
            "es": {
                ClarificationMode.BATCH: "\n\n¬°Estos detalles me ayudar√°n a darle consejos espec√≠ficos adaptados a su situaci√≥n! üêî",
                ClarificationMode.INTERACTIVE: "\n\n¬°Gracias por la aclaraci√≥n! üêî",
                ClarificationMode.ADAPTIVE: "\n\n¬°Esto me ayudar√° a darle una respuesta m√°s precisa! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\n¬°Esto me permitir√° darle los consejos m√°s relevantes! üêî"
            }
        }
        
        mode = result.clarification_mode or ClarificationMode.BATCH
        intro = intros.get(language, intros["fr"]).get(mode, intros["fr"][ClarificationMode.BATCH])
        outro = outros.get(language, outros["fr"]).get(mode, outros["fr"][ClarificationMode.BATCH])
        
        if mode == ClarificationMode.INTERACTIVE or len(result.questions) == 1:
            # Mode interactif ou une seule question
            return f"{intro}\n\n{result.questions[0]}{outro}"
        else:
            # Mode batch - plusieurs questions
            formatted_questions = "\n".join([f"‚Ä¢ {q}" for q in result.questions])
            return f"{intro}\n\n{formatted_questions}{outro}"

    async def _log_clarification_decision(
        self,
        question: str,
        language: str,
        user_id: str,
        conversation_id: str,
        result: ClarificationResult
    ):
        """Log d√©taill√© des d√©cisions de clarification enrichi avec validation (AM√âLIOR√â)"""
        
        clarification_data = {
            "timestamp": datetime.now().isoformat(),
            "conversation_id": conversation_id,
            "user_id": user_id,
            "question": question,
            "question_length": len(question),
            "language": language,
            "result": result.to_dict(),
            "system_config": {
                "enabled": self.enabled,
                "model": self.model,
                "max_questions": self.max_questions,
                "confidence_threshold": self.confidence_threshold,
                "min_question_length": self.min_question_length,
                "clarification_mode": self.clarification_mode.value,
                "smart_entity_extraction": self.smart_entity_extraction,
                "auto_reprocess_after_clarification": self.auto_reprocess_after_clarification,
                "adaptive_question_count": self.adaptive_question_count,
                "enable_semantic_dynamic": self.enable_semantic_dynamic,
                "semantic_dynamic_max_questions": self.semantic_dynamic_max_questions,
                "enable_question_validation": self.enable_question_validation,
                "validation_threshold": self.validation_threshold,
                "enable_intelligent_fallback": self.enable_intelligent_fallback
            }
        }
        
        # Log structur√©
        self.clarification_logger.info(json.dumps(clarification_data, ensure_ascii=False))
        
        # Log standard enrichi avec informations de validation
        if result.needs_clarification:
            logger.info(
                f"‚ùì [Enhanced Clarification] CLARIFICATION - "
                f"User: {user_id[:8]} | Type: {result.question_type} | "
                f"Questions: {len(result.questions)} | Mode: {result.clarification_mode.value if result.clarification_mode else 'N/A'} | "
                f"Missing: {result.missing_critical_info} | "
                f"Mod√®le: {result.model_used} | "
                f"Confiance: {result.confidence_score:.1f}% | "
                f"Validation: {result.validation_score:.1f} | "
                f"Fallback: {'‚úÖ' if result.fallback_used else '‚ùå'} | "
                f"GPT: {'‚ùå' if result.gpt_failed else '‚úÖ'} | "
                f"Temps: {result.processing_time_ms}ms"
            )
        else:
            logger.info(
                f"‚úÖ [Enhanced Clarification] CLEAR - "
                f"User: {user_id[:8]} | Type: {result.question_type} | "
                f"Raison: {result.reason} | "
                f"Entit√©s: {len(result.extracted_entities.to_dict()) if result.extracted_entities else 0} | "
                f"Mod√®le: {result.model_used} | "
                f"Validation: {result.validation_score:.1f} | "
                f"Fallback: {'‚úÖ' if result.fallback_used else '‚ùå'} | "
                f"GPT: {'‚ùå' if result.gpt_failed else '‚úÖ'} | "
                f"Temps: {result.processing_time_ms}ms"
            )

    def get_stats_enhanced(self) -> Dict:
        """Retourne les statistiques du syst√®me enrichi avec nouvelles fonctionnalit√©s (AM√âLIOR√â)"""
        return {
            "enabled": self.enabled,
            "model": self.model,
            "timeout": self.timeout,
            "max_questions": self.max_questions,
            "min_question_length": self.min_question_length,
            "confidence_threshold": self.confidence_threshold,
            "log_all_clarifications": self.log_all_clarifications,
            "openai_available": OPENAI_AVAILABLE,
            "supported_languages": list(self.clarification_prompts.keys()),
            "settings_source": "intelia_settings" if SETTINGS_AVAILABLE else "environment_variables",
            
            # ‚úÖ NOUVELLES STATISTIQUES
            "clarification_mode": self.clarification_mode.value,
            "smart_entity_extraction": self.smart_entity_extraction,
            "auto_reprocess_after_clarification": self.auto_reprocess_after_clarification,
            "adaptive_question_count": self.adaptive_question_count,
            "intelligent_missing_detection": self.intelligent_missing_detection,
            "question_types_supported": list(self.question_type_patterns.keys()),
            "entity_types_extracted": [
                "breed", "age_days", "weight_grams", "mortality_rate", 
                "temperature", "humidity", "housing_type", "feed_type", 
                "symptoms", "duration_problem", "previous_treatments"
            ],
            "clarification_modes_available": [mode.value for mode in ClarificationMode],
            "clarification_states_available": [state.value for state in ClarificationState],
            
            # üÜï NOUVELLES STATISTIQUES MODE S√âMANTIQUE DYNAMIQUE
            "semantic_dynamic_enabled": self.enable_semantic_dynamic,
            "semantic_dynamic_max_questions": self.semantic_dynamic_max_questions,
            "semantic_dynamic_available": OPENAI_AVAILABLE and bool(os.getenv('OPENAI_API_KEY')),
            
            # üîß NOUVELLES STATISTIQUES VALIDATION GPT ROBUSTE
            "question_validation_enabled": self.enable_question_validation,
            "validation_threshold": self.validation_threshold,
            "validation_available": OPENAI_AVAILABLE and bool(os.getenv('OPENAI_API_KEY')),
            "intelligent_fallback_enabled": self.enable_intelligent_fallback,
            
            # üîß NOUVELLES STATISTIQUES GESTION D'ERREURS
            "error_handling_features": {
                "openai_unavailable_fallback": True,
                "api_key_missing_fallback": True,
                "gpt_error_fallback": self.enable_intelligent_fallback,
                "validation_failure_fallback": self.enable_intelligent_fallback,
                "json_parsing_fallback": True,
                "question_extraction_fallback": True
            },
            
            # üîß STATISTIQUES FALLBACK
            "fallback_strategies": {
                "adaptive_clarification_questions": True,
                "basic_fallback_questions": True,
                "intelligent_question_selection": True,
                "type_specific_fallbacks": True
            }
        }

# ==================== INSTANCE GLOBALE AM√âLIOR√âE ====================

# Instance singleton du syst√®me de clarification AM√âLIOR√â avec validation robuste
enhanced_clarification_system = EnhancedQuestionClarificationSystem()

# ==================== FONCTIONS UTILITAIRES AM√âLIOR√âES ====================

async def analyze_question_for_clarification_enhanced(
    question: str, 
    language: str = "fr",
    user_id: str = "unknown", 
    conversation_id: str = None,
    conversation_context: Dict = None,
    original_question: str = None
) -> ClarificationResult:
    """Fonction utilitaire pour analyser les questions avec le syst√®me am√©lior√©"""
    return await enhanced_clarification_system.analyze_question_enhanced(
        question, language, user_id, conversation_id, conversation_context, original_question
    )

# üÜï NOUVELLE FONCTION: Mode s√©mantique dynamique
async def analyze_question_for_clarification_semantic_dynamic(
    question: str, 
    language: str = "fr",
    user_id: str = "unknown", 
    conversation_id: str = None,
    conversation_context: Dict = None
) -> ClarificationResult:
    """Fonction utilitaire pour utiliser le mode s√©mantique dynamique directement"""
    return await enhanced_clarification_system.analyze_question_enhanced(
        question, language, user_id, conversation_id, conversation_context, mode="semantic_dynamic"
    )

def format_clarification_response_enhanced(result: ClarificationResult, language: str) -> str:
    """Formate la r√©ponse de clarification avec le syst√®me am√©lior√©"""
    return enhanced_clarification_system.format_clarification_response_enhanced(result, language)

async def check_for_reprocessing_after_clarification(
    conversation_id: str,
    user_response: str,
    original_clarification_result: ClarificationResult
) -> Optional[ClarificationResult]:
    """V√©rifie si une question peut √™tre retrait√©e apr√®s clarification"""
    return await enhanced_clarification_system.check_for_reprocessing(
        conversation_id, user_response, original_clarification_result
    )

def get_enhanced_clarification_system_stats() -> Dict:
    """Retourne les statistiques du syst√®me am√©lior√©"""
    return enhanced_clarification_system.get_stats_enhanced()

def is_enhanced_clarification_system_enabled() -> bool:
    """V√©rifie si le syst√®me de clarification am√©lior√© est activ√©"""
    return enhanced_clarification_system.enabled

def build_enriched_question_enhanced(
    original_question: str, 
    clarification_answers: Dict[str, str], 
    clarification_questions: List[str]
) -> str:
    """Construit une question enrichie avec les r√©ponses de clarification (version am√©lior√©e)"""
    enriched_question = original_question + "\n\nInformations suppl√©mentaires :"
    
    for index_str, answer in clarification_answers.items():
        if answer and answer.strip():
            try:
                index = int(index_str)
                if 0 <= index < len(clarification_questions):
                    question = clarification_questions[index]
                    enriched_question += f"\n- {question}: {answer.strip()}"
            except (ValueError, IndexError):
                continue
    
    return enriched_question

# üÜï NOUVELLE FONCTION: G√©n√©ration directe de questions dynamiques avec validation
def generate_dynamic_clarification_questions_with_validation(question: str, language: str = "fr") -> Tuple[List[str], Dict[str, Any]]:
    """G√©n√®re dynamiquement des questions de clarification avec validation robuste"""
    return enhanced_clarification_system.generate_dynamic_clarification_questions(question, language)

# ==================== LOGGING DE D√âMARRAGE AM√âLIOR√â ====================

logger.info("‚ùì [EnhancedQuestionClarificationSystem] Module COMPL√àTEMENT R√â√âCRIT avec VALIDATION ROBUSTE initialis√©")
logger.info(f"üìä [EnhancedQuestionClarificationSystem] Statistiques: {enhanced_clarification_system.get_stats_enhanced()}")
logger.info("‚úÖ [EnhancedQuestionClarificationSystem] FONCTIONNALIT√âS CONSERV√âES:")
logger.info("   - ü§ñ Extraction intelligente d'entit√©s via OpenAI")
logger.info("   - üîÑ Retraitement automatique apr√®s clarification")
logger.info("   - üéØ Clarification adaptative (1 question si 1 info manque)")
logger.info("   - üß† Gestion avanc√©e du contexte conversationnel")
logger.info("   - üìä Classification automatique des types de questions")
logger.info("   - üéõÔ∏è Modes de clarification multiples (batch/interactive/adaptive)")
logger.info("   - üìà Prompts optimis√©s pour donn√©es num√©riques")
logger.info("   - üîç D√©tection intelligente des informations critiques manquantes")
logger.info("üÜï [EnhancedQuestionClarificationSystem] MODE S√âMANTIQUE DYNAMIQUE CONSERV√â:")
logger.info("   - üé≠ G√©n√©ration GPT de 1-4 questions contextuelles")
logger.info("   - ü§ñ Prompt contextualis√© pour questions m√©tier intelligentes")
logger.info("   - üîÑ Fallback automatique si g√©n√©ration √©choue")
logger.info("   - ‚öôÔ∏è Configuration flexible (enable_semantic_dynamic, max_questions)")
logger.info("üîß [EnhancedQuestionClarificationSystem] NOUVELLES FONCTIONNALIT√âS VALIDATION ROBUSTE:")
logger.info("   - ‚úÖ Validation automatique compl√®te des questions g√©n√©r√©es par GPT")
logger.info("   - üéØ Filtrage avanc√©: longueur, mots-cl√©s, phrases interdites, doublons")
logger.info("   - üìä Score de qualit√© d√©taill√© (0.0 √† 1.0) avec bonus diversit√©/sp√©cificit√©")
logger.info("   - üö´ D√©tection reformulations, exemples g√©n√©riques, questions non pertinentes")
logger.info("   - üîÑ Fallback intelligent par type de question si validation √©choue")
logger.info("   - üìà M√©tadonn√©es validation compl√®tes dans les r√©sultats")
logger.info("üîß [EnhancedQuestionClarificationSystem] GESTION D'ERREURS COMPL√àTE:")
logger.info("   - üõ°Ô∏è Fallback si OpenAI indisponible ‚Üí Questions adaptatives")
logger.info("   - üõ°Ô∏è Fallback si cl√© API manquante ‚Üí Questions adaptatives")
logger.info("   - üõ°Ô∏è Fallback si erreur GPT ‚Üí Questions adaptatives (si enabled)")
logger.info("   - üõ°Ô∏è Fallback si validation √©choue ‚Üí Questions par type")
logger.info("   - üõ°Ô∏è Fallback si JSON parsing √©choue ‚Üí Extraction texte libre")
logger.info("   - üõ°Ô∏è Fallback si imports √©chouent ‚Üí Questions de base")
logger.info("   - üìä Tra√ßabilit√© compl√®te: gpt_failed, fallback_used dans r√©sultats")
logger.info("‚ú® [EnhancedQuestionClarificationSystem] R√âSULTAT FINAL:")
logger.info('   - Question floue: "J\'ai un probl√®me avec mes poulets"')
logger.info('   - G√©n√©ration GPT: 3-4 questions contextuelles')
logger.info('   - Validation robuste: score qualit√© > seuil configurable')
logger.info('   - Si √©chec: fallback intelligent par type de question')
logger.info('   - Si erreur technique: fallback adaptatif garanti')
logger.info