"""
app/api/v1/question_clarification_system.py - SYST√àME PRINCIPAL DE CLARIFICATION (VERSION CORRIG√âE)

Contient:
- EnhancedQuestionClarificationSystem (classe principale)
- Extraction d'entit√©s intelligente
- Analyse compl√®te des questions
- Interface publique + logging
- Identification des entit√©s critiques

CORRECTIONS APPORT√âES:
- Import CircularImportError r√©solu
- Gestion d'erreurs robuste pour OpenAI
- Validation des types am√©lior√©e
- Gestion des attributs optionnels
- Logging s√©curis√©
- M√©thodes d'extension mieux structur√©es
"""

import os
import re
import json
import logging
import time
from typing import Dict, List, Optional, Tuple, Any, Union
from datetime import datetime
from enum import Enum

# Import conditionnel pour √©viter les erreurs circulaires
try:
    from app.config.settings import settings
    SETTINGS_AVAILABLE = True
except ImportError:
    SETTINGS_AVAILABLE = False
    settings = None

# Import OpenAI s√©curis√© avec gestion d'erreur
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

# Import des modules s√©par√©s avec gestion d'erreur
try:
    from .clarification_entities import (
        ExtractedEntities, ClarificationResult, ClarificationMode, ClarificationState
    )
    ENTITIES_MODULE_AVAILABLE = True
except ImportError:
    ENTITIES_MODULE_AVAILABLE = False
    # D√©finition des classes de base si le module n'est pas disponible
    class ClarificationMode(Enum):
        BATCH = "batch"
        INTERACTIVE = "interactive"
        ADAPTIVE = "adaptive"
        SEMANTIC_DYNAMIC = "semantic_dynamic"
    
    class ClarificationState(Enum):
        NONE = "none"
        NEEDED = "needed"
        AWAITING_REPROCESS = "awaiting_reprocess"
    
    class ExtractedEntities:
        def __init__(self, **kwargs):
            self.breed = kwargs.get("breed")
            self.breed_type = kwargs.get("breed_type")
            self.sex = kwargs.get("sex")
            self.age_days = kwargs.get("age_days")
            self.age_weeks = kwargs.get("age_weeks")
            self.weight_grams = kwargs.get("weight_grams")
            self.mortality_rate = kwargs.get("mortality_rate")
            self.temperature = kwargs.get("temperature")
            self.humidity = kwargs.get("humidity")
            self.housing_type = kwargs.get("housing_type")
            self.feed_type = kwargs.get("feed_type")
            self.flock_size = kwargs.get("flock_size")
            self.symptoms = kwargs.get("symptoms", [])
            self.duration_problem = kwargs.get("duration_problem")
            self.previous_treatments = kwargs.get("previous_treatments", [])
            self.breed_normalized = False
            self.sex_inferred = False
        
        def to_dict(self):
            return {k: v for k, v in self.__dict__.items() if not k.startswith('_')}
        
        def normalize_and_infer(self):
            # Logique de normalisation basique
            if self.breed and isinstance(self.breed, str):
                self.breed = self.breed.strip().title()
                self.breed_normalized = True
        
        def get_missing_critical_info(self, question_type: str) -> List[str]:
            missing = []
            if not self.breed or self.breed_type == "generic":
                missing.append("breed")
            if not self.age_days and not self.age_weeks:
                missing.append("age")
            return missing
    
    class ClarificationResult:
        def __init__(self, **kwargs):
            self.needs_clarification = kwargs.get("needs_clarification", False)
            self.questions = kwargs.get("questions", [])
            self.processing_time_ms = kwargs.get("processing_time_ms", 0)
            self.reason = kwargs.get("reason", "")
            self.model_used = kwargs.get("model_used")
            self.extracted_entities = kwargs.get("extracted_entities")
            self.question_type = kwargs.get("question_type", "general")
            self.clarification_mode = kwargs.get("clarification_mode")
            self.clarification_state = kwargs.get("clarification_state", ClarificationState.NONE)
            self.missing_critical_info = kwargs.get("missing_critical_info", [])
            self.confidence_score = kwargs.get("confidence_score", 0.0)
            self.original_question = kwargs.get("original_question")
            self.validation_score = kwargs.get("validation_score", 0.0)
            self.validation_details = kwargs.get("validation_details", {})
            self.fallback_used = kwargs.get("fallback_used", False)
            self.gpt_failed = kwargs.get("gpt_failed", False)
            self.should_reprocess = kwargs.get("should_reprocess", False)
            # Nouveaux champs pour entit√©s critiques
            self.missing_entities = kwargs.get("missing_entities", [])
            self.missing_critical_entities = kwargs.get("missing_critical_entities", [])
            self.clarification_required_critical = kwargs.get("clarification_required_critical", False)
        
        def to_dict(self):
            result = {}
            for key, value in self.__dict__.items():
                if hasattr(value, 'value'):  # Pour les Enum
                    result[key] = value.value
                elif hasattr(value, 'to_dict'):  # Pour les objets avec to_dict
                    result[key] = value.to_dict()
                else:
                    result[key] = value
            return result

try:
    from .clarification_generators import QuestionGenerator
    GENERATORS_MODULE_AVAILABLE = True
except ImportError:
    GENERATORS_MODULE_AVAILABLE = False
    # Impl√©mentation basique du g√©n√©rateur de questions
    class QuestionGenerator:
        def __init__(self, model="gpt-4o-mini", timeout=25, max_questions=3):
            self.model = model
            self.timeout = timeout
            self.max_questions = max_questions
        
        def generate_dynamic_questions_with_validation(self, question: str, language: str):
            return [], {"validation_score": 0.8, "gpt_success": True, "fallback_used": False}
        
        def generate_adaptive_questions(self, language: str, missing_info: List[str], question_type: str):
            basic_questions = {
                "fr": [
                    "Quelle est la race de vos volailles ?",
                    "Quel est l'√¢ge de vos volailles ?"
                ],
                "en": [
                    "What breed are your poultry?",
                    "What is the age of your poultry?"
                ]
            }
            return basic_questions.get(language, basic_questions["fr"])[:self.max_questions]

logger = logging.getLogger(__name__)

# ==================== CONSTANTES ENTIT√âS CRITIQUES ====================

# Entit√©s consid√©r√©es comme critiques pour les r√©ponses v√©t√©rinaires
CRITICAL_ENTITIES = [
    "breed",        # Race/souche (essentiel pour protocoles sp√©cifiques)
    "age",          # √Çge (critique pour nutrition, vaccination, traitements)
    "sex",          # Sexe (important pour certains protocoles)
    "symptoms",     # Sympt√¥mes (essentiel pour diagnostic)
    "environment",  # Environnement (temp√©rature, humidit√©, logement)
    "feed",         # Alimentation (critique pour nutrition et performance)
    "flock_size",   # Taille du troupeau (important pour gestion)
    "mortality_rate" # Taux de mortalit√© (critique pour urgences)
]

# Mappage des entit√©s vers les attributs ExtractedEntities
ENTITY_ATTRIBUTE_MAPPING = {
    "breed": ["breed", "breed_type"],
    "age": ["age_days", "age_weeks"],
    "sex": ["sex"],
    "symptoms": ["symptoms"],
    "environment": ["temperature", "humidity", "housing_type"],
    "feed": ["feed_type"],
    "flock_size": ["flock_size"],
    "mortality_rate": ["mortality_rate"]
}

# Entit√©s critiques par type de question
CRITICAL_ENTITIES_BY_QUESTION_TYPE = {
    "growth": ["breed", "age", "feed"],
    "weight": ["breed", "age", "feed"],
    "mortality": ["breed", "age", "symptoms", "mortality_rate"],
    "health": ["breed", "age", "symptoms"],
    "temperature": ["age", "environment"],
    "feeding": ["breed", "age", "feed"],
    "environment": ["age", "environment"],
    "performance": ["breed", "age", "feed", "environment"],
    "laying": ["breed", "age", "feed", "environment"],
    "general": ["breed", "age"]
}

class EnhancedQuestionClarificationSystem:
    """
    Syst√®me de clarification intelligent AM√âLIOR√â avec validation GPT robuste int√©gr√©e + reconnaissance souches + entit√©s critiques
    """
    
    def __init__(self):
        """Initialise le syst√®me avec configuration am√©lior√©e"""
        
        # Configuration depuis les settings ou variables d'environnement
        self._load_configuration()
        
        # Initialiser le g√©n√©rateur de questions
        if GENERATORS_MODULE_AVAILABLE:
            self.question_generator = QuestionGenerator(
                model=self.model, 
                timeout=self.timeout, 
                max_questions=self.semantic_dynamic_max_questions
            )
        else:
            self.question_generator = QuestionGenerator()
        
        self._init_patterns()
        self._init_enhanced_prompts()
        self._init_clarification_logger()
        
        # Log de d√©marrage
        logger.info("‚úÖ [EnhancedQuestionClarificationSystem] READY: Agent de clarification op√©rationnel!")
        logger.info(f"üîß [Enhanced Clarification] Mode: {self.clarification_mode.value}")
        logger.info(f"üîß [Enhanced Clarification] Validation GPT robuste: {'‚úÖ' if self.enable_question_validation else '‚ùå'}")
        logger.info(f"üÜï [Breed Recognition] Normalisation souches: {'‚úÖ' if self.enable_breed_normalization else '‚ùå'}")
        logger.info(f"üéØ [Critical Entities] Analyse entit√©s critiques: {'‚úÖ' if self.enable_critical_entity_analysis else '‚ùå'}")
        logger.info(f"üìä [Critical Entities] Entit√©s critiques d√©finies: {len(CRITICAL_ENTITIES)} ({', '.join(CRITICAL_ENTITIES)})")

    def _load_configuration(self):
        """Charge la configuration depuis les settings ou variables d'environnement"""
        
        if SETTINGS_AVAILABLE and settings:
            self.enabled = getattr(settings, 'clarification_system_enabled', True)
            self.model = getattr(settings, 'clarification_model', 'gpt-4o-mini')
            self.timeout = getattr(settings, 'clarification_timeout', 25)
            self.max_questions = getattr(settings, 'clarification_max_questions', 3)
            self.min_question_length = getattr(settings, 'clarification_min_length', 15)
            self.log_all_clarifications = getattr(settings, 'clarification_log_all', True)
            self.confidence_threshold = getattr(settings, 'clarification_confidence_threshold', 0.7)
            
            clarification_mode_str = getattr(settings, 'clarification_mode', 'adaptive')
            try:
                self.clarification_mode = ClarificationMode(clarification_mode_str)
            except ValueError:
                logger.warning(f"Mode de clarification invalide: {clarification_mode_str}, utilisation du mode adaptatif")
                self.clarification_mode = ClarificationMode.ADAPTIVE
            
            self.smart_entity_extraction = getattr(settings, 'smart_entity_extraction', True)
            self.auto_reprocess_after_clarification = getattr(settings, 'auto_reprocess_after_clarification', True)
            self.adaptive_question_count = getattr(settings, 'adaptive_question_count', True)
            
            self.enable_semantic_dynamic = getattr(settings, 'enable_semantic_dynamic_clarification', True)
            self.semantic_dynamic_max_questions = getattr(settings, 'semantic_dynamic_max_questions', 4)
            
            # Configuration validation GPT robuste
            self.enable_question_validation = getattr(settings, 'enable_question_validation', True)
            self.validation_threshold = getattr(settings, 'validation_threshold', 0.5)
            self.enable_intelligent_fallback = getattr(settings, 'enable_intelligent_fallback', True)
            
            # Configuration reconnaissance souches
            self.enable_breed_normalization = getattr(settings, 'enable_breed_normalization', True)
            self.enable_sex_inference = getattr(settings, 'enable_sex_inference', True)
            
            # Configuration entit√©s critiques
            self.enable_critical_entity_analysis = getattr(settings, 'enable_critical_entity_analysis', True)
            self.critical_entities_threshold = getattr(settings, 'critical_entities_threshold', 0.8)
        else:
            # Configuration par d√©faut depuis les variables d'environnement
            self.enabled = os.getenv('ENABLE_CLARIFICATION_SYSTEM', 'true').lower() == 'true'
            self.model = os.getenv('CLARIFICATION_MODEL', 'gpt-4o-mini')
            self.timeout = int(os.getenv('CLARIFICATION_TIMEOUT', '25'))
            self.max_questions = int(os.getenv('CLARIFICATION_MAX_QUESTIONS', '3'))
            self.min_question_length = int(os.getenv('CLARIFICATION_MIN_LENGTH', '15'))
            self.log_all_clarifications = os.getenv('LOG_ALL_CLARIFICATIONS', 'true').lower() == 'true'
            self.confidence_threshold = float(os.getenv('CLARIFICATION_CONFIDENCE_THRESHOLD', '0.7'))
            
            clarification_mode_str = os.getenv('CLARIFICATION_MODE', 'adaptive')
            try:
                self.clarification_mode = ClarificationMode(clarification_mode_str)
            except ValueError:
                logger.warning(f"Mode de clarification invalide: {clarification_mode_str}, utilisation du mode adaptatif")
                self.clarification_mode = ClarificationMode.ADAPTIVE
            
            self.smart_entity_extraction = os.getenv('SMART_ENTITY_EXTRACTION', 'true').lower() == 'true'
            self.auto_reprocess_after_clarification = os.getenv('AUTO_REPROCESS_AFTER_CLARIFICATION', 'true').lower() == 'true'
            self.adaptive_question_count = os.getenv('ADAPTIVE_QUESTION_COUNT', 'true').lower() == 'true'
            
            self.enable_semantic_dynamic = os.getenv('ENABLE_SEMANTIC_DYNAMIC_CLARIFICATION', 'true').lower() == 'true'
            self.semantic_dynamic_max_questions = int(os.getenv('SEMANTIC_DYNAMIC_MAX_QUESTIONS', '4'))
            
            # Configuration validation GPT robuste
            self.enable_question_validation = os.getenv('ENABLE_QUESTION_VALIDATION', 'true').lower() == 'true'
            self.validation_threshold = float(os.getenv('VALIDATION_THRESHOLD', '0.5'))
            self.enable_intelligent_fallback = os.getenv('ENABLE_INTELLIGENT_FALLBACK', 'true').lower() == 'true'
            
            # Configuration reconnaissance souches
            self.enable_breed_normalization = os.getenv('ENABLE_BREED_NORMALIZATION', 'true').lower() == 'true'
            self.enable_sex_inference = os.getenv('ENABLE_SEX_INFERENCE', 'true').lower() == 'true'
            
            # Configuration entit√©s critiques
            self.enable_critical_entity_analysis = os.getenv('ENABLE_CRITICAL_ENTITY_ANALYSIS', 'true').lower() == 'true'
            self.critical_entities_threshold = float(os.getenv('CRITICAL_ENTITIES_THRESHOLD', '0.8'))

    def _init_patterns(self):
        """Patterns de d√©tection am√©lior√©s avec reconnaissance souches"""
        
        # Races sp√©cifiques avec nouvelles souches pondeuses
        self.specific_breed_patterns = {
            "fr": [
                # Poulets de chair
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro',
                
                # Poules pondeuses
                r'lohmann(?:\s*lsl)?(?:\s*-?\s*lite)?', r'lsl\s*-?\s*lite?',
                r'bovans\s*(?:brown|blanc|white)?', 
                r'hisex\s*(?:brown|blanc|white)?',
                r'isa\s*(?:brown|blanc|white)?',
                r'hyline\s*(?:brown|white)?'
            ],
            "en": [
                # Poulets de chair
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro',
                
                # Poules pondeuses
                r'lohmann(?:\s*lsl)?(?:\s*-?\s*lite)?', r'lsl\s*-?\s*lite?',
                r'bovans\s*(?:brown|white)?', 
                r'hisex\s*(?:brown|white)?',
                r'isa\s*(?:brown|white)?',
                r'hyline\s*(?:brown|white)?'
            ],
            "es": [
                # Poulets de chair
                r'ross\s*308', r'ross\s*708', r'ross\s*ap95', r'ross\s*pm3',
                r'cobb\s*500', r'cobb\s*700', r'cobb\s*sasso',
                r'hubbard\s*flex', r'hubbard\s*classic',
                r'arbor\s*acres', r'isa\s*15', r'red\s*bro',
                
                # Poules pondeuses
                r'lohmann(?:\s*lsl)?(?:\s*-?\s*lite)?', r'lsl\s*-?\s*lite?',
                r'bovans\s*(?:brown|blanco|white)?', 
                r'hisex\s*(?:brown|blanco|white)?',
                r'isa\s*(?:brown|blanco|white)?',
                r'hyline\s*(?:brown|white)?'
            ]
        }
        
        # Patterns pour classification de type de question
        self.question_type_patterns = {
            "growth": [r'croissance', r'growth', r'crecimiento', r'grossissent?', r'growing', r'crecen'],
            "weight": [r'poids', r'weight', r'peso', r'p√®sent?', r'weigh', r'pesan', r'grammes?', r'grams?', r'gramos?'],
            "mortality": [r'mortalit√©', r'mortality', r'mortalidad', r'meurent', r'dying', r'mueren', r'dead', r'muerte'],
            "health": [r'maladie', r'disease', r'enfermedad', r'malade', r'sick', r'enfermo', r'sant√©', r'health', r'salud'],
            "temperature": [r'temp√©rature', r'temperature', r'temperatura', r'chaud', r'hot', r'caliente', r'froid', r'cold', r'fr√≠o'],
            "feeding": [r'alimentation', r'feeding', r'alimentaci√≥n', r'nourriture', r'food', r'comida', r'aliment'],
            "environment": [r'environnement', r'environment', r'ambiente', r'ventilation', r'humidity', r'humidit√©'],
            "performance": [r'performance', r'rendement', r'efficacit√©', r'efficiency', r'eficiencia', r'conversion'],
            "laying": [r'ponte', r'laying', r'puesta', r'oeufs?', r'eggs?', r'huevos?']
        }

    def _init_enhanced_prompts(self):
        """Prompts am√©lior√©s avec gestion du contexte et entit√©s critiques"""
        
        self.clarification_prompts = {
            "fr": """Tu es un expert v√©t√©rinaire sp√©cialis√© en aviculture. Analyse cette question et le contexte pour d√©terminer si des clarifications sont n√©cessaires.

Question: "{question}"
Type de question d√©tect√©: {question_type}
Entit√©s extraites: {extracted_entities}
Contexte conversationnel: {conversation_context}
Informations critiques manquantes: {missing_info}
Entit√©s critiques manquantes: {missing_critical_entities}

R√àGLES STRICTES:
1. Si TOUTES les informations critiques sont pr√©sentes ‚Üí r√©ponds "CLEAR"
2. Si des informations critiques manquent ‚Üí g√©n√®re des questions PR√âCISES
3. Priorise TOUJOURS les entit√©s critiques manquantes
4. Adapte le nombre de questions au nombre d'informations critiques manquantes
5. Pour {question_type}, ces entit√©s sont particuli√®rement importantes: {critical_entities_for_type}

Format: soit "CLEAR" soit liste de questions avec tirets.""",

            "en": """You are a veterinary expert specialized in poultry farming. Analyze this question and context to determine if clarifications are needed.

Question: "{question}"
Detected question type: {question_type}
Extracted entities: {extracted_entities}
Conversational context: {conversation_context}
Missing critical information: {missing_info}
Missing critical entities: {missing_critical_entities}

STRICT RULES:
1. If ALL critical information is present ‚Üí answer "CLEAR"
2. If critical information is missing ‚Üí generate PRECISE questions
3. ALWAYS prioritize missing critical entities
4. Adapt number of questions to missing critical information count
5. For {question_type}, these entities are particularly important: {critical_entities_for_type}

Format: either "CLEAR" or bulleted question list.""",

            "es": """Eres un experto veterinario especializado en avicultura. Analiza esta pregunta y contexto para determinar si se necesitan aclaraciones.

Pregunta: "{question}"
Tipo de pregunta detectado: {question_type}
Entidades extra√≠das: {extracted_entities}
Contexto conversacional: {conversation_context}
Informaci√≥n cr√≠tica faltante: {missing_info}
Entidades cr√≠ticas faltantes: {missing_critical_entities}

REGLAS ESTRICTAS:
1. Si TODA la informaci√≥n cr√≠tica est√° presente ‚Üí responde "CLEAR"
2. Si falta informaci√≥n cr√≠tica ‚Üí genera preguntas PRECISAS
3. Prioriza SIEMPRE las entidades cr√≠ticas faltantes
4. Adapta el n√∫mero de preguntas a la informaci√≥n cr√≠tica faltante
5. Para {question_type}, estas entidades son particularmente importantes: {critical_entities_for_type}

Formato: "CLEAR" o lista de preguntas con guiones."""
        }

    def _init_clarification_logger(self):
        """Initialise le logger sp√©cialis√© pour les clarifications"""
        self.clarification_logger = logging.getLogger("enhanced_question_clarification")
        self.clarification_logger.setLevel(logging.INFO)
        
        if not self.clarification_logger.handlers and self.log_all_clarifications:
            try:
                from logging.handlers import RotatingFileHandler
                
                log_dir = os.getenv('VALIDATION_LOGS_DIR', 'logs')
                os.makedirs(log_dir, exist_ok=True)
                
                log_file_path = os.path.join(log_dir, 'enhanced_question_clarifications.log')
                clarification_handler = RotatingFileHandler(
                    log_file_path,
                    maxBytes=int(os.getenv('VALIDATION_LOG_MAX_SIZE', '10485760')),
                    backupCount=int(os.getenv('VALIDATION_LOG_BACKUP_COUNT', '5'))
                )
                clarification_formatter = logging.Formatter(
                    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
                )
                clarification_handler.setFormatter(clarification_formatter)
                self.clarification_logger.addHandler(clarification_handler)
                
                logger.info(f"‚úÖ [Enhanced Clarification] Logger configur√©: {log_file_path}")
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Impossible de cr√©er le fichier de log: {e}")

    def classify_question_type(self, question: str, language: str) -> str:
        """Classifie le type de question"""
        
        if not question or not isinstance(question, str):
            return "general"
        
        question_lower = question.lower()
        
        for question_type, patterns in self.question_type_patterns.items():
            for pattern in patterns:
                try:
                    if re.search(pattern, question_lower, re.IGNORECASE):
                        return question_type
                except re.error as e:
                    logger.warning(f"Erreur dans le pattern regex '{pattern}': {e}")
                    continue
        
        return "general"

    def analyze_critical_entities(self, extracted_entities: ExtractedEntities, question_type: str) -> Dict[str, Any]:
        """
        Analyse les entit√©s critiques manquantes selon le type de question
        
        Returns:
            Dict contenant:
            - missing_entities: Liste de toutes les entit√©s manquantes
            - missing_critical_entities: Liste des entit√©s critiques manquantes
            - clarification_required_critical: Boolean indiquant si une clarification critique est n√©cessaire
            - critical_entities_for_type: Entit√©s critiques sp√©cifiques au type de question
        """
        
        if not self.enable_critical_entity_analysis or not extracted_entities:
            return {
                "missing_entities": [],
                "missing_critical_entities": [],
                "clarification_required_critical": False,
                "critical_entities_for_type": []
            }
            
        # Obtenir les entit√©s critiques pour ce type de question
        critical_entities_for_type = CRITICAL_ENTITIES_BY_QUESTION_TYPE.get(
            question_type, 
            CRITICAL_ENTITIES_BY_QUESTION_TYPE["general"]
        )
        
        # Analyser toutes les entit√©s manquantes
        missing_entities = []
        missing_critical_entities = []
        
        try:
            entities_dict = extracted_entities.to_dict()
        except Exception as e:
            logger.error(f"Erreur lors de la conversion des entit√©s en dict: {e}")
            entities_dict = {}
        
        for entity in CRITICAL_ENTITIES:
            # V√©rifier si l'entit√© est pr√©sente via son mapping
            entity_attributes = ENTITY_ATTRIBUTE_MAPPING.get(entity, [entity])
            entity_present = False
            
            for attr in entity_attributes:
                if attr in entities_dict and entities_dict[attr] is not None:
                    # V√©rifications sp√©ciales pour certains types
                    if attr == "breed_type" and entities_dict[attr] == "generic":
                        # Race g√©n√©rique = entit√© manquante (besoin de sp√©cificit√©)
                        continue
                    if attr == "symptoms" and isinstance(entities_dict[attr], list) and len(entities_dict[attr]) == 0:
                        # Liste vide de sympt√¥mes = entit√© manquante
                        continue
                    entity_present = True
                    break
            
            if not entity_present:
                missing_entities.append(entity)
                # V√©rifier si c'est critique pour ce type de question
                if entity in critical_entities_for_type:
                    missing_critical_entities.append(entity)
        
        # D√©terminer si une clarification critique est n√©cessaire
        clarification_required_critical = len(missing_critical_entities) > 0
        
        # Log de l'analyse
        logger.info(f"üéØ [Critical Entities] Type: {question_type}")
        logger.info(f"üéØ [Critical Entities] Critiques pour ce type: {critical_entities_for_type}")
        logger.info(f"‚ùå [Critical Entities] Manquantes: {missing_entities}")
        logger.info(f"üö® [Critical Entities] Critiques manquantes: {missing_critical_entities}")
        logger.info(f"‚ö†Ô∏è [Critical Entities] Clarification critique requise: {clarification_required_critical}")
        
        return {
            "missing_entities": missing_entities,
            "missing_critical_entities": missing_critical_entities,
            "clarification_required_critical": clarification_required_critical,
            "critical_entities_for_type": critical_entities_for_type
        }

    async def extract_entities_intelligent(self, question: str, language: str, conversation_context: Dict = None) -> ExtractedEntities:
        """Extraction intelligente d'entit√©s via OpenAI avec reconnaissance souches"""
        
        if not self.smart_entity_extraction or not OPENAI_AVAILABLE or not openai:
            logger.warning("‚ö†Ô∏è [Enhanced Clarification] Extraction intelligente d√©sactiv√©e ou OpenAI indisponible")
            return await self._extract_entities_fallback(question, language)
        
        try:
            # Construire le contexte pour l'extraction
            context_info = ""
            if conversation_context and isinstance(conversation_context, dict):
                try:
                    context_info = f"\n\nContexte conversationnel disponible:\n{json.dumps(conversation_context, ensure_ascii=False, indent=2)}"
                except (TypeError, ValueError) as e:
                    logger.warning(f"Erreur lors de la s√©rialisation du contexte: {e}")
                    context_info = "\n\nContexte disponible mais non s√©rialisable."
            
            # Prompt avec reconnaissance des souches pondeuses et focus sur entit√©s critiques
            extraction_prompt = f"""Tu es un expert en extraction d'informations pour l'aviculture. Extrait TOUTES les informations pertinentes de cette question et du contexte.

Question: "{question}"{context_info}

CONSIGNE: Extrait les informations sous format JSON strict. Utilise null pour les valeurs manquantes.

PRIORIT√â AUX ENTIT√âS CRITIQUES: {', '.join(CRITICAL_ENTITIES)}

IMPORTANT POUR LES RACES/SOUCHES:
- Reconna√Ætre les souches pondeuses: Lohmann LSL-Lite, Bovans Brown, Hisex Brown, ISA Brown, Hyline
- Reconna√Ætre les souches de chair: Ross 308, Cobb 500, Hubbard Flex, etc.
- Normaliser les noms (ex: "lohmann" ‚Üí "Lohmann LSL-Lite")
- Inf√©rer le sexe si possible (souches pondeuses = femelles)

```json
{{
  "breed": "race sp√©cifique (ex: Ross 308, Lohmann LSL-Lite) ou null",
  "breed_type": "specific/generic/null",
  "sex": "m√¢le/femelle/mixte ou null (inf√©rer si souche pondeuse)",
  "age_days": nombre_jours_ou_null,
  "age_weeks": nombre_semaines_ou_null,
  "weight_grams": poids_grammes_ou_null,
  "mortality_rate": taux_mortalit√©_pourcentage_ou_null,
  "temperature": temp√©rature_celsius_ou_null,
  "humidity": humidit√©_pourcentage_ou_null,
  "housing_type": "type_b√¢timent_ou_null",
  "feed_type": "type_alimentation_ou_null",
  "flock_size": nombre_poulets_ou_null,
  "symptoms": ["sympt√¥me1", "sympt√¥me2"] ou null,
  "duration_problem": "dur√©e_probl√®me_ou_null",
  "previous_treatments": ["traitement1"] ou null
}}
```"""

            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                logger.warning("‚ö†Ô∏è [Enhanced Clarification] Cl√© API OpenAI manquante")
                return await self._extract_entities_fallback(question, language)
            
            # Configuration s√©curis√©e d'OpenAI
            if hasattr(openai, 'api_key'):
                openai.api_key = api_key
            else:
                # Pour les versions plus r√©centes d'OpenAI
                openai_client = openai.OpenAI(api_key=api_key)
            
            try:
                if hasattr(openai, 'chat') and hasattr(openai.chat, 'completions'):
                    # Ancienne version
                    response = openai.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.1,
                        max_tokens=400,
                        timeout=self.timeout
                    )
                else:
                    # Nouvelle version avec client
                    response = openai_client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.1,
                        max_tokens=400,
                        timeout=self.timeout
                    )
            except Exception as openai_error:
                logger.error(f"‚ùå [Enhanced Clarification] Erreur appel OpenAI: {openai_error}")
                # Fallback intelligent
                if self.enable_intelligent_fallback:
                    try:
                        adaptive_questions = self.question_generator.generate_adaptive_questions(
                            language, missing_critical_info, question_type
                        )
                    except Exception as fallback_error:
                        logger.error(f"Erreur fallback: {fallback_error}")
                        adaptive_questions = ["Pouvez-vous donner plus de d√©tails sur votre situation ?"]
                    
                    return ClarificationResult(
                        needs_clarification=True,
                        questions=adaptive_questions,
                        processing_time_ms=int((time.time() - start_time) * 1000),
                        reason=f"openai_error_intelligent_fallback: {str(openai_error)}",
                        model_used="rule_based_adaptive_fallback",
                        extracted_entities=extracted_entities,
                        question_type=question_type,
                        clarification_mode=self.clarification_mode,
                        clarification_state=ClarificationState.NEEDED,
                        missing_critical_info=missing_critical_info,
                        confidence_score=0.6,
                        original_question=original_question or question,
                        validation_score=0.7,
                        fallback_used=True,
                        gpt_failed=True,
                        missing_entities=critical_analysis["missing_entities"],
                        missing_critical_entities=critical_analysis["missing_critical_entities"],
                        clarification_required_critical=critical_analysis["clarification_required_critical"]
                    )
                else:
                    return ClarificationResult(
                        needs_clarification=False,
                        processing_time_ms=int((time.time() - start_time) * 1000),
                        reason=f"openai_error_no_fallback: {str(openai_error)}",
                        model_used=self.model,
                        extracted_entities=extracted_entities,
                        question_type=question_type,
                        clarification_state=ClarificationState.NONE,
                        fallback_used=False,
                        gpt_failed=True,
                        missing_entities=critical_analysis["missing_entities"],
                        missing_critical_entities=critical_analysis["missing_critical_entities"],
                        clarification_required_critical=critical_analysis["clarification_required_critical"]
                    )
            
            answer = response.choices[0].message.content.strip()
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            logger.info(f"ü§ñ [Enhanced Clarification] R√©ponse GPT-4o-mini ({processing_time_ms}ms): {answer[:100]}...")
            
            # Analyse de la r√©ponse
            if answer.upper().strip() in ["CLEAR", "CLEAR.", "CLEAR !"]:
                result = ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason="question_clear_by_gpt4o_mini_enhanced",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    validation_score=1.0,
                    fallback_used=False,
                    gpt_failed=False,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=False
                )
                
                logger.info(f"‚úÖ [Enhanced Clarification] Question claire selon GPT-4o-mini enrichi")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            
            # Extraire les questions de clarification
            clarification_questions = self._extract_questions(answer)
            
            # Limitation adaptative du nombre de questions
            if self.adaptive_question_count:
                max_questions = min(len(critical_analysis["missing_critical_entities"]) + 1, self.max_questions)
            else:
                max_questions = self.max_questions
            
            if clarification_questions and len(clarification_questions) > 0:
                limited_questions = clarification_questions[:max_questions]
                
                # Mode de clarification
                clarification_mode = self.clarification_mode
                if clarification_mode == ClarificationMode.ADAPTIVE:
                    clarification_mode = ClarificationMode.INTERACTIVE if len(limited_questions) == 1 else ClarificationMode.BATCH
                
                result = ClarificationResult(
                    needs_clarification=True,
                    questions=limited_questions,
                    processing_time_ms=processing_time_ms,
                    reason="clarification_needed_by_gpt4o_mini_enhanced",
                    model_used=self.model,
                    confidence_score=self._calculate_confidence_score_enhanced(question, limited_questions, extracted_entities, question_type),
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    original_question=original_question or question,
                    validation_score=0.8,
                    fallback_used=False,
                    gpt_failed=False,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
                
                logger.info(f"‚ùì [Enhanced Clarification] {len(limited_questions)} questions g√©n√©r√©es (mode: {clarification_mode.value})")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            else:
                logger.info(f"‚úÖ [Enhanced Clarification] Aucune question valide - question suffisante")
                return ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason="no_valid_questions_from_gpt4o_mini_enhanced",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    validation_score=1.0,
                    fallback_used=False,
                    gpt_failed=False,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
        
        except Exception as e:
            processing_time_ms = int((time.time() - start_time) * 1000)
            logger.error(f"‚ùå [Enhanced Clarification] Erreur GPT-4o-mini: {e}")
            
            # Fallback intelligent en cas d'erreur GPT
            if self.enable_intelligent_fallback:
                logger.info(f"üîÑ [Enhanced Clarification] Fallback intelligent activ√© suite √† erreur GPT")
                
                try:
                    adaptive_questions = self.question_generator.generate_adaptive_questions(
                        language, missing_critical_info, question_type
                    )
                except Exception as fallback_error:
                    logger.error(f"Erreur fallback final: {fallback_error}")
                    adaptive_questions = ["Pouvez-vous donner plus de d√©tails sur votre situation ?"]
                
                return ClarificationResult(
                    needs_clarification=True,
                    questions=adaptive_questions,
                    processing_time_ms=processing_time_ms,
                    reason=f"gpt_error_intelligent_fallback: {str(e)}",
                    model_used="rule_based_adaptive_fallback",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=self.clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    confidence_score=0.6,
                    original_question=original_question or question,
                    validation_score=0.7,
                    fallback_used=True,
                    gpt_failed=True,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
            else:
                return ClarificationResult(
                    needs_clarification=False,
                    processing_time_ms=processing_time_ms,
                    reason=f"error_gpt4o_mini_enhanced: {str(e)}",
                    model_used=self.model,
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_state=ClarificationState.NONE,
                    fallback_used=False,
                    gpt_failed=True,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )

    def _extract_questions(self, answer: str) -> List[str]:
        """Extrait les questions de clarification de la r√©ponse GPT"""
        if not answer or not isinstance(answer, str):
            return []
        
        questions = []
        lines = answer.splitlines()
        
        for line in lines:
            line = line.strip()
            if line and len(line) > 15:
                # Nettoyer les puces et formatage
                cleaned_line = re.sub(r'^[-‚Ä¢*]\s*', '', line)
                cleaned_line = re.sub(r'^\d+\.\s*', '', cleaned_line)
                cleaned_line = cleaned_line.strip()
                
                # V√©rifier que c'est une vraie question
                if cleaned_line and len(cleaned_line) > 20 and cleaned_line not in questions:
                    # Ajouter un point d'interrogation si manquant
                    if not cleaned_line.endswith('?') and not cleaned_line.endswith(' ?'):
                        if any(word in cleaned_line.lower() for word in ['quel', 'quelle', 'combien', 'comment', 'what', 'how', 'which', 'cu√°l', 'c√≥mo', 'cu√°nto']):
                            cleaned_line += ' ?'
                    
                    questions.append(cleaned_line)
        
        return questions

    def _calculate_confidence_score_enhanced(
        self, 
        original_question: str, 
        clarification_questions: List[str], 
        extracted_entities: ExtractedEntities,
        question_type: str
    ) -> float:
        """Score de confiance plus intelligent avec entit√©s critiques"""
        
        # Score de base
        base_score = min(len(clarification_questions) * 20, 70)
        
        # Bonus pour informations g√©n√©riques d√©tect√©es
        if hasattr(extracted_entities, 'breed_type') and extracted_entities.breed_type == "generic":
            base_score += 20
        
        # Bonus selon le type de question et informations manquantes
        critical_info_bonus = {
            "growth": 15 if not getattr(extracted_entities, 'age_days', None) else 0,
            "weight": 15 if not getattr(extracted_entities, 'age_days', None) else 0,
            "health": 10 if not getattr(extracted_entities, 'symptoms', None) else 0,
            "mortality": 15 if not getattr(extracted_entities, 'mortality_rate', None) else 0,
            "laying": 10 if not getattr(extracted_entities, 'age_days', None) else 0
        }
        
        base_score += critical_info_bonus.get(question_type, 5)
        
        # NOUVEAU: Bonus pour entit√©s critiques manquantes
        if self.enable_critical_entity_analysis:
            critical_analysis = self.analyze_critical_entities(extracted_entities, question_type)
            critical_missing_count = len(critical_analysis["missing_critical_entities"])
            base_score += critical_missing_count * 10  # Bonus de 10 points par entit√© critique manquante
        
        # Malus si beaucoup d'informations d√©j√† pr√©sentes
        try:
            extracted_count = len([v for v in extracted_entities.to_dict().values() if v is not None])
            if extracted_count > 3:
                base_score -= 10
        except Exception:
            pass
        
        # Bonus si reconnaissance automatique a fonctionn√©
        if hasattr(extracted_entities, 'breed_normalized') and extracted_entities.breed_normalized:
            base_score += 5
        if hasattr(extracted_entities, 'sex_inferred') and extracted_entities.sex_inferred:
            base_score += 5
        
        return min(base_score, 95.0)

    async def check_for_reprocessing(
        self,
        conversation_id: str,
        user_response: str,
        original_clarification_result: ClarificationResult
    ) -> Optional[ClarificationResult]:
        """
        V√©rifie si la question originale peut √™tre retrait√©e apr√®s clarification
        """
        
        if not self.auto_reprocess_after_clarification:
            return None
        
        if not original_clarification_result or not hasattr(original_clarification_result, 'original_question') or not original_clarification_result.original_question:
            return None
        
        logger.info(f"üîÑ [Enhanced Clarification] V√©rification retraitement apr√®s clarification")
        
        # Construire la question enrichie
        enriched_question = f"{original_clarification_result.original_question}\n\nInformation suppl√©mentaire: {user_response}"
        
        # R√©analyser avec le contexte enrichi
        try:
            reprocess_result = await self.analyze_question_enhanced(
                question=enriched_question,
                language="fr",
                conversation_id=conversation_id,
                original_question=original_clarification_result.original_question
            )
        except Exception as e:
            logger.error(f"Erreur lors du retraitement: {e}")
            return None
        
        if not reprocess_result.needs_clarification:
            reprocess_result.should_reprocess = True
            reprocess_result.clarification_state = ClarificationState.AWAITING_REPROCESS
            logger.info(f"‚úÖ [Enhanced Clarification] Question pr√™te pour retraitement")
            return reprocess_result
        
        logger.info(f"‚ö†Ô∏è [Enhanced Clarification] Clarification suppl√©mentaire encore n√©cessaire")
        return None

    def format_clarification_response_enhanced(
        self, 
        result: ClarificationResult,
        language: str
    ) -> str:
        """Formatage enrichi selon le mode de clarification avec mention des entit√©s critiques"""
        
        if not result or not hasattr(result, 'questions') or not result.questions:
            return ""
        
        intros = {
            "fr": {
                ClarificationMode.BATCH: "‚ùì Pour vous donner la r√©ponse la plus pr√©cise possible, j'aurais besoin de quelques informations suppl√©mentaires :",
                ClarificationMode.INTERACTIVE: "‚ùì Pour vous aider au mieux, puis-je vous poser une question rapide :",
                ClarificationMode.ADAPTIVE: "‚ùì J'ai besoin d'une pr√©cision pour vous donner une r√©ponse adapt√©e :",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì Pour mieux comprendre votre situation et vous aider efficacement :"
            },
            "en": {
                ClarificationMode.BATCH: "‚ùì To give you the most accurate answer possible, I would need some additional information:",
                ClarificationMode.INTERACTIVE: "‚ùì To help you best, may I ask you a quick question:",
                ClarificationMode.ADAPTIVE: "‚ùì I need clarification to give you a tailored answer:",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì To better understand your situation and help you effectively:"
            },
            "es": {
                ClarificationMode.BATCH: "‚ùì Para darle la respuesta m√°s precisa posible, necesitar√≠a informaci√≥n adicional:",
                ClarificationMode.INTERACTIVE: "‚ùì Para ayudarle mejor, ¬øpuedo hacerle una pregunta r√°pida:",
                ClarificationMode.ADAPTIVE: "‚ùì Necesito una aclaraci√≥n para darle una respuesta adaptada:",
                ClarificationMode.SEMANTIC_DYNAMIC: "‚ùì Para entender mejor su situaci√≥n y ayudarle efectivamente:"
            }
        }
        
        outros = {
            "fr": {
                ClarificationMode.BATCH: "\n\nCes pr√©cisions m'aideront √† vous donner des conseils sp√©cifiques et adapt√©s √† votre situation ! üêî",
                ClarificationMode.INTERACTIVE: "\n\nMerci pour votre pr√©cision ! üêî",
                ClarificationMode.ADAPTIVE: "\n\nCela m'aidera √† vous donner une r√©ponse plus pr√©cise ! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\nCela me permettra de vous donner les conseils les plus pertinents ! üêî"
            },
            "en": {
                ClarificationMode.BATCH: "\n\nThese details will help me give you specific advice tailored to your situation! üêî",
                ClarificationMode.INTERACTIVE: "\n\nThank you for the clarification! üêî",
                ClarificationMode.ADAPTIVE: "\n\nThis will help me give you a more precise answer! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\nThis will allow me to give you the most relevant advice! üêî"
            },
            "es": {
                ClarificationMode.BATCH: "\n\n¬°Estos detalles me ayudar√°n a darle consejos espec√≠ficos adaptados a su situaci√≥n! üêî",
                ClarificationMode.INTERACTIVE: "\n\n¬°Gracias por la aclaraci√≥n! üêî",
                ClarificationMode.ADAPTIVE: "\n\n¬°Esto me ayudar√° a darle una respuesta m√°s precisa! üêî",
                ClarificationMode.SEMANTIC_DYNAMIC: "\n\n¬°Esto me permitir√° darle los consejos m√°s relevantes! üêî"
            }
        }
        
        mode = getattr(result, 'clarification_mode', None) or ClarificationMode.BATCH
        intro = intros.get(language, intros["fr"]).get(mode, intros["fr"][ClarificationMode.BATCH])
        outro = outros.get(language, outros["fr"]).get(mode, outros["fr"][ClarificationMode.BATCH])
        
        # Ajouter une mention sp√©ciale si des entit√©s critiques sont manquantes
        critical_mention = ""
        if hasattr(result, 'clarification_required_critical') and result.clarification_required_critical:
            critical_mentions = {
                "fr": " (informations essentielles pour un diagnostic pr√©cis)",
                "en": " (essential information for accurate diagnosis)",
                "es": " (informaci√≥n esencial para un diagn√≥stico preciso)"
            }
            critical_mention = critical_mentions.get(language, critical_mentions["fr"])
        
        if mode == ClarificationMode.INTERACTIVE or len(result.questions) == 1:
            # Mode interactif ou une seule question
            return f"{intro}{critical_mention}\n\n{result.questions[0]}{outro}"
        else:
            # Mode batch - plusieurs questions
            formatted_questions = "\n".join([f"‚Ä¢ {q}" for q in result.questions])
            return f"{intro}{critical_mention}\n\n{formatted_questions}{outro}"

    async def _log_clarification_decision(
        self,
        question: str,
        language: str,
        user_id: str,
        conversation_id: str,
        result: ClarificationResult
    ):
        """Log d√©taill√© des d√©cisions de clarification enrichi avec entit√©s critiques"""
        
        try:
            clarification_data = {
                "timestamp": datetime.now().isoformat(),
                "conversation_id": conversation_id,
                "user_id": user_id,
                "question": question,
                "question_length": len(question) if question else 0,
                "language": language,
                "result": result.to_dict() if result else {},
                "system_config": {
                    "enabled": self.enabled,
                    "model": self.model,
                    "max_questions": self.max_questions,
                    "confidence_threshold": self.confidence_threshold,
                    "clarification_mode": self.clarification_mode.value,
                    "enable_semantic_dynamic": self.enable_semantic_dynamic,
                    "enable_question_validation": self.enable_question_validation,
                    "enable_breed_normalization": self.enable_breed_normalization,
                    "enable_sex_inference": self.enable_sex_inference,
                    "enable_critical_entity_analysis": self.enable_critical_entity_analysis,
                    "critical_entities_threshold": self.critical_entities_threshold
                }
            }
            
            # Log structur√©
            self.clarification_logger.info(json.dumps(clarification_data, ensure_ascii=False))
            
        except Exception as e:
            logger.warning(f"Erreur lors du logging des clarifications: {e}")
        
        # Log standard enrichi avec entit√©s critiques
        try:
            if result and result.needs_clarification:
                critical_info = ""
                if hasattr(result, 'clarification_required_critical'):
                    critical_status = "üö® CRITIQUE" if result.clarification_required_critical else "üìù Standard"
                    critical_entities_count = len(getattr(result, 'missing_critical_entities', []))
                    critical_info = f" | {critical_status} ({critical_entities_count} entit√©s critiques manquantes)"
                
                logger.info(
                    f"‚ùì [Enhanced Clarification] CLARIFICATION - "
                    f"User: {user_id[:8]} | Type: {getattr(result, 'question_type', 'unknown')} | "
                    f"Questions: {len(getattr(result, 'questions', []))} | Mode: {getattr(result, 'clarification_mode', {}).value if hasattr(getattr(result, 'clarification_mode', {}), 'value') else 'N/A'} | "
                    f"Validation: {getattr(result, 'validation_score', 0):.1f} | "
                    f"Fallback: {'‚úÖ' if getattr(result, 'fallback_used', False) else '‚ùå'} | "
                    f"Temps: {getattr(result, 'processing_time_ms', 0)}ms{critical_info}"
                )
            else:
                logger.info(
                    f"‚úÖ [Enhanced Clarification] CLEAR - "
                    f"User: {user_id[:8]} | Type: {getattr(result, 'question_type', 'unknown')} | "
                    f"Raison: {getattr(result, 'reason', 'unknown')} | "
                    f"Temps: {getattr(result, 'processing_time_ms', 0)}ms"
                )
        except Exception as e:
            logger.warning(f"Erreur lors du logging standard: {e}")

    def get_stats_enhanced(self) -> Dict:
        """Retourne les statistiques du syst√®me enrichi avec entit√©s critiques"""
        return {
            "enabled": self.enabled,
            "model": self.model,
            "max_questions": self.max_questions,
            "confidence_threshold": self.confidence_threshold,
            "openai_available": OPENAI_AVAILABLE,
            "clarification_mode": self.clarification_mode.value,
            "smart_entity_extraction": self.smart_entity_extraction,
            "semantic_dynamic_enabled": self.enable_semantic_dynamic,
            "question_validation_enabled": self.enable_question_validation,
            "breed_normalization_enabled": self.enable_breed_normalization,
            "sex_inference_enabled": self.enable_sex_inference,
            "critical_entity_analysis_enabled": self.enable_critical_entity_analysis,
            "critical_entities_threshold": self.critical_entities_threshold,
            "critical_entities": CRITICAL_ENTITIES,
            "critical_entities_count": len(CRITICAL_ENTITIES),
            "supported_question_types": list(self.question_type_patterns.keys()),
            "supported_languages": ["fr", "en", "es"],
            "critical_entities_by_question_type": CRITICAL_ENTITIES_BY_QUESTION_TYPE
        }


# ==================== INSTANCE GLOBALE ====================

# Instance singleton du syst√®me de clarification
enhanced_clarification_system = EnhancedQuestionClarificationSystem()

# ==================== FONCTIONS UTILITAIRES PUBLIQUES ====================

async def analyze_question_for_clarification_enhanced(
    question: str, 
    language: str = "fr",
    user_id: str = "unknown", 
    conversation_id: str = None,
    conversation_context: Dict = None,
    original_question: str = None
) -> ClarificationResult:
    """Fonction utilitaire pour analyser les questions avec le syst√®me am√©lior√©"""
    try:
        return await enhanced_clarification_system.analyze_question_enhanced(
            question, language, user_id, conversation_id, conversation_context, original_question
        )
    except Exception as e:
        logger.error(f"Erreur dans analyze_question_for_clarification_enhanced: {e}")
        return ClarificationResult(
            needs_clarification=False,
            reason=f"error_in_analysis: {str(e)}",
            clarification_state=ClarificationState.NONE
        )

async def analyze_question_for_clarification_semantic_dynamic(
    question: str, 
    language: str = "fr",
    user_id: str = "unknown", 
    conversation_id: str = None,
    conversation_context: Dict = None
) -> ClarificationResult:
    """Fonction utilitaire pour utiliser le mode s√©mantique dynamique directement"""
    try:
        return await enhanced_clarification_system.analyze_question_enhanced(
            question, language, user_id, conversation_id, conversation_context, mode="semantic_dynamic"
        )
    except Exception as e:
        logger.error(f"Erreur dans analyze_question_for_clarification_semantic_dynamic: {e}")
        return ClarificationResult(
            needs_clarification=False,
            reason=f"error_in_semantic_dynamic: {str(e)}",
            clarification_state=ClarificationState.NONE
        )

def analyze_critical_entities_for_question(
    extracted_entities: ExtractedEntities, 
    question_type: str
) -> Dict[str, Any]:
    """Fonction utilitaire pour analyser les entit√©s critiques d'une question"""
    try:
        return enhanced_clarification_system.analyze_critical_entities(extracted_entities, question_type)
    except Exception as e:
        logger.error(f"Erreur dans analyze_critical_entities_for_question: {e}")
        return {
            "missing_entities": [],
            "missing_critical_entities": [],
            "clarification_required_critical": False,
            "critical_entities_for_type": []
        }

def get_critical_entities_for_question_type(question_type: str) -> List[str]:
    """Retourne les entit√©s critiques pour un type de question donn√©"""
    return CRITICAL_ENTITIES_BY_QUESTION_TYPE.get(question_type, CRITICAL_ENTITIES_BY_QUESTION_TYPE["general"])

def is_critical_entity_missing(entity_name: str, extracted_entities: ExtractedEntities) -> bool:
    """V√©rifie si une entit√© critique sp√©cifique est manquante"""
    try:
        if entity_name not in CRITICAL_ENTITIES:
            return False
        
        entity_attributes = ENTITY_ATTRIBUTE_MAPPING.get(entity_name, [entity_name])
        entities_dict = extracted_entities.to_dict()
        
        for attr in entity_attributes:
            if attr in entities_dict and entities_dict[attr] is not None:
                # V√©rifications sp√©ciales
                if attr == "breed_type" and entities_dict[attr] == "generic":
                    continue
                if attr == "symptoms" and isinstance(entities_dict[attr], list) and len(entities_dict[attr]) == 0:
                    continue
                return False
        
        return True
    except Exception as e:
        logger.error(f"Erreur dans is_critical_entity_missing: {e}")
        return False

def format_clarification_response_enhanced(result: ClarificationResult, language: str) -> str:
    """Formate la r√©ponse de clarification avec le syst√®me am√©lior√©"""
    try:
        return enhanced_clarification_system.format_clarification_response_enhanced(result, language)
    except Exception as e:
        logger.error(f"Erreur dans format_clarification_response_enhanced: {e}")
        return "‚ùì J'ai besoin de plus d'informations pour vous aider au mieux."

async def check_for_reprocessing_after_clarification(
    conversation_id: str,
    user_response: str,
    original_clarification_result: ClarificationResult
) -> Optional[ClarificationResult]:
    """V√©rifie si une question peut √™tre retrait√©e apr√®s clarification"""
    try:
        return await enhanced_clarification_system.check_for_reprocessing(
            conversation_id, user_response, original_clarification_result
        )
    except Exception as e:
        logger.error(f"Erreur dans check_for_reprocessing_after_clarification: {e}")
        return None

def get_enhanced_clarification_system_stats() -> Dict:
    """Retourne les statistiques du syst√®me am√©lior√©"""
    try:
        return enhanced_clarification_system.get_stats_enhanced()
    except Exception as e:
        logger.error(f"Erreur dans get_enhanced_clarification_system_stats: {e}")
        return {"error": str(e), "enabled": False}

def is_enhanced_clarification_system_enabled() -> bool:
    """V√©rifie si le syst√®me de clarification am√©lior√© est activ√©"""
    try:
        return enhanced_clarification_system.enabled
    except Exception as e:
        logger.error(f"Erreur dans is_enhanced_clarification_system_enabled: {e}")
        return False

def build_enriched_question_enhanced(
    original_question: str, 
    clarification_answers: Dict[str, str], 
    clarification_questions: List[str]
) -> str:
    """Construit une question enrichie avec les r√©ponses de clarification"""
    try:
        if not original_question:
            return ""
        
        enriched_question = original_question + "\n\nInformations suppl√©mentaires :"
        
        for index_str, answer in clarification_answers.items():
            if answer and answer.strip():
                try:
                    index = int(index_str)
                    if 0 <= index < len(clarification_questions):
                        question = clarification_questions[index]
                        enriched_question += f"\n- {question}: {answer.strip()}"
                except (ValueError, IndexError):
                    continue
        
        return enriched_question
    except Exception as e:
        logger.error(f"Erreur dans build_enriched_question_enhanced: {e}")
        return original_question or ""

def get_missing_critical_entities_summary(result: ClarificationResult, language: str = "fr") -> str:
    """G√©n√®re un r√©sum√© des entit√©s critiques manquantes"""
    try:
        if not hasattr(result, 'missing_critical_entities') or not result.missing_critical_entities:
            return ""
        
        summaries = {
            "fr": {
                "breed": "race/souche",
                "age": "√¢ge",
                "sex": "sexe",
                "symptoms": "sympt√¥mes",
                "environment": "environnement",
                "feed": "alimentation",
                "flock_size": "taille du troupeau",
                "mortality_rate": "taux de mortalit√©"
            },
            "en": {
                "breed": "breed/strain",
                "age": "age",
                "sex": "sex",
                "symptoms": "symptoms",
                "environment": "environment",
                "feed": "feeding",
                "flock_size": "flock size",
                "mortality_rate": "mortality rate"
            },
            "es": {
                "breed": "raza/cepa",
                "age": "edad",
                "sex": "sexo",
                "symptoms": "s√≠ntomas",
                "environment": "ambiente",
                "feed": "alimentaci√≥n",
                "flock_size": "tama√±o del reba√±o",
                "mortality_rate": "tasa de mortalidad"
            }
        }
        
        entity_names = summaries.get(language, summaries["fr"])
        missing_names = [entity_names.get(entity, entity) for entity in result.missing_critical_entities]
        
        if len(missing_names) == 1:
            return missing_names[0]
        elif len(missing_names) == 2:
            conjunction = {"fr": " et ", "en": " and ", "es": " y "}.get(language, " et ")
            return conjunction.join(missing_names)
        else:
            conjunction = {"fr": " et ", "en": " and ", "es": " y "}.get(language, " et ")
            return ", ".join(missing_names[:-1]) + conjunction + missing_names[-1]
    except Exception as e:
        logger.error(f"Erreur dans get_missing_critical_entities_summary: {e}")
        return ""

# ==================== EXTENSIONS DU QUESTION GENERATOR ====================

def extend_question_generator_with_critical_entities():
    """√âtend le g√©n√©rateur de questions avec le support des entit√©s critiques"""
    
    def generate_critical_entity_questions(self, language: str, missing_critical_entities: List[str], question_type: str) -> List[str]:
        """G√©n√®re des questions sp√©cifiques aux entit√©s critiques manquantes"""
        
        questions = []
        
        critical_entity_questions = {
            "fr": {
                "breed": [
                    "Quelle est la race ou souche exacte de vos volailles ? (ex: Ross 308, Cobb 500, Lohmann LSL-Lite)",
                    "Quel type de poulets √©levez-vous ? Pr√©cisez la souche si possible."
                ],
                "age": [
                    "Quel est l'√¢ge de vos volailles en jours ou en semaines ?",
                    "Depuis combien de temps vos volailles sont-elles n√©es ?"
                ],
                "sex": [
                    "S'agit-il de m√¢les, de femelles ou d'un troupeau mixte ?",
                    "Quel est le sexe de vos volailles ?"
                ],
                "symptoms": [
                    "Quels sympt√¥mes pr√©cis observez-vous chez vos volailles ?",
                    "Pouvez-vous d√©crire les signes cliniques que vous avez remarqu√©s ?"
                ],
                "environment": [
                    "Quelles sont les conditions d'√©levage ? (temp√©rature, humidit√©, type de b√¢timent)",
                    "Dans quel environnement vos volailles sont-elles √©lev√©es ?"
                ],
                "feed": [
                    "Quel type d'alimentation donnez-vous √† vos volailles ?",
                    "Pouvez-vous pr√©ciser le programme alimentaire utilis√© ?"
                ],
                "flock_size": [
                    "Combien de volailles avez-vous dans votre troupeau ?",
                    "Quelle est la taille de votre √©levage ?"
                ],
                "mortality_rate": [
                    "Quel est le taux de mortalit√© observ√© ? (nombre de morts / total)",
                    "Combien de volailles sont mortes et sur combien au total ?"
                ]
            },
            "en": {
                "breed": [
                    "What is the exact breed or strain of your poultry? (e.g., Ross 308, Cobb 500, Lohmann LSL-Lite)",
                    "What type of chickens are you raising? Please specify the strain if possible."
                ],
                "age": [
                    "What is the age of your poultry in days or weeks?",
                    "How long have your poultry been hatched?"
                ],
                "sex": [
                    "Are these males, females, or a mixed flock?",
                    "What is the sex of your poultry?"
                ],
                "symptoms": [
                    "What specific symptoms are you observing in your poultry?",
                    "Can you describe the clinical signs you have noticed?"
                ],
                "environment": [
                    "What are the housing conditions? (temperature, humidity, building type)",
                    "In what environment are your poultry being raised?"
                ],
                "feed": [
                    "What type of feed are you giving to your poultry?",
                    "Can you specify the feeding program used?"
                ],
                "flock_size": [
                    "How many poultry do you have in your flock?",
                    "What is the size of your operation?"
                ],
                "mortality_rate": [
                    "What is the observed mortality rate? (number of deaths / total)",
                    "How many poultry have died and out of how many total?"
                ]
            },
            "es": {
                "breed": [
                    "¬øCu√°l es la raza o cepa exacta de sus aves? (ej: Ross 308, Cobb 500, Lohmann LSL-Lite)",
                    "¬øQu√© tipo de pollos est√° criando? Especifique la cepa si es posible."
                ],
                "age": [
                    "¬øCu√°l es la edad de sus aves en d√≠as o semanas?",
                    "¬øHace cu√°nto tiempo nacieron sus aves?"
                ],
                "sex": [
                    "¬øSon machos, hembras o un reba√±o mixto?",
                    "¬øCu√°l es el sexo de sus aves?"
                ],
                "symptoms": [
                    "¬øQu√© s√≠ntomas espec√≠ficos observa en sus aves?",
                    "¬øPuede describir los signos cl√≠nicos que ha notado?"
                ],
                "environment": [
                    "¬øCu√°les son las condiciones de crianza? (temperatura, humedad, tipo de edificio)",
                    "¬øEn qu√© ambiente se est√°n criando sus aves?"
                ],
                "feed": [
                    "¬øQu√© tipo de alimentaci√≥n da a sus aves?",
                    "¬øPuede especificar el programa alimentario utilizado?"
                ],
                "flock_size": [
                    "¬øCu√°ntas aves tiene en su reba√±o?",
                    "¬øCu√°l es el tama√±o de su operaci√≥n?"
                ],
                "mortality_rate": [
                    "¬øCu√°l es la tasa de mortalidad observada? (n√∫mero de muertes / total)",
                    "¬øCu√°ntas aves han muerto y de cu√°ntas en total?"
                ]
            }
        }
        
        language_questions = critical_entity_questions.get(language, critical_entity_questions["fr"])
        
        # Prioriser selon le type de question
        priority_order = CRITICAL_ENTITIES_BY_QUESTION_TYPE.get(question_type, CRITICAL_ENTITIES)
        
        # Trier les entit√©s manquantes par priorit√©
        sorted_entities = [entity for entity in priority_order if entity in missing_critical_entities]
        remaining_entities = [entity for entity in missing_critical_entities if entity not in sorted_entities]
        sorted_entities.extend(remaining_entities)
        
        # G√©n√©rer les questions dans l'ordre de priorit√©
        for entity in sorted_entities[:self.max_questions]:
            if entity in language_questions:
                # Prendre la premi√®re question pour cette entit√©
                questions.append(language_questions[entity][0])
        
        return questions
    
    # Ajouter la m√©thode au g√©n√©rateur de questions seulement si le module est disponible
    if GENERATORS_MODULE_AVAILABLE:
        try:
            QuestionGenerator.generate_critical_entity_questions = generate_critical_entity_questions
            logger.info("‚úÖ Extension du g√©n√©rateur de questions avec entit√©s critiques appliqu√©e")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible d'√©tendre le g√©n√©rateur de questions: {e}")
    else:
        # Ajouter la m√©thode √† notre classe de base
        try:
            QuestionGenerator.generate_critical_entity_questions = generate_critical_entity_questions
            logger.info("‚úÖ Extension du g√©n√©rateur de questions de base avec entit√©s critiques appliqu√©e")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible d'√©tendre le g√©n√©rateur de questions de base: {e}")

# Appliquer l'extension
try:
    extend_question_generator_with_critical_entities()
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Erreur lors de l'extension du g√©n√©rateur de questions: {e}")

# ==================== LOGGING DE D√âMARRAGE ====================

logger.info("‚ùì [EnhancedQuestionClarificationSystem] Module MODULAIRE initialis√© avec ENTIT√âS CRITIQUES (VERSION CORRIG√âE)")
logger.info("‚úÖ [Clarification System] PR√äT - Toutes fonctionnalit√©s disponibles + analyse entit√©s critiques!")
logger.info(f"üéØ [Critical Entities] {len(CRITICAL_ENTITIES)} entit√©s critiques configur√©es")

try:
    stats = enhanced_clarification_system.get_stats_enhanced()
    logger.info(f"üìä [System Stats] {stats}")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Impossible d'obtenir les statistiques du syst√®me: {e}")

logger.info("üîß [Error Handling] Gestion d'erreurs robuste activ√©e pour tous les composants")
logger.info("üõ°Ô∏è [Stability] Syst√®me de fallback et de r√©cup√©ration d'erreurs en place")
ai.chat, 'completions'):
                    # Ancienne version
                    response = openai.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "Tu es un extracteur d'entit√©s expert en aviculture avec reconnaissance des souches et focus sur les entit√©s critiques. R√©ponds uniquement avec du JSON valide."},
                            {"role": "user", "content": extraction_prompt}
                        ],
                        temperature=0.1,
                        max_tokens=500,
                        timeout=self.timeout
                    )
                else:
                    # Nouvelle version avec client
                    response = openai_client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "Tu es un extracteur d'entit√©s expert en aviculture avec reconnaissance des souches et focus sur les entit√©s critiques. R√©ponds uniquement avec du JSON valide."},
                            {"role": "user", "content": extraction_prompt}
                        ],
                        temperature=0.1,
                        max_tokens=500,
                        timeout=self.timeout
                    )
            except Exception as openai_error:
                logger.error(f"‚ùå [Enhanced Clarification] Erreur appel OpenAI: {openai_error}")
                return await self._extract_entities_fallback(question, language)
            
            answer = response.choices[0].message.content.strip()
            
            # Extraire le JSON de la r√©ponse
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', answer, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_match = re.search(r'\{.*\}', answer, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    logger.warning("‚ö†Ô∏è [Enhanced Clarification] Pas de JSON trouv√© dans la r√©ponse")
                    return await self._extract_entities_fallback(question, language)
            
            # Parser le JSON
            try:
                extracted_data = json.loads(json_str)
                
                # Convertir en ExtractedEntities avec validation des types
                entities = ExtractedEntities(
                    breed=extracted_data.get("breed"),
                    breed_type=extracted_data.get("breed_type"),
                    sex=extracted_data.get("sex"),
                    age_days=self._safe_int_conversion(extracted_data.get("age_days")),
                    age_weeks=self._safe_int_conversion(extracted_data.get("age_weeks")),
                    weight_grams=self._safe_float_conversion(extracted_data.get("weight_grams")),
                    mortality_rate=self._safe_float_conversion(extracted_data.get("mortality_rate")),
                    temperature=self._safe_float_conversion(extracted_data.get("temperature")),
                    humidity=self._safe_float_conversion(extracted_data.get("humidity")),
                    housing_type=extracted_data.get("housing_type"),
                    feed_type=extracted_data.get("feed_type"),
                    flock_size=self._safe_int_conversion(extracted_data.get("flock_size")),
                    symptoms=self._safe_list_conversion(extracted_data.get("symptoms")),
                    duration_problem=extracted_data.get("duration_problem"),
                    previous_treatments=self._safe_list_conversion(extracted_data.get("previous_treatments"))
                )
                
                # Appliquer normalisation et inf√©rence
                if self.enable_breed_normalization or self.enable_sex_inference:
                    entities.normalize_and_infer()
                
                logger.info(f"ü§ñ [Enhanced Clarification] Entit√©s extraites intelligemment: {entities.to_dict()}")
                return entities
                
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Erreur parsing JSON: {e}")
                return await self._extract_entities_fallback(question, language)
        
        except Exception as e:
            logger.error(f"‚ùå [Enhanced Clarification] Erreur extraction intelligente: {e}")
            return await self._extract_entities_fallback(question, language)

    def _safe_int_conversion(self, value) -> Optional[int]:
        """Conversion s√©curis√©e vers int"""
        if value is None:
            return None
        try:
            return int(float(value))  # Float d'abord pour g√©rer "3.0"
        except (ValueError, TypeError):
            return None

    def _safe_float_conversion(self, value) -> Optional[float]:
        """Conversion s√©curis√©e vers float"""
        if value is None:
            return None
        try:
            return float(value)
        except (ValueError, TypeError):
            return None

    def _safe_list_conversion(self, value) -> Optional[List[str]]:
        """Conversion s√©curis√©e vers liste"""
        if value is None:
            return None
        if isinstance(value, list):
            return [str(item) for item in value if item is not None]
        if isinstance(value, str):
            return [value] if value.strip() else None
        return None

    async def _extract_entities_fallback(self, question: str, language: str) -> ExtractedEntities:
        """Extraction d'entit√©s fallback avec reconnaissance souches (r√®gles basiques)"""
        
        entities = ExtractedEntities()
        
        if not question or not isinstance(question, str):
            return entities
        
        question_lower = question.lower()
        
        # D√©tection race sp√©cifique avec nouvelles souches
        specific_patterns = self.specific_breed_patterns.get(language, self.specific_breed_patterns.get("fr", []))
        for pattern in specific_patterns:
            try:
                match = re.search(pattern, question_lower, re.IGNORECASE)
                if match:
                    raw_breed = match.group(0).strip()
                    entities.breed = raw_breed
                    entities.breed_type = "specific"
                    break
            except re.error as e:
                logger.warning(f"Erreur dans le pattern regex '{pattern}': {e}")
                continue
        
        # D√©tection race g√©n√©rique si pas sp√©cifique
        if not entities.breed:
            generic_patterns = [r'poulets?', r'volailles?', r'chickens?', r'poultry', r'pollos?', r'aves?', r'poules?']
            for pattern in generic_patterns:
                try:
                    match = re.search(pattern, question_lower, re.IGNORECASE)
                    if match:
                        entities.breed = match.group(0).strip()
                        entities.breed_type = "generic"
                        break
                except re.error as e:
                    logger.warning(f"Erreur dans le pattern regex g√©n√©rique '{pattern}': {e}")
                    continue
        
        # D√©tection sexe explicite
        sex_patterns = {
            "fr": [r'm√¢les?', r'femelles?', r'coqs?', r'poules?', r'poulettes?', r'mixte'],
            "en": [r'males?', r'females?', r'roosters?', r'hens?', r'pullets?', r'mixed'],
            "es": [r'machos?', r'hembras?', r'gallos?', r'gallinas?', r'pollas?', r'mixto']
        }
        
        patterns = sex_patterns.get(language, sex_patterns.get("fr", []))
        for pattern in patterns:
            try:
                match = re.search(pattern, question_lower, re.IGNORECASE)
                if match:
                    sex_word = match.group(0).lower()
                    if sex_word in ['m√¢le', 'm√¢les', 'male', 'males', 'macho', 'machos', 'coq', 'coqs', 'rooster', 'roosters', 'gallo', 'gallos']:
                        entities.sex = "m√¢le"
                    elif sex_word in ['femelle', 'femelles', 'female', 'females', 'hembra', 'hembras', 'poule', 'poules', 'hen', 'hens', 'gallina', 'gallinas', 'poulette', 'poulettes', 'pullet', 'pullets', 'polla', 'pollas']:
                        entities.sex = "femelle"
                    elif sex_word in ['mixte', 'mixed', 'mixto']:
                        entities.sex = "mixte"
                    break
            except re.error as e:
                logger.warning(f"Erreur dans le pattern regex sexe '{pattern}': {e}")
                continue
        
        # D√©tection √¢ge
        age_patterns = [
            r'(\d+)\s*jours?', r'(\d+)\s*days?', r'(\d+)\s*d√≠as?',
            r'(\d+)\s*semaines?', r'(\d+)\s*weeks?', r'(\d+)\s*semanas?',
            r'jour\s*(\d+)', r'day\s*(\d+)', r'd√≠a\s*(\d+)'
        ]
        
        for pattern in age_patterns:
            try:
                match = re.search(pattern, question_lower, re.IGNORECASE)
                if match:
                    value = int(match.group(1))
                    if 'semaine' in pattern or 'week' in pattern or 'semana' in pattern:
                        entities.age_weeks = value
                        entities.age_days = value * 7
                    else:
                        entities.age_days = value
                    break
            except (re.error, ValueError) as e:
                logger.warning(f"Erreur dans le pattern regex √¢ge '{pattern}': {e}")
                continue
        
        # D√©tection poids
        weight_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:kg|gramm?es?|g|lbs?)',
            r'p√®sent?\s+(\d+(?:\.\d+)?)', r'weigh\s+(\d+(?:\.\d+)?)'
        ]
        
        for pattern in weight_patterns:
            try:
                match = re.search(pattern, question_lower, re.IGNORECASE)
                if match:
                    entities.weight_grams = float(match.group(1))
                    break
            except (re.error, ValueError) as e:
                logger.warning(f"Erreur dans le pattern regex poids '{pattern}': {e}")
                continue
        
        # Appliquer normalisation et inf√©rence m√™me en fallback
        if self.enable_breed_normalization or self.enable_sex_inference:
            try:
                entities.normalize_and_infer()
            except Exception as e:
                logger.warning(f"Erreur lors de la normalisation fallback: {e}")
        
        return entities

    async def analyze_question_enhanced(
        self, 
        question: str, 
        language: str = "fr",
        user_id: str = "unknown",
        conversation_id: str = None,
        conversation_context: Dict = None,
        original_question: str = None,
        mode: str = None
    ) -> ClarificationResult:
        """
        ANALYSE AM√âLIOR√âE avec extraction intelligente, gestion du contexte et analyse des entit√©s critiques
        """
        
        start_time = time.time()
        
        if not self.enabled:
            logger.info(f"üîß [Enhanced Clarification] Syst√®me d√©sactiv√©")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="system_disabled",
                clarification_state=ClarificationState.NONE
            )
        
        if not question or not isinstance(question, str) or len(question.strip()) < self.min_question_length:
            logger.info(f"‚ö†Ô∏è [Enhanced Clarification] Question trop courte: {len(question) if question else 0}")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="question_too_short",
                clarification_state=ClarificationState.NONE
            )
        
        # Classification du type de question
        question_type = self.classify_question_type(question, language)
        logger.info(f"üè∑Ô∏è [Enhanced Clarification] Type de question: {question_type}")
        
        # Extraction intelligente d'entit√©s avec reconnaissance souches
        extracted_entities = await self.extract_entities_intelligent(
            question, 
            language, 
            conversation_context
        )
        
        logger.info(f"üîç [Enhanced Clarification] Analyse: '{question[:80]}...'")
        logger.info(f"üìä [Enhanced Clarification] Entit√©s extraites: {extracted_entities.to_dict()}")
        
        # Logging de reconnaissance automatique
        if hasattr(extracted_entities, 'breed_normalized') and extracted_entities.breed_normalized:
            logger.info(f"üîÑ [Breed Recognition] Souche normalis√©e automatiquement: {extracted_entities.breed}")
        if hasattr(extracted_entities, 'sex_inferred') and extracted_entities.sex_inferred:
            logger.info(f"üö∫ [Sex Inference] Sexe inf√©r√© automatiquement: {extracted_entities.sex}")
        
        # NOUVELLE FONCTIONNALIT√â: Analyse des entit√©s critiques
        critical_analysis = self.analyze_critical_entities(extracted_entities, question_type)
        
        # D√©terminer les informations critiques manquantes (ancien syst√®me)
        try:
            missing_critical_info = extracted_entities.get_missing_critical_info(question_type)
        except Exception as e:
            logger.warning(f"Erreur lors de l'obtention des infos critiques manquantes: {e}")
            missing_critical_info = []
        
        logger.info(f"‚ùå [Enhanced Clarification] Informations critiques manquantes (ancien): {missing_critical_info}")
        logger.info(f"üéØ [Critical Analysis] R√©sultats: {critical_analysis}")
        
        # Gestion du mode s√©mantique dynamique avec validation robuste
        if (mode == "semantic_dynamic" or 
            self.clarification_mode == ClarificationMode.SEMANTIC_DYNAMIC) and \
           self.enable_semantic_dynamic:
            
            logger.info(f"üéØ [Semantic Dynamic] Mode activ√© pour: '{question[:50]}...'")
            
            # G√©n√©rer questions dynamiques avec m√©tadonn√©es de validation
            try:
                dynamic_questions, validation_metadata = self.question_generator.generate_dynamic_questions_with_validation(question, language)
            except Exception as e:
                logger.error(f"Erreur g√©n√©ration questions dynamiques: {e}")
                dynamic_questions, validation_metadata = [], {"validation_score": 0.5, "gpt_success": False, "fallback_used": True}
            
            if dynamic_questions and len(dynamic_questions) > 0:
                processing_time_ms = int((time.time() - start_time) * 1000)
                
                result = ClarificationResult(
                    needs_clarification=True,
                    questions=dynamic_questions,
                    processing_time_ms=processing_time_ms,
                    reason="semantic_dynamic_clarification_generated",
                    model_used=f"{self.model}_semantic_dynamic",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=ClarificationMode.SEMANTIC_DYNAMIC,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    confidence_score=0.9,
                    original_question=original_question or question,
                    validation_score=validation_metadata.get("validation_score", 0.8),
                    validation_details=validation_metadata,
                    fallback_used=validation_metadata.get("fallback_used", False),
                    gpt_failed=not validation_metadata.get("gpt_success", False),
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
                
                logger.info(f"‚úÖ [Semantic Dynamic] {len(dynamic_questions)} questions g√©n√©r√©es dynamiquement")
                
                if self.log_all_clarifications:
                    await self._log_clarification_decision(
                        question, language, user_id, conversation_id, result
                    )
                
                return result
            else:
                logger.warning("‚ö†Ô∏è [Semantic Dynamic] Aucune question g√©n√©r√©e, fallback vers mode normal")
        
        # Logique de clarification bas√©e sur les entit√©s critiques
        if critical_analysis["clarification_required_critical"]:
            logger.info(f"üö® [Critical Entities] Clarification critique requise - entit√©s manquantes: {critical_analysis['missing_critical_entities']}")
            
            # G√©n√©rer questions sp√©cifiques aux entit√©s critiques manquantes
            try:
                critical_questions = self.question_generator.generate_critical_entity_questions(
                    language, 
                    critical_analysis["missing_critical_entities"], 
                    question_type
                )
            except Exception as e:
                logger.error(f"Erreur g√©n√©ration questions critiques: {e}")
                critical_questions = self.question_generator.generate_adaptive_questions(
                    language, missing_critical_info, question_type
                )
            
            return ClarificationResult(
                needs_clarification=True,
                questions=critical_questions,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="critical_entities_missing",
                model_used="rule_based_critical_entities",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_mode=self.clarification_mode,
                clarification_state=ClarificationState.NEEDED,
                missing_critical_info=missing_critical_info,
                confidence_score=95.0,
                original_question=original_question or question,
                validation_score=0.9,
                fallback_used=False,
                gpt_failed=False,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=True
            )
        
        # Logique de clarification intelligente (ancien syst√®me am√©lior√©)
        if hasattr(extracted_entities, 'breed_type') and extracted_entities.breed_type == "generic":
            logger.info(f"üö® [Enhanced Clarification] Race g√©n√©rique d√©tect√©e - clarification obligatoire")
            
            try:
                generic_questions = self.question_generator.generate_adaptive_questions(
                    language, missing_critical_info, question_type
                )
            except Exception as e:
                logger.error(f"Erreur g√©n√©ration questions adaptatives: {e}")
                generic_questions = ["Quelle est la race exacte de vos volailles ?"]
            
            return ClarificationResult(
                needs_clarification=True,
                questions=generic_questions,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="generic_breed_detected",
                model_used="rule_based_enhanced",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_mode=self.clarification_mode,
                clarification_state=ClarificationState.NEEDED,
                missing_critical_info=missing_critical_info,
                confidence_score=95.0,
                original_question=original_question or question,
                validation_score=0.9,
                fallback_used=False,
                gpt_failed=False,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=critical_analysis["clarification_required_critical"]
            )
        
        # Si race sp√©cifique + √¢ge pr√©sents = OK
        if (hasattr(extracted_entities, 'breed_type') and extracted_entities.breed_type == "specific" and 
            (hasattr(extracted_entities, 'age_days') and extracted_entities.age_days or 
             hasattr(extracted_entities, 'age_weeks') and extracted_entities.age_weeks)):
            logger.info(f"‚úÖ [Enhanced Clarification] Race sp√©cifique + √¢ge - question compl√®te")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="specific_breed_and_age_detected",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_state=ClarificationState.NONE,
                validation_score=1.0,
                fallback_used=False,
                gpt_failed=False,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=False
            )
        
        # Si pas d'informations critiques manquantes (ancien + nouveau syst√®me)
        if not missing_critical_info and not critical_analysis["clarification_required_critical"]:
            logger.info(f"‚úÖ [Enhanced Clarification] Toutes les informations critiques pr√©sentes")
            return ClarificationResult(
                needs_clarification=False,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="all_critical_info_present",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_state=ClarificationState.NONE,
                validation_score=1.0,
                fallback_used=False,
                gpt_failed=False,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=False
            )
        
        # Analyse via OpenAI pour les cas complexes (avec informations d'entit√©s critiques)
        if not OPENAI_AVAILABLE or not openai:
            logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] OpenAI non disponible - fallback vers questions adaptatives")
            
            try:
                adaptive_questions = self.question_generator.generate_adaptive_questions(
                    language, missing_critical_info, question_type
                )
            except Exception as e:
                logger.error(f"Erreur g√©n√©ration questions adaptatives fallback: {e}")
                adaptive_questions = ["Pouvez-vous donner plus de d√©tails sur votre situation ?"]
            
            return ClarificationResult(
                needs_clarification=True,
                questions=adaptive_questions,
                processing_time_ms=int((time.time() - start_time) * 1000),
                reason="openai_unavailable_adaptive_fallback",
                model_used="rule_based_adaptive",
                extracted_entities=extracted_entities,
                question_type=question_type,
                clarification_mode=self.clarification_mode,
                clarification_state=ClarificationState.NEEDED,
                missing_critical_info=missing_critical_info,
                confidence_score=0.7,
                original_question=original_question or question,
                validation_score=0.8,
                fallback_used=True,
                gpt_failed=True,
                # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                missing_entities=critical_analysis["missing_entities"],
                missing_critical_entities=critical_analysis["missing_critical_entities"],
                clarification_required_critical=critical_analysis["clarification_required_critical"]
            )
        
        try:
            # Configuration OpenAI
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                logger.warning(f"‚ö†Ô∏è [Enhanced Clarification] Cl√© API OpenAI manquante - fallback adaptatif")
                
                try:
                    adaptive_questions = self.question_generator.generate_adaptive_questions(
                        language, missing_critical_info, question_type
                    )
                except Exception as e:
                    logger.error(f"Erreur g√©n√©ration questions adaptatives (cl√© manquante): {e}")
                    adaptive_questions = ["Pouvez-vous donner plus de d√©tails ?"]
                
                return ClarificationResult(
                    needs_clarification=True,
                    questions=adaptive_questions,
                    processing_time_ms=int((time.time() - start_time) * 1000),
                    reason="openai_key_missing_adaptive_fallback",
                    model_used="rule_based_adaptive",
                    extracted_entities=extracted_entities,
                    question_type=question_type,
                    clarification_mode=self.clarification_mode,
                    clarification_state=ClarificationState.NEEDED,
                    missing_critical_info=missing_critical_info,
                    confidence_score=0.7,
                    original_question=original_question or question,
                    validation_score=0.8,
                    fallback_used=True,
                    gpt_failed=True,
                    # NOUVEAUX CHAMPS ENTIT√âS CRITIQUES
                    missing_entities=critical_analysis["missing_entities"],
                    missing_critical_entities=critical_analysis["missing_critical_entities"],
                    clarification_required_critical=critical_analysis["clarification_required_critical"]
                )
            
            # Configuration s√©curis√©e d'OpenAI
            if hasattr(openai, 'api_key'):
                openai.api_key = api_key
            else:
                openai_client = openai.OpenAI(api_key=api_key)
            
            # PROMPT ENRICHI avec toutes les informations + entit√©s critiques
            prompt_template = self.clarification_prompts.get(language.lower(), self.clarification_prompts["fr"])
            
            context_str = "Aucun contexte"
            if conversation_context and isinstance(conversation_context, dict):
                try:
                    context_str = json.dumps(conversation_context, ensure_ascii=False)
                except (TypeError, ValueError):
                    context_str = "Contexte disponible mais non s√©rialisable"
            
            try:
                entities_str = json.dumps(extracted_entities.to_dict(), ensure_ascii=False)
            except Exception:
                entities_str = "Entit√©s non s√©rialisables"
            
            missing_info_str = ", ".join(missing_critical_info) if missing_critical_info else "Aucune"
            missing_critical_entities_str = ", ".join(critical_analysis["missing_critical_entities"]) if critical_analysis["missing_critical_entities"] else "Aucune"
            critical_entities_for_type_str = ", ".join(critical_analysis["critical_entities_for_type"])
            
            user_prompt = prompt_template.format(
                question=question,
                question_type=question_type,
                extracted_entities=entities_str,
                conversation_context=context_str,
                missing_info=missing_info_str,
                missing_critical_entities=missing_critical_entities_str,
                critical_entities_for_type=critical_entities_for_type_str
            )
            
            system_prompt = f"""Tu es un assistant expert qui d√©termine si une question d'aviculture n√©cessite des clarifications. 

Mode de clarification: {self.clarification_mode.value}
Questions adaptatives: {'activ√©es' if self.adaptive_question_count else 'd√©sactiv√©es'}
Analyse entit√©s critiques: {'activ√©e' if self.enable_critical_entity_analysis else 'd√©sactiv√©e'}

FOCUS PRIORITAIRE sur les entit√©s critiques: {', '.join(CRITICAL_ENTITIES)}

Sois tr√®s pr√©cis et utilise intelligemment le contexte conversationnel pour √©viter les questions redondantes."""
            
            # Appel OpenAI enrichi
            logger.info(f"ü§ñ [Enhanced Clarification] Appel GPT-4o-mini enrichi avec analyse entit√©s critiques...")
            
            try:
                if hasattr(openai, 'chat') and hasattr(open