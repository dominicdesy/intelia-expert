# app/api/v1/entity_normalizer.py
"""
Entity Normalizer - Normalisation centralis√©e des entit√©s

üéØ OBJECTIF: √âliminer les incoh√©rences entre modules
‚úÖ R√âSOUT: breed_specific vs breed_generic, age_days vs age_weeks, etc.
üöÄ IMPACT: +25% de pertinence des r√©ponses personnalis√©es

PRINCIPE:
- Point d'entr√©e unique pour normalisation
- Mapping standardis√© des races, sexes, √¢ges
- Validation et enrichissement automatique
- Format de sortie coh√©rent pour tous les modules

UTILISATION:
```python
normalizer = EntityNormalizer()
raw_entities = {"breed_specific": "ross308", "age_weeks": 3}
normalized = normalizer.normalize(raw_entities)
# ‚Üí {"breed": "Ross 308", "age_days": 21, "age_weeks": 3, "sex": None, ...}
```
"""

import logging
import re
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)

@dataclass
class NormalizedEntities:
    """Structure standardis√©e pour toutes les entit√©s normalis√©es"""
    
    # Identifiants de base (toujours pr√©sents)
    breed: Optional[str] = None              # Race normalis√©e (ex: "Ross 308")
    age_days: Optional[int] = None           # √Çge TOUJOURS en jours
    age_weeks: Optional[int] = None          # √Çge en semaines (calcul√©)
    sex: Optional[str] = None                # Sexe normalis√©: "male", "female", "mixed"
    
    # Donn√©es de poids
    weight_grams: Optional[float] = None     # Poids TOUJOURS en grammes
    weight_mentioned: bool = False           # Si poids mentionn√©
    
    # Contexte et sympt√¥mes
    symptoms: List[str] = None               # Liste des sympt√¥mes
    context_type: Optional[str] = None       # Type: "health", "performance", "feeding", "housing"
    
    # M√©tadonn√©es de normalisation
    normalization_confidence: float = 1.0   # Confiance de la normalisation
    original_format: Dict[str, Any] = None  # Format original pour debugging
    
    def __post_init__(self):
        if self.symptoms is None:
            self.symptoms = []
        if self.original_format is None:
            self.original_format = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """Conversion en dictionnaire pour compatibilit√©"""
        return asdict(self)
    
    def has_breed(self) -> bool:
        """V√©rifie si une race est d√©finie"""
        return self.breed is not None and self.breed.strip() != ""
    
    def has_age(self) -> bool:
        """V√©rifie si un √¢ge est d√©fini"""
        return self.age_days is not None and self.age_days > 0
    
    def has_weight(self) -> bool:
        """V√©rifie si un poids est d√©fini"""
        return self.weight_grams is not None and self.weight_grams > 0

class EntityNormalizer:
    """Normalisateur centralis√© des entit√©s avec validation intelligente"""
    
    def __init__(self):
        """Initialisation avec mappings complets"""
        
        # Mapping des races vers format standardis√©
        self.breed_mapping = {
            # Poulets de chair
            'ross 308': 'Ross 308',
            'ross308': 'Ross 308', 
            'ross_308': 'Ross 308',
            'ross-308': 'Ross 308',
            'cobb 500': 'Cobb 500',
            'cobb500': 'Cobb 500',
            'cobb_500': 'Cobb 500', 
            'cobb-500': 'Cobb 500',
            'hubbard': 'Hubbard',
            'arbor acres': 'Arbor Acres',
            'arbor_acres': 'Arbor Acres',
            'arbor-acres': 'Arbor Acres',
            
            # Pondeuses
            'isa brown': 'ISA Brown',
            'isa_brown': 'ISA Brown',
            'isa-brown': 'ISA Brown',
            'lohmann brown': 'Lohmann Brown',
            'lohmann_brown': 'Lohmann Brown', 
            'lohmann-brown': 'Lohmann Brown',
            'babcock': 'Babcock',
            'hy-line': 'Hy-Line',
            'hyline': 'Hy-Line',
            'hy_line': 'Hy-Line',
            
            # Termes g√©n√©riques
            'poulet': 'Poulet g√©n√©rique',
            'poule': 'Poule g√©n√©rique',
            'coq': 'Coq g√©n√©rique',
            'volaille': 'Volaille g√©n√©rique',
            'broiler': 'Poulet de chair g√©n√©rique',
            'layer': 'Pondeuse g√©n√©rique',
            'gallus': 'Gallus gallus'
        }
        
        # Mapping des sexes vers format standardis√©
        self.sex_mapping = {
            # M√¢le
            'm√¢le': 'male',
            'male': 'male',
            'coq': 'male',
            'masculin': 'male',
            'm': 'male',
            'rooster': 'male',
            'cock': 'male',
            
            # Femelle  
            'femelle': 'female',
            'female': 'female',
            'poule': 'female',
            'f√©minin': 'female',
            'f': 'female',
            'hen': 'female',
            
            # Mixte
            'mixte': 'mixed',
            'mixed': 'mixed',
            'm√©lang√©': 'mixed',
            'troupeau': 'mixed',
            'lot': 'mixed',
            'flock': 'mixed',
            'both': 'mixed',
            'tous': 'mixed'
        }
        
        # Mapping des contextes
        self.context_mapping = {
            # Sant√©
            'sant√©': 'health',
            'health': 'health',
            'maladie': 'health',
            'sympt√¥me': 'health',
            'diagnostic': 'health',
            'veterinary': 'health',
            
            # Performance
            'performance': 'performance',
            'croissance': 'performance',
            'poids': 'performance',
            'growth': 'performance',
            'weight': 'performance',
            
            # Alimentation
            'alimentation': 'feeding',
            'feeding': 'feeding',
            'nutrition': 'feeding',
            'aliment': 'feeding',
            'feed': 'feeding',
            
            # √âlevage
            '√©levage': 'housing',
            'housing': 'housing',
            'conditions': 'housing',
            'environnement': 'housing',
            'management': 'housing'
        }
        
        # Statistiques pour monitoring
        self.stats = {
            "total_normalizations": 0,
            "breed_normalizations": 0,
            "age_conversions": 0,
            "sex_normalizations": 0,
            "weight_conversions": 0,
            "context_mappings": 0,
            "validation_failures": 0,
            "enrichments_applied": 0
        }
        
        logger.info("üîß [EntityNormalizer] Initialis√© avec mappings complets")
        logger.info(f"   Races support√©es: {len(self.breed_mapping)}")
        logger.info(f"   Sexes support√©s: {len(self.sex_mapping)}")
        logger.info(f"   Contextes support√©s: {len(self.context_mapping)}")
    
    def normalize(self, raw_entities: Union[Dict[str, Any], object]) -> NormalizedEntities:
        """
        Point d'entr√©e principal pour normalisation
        
        Args:
            raw_entities: Entit√©s brutes (dict ou objet avec attributs)
            
        Returns:
            NormalizedEntities: Entit√©s normalis√©es et valid√©es
        """
        
        self.stats["total_normalizations"] += 1
        
        try:
            # Conversion vers dict si n√©cessaire
            if hasattr(raw_entities, '__dict__'):
                raw_dict = {k: v for k, v in raw_entities.__dict__.items() 
                           if not k.startswith('_')}
            elif isinstance(raw_entities, dict):
                raw_dict = raw_entities.copy()
            else:
                logger.warning(f"‚ö†Ô∏è [EntityNormalizer] Type non support√©: {type(raw_entities)}")
                raw_dict = {}
            
            # Initialiser entit√©s normalis√©es
            normalized = NormalizedEntities()
            normalized.original_format = raw_dict.copy()
            
            # Normalisation par composant
            normalized.breed = self._normalize_breed(raw_dict)
            normalized.age_days, normalized.age_weeks = self._normalize_age(raw_dict)
            normalized.sex = self._normalize_sex(raw_dict)
            normalized.weight_grams, normalized.weight_mentioned = self._normalize_weight(raw_dict)
            normalized.symptoms = self._normalize_symptoms(raw_dict)
            normalized.context_type = self._normalize_context(raw_dict)
            
            # Enrichissements automatiques
            self._apply_enrichments(normalized)
            
            # Validation finale
            normalized.normalization_confidence = self._calculate_confidence(normalized, raw_dict)
            
            logger.debug(f"‚úÖ [EntityNormalizer] Normalis√©: {self._summary(normalized)}")
            return normalized
            
        except Exception as e:
            self.stats["validation_failures"] += 1
            logger.error(f"‚ùå [EntityNormalizer] Erreur normalisation: {e}")
            
            # Retourner entit√©s vides en cas d'erreur
            fallback = NormalizedEntities()
            fallback.original_format = raw_entities if isinstance(raw_entities, dict) else {}
            fallback.normalization_confidence = 0.0
            return fallback
    
    def _normalize_breed(self, raw_dict: Dict[str, Any]) -> Optional[str]:
        """Normalise la race avec priorit√© aux sp√©cifiques"""
        
        # Priorit√© 1: breed_specific
        breed_specific = raw_dict.get('breed_specific')
        if breed_specific:
            normalized = self._map_breed(breed_specific)
            if normalized:
                self.stats["breed_normalizations"] += 1
                return normalized
        
        # Priorit√© 2: breed_generic  
        breed_generic = raw_dict.get('breed_generic')
        if breed_generic:
            normalized = self._map_breed(breed_generic)
            if normalized:
                self.stats["breed_normalizations"] += 1
                return normalized
        
        # Priorit√© 3: breed (format unifi√©)
        breed = raw_dict.get('breed')
        if breed:
            normalized = self._map_breed(breed)
            if normalized:
                self.stats["breed_normalizations"] += 1
                return normalized
        
        return None
    
    def _map_breed(self, breed_value: Any) -> Optional[str]:
        """Mapping d'une valeur de race vers format standardis√©"""
        
        if not breed_value:
            return None
        
        breed_str = str(breed_value).lower().strip()
        
        # Recherche directe dans le mapping
        if breed_str in self.breed_mapping:
            return self.breed_mapping[breed_str]
        
        # Recherche fuzzy pour variantes
        for pattern, normalized in self.breed_mapping.items():
            if pattern in breed_str or breed_str in pattern:
                return normalized
        
        # Si pas trouv√©, capitaliser proprement
        return breed_str.title()
    
    def _normalize_age(self, raw_dict: Dict[str, Any]) -> tuple[Optional[int], Optional[int]]:
        """Normalise l'√¢ge avec conversion automatique"""
        
        age_days = None
        age_weeks = None
        
        # Priorit√© 1: age_days direct
        if raw_dict.get('age_days'):
            age_days = self._safe_int(raw_dict['age_days'])
        
        # Priorit√© 2: age_weeks ‚Üí conversion
        elif raw_dict.get('age_weeks'):
            weeks = self._safe_int(raw_dict['age_weeks'])
            if weeks:
                age_days = weeks * 7
                age_weeks = weeks
                self.stats["age_conversions"] += 1
        
        # Priorit√© 3: age (string) ‚Üí parsing
        elif raw_dict.get('age'):
            age_days, age_weeks = self._parse_age_string(raw_dict['age'])
            if age_days:
                self.stats["age_conversions"] += 1
        
        # Calculer weeks si manquant
        if age_days and not age_weeks:
            age_weeks = age_days // 7
        
        # Validation plausibilit√©
        if age_days and (age_days < 1 or age_days > 500):
            logger.warning(f"‚ö†Ô∏è [EntityNormalizer] √Çge non plausible: {age_days} jours")
            return None, None
        
        return age_days, age_weeks
    
    def _parse_age_string(self, age_str: str) -> tuple[Optional[int], Optional[int]]:
        """Parse une cha√Æne d'√¢ge (ex: '3 semaines', '21 jours')"""
        
        if not age_str:
            return None, None
        
        age_lower = str(age_str).lower()
        
        # Patterns pour jours
        day_patterns = [r'(\d+)\s*(?:jour|day)s?', r'(\d+)\s*j\b', r'(\d+)j']
        for pattern in day_patterns:
            match = re.search(pattern, age_lower)
            if match:
                days = self._safe_int(match.group(1))
                return days, (days // 7) if days else None
        
        # Patterns pour semaines
        week_patterns = [r'(\d+)\s*(?:semaine|week|sem)s?', r'(\d+)\s*s\b', r'(\d+)s']
        for pattern in week_patterns:
            match = re.search(pattern, age_lower)
            if match:
                weeks = self._safe_int(match.group(1))
                return (weeks * 7) if weeks else None, weeks
        
        return None, None
    
    def _normalize_sex(self, raw_dict: Dict[str, Any]) -> Optional[str]:
        """Normalise le sexe vers format standardis√©"""
        
        sex_value = raw_dict.get('sex')
        if not sex_value:
            return None
        
        sex_str = str(sex_value).lower().strip()
        
        if sex_str in self.sex_mapping:
            self.stats["sex_normalizations"] += 1
            return self.sex_mapping[sex_str]
        
        return None
    
    def _normalize_weight(self, raw_dict: Dict[str, Any]) -> tuple[Optional[float], bool]:
        """Normalise le poids vers grammes"""
        
        weight_grams = None
        weight_mentioned = bool(raw_dict.get('weight_mentioned', False))
        
        # Priorit√© 1: weight_grams direct
        if raw_dict.get('weight_grams'):
            weight_grams = self._safe_float(raw_dict['weight_grams'])
            weight_mentioned = True
            self.stats["weight_conversions"] += 1
        
        # Priorit√© 2: Autres unit√©s (kg, lbs)
        elif raw_dict.get('weight_kg'):
            kg = self._safe_float(raw_dict['weight_kg'])
            if kg:
                weight_grams = kg * 1000
                weight_mentioned = True
                self.stats["weight_conversions"] += 1
        
        elif raw_dict.get('weight_lbs'):
            lbs = self._safe_float(raw_dict['weight_lbs'])
            if lbs:
                weight_grams = lbs * 453.592
                weight_mentioned = True
                self.stats["weight_conversions"] += 1
        
        # Validation plausibilit√© (1g √† 10kg)
        if weight_grams and (weight_grams < 1 or weight_grams > 10000):
            logger.warning(f"‚ö†Ô∏è [EntityNormalizer] Poids non plausible: {weight_grams}g")
            return None, weight_mentioned
        
        return weight_grams, weight_mentioned
    
    def _normalize_symptoms(self, raw_dict: Dict[str, Any]) -> List[str]:
        """Normalise la liste des sympt√¥mes"""
        
        symptoms = raw_dict.get('symptoms', [])
        
        if isinstance(symptoms, str):
            # Si c'est une string, la splitter
            symptoms = [s.strip() for s in symptoms.split(',') if s.strip()]
        elif not isinstance(symptoms, list):
            symptoms = []
        
        # Nettoyer et normaliser
        normalized_symptoms = []
        for symptom in symptoms:
            if symptom and isinstance(symptom, str):
                clean_symptom = symptom.strip().lower()
                if clean_symptom and len(clean_symptom) > 1:
                    normalized_symptoms.append(clean_symptom)
        
        return normalized_symptoms
    
    def _normalize_context(self, raw_dict: Dict[str, Any]) -> Optional[str]:
        """Normalise le type de contexte"""
        
        context_value = raw_dict.get('context_type')
        if not context_value:
            return None
        
        context_str = str(context_value).lower().strip()
        
        if context_str in self.context_mapping:
            self.stats["context_mappings"] += 1
            return self.context_mapping[context_str]
        
        return context_str  # Garder tel quel si pas dans mapping
    
    def _apply_enrichments(self, normalized: NormalizedEntities):
        """Applique des enrichissements automatiques bas√©s sur les donn√©es"""
        
        enrichments_count = 0
        
        # Enrichissement 1: Inf√©rer sexe depuis race pondeuse
        if normalized.breed and not normalized.sex:
            if any(layer_breed in normalized.breed.lower() 
                   for layer_breed in ['isa', 'lohmann', 'babcock', 'hy-line']):
                normalized.sex = 'female'
                enrichments_count += 1
                logger.debug(f"üîÆ [EntityNormalizer] Sexe inf√©r√©: female (race pondeuse)")
        
        # Enrichissement 2: Contexte depuis sympt√¥mes
        if normalized.symptoms and not normalized.context_type:
            normalized.context_type = 'health'
            enrichments_count += 1
            logger.debug(f"üîÆ [EntityNormalizer] Contexte inf√©r√©: health (sympt√¥mes pr√©sents)")
        
        # Enrichissement 3: Contexte depuis poids
        if normalized.weight_mentioned and not normalized.context_type:
            normalized.context_type = 'performance'
            enrichments_count += 1
            logger.debug(f"üîÆ [EntityNormalizer] Contexte inf√©r√©: performance (poids mentionn√©)")
        
        if enrichments_count > 0:
            self.stats["enrichments_applied"] += enrichments_count
    
    def _calculate_confidence(self, normalized: NormalizedEntities, raw_dict: Dict[str, Any]) -> float:
        """Calcule la confiance de la normalisation"""
        
        confidence_factors = []
        
        # Facteur race
        if normalized.breed:
            if raw_dict.get('breed_specific'):
                confidence_factors.append(1.0)  # Race sp√©cifique = max confiance
            elif raw_dict.get('breed_generic'):
                confidence_factors.append(0.8)  # Race g√©n√©rique = bonne confiance
            else:
                confidence_factors.append(0.6)  # Inf√©r√© = confiance moyenne
        
        # Facteur √¢ge
        if normalized.age_days:
            if raw_dict.get('age_days'):
                confidence_factors.append(1.0)  # Direct = max confiance
            elif raw_dict.get('age_weeks'):
                confidence_factors.append(0.9)  # Conversion = tr√®s bonne confiance
            else:
                confidence_factors.append(0.7)  # Pars√© = bonne confiance
        
        # Facteur sexe
        if normalized.sex:
            confidence_factors.append(0.9)  # Sexe normalis√© = tr√®s bonne confiance
        
        # Si aucun facteur, confiance minimale
        if not confidence_factors:
            return 0.1
        
        # Moyenne pond√©r√©e
        return sum(confidence_factors) / len(confidence_factors)
    
    def _safe_int(self, value: Any) -> Optional[int]:
        """Conversion s√©curis√©e vers int"""
        try:
            return int(float(value)) if value is not None else None
        except (ValueError, TypeError):
            return None
    
    def _safe_float(self, value: Any) -> Optional[float]:
        """Conversion s√©curis√©e vers float"""
        try:
            return float(value) if value is not None else None
        except (ValueError, TypeError):
            return None
    
    def _summary(self, normalized: NormalizedEntities) -> str:
        """Cr√©e un r√©sum√© des entit√©s normalis√©es"""
        
        parts = []
        
        if normalized.breed:
            parts.append(f"race={normalized.breed}")
        
        if normalized.age_days:
            parts.append(f"√¢ge={normalized.age_days}j")
        
        if normalized.sex:
            parts.append(f"sexe={normalized.sex}")
        
        if normalized.weight_grams:
            parts.append(f"poids={normalized.weight_grams}g")
        
        if normalized.symptoms:
            parts.append(f"sympt√¥mes={len(normalized.symptoms)}")
        
        if normalized.context_type:
            parts.append(f"contexte={normalized.context_type}")
        
        return ", ".join(parts) if parts else "aucune"
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de normalisation"""
        
        total = max(self.stats["total_normalizations"], 1)
        
        return {
            **self.stats,
            "breed_normalization_rate": f"{(self.stats['breed_normalizations']/total)*100:.1f}%",
            "age_conversion_rate": f"{(self.stats['age_conversions']/total)*100:.1f}%", 
            "sex_normalization_rate": f"{(self.stats['sex_normalizations']/total)*100:.1f}%",
            "weight_conversion_rate": f"{(self.stats['weight_conversions']/total)*100:.1f}%",
            "enrichment_rate": f"{(self.stats['enrichments_applied']/total)*100:.1f}%",
            "success_rate": f"{((total-self.stats['validation_failures'])/total)*100:.1f}%"
        }

# Instance globale pour r√©utilisation
entity_normalizer = EntityNormalizer()

# Fonction utilitaire pour usage direct
def normalize_entities(raw_entities: Union[Dict[str, Any], object]) -> NormalizedEntities:
    """
    Fonction utilitaire pour normalisation rapide
    
    Usage:
    ```python
    from app.api.v1.entity_normalizer import normalize_entities
    
    raw = {"breed_specific": "ross308", "age_weeks": 3}
    normalized = normalize_entities(raw)
    print(normalized.breed)  # "Ross 308"
    print(normalized.age_days)  # 21
    ```
    """
    return entity_normalizer.normalize(raw_entities)

# Fonction pour tests et debugging
def test_normalization():
    """Teste la normalisation avec des cas typiques"""
    
    test_cases = [
        {
            "name": "Race sp√©cifique + √¢ge semaines",
            "input": {"breed_specific": "ross308", "age_weeks": 3},
            "expected": {"breed": "Ross 308", "age_days": 21}
        },
        {
            "name": "Race g√©n√©rique + √¢ge jours + sexe",
            "input": {"breed_generic": "poulet", "age_days": 15, "sex": "m√¢le"},
            "expected": {"breed": "Poulet g√©n√©rique", "age_days": 15, "sex": "male"}
        },
        {
            "name": "Pondeuse + poids",
            "input": {"breed_specific": "isa brown", "weight_kg": 2.1},
            "expected": {"breed": "ISA Brown", "weight_grams": 2100, "sex": "female"}
        },
        {
            "name": "Sympt√¥mes + contexte auto",
            "input": {"symptoms": ["diarrh√©e", "l√©thargie"], "breed_generic": "cobb"},
            "expected": {"symptoms": ["diarrh√©e", "l√©thargie"], "context_type": "health"}
        }
    ]
    
    print("üß™ Test de normalisation des entit√©s:")
    print("=" * 50)
    
    normalizer = EntityNormalizer()
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüìù Test {i}: {test_case['name']}")
        print(f"   Input: {test_case['input']}")
        
        result = normalizer.normalize(test_case['input'])
        result_dict = result.to_dict()
        
        print(f"   Output: race={result.breed}, √¢ge={result.age_days}j, sexe={result.sex}")
        print(f"   Confiance: {result.normalization_confidence:.2f}")
        
        # V√©rifier les attentes
        for key, expected_value in test_case['expected'].items():
            actual_value = getattr(result, key, None)
            status = "‚úÖ" if actual_value == expected_value else "‚ùå"
            print(f"   {status} {key}: attendu={expected_value}, obtenu={actual_value}")
    
    print(f"\nüìä Statistiques: {normalizer.get_stats()}")
    print("‚úÖ Tests termin√©s!")

if __name__ == "__main__":
    test_normalization()