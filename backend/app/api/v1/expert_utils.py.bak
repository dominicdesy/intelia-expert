# Fixed expert_utils.py - Add missing functions
import os
import logging
import uuid
from typing import Dict, Any, Optional
from fastapi import Request

logger = logging.getLogger(__name__)

def get_user_id_from_request(request: Request) -> str:
    """Extrait l'user_id depuis la requ√™te"""
    # Essayer d'extraire depuis les headers ou token
    authorization = request.headers.get("authorization", "")
    if authorization:
        # Ici vous pouvez parser le JWT pour extraire l'user_id
        # Pour l'instant, g√©n√©ration d'un ID temporaire
        return f"user_{uuid.uuid4().hex[:8]}"
    
    # Fallback
    return f"anonymous_{uuid.uuid4().hex[:8]}"

def build_enriched_question_from_clarification(
    original_question: str,
    clarification_response: str, 
    conversation_context: str = ""
) -> str:
    """Construit une question enrichie √† partir d'une clarification"""
    if conversation_context:
        return f"{original_question}\n\nClarification: {clarification_response}\n\nContexte: {conversation_context}"
    else:
        return f"{original_question}\n\nClarification: {clarification_response}"

def get_enhanced_topics_by_language() -> Dict[str, list]:
    """Retourne les topics sugg√©r√©s par langue"""
    return {
        "fr": [
            "Probl√®mes de croissance poulets",
            "Conditions environnementales optimales",
            "Protocoles de vaccination",
            "Diagnostic probl√®mes de sant√©",
            "Nutrition et alimentation",
            "Gestion de la mortalit√©",
            "Temp√©rature et humidit√©",
            "Qualit√© de l'eau"
        ],
        "en": [
            "Chicken growth problems",
            "Optimal environmental conditions", 
            "Vaccination protocols",
            "Health problem diagnosis",
            "Nutrition and feeding",
            "Mortality management",
            "Temperature and humidity",
            "Water quality"
        ],
        "es": [
            "Problemas de crecimiento de pollos",
            "Condiciones ambientales √≥ptimas",
            "Protocolos de vacunaci√≥n", 
            "Diagn√≥stico de problemas de salud",
            "Nutrici√≥n y alimentaci√≥n",
            "Gesti√≥n de mortalidad",
            "Temperatura y humedad",
            "Calidad del agua"
        ]
    }

async def save_conversation_auto_enhanced(
    conversation_id: str,
    question: str,
    response: str,
    user_id: str,
    language: str = "fr"
) -> bool:
    """Sauvegarde automatique de conversation"""
    try:
        # Ici vous pouvez int√©grer avec votre syst√®me de logging
        logger.info(f"üíæ Sauvegarde conversation {conversation_id}: {question[:50]}...")
        return True
    except Exception as e:
        logger.error(f"‚ùå Erreur sauvegarde: {e}")
        return False

def get_fallback_response_enhanced(question: str, language: str = "fr") -> str:
    """R√©ponse de fallback am√©lior√©e"""
    responses = {
        "fr": "Je rencontre actuellement des difficult√©s techniques. Veuillez reformuler votre question ou r√©essayer dans quelques instants.",
        "en": "I'm currently experiencing technical difficulties. Please rephrase your question or try again in a few moments.",
        "es": "Actualmente estoy experimentando dificultades t√©cnicas. Por favor reformule su pregunta o int√©ntelo de nuevo en unos momentos."
    }
    return responses.get(language.lower(), responses["fr"])

async def process_question_with_enhanced_prompt(
    question: str, 
    language: str = "fr", 
    speed_mode: str = "balanced",
    extracted_entities: Optional[Dict] = None,
    conversation_context: str = ""
) -> str:
    """Traite une question avec prompt am√©lior√© AVEC DONN√âES DE R√âF√âRENCE ROSS 308"""
    
    try:
        import openai
        
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return get_fallback_response_enhanced(question, language)
        
        openai.api_key = api_key
        
        # ‚úÖ DONN√âES DE R√âF√âRENCE ROSS 308 INT√âGR√âES
        reference_data = """
DONN√âES DE R√âF√âRENCE AVICULTURE (UTILISATION OBLIGATOIRE) :

üêî Ross 308 - Poids Standards (√Ä UTILISER EXACTEMENT) :
- Jour 1: 42-45g
- Jour 7: 160-180g  
- Jour 12: 340-370g ‚Üê CRITIQUE ! (JAMAIS 700-900g)
- Jour 14: 430-470g
- Jour 21: 800-900g
- Jour 28: 1400-1600g
- Jour 35: 2000-2300g
- Jour 42: 2500-2800g

üêî Cobb 500 - Poids Standards :
- Jour 12: 320-350g
- Jour 21: 750-850g
- Jour 42: 2400-2700g

R√àGLES CRITIQUES OBLIGATOIRES :
- Ross 308 jour 12 = 340-370g (JAMAIS autre chose !)
- Si contexte mentionne Ross 308 + √¢ge = r√©ponse PR√âCISE obligatoire
- Utilise TOUJOURS ces donn√©es exactes, jamais d'approximations
"""

        # ‚úÖ PROMPT AM√âLIOR√â avec d√©tection contextuelle
        enhanced_prompts = {
            "fr": f"""{reference_data}

Tu es un expert en production avicole sp√©cialis√© en sant√© et nutrition animale. Tu assists tous les acteurs de la fili√®re : fermiers, v√©t√©rinaires, nutritionnistes, consultants et techniciens.

CONSIGNES CRITIQUES:
1. UTILISE OBLIGATOIREMENT les donn√©es de r√©f√©rence ci-dessus
2. Si le contexte mentionne "Ross 308" et un √¢ge, donne la r√©ponse EXACTE
3. Ross 308 de 12 jours = 340-370g (JAMAIS 700-900g !)
4. Si pronom "son/sa/ses" + √¢ge mentionn√© = utilise la race du contexte
5. Commence par r√©pondre directement avec les chiffres exacts

Contexte conversationnel disponible:
{conversation_context}

EXEMPLE CRITIQUE :
Contexte pr√©c√©dent: "Ross 308"
Question: "Quel est son poids id√©al au jour 12 ?"
R√©ponse CORRECTE: "Pour un Ross 308 de 12 jours, le poids id√©al se situe entre 340-370 grammes selon les standards de performance. Si vos poulets p√®sent moins de 320g √† cet √¢ge, cela peut indiquer un probl√®me nutritionnel."

IMPORTANT: 
- D√©tecte les r√©f√©rences contextuelles ("son", "sa", "ils", etc.)
- Utilise le contexte fourni pour identifier la race
- Donne TOUJOURS des r√©ponses chiffr√©es pr√©cises
- UTILISE les donn√©es de r√©f√©rence ci-dessus OBLIGATOIREMENT""",

            "en": f"""{reference_data}

You are an expert in poultry production specialized in animal health and nutrition. You assist all stakeholders in the industry: farmers, veterinarians, nutritionists, consultants and technicians.

CRITICAL INSTRUCTIONS:
1. USE the reference data above MANDATORILY
2. If context mentions "Ross 308" and age, give EXACT answer
3. Ross 308 at 12 days = 340-370g (NEVER 700-900g!)
4. If pronoun "its/their" + age mentioned = use breed from context
5. Start by directly answering with exact figures

Available conversational context:
{conversation_context}

IMPORTANT: Always use the reference data above, never approximations!""",

            "es": f"""{reference_data}

Eres un experto en producci√≥n av√≠cola especializado en salud y nutrici√≥n animal. Asistes a todos los actores de la industria: granjeros, veterinarios, nutricionistas, consultores y t√©cnicos.

INSTRUCCIONES CR√çTICAS:
1. USA los datos de referencia arriba OBLIGATORIAMENTE
2. Si el contexto menciona "Ross 308" y edad, da respuesta EXACTA
3. Ross 308 a los 12 d√≠as = 340-370g (¬°NUNCA 700-900g!)
4. Si pronombre "su/sus" + edad mencionada = usa raza del contexto
5. Comienza respondiendo directamente con cifras exactas

Contexto conversacional disponible:
{conversation_context}

IMPORTANTE: Usa SIEMPRE los datos de referencia arriba, ¬°nunca aproximaciones!"""
        }
        
        system_prompt = enhanced_prompts.get(language.lower(), enhanced_prompts["fr"])
        
        # ‚úÖ DEBUG LOG pour voir le contexte
        logger.info(f"üîç [Expert Utils] Question: {question}")
        logger.info(f"üîç [Expert Utils] Contexte: {conversation_context[:100]}...")
        
        # Configuration par mode
        model_config = {
            "fast": {"model": "gpt-3.5-turbo", "max_tokens": 400},
            "balanced": {"model": "gpt-4o-mini", "max_tokens": 600},
            "quality": {"model": "gpt-4o-mini", "max_tokens": 800}
        }
        
        config = model_config.get(speed_mode, model_config["balanced"])
        
        response = openai.chat.completions.create(
            model=config["model"],
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": str(question)}
            ],
            temperature=0.1,  # ‚Üê R√©duire pour plus de pr√©cision
            max_tokens=config["max_tokens"],
            timeout=20
        )
        
        answer = response.choices[0].message.content
        logger.info(f"ü§ñ [Expert Utils] R√©ponse GPT: {answer[:100]}...")
        
        return str(answer) if answer else get_fallback_response_enhanced(question, language)
        
    except Exception as e:
        logger.error(f"‚ùå [Expert Utils] Erreur OpenAI: {e}")
        return get_fallback_response_enhanced(question, language)