"""
expert_services.py - SERVICE PRINCIPAL SIMPLIFI√â

üéØ REMPLACE: Tous les services complexes et contradictoires
üöÄ PRINCIPE: Un seul point d'entr√©e, logique claire et unifi√©e
‚ú® SIMPLE: Flux lin√©aire sans conflits

Architecture:
1. EntitiesExtractor -> Extraction des informations
2. SmartClassifier -> D√©cision du type de r√©ponse  
3. UnifiedResponseGenerator -> G√©n√©ration de la r√©ponse
4. Formatage final -> R√©ponse standardis√©e

Fini les imports circulaires, les conflits de r√®gles, et la complexit√© excessive !
"""

import logging
import time
import uuid
from datetime import datetime
from typing import Dict, Any, Optional, List

# Imports des nouveaux modules simplifi√©s
from .entities_extractor import EntitiesExtractor, ExtractedEntities
from .smart_classifier import SmartClassifier, ClassificationResult, ResponseType
from .unified_response_generator import UnifiedResponseGenerator, ResponseData

# Import des mod√®les (gard√©s pour compatibilit√©)
try:
    from .expert_models import EnhancedExpertResponse, EnhancedQuestionRequest
    MODELS_AVAILABLE = True
except ImportError:
    MODELS_AVAILABLE = False
    # Classes de fallback minimalistes
    class EnhancedExpertResponse:
        def __init__(self, **kwargs):
            for key, value in kwargs.items():
                setattr(self, key, value)
    
    class EnhancedQuestionRequest:
        def __init__(self, **kwargs):
            for key, value in kwargs.items():
                setattr(self, key, value)

logger = logging.getLogger(__name__)

class ProcessingResult:
    """R√©sultat du traitement d'une question"""
    def __init__(self, success: bool, response: str, response_type: str, 
                 confidence: float, entities: ExtractedEntities, 
                 processing_time_ms: int, error: str = None):
        self.success = success
        self.response = response
        self.response_type = response_type
        self.confidence = confidence
        self.entities = entities
        self.processing_time_ms = processing_time_ms
        self.error = error
        self.timestamp = datetime.now().isoformat()

class ExpertService:
    """Service expert unifi√© - Point d'entr√©e unique pour toutes les questions"""
    
    def __init__(self):
        """Initialisation du service avec les 3 composants principaux"""
        self.entities_extractor = EntitiesExtractor()
        self.smart_classifier = SmartClassifier()
        self.response_generator = UnifiedResponseGenerator()
        
        # Statistiques pour monitoring
        self.stats = {
            "questions_processed": 0,
            "precise_answers": 0,
            "general_answers": 0,
            "clarifications": 0,
            "errors": 0,
            "average_processing_time_ms": 0
        }
        
        # Configuration
        self.config = {
            "enable_logging": True,
            "enable_stats": True,
            "max_processing_time_ms": 10000,  # 10 secondes max
            "fallback_enabled": True
        }
        
        logger.info("‚úÖ [Expert Service] Service unifi√© initialis√©")
        logger.info(f"   üìä Extracteur: {self.entities_extractor.get_extraction_stats()}")
        logger.info(f"   üß† Classifier: {self.smart_classifier.get_classification_stats()}")

    async def process_question(self, question: str, context: Dict[str, Any] = None, 
                             language: str = "fr") -> ProcessingResult:
        """
        POINT D'ENTR√âE PRINCIPAL - Traite une question de A √† Z
        
        Args:
            question: Question √† traiter
            context: Contexte optionnel (conversation_id, user_id, etc.)
            language: Langue de r√©ponse
            
        Returns:
            ProcessingResult avec la r√©ponse et les m√©tadonn√©es
        """
        start_time = time.time()
        
        try:
            logger.info(f"üöÄ [Expert Service] Traitement: '{question[:50]}...'")
            
            # Validation de base
            if not question or len(question.strip()) < 2:
                return ProcessingResult(
                    success=False,
                    response="Question trop courte. Pouvez-vous pr√©ciser votre demande ?",
                    response_type="error",
                    confidence=0.0,
                    entities=ExtractedEntities(),
                    processing_time_ms=int((time.time() - start_time) * 1000),
                    error="Question invalide"
                )
            
            # 1Ô∏è‚É£ EXTRACTION DES ENTIT√âS
            entities = self.entities_extractor.extract(question)
            logger.info(f"   üîç Entit√©s extraites: {entities}")
            
            # 2Ô∏è‚É£ CLASSIFICATION INTELLIGENTE
            classification = self.smart_classifier.classify_question(question, self._entities_to_dict(entities))
            logger.info(f"   üß† Classification: {classification.response_type.value} (confiance: {classification.confidence})")
            
            # 3Ô∏è‚É£ G√âN√âRATION DE LA R√âPONSE
            response_data = self.response_generator.generate(question, self._entities_to_dict(entities), classification)
            logger.info(f"   üé® R√©ponse g√©n√©r√©e: {response_data.response_type}")
            
            # 4Ô∏è‚É£ FORMATAGE FINAL
            processing_time_ms = int((time.time() - start_time) * 1000)
            
            result = ProcessingResult(
                success=True,
                response=response_data.response,
                response_type=response_data.response_type,
                confidence=response_data.confidence,
                entities=entities,
                processing_time_ms=processing_time_ms
            )
            
            # 5Ô∏è‚É£ MISE √Ä JOUR DES STATISTIQUES
            self._update_stats(classification.response_type, processing_time_ms, True)
            
            logger.info(f"‚úÖ [Expert Service] Traitement r√©ussi en {processing_time_ms}ms")
            return result
            
        except Exception as e:
            processing_time_ms = int((time.time() - start_time) * 1000)
            error_msg = f"Erreur de traitement: {str(e)}"
            
            logger.error(f"‚ùå [Expert Service] {error_msg}")
            
            # R√©ponse de fallback
            fallback_response = self._generate_fallback_response(question, language)
            
            result = ProcessingResult(
                success=False,
                response=fallback_response,
                response_type="error_fallback",
                confidence=0.3,
                entities=ExtractedEntities(),
                processing_time_ms=processing_time_ms,
                error=error_msg
            )
            
            self._update_stats(ResponseType.NEEDS_CLARIFICATION, processing_time_ms, False)
            return result

    async def ask_expert_enhanced(self, request: EnhancedQuestionRequest) -> EnhancedExpertResponse:
        """
        Interface compatible avec l'ancien syst√®me - Point d'entr√©e pour API
        
        Args:
            request: Requ√™te format√©e selon l'ancien mod√®le
            
        Returns:
            EnhancedExpertResponse compatible avec l'ancien syst√®me
        """
        try:
            # Traitement unifi√©
            context = {
                "conversation_id": getattr(request, 'conversation_id', None),
                "user_id": getattr(request, 'user_id', None),
                "is_clarification_response": getattr(request, 'is_clarification_response', False),
                "original_question": getattr(request, 'original_question', None)
            }
            
            result = await self.process_question(
                question=request.text,
                context=context,
                language=getattr(request, 'language', 'fr')
            )
            
            # Conversion en format ancien pour compatibilit√©
            return self._convert_to_legacy_response(request, result)
            
        except Exception as e:
            logger.error(f"‚ùå [Expert Service] Erreur ask_expert_enhanced: {e}")
            return self._create_error_response(request, str(e))

    def _entities_to_dict(self, entities: ExtractedEntities) -> Dict[str, Any]:
        """Convertit les entit√©s en dictionnaire pour compatibilit√©"""
        return {
            'age_days': entities.age_days,
            'age_weeks': entities.age_weeks,
            'age': entities.age,
            'breed_specific': entities.breed_specific,
            'breed_generic': entities.breed_generic,
            'sex': entities.sex,
            'weight_mentioned': entities.weight_mentioned,
            'weight_grams': entities.weight_grams,
            'weight_unit': entities.weight_unit,
            'symptoms': entities.symptoms,
            'context_type': entities.context_type,
            'housing_conditions': entities.housing_conditions,
            'feeding_context': entities.feeding_context
        }

    def _convert_to_legacy_response(self, request: EnhancedQuestionRequest, 
                                  result: ProcessingResult) -> EnhancedExpertResponse:
        """Convertit le r√©sultat moderne vers le format legacy"""
        
        conversation_id = getattr(request, 'conversation_id', None) or str(uuid.uuid4())
        language = getattr(request, 'language', 'fr')
        
        # Donn√©es de base obligatoires
        response_data = {
            "question": request.text,
            "response": result.response,
            "conversation_id": conversation_id,
            "rag_used": False,  # Le nouveau syst√®me n'utilise plus RAG
            "timestamp": result.timestamp,
            "language": language,
            "response_time_ms": result.processing_time_ms,
            "mode": "unified_intelligent_system"
        }
        
        # Ajout des champs optionnels pour compatibilit√©
        optional_fields = {
            "user": getattr(request, 'user_id', None),
            "logged": True,
            "validation_passed": result.success,
            "processing_steps": [
                "entities_extraction",
                "smart_classification", 
                "unified_response_generation"
            ],
            "ai_enhancements_used": [
                "smart_classifier_v1",
                "unified_generator_v1",
                "entities_extractor_v1"
            ]
        }
        
        # Informations de classification pour debugging
        classification_info = {
            "response_type_detected": result.response_type,
            "confidence_score": result.confidence,
            "entities_extracted": self._entities_to_dict(result.entities),
            "processing_successful": result.success
        }
        
        # Fusionner toutes les donn√©es
        response_data.update(optional_fields)
        response_data["classification_result"] = classification_info
        
        # Gestion d'erreur si √©chec
        if not result.success:
            response_data["error_details"] = {
                "error_message": result.error,
                "fallback_used": True,
                "original_processing_failed": True
            }
        
        if MODELS_AVAILABLE:
            return EnhancedExpertResponse(**response_data)
        else:
            # Fallback si mod√®les pas disponibles
            return EnhancedExpertResponse(**response_data)

    def _create_error_response(self, request: EnhancedQuestionRequest, error: str) -> EnhancedExpertResponse:
        """Cr√©e une r√©ponse d'erreur compatible"""
        
        error_responses = {
            "fr": f"D√©sol√©, je rencontre une difficult√© technique. Erreur: {error}. Pouvez-vous reformuler votre question ?",
            "en": f"Sorry, I'm experiencing a technical difficulty. Error: {error}. Could you rephrase your question?",
            "es": f"Lo siento, estoy experimentando una dificultad t√©cnica. Error: {error}. ¬øPodr√≠as reformular tu pregunta?"
        }
        
        language = getattr(request, 'language', 'fr')
        error_response = error_responses.get(language, error_responses['fr'])
        
        return EnhancedExpertResponse(
            question=request.text,
            response=error_response,
            conversation_id=getattr(request, 'conversation_id', str(uuid.uuid4())),
            rag_used=False,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=0,
            mode="error_fallback",
            logged=True,
            validation_passed=False,
            error_details={"error": error, "system": "unified_expert_service"}
        )

    def _generate_fallback_response(self, question: str, language: str = "fr") -> str:
        """G√©n√®re une r√©ponse de fallback en cas d'erreur"""
        
        fallback_responses = {
            "fr": """Je rencontre une difficult√© technique pour analyser votre question.

üí° **Pour m'aider √† mieux vous r√©pondre, pr√©cisez** :
‚Ä¢ Le type de volailles (poulets de chair, pondeuses...)
‚Ä¢ L'√¢ge de vos animaux (21 jours, 3 semaines...)
‚Ä¢ Votre probl√®me ou objectif sp√©cifique

**Exemple** : "Poids normal Ross 308 m√¢les √† 21 jours ?"

üîÑ Veuillez r√©essayer en reformulant votre question.""",

            "en": """I'm experiencing a technical difficulty analyzing your question.

üí° **To help me better assist you, please specify** :
‚Ä¢ Type of poultry (broilers, layers...)
‚Ä¢ Age of your animals (21 days, 3 weeks...)
‚Ä¢ Your specific problem or objective

**Example** : "Normal weight Ross 308 males at 21 days?"

üîÑ Please try again by rephrasing your question.""",

            "es": """Estoy experimentando una dificultad t√©cnica para analizar tu pregunta.

üí° **Para ayudarme a responderte mejor, especifica** :
‚Ä¢ Tipo de aves (pollos de engorde, ponedoras...)
‚Ä¢ Edad de tus animales (21 d√≠as, 3 semanas...)
‚Ä¢ Tu problema u objetivo espec√≠fico

**Ejemplo** : "Peso normal Ross 308 machos a 21 d√≠as?"

üîÑ Por favor, int√©ntalo de nuevo reformulando tu pregunta."""
        }
        
        return fallback_responses.get(language, fallback_responses['fr'])

    def _update_stats(self, response_type: ResponseType, processing_time_ms: int, success: bool):
        """Met √† jour les statistiques de traitement"""
        
        if not self.config["enable_stats"]:
            return
        
        self.stats["questions_processed"] += 1
        
        if success:
            if response_type == ResponseType.PRECISE_ANSWER:
                self.stats["precise_answers"] += 1
            elif response_type == ResponseType.GENERAL_ANSWER:
                self.stats["general_answers"] += 1
            elif response_type == ResponseType.NEEDS_CLARIFICATION:
                self.stats["clarifications"] += 1
        else:
            self.stats["errors"] += 1
        
        # Mise √† jour du temps moyen (moyenne mobile)
        current_avg = self.stats["average_processing_time_ms"]
        total_questions = self.stats["questions_processed"]
        
        self.stats["average_processing_time_ms"] = int(
            (current_avg * (total_questions - 1) + processing_time_ms) / total_questions
        )

    def get_system_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques syst√®me pour monitoring"""
        
        total_questions = self.stats["questions_processed"]
        
        if total_questions == 0:
            return {
                "service_status": "ready",
                "questions_processed": 0,
                "statistics": "No questions processed yet"
            }
        
        success_rate = ((total_questions - self.stats["errors"]) / total_questions) * 100
        
        return {
            "service_status": "active",
            "version": "unified_v1.0.0",
            "questions_processed": total_questions,
            "success_rate_percent": round(success_rate, 2),
            "response_distribution": {
                "precise_answers": self.stats["precise_answers"],
                "general_answers": self.stats["general_answers"], 
                "clarifications": self.stats["clarifications"],
                "errors": self.stats["errors"]
            },
            "performance": {
                "average_processing_time_ms": self.stats["average_processing_time_ms"],
                "system_components": {
                    "entities_extractor": "active",
                    "smart_classifier": "active",
                    "response_generator": "active"
                }
            },
            "configuration": self.config,
            "timestamp": datetime.now().isoformat()
        }

    def reset_stats(self):
        """Remet √† z√©ro les statistiques"""
        self.stats = {
            "questions_processed": 0,
            "precise_answers": 0,
            "general_answers": 0,
            "clarifications": 0,
            "errors": 0,
            "average_processing_time_ms": 0
        }
        logger.info("üìä [Expert Service] Statistiques remises √† z√©ro")

    def update_config(self, new_config: Dict[str, Any]):
        """Met √† jour la configuration du service"""
        self.config.update(new_config)
        logger.info(f"‚öôÔ∏è [Expert Service] Configuration mise √† jour: {new_config}")

# =============================================================================
# FONCTIONS UTILITAIRES ET TESTS
# =============================================================================

async def quick_ask(question: str, language: str = "fr") -> str:
    """Interface rapide pour poser une question"""
    service = ExpertService()
    result = await service.process_question(question, language=language)
    return result.response

def create_expert_service() -> ExpertService:
    """Factory pour cr√©er une instance du service"""
    return ExpertService()

# =============================================================================
# TESTS INT√âGR√âS
# =============================================================================

async def test_expert_service():
    """Tests du service expert unifi√©"""
    
    print("üß™ Tests du Service Expert Unifi√©")
    print("=" * 60)
    
    service = ExpertService()
    
    test_cases = [
        # Cas pr√©cis (devrait donner une r√©ponse sp√©cifique)
        ("Quel est le poids d'un Ross 308 m√¢le de 21 jours ?", "precise"),
        
        # Cas g√©n√©ral (devrait donner une r√©ponse g√©n√©rale + offre de pr√©cision)
        ("Poids normal poulet 22 jours ?", "general"),
        
        # Cas clarification (vraiment trop vague)
        ("Mes poulets vont mal", "clarification"),
        
        # Cas sant√© avec contexte
        ("Poules 25 semaines font diarrh√©e depuis 2 jours", "general")
    ]
    
    for question, expected_type in test_cases:
        print(f"\nüìù Question: {question}")
        print(f"   üéØ Type attendu: {expected_type}")
        
        try:
            result = await service.process_question(question)
            status = "‚úÖ" if result.success else "‚ùå"
            print(f"   {status} Type: {result.response_type}")
            print(f"   ‚è±Ô∏è Temps: {result.processing_time_ms}ms")
            print(f"   üéØ Confiance: {result.confidence:.2f}")
            
            if len(result.response) > 100:
                preview = result.response[:100] + "..."
            else:
                preview = result.response
            print(f"   üí¨ R√©ponse: {preview}")
            
        except Exception as e:
            print(f"   ‚ùå Erreur: {e}")
    
    print(f"\nüìä Statistiques finales:")
    stats = service.get_system_stats()
    print(f"   Questions trait√©es: {stats['questions_processed']}")
    print(f"   Taux de succ√®s: {stats['success_rate_percent']:.1f}%")
    print(f"   Temps moyen: {stats['performance']['average_processing_time_ms']}ms")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_expert_service())