"""
app/api/v1/expert_services.py - SERVICES MÃ‰TIER EXPERT SYSTEM AVEC CONCISION

ðŸš¨ NOUVELLES FONCTIONNALITÃ‰S AJOUTÃ‰ES:
1. âœ… SystÃ¨me de concision des rÃ©ponses intÃ©grÃ©
2. âœ… Nettoyage avancÃ© verbositÃ© + rÃ©fÃ©rences documents
3. âœ… Configuration flexible par type de question
4. âœ… DÃ©tection automatique niveau de concision requis
5. âœ… Conservation de toutes les fonctionnalitÃ©s existantes

FONCTIONNALITÃ‰S CONSERVÃ‰ES:
- âœ… SystÃ¨me de clarification intelligent complet
- âœ… MÃ©moire conversationnelle
- âœ… RAG avec contexte enrichi
- âœ… Multi-LLM support
- âœ… Validation agricole
- âœ… Support multilingue
"""

import os
import logging
import uuid
import time
import re
from datetime import datetime
from typing import Optional, Dict, Any, Tuple
from enum import Enum

from fastapi import HTTPException, Request

from .expert_models import (
    EnhancedQuestionRequest, EnhancedExpertResponse, FeedbackRequest,
    ValidationResult, ProcessingContext, VaguenessResponse, ResponseFormat
)
from .expert_utils import (
    get_user_id_from_request, 
    build_enriched_question_from_clarification,
    get_enhanced_topics_by_language,
    save_conversation_auto_enhanced,
    extract_breed_and_sex_from_clarification,
    build_enriched_question_with_breed_sex,
    validate_clarification_completeness
)
from .expert_integrations import IntegrationsManager
from .api_enhancement_service import APIEnhancementService
from .prompt_templates import build_structured_prompt, extract_context_from_entities, validate_prompt_context, build_clarification_prompt

logger = logging.getLogger(__name__)

# =============================================================================
# ðŸ†• SYSTÃˆME DE CONCISION DES RÃ‰PONSES
# =============================================================================

class ConcisionLevel(Enum):
    """Niveaux de concision disponibles"""
    ULTRA_CONCISE = "ultra_concise"    # RÃ©ponse minimale (ex: "410-450g")
    CONCISE = "concise"                # RÃ©ponse courte mais complÃ¨te
    STANDARD = "standard"              # RÃ©ponse normale sans conseils excessifs
    DETAILED = "detailed"              # RÃ©ponse complÃ¨te (mode actuel)

class ConcisionConfig:
    """Configuration du systÃ¨me de concision"""
    
    # Activer/dÃ©sactiver le systÃ¨me
    ENABLE_CONCISE_RESPONSES = True
    
    # Niveau par dÃ©faut
    DEFAULT_CONCISION_LEVEL = ConcisionLevel.CONCISE
    
    # Seuils de longueur par type de question
    MAX_RESPONSE_LENGTH = {
        "weight_question": 80,      # Questions de poids: max 80 caractÃ¨res
        "temperature_question": 60, # Questions tempÃ©rature: max 60 caractÃ¨res
        "measurement_question": 70, # Questions de mesure: max 70 caractÃ¨res
        "general_question": 150,    # Questions gÃ©nÃ©rales: max 150 caractÃ¨res
        "complex_question": 300     # Questions complexes: max 300 caractÃ¨res
    }
    
    # Mots-clÃ©s qui dÃ©clenchent le mode ultra-concis
    ULTRA_CONCISE_KEYWORDS = [
        "poids", "weight", "peso",
        "tempÃ©rature", "temperature", "temperatura",
        "combien", "how much", "cuÃ¡nto",
        "quel est", "what is", "cuÃ¡l es"
    ]
    
    # Mots-clÃ©s pour questions complexes (mode dÃ©taillÃ©)
    COMPLEX_KEYWORDS = [
        "comment", "how to", "cÃ³mo",
        "pourquoi", "why", "por quÃ©", 
        "expliquer", "explain", "explicar",
        "procÃ©dure", "procedure", "procedimiento",
        "protocole", "protocol", "protocolo"
    ]

class ResponseConcisionProcessor:
    """Processeur de concision des rÃ©ponses"""
    
    def __init__(self):
        self.config = ConcisionConfig()
        logger.info("âœ… [Concision] Processeur de concision initialisÃ©")
    
    def detect_question_type(self, question: str) -> str:
        """DÃ©tecte le type de question pour appliquer les bonnes rÃ¨gles"""
        
        question_lower = question.lower().strip()
        
        # Questions de poids/mesures = rÃ©ponses trÃ¨s courtes
        weight_keywords = ["poids", "weight", "peso", "grammes", "grams", "gramos", "kg"]
        if any(word in question_lower for word in weight_keywords):
            return "weight_question"
        
        # Questions de tempÃ©rature
        temp_keywords = ["tempÃ©rature", "temperature", "temperatura", "Â°c", "degrÃ©", "degree"]
        if any(word in question_lower for word in temp_keywords):
            return "temperature_question"
        
        # Questions de mesure gÃ©nÃ©rale
        measurement_keywords = ["taille", "size", "tamaÃ±o", "longueur", "length", "hauteur", "height"]
        if any(word in question_lower for word in measurement_keywords):
            return "measurement_question"
        
        # Questions complexes avec "comment", "pourquoi", etc.
        if any(word in question_lower for word in self.config.COMPLEX_KEYWORDS):
            return "complex_question"
        
        # Par dÃ©faut: question gÃ©nÃ©rale
        return "general_question"
    
    def detect_optimal_concision_level(self, question: str, user_preference: Optional[ConcisionLevel] = None) -> ConcisionLevel:
        """DÃ©tecte le niveau de concision optimal pour une question"""
        
        # Si l'utilisateur a une prÃ©fÃ©rence explicite, l'utiliser
        if user_preference:
            return user_preference
        
        question_lower = question.lower().strip()
        
        # Questions ultra-concises (poids, tempÃ©rature, mesures simples)
        if any(keyword in question_lower for keyword in self.config.ULTRA_CONCISE_KEYWORDS):
            return ConcisionLevel.ULTRA_CONCISE
        
        # Questions complexes = rÃ©ponses dÃ©taillÃ©es
        if any(keyword in question_lower for keyword in self.config.COMPLEX_KEYWORDS):
            return ConcisionLevel.DETAILED
        
        # Par dÃ©faut: concis
        return self.config.DEFAULT_CONCISION_LEVEL
    
    def process_response(
        self, 
        response: str, 
        question: str, 
        concision_level: Optional[ConcisionLevel] = None,
        language: str = "fr"
    ) -> str:
        """Traite une rÃ©ponse selon le niveau de concision demandÃ©"""
        
        if not self.config.ENABLE_CONCISE_RESPONSES:
            return response
        
        # DÃ©terminer le niveau de concision
        level = concision_level or self.detect_optimal_concision_level(question)
        
        logger.info(f"ðŸŽ¯ [Concision] Traitement rÃ©ponse niveau {level.value}")
        
        # Appliquer le traitement selon le niveau
        if level == ConcisionLevel.ULTRA_CONCISE:
            return self._extract_essential_info(response, question, language)
        elif level == ConcisionLevel.CONCISE:
            return self._make_concise(response, question, language)
        elif level == ConcisionLevel.STANDARD:
            return self._remove_excessive_advice(response, language)
        else:  # DETAILED
            return self._clean_document_references_only(response)
    
    def _extract_essential_info(self, response: str, question: str, language: str = "fr") -> str:
        """Extrait uniquement l'information essentielle (mode ultra-concis)"""
        
        question_lower = question.lower()
        
        # Questions de poids â†’ extraire juste les chiffres + unitÃ©
        if any(word in question_lower for word in ["poids", "weight", "peso"]):
            # Chercher pattern "X grammes" ou "entre X et Y grammes"
            weight_patterns = [
                r'(?:entre\s+)?(\d+(?:-\d+|[^\d]*\d+)?)\s*(?:grammes?|g\b)',
                r'(\d+)\s*(?:Ã |to|a)\s*(\d+)\s*(?:grammes?|g\b)',
                r'(\d+)\s*(?:grammes?|g\b)'
            ]
            
            for pattern in weight_patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    if len(match.groups()) >= 2:  # Range
                        return f"{match.group(1)}-{match.group(2)}g"
                    else:  # Single value
                        value = match.group(1)
                        if "entre" in response.lower() or "-" in value:
                            return f"{value}g"
                        else:
                            return f"~{value}g"
        
        # Questions de tempÃ©rature â†’ extraire juste les degrÃ©s
        if any(word in question_lower for word in ["tempÃ©rature", "temperature"]):
            temp_patterns = [
                r'(\d+(?:-\d+)?)\s*(?:Â°C|degrÃ©s?|degrees?)',
                r'(\d+)\s*(?:Ã |to|a)\s*(\d+)\s*(?:Â°C|degrÃ©s?)'
            ]
            
            for pattern in temp_patterns:
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    if len(match.groups()) >= 2:
                        return f"{match.group(1)}-{match.group(2)}Â°C"
                    else:
                        return f"{match.group(1)}Â°C"
        
        # Fallback: premiÃ¨re phrase avec chiffres
        sentences = response.split('.')
        for sentence in sentences:
            if re.search(r'\d+', sentence) and len(sentence.strip()) > 10:
                return sentence.strip() + '.'
        
        # Ultime fallback: premiÃ¨re phrase tout court
        if sentences:
            return sentences[0].strip() + '.'
        
        return response
    
    def _make_concise(self, response: str, question: str, language: str = "fr") -> str:
        """Rend concis (enlÃ¨ve conseils mais garde info principale)"""
        
        # D'abord nettoyer les rÃ©fÃ©rences aux documents
        cleaned = self._clean_document_references_only(response)
        
        # Ensuite supprimer la verbositÃ© excessive
        verbose_patterns = [
            # FranÃ§ais - Conseils gÃ©nÃ©raux non demandÃ©s
            r'\.?\s*Il est essentiel de[^.]*\.',
            r'\.?\s*Assurez-vous de[^.]*\.',
            r'\.?\s*N\'hÃ©sitez pas Ã [^.]*\.',
            r'\.?\s*Pour garantir[^.]*\.',
            r'\.?\s*Il est important de[^.]*\.',
            r'\.?\s*Veillez Ã [^.]*\.',
            r'\.?\s*Il convient de[^.]*\.',
            r'\.?\s*Ã€ ce stade[^.]*\.',
            r'\.?\s*En cas de doute[^.]*\.',
            r'\.?\s*pour favoriser le bien-Ãªtre[^.]*\.',
            r'\.?\s*en termes de[^.]*\.',
            
            # Anglais - Conseils gÃ©nÃ©raux non demandÃ©s
            r'\.?\s*It is essential to[^.]*\.',
            r'\.?\s*Make sure to[^.]*\.',
            r'\.?\s*Don\'t hesitate to[^.]*\.',
            r'\.?\s*To ensure[^.]*\.',
            r'\.?\s*It is important to[^.]*\.',
            r'\.?\s*Be sure to[^.]*\.',
            r'\.?\s*At this stage[^.]*\.',
            
            # Espagnol - Consejos generales no solicitados
            r'\.?\s*Es esencial[^.]*\.',
            r'\.?\s*AsegÃºrese de[^.]*\.',
            r'\.?\s*No dude en[^.]*\.',
            r'\.?\s*Para garantizar[^.]*\.',
            r'\.?\s*Es importante[^.]*\.',
            r'\.?\s*En esta etapa[^.]*\.',
        ]
        
        # Supprimer les patterns verbeux
        for pattern in verbose_patterns:
            cleaned = re.sub(pattern, '.', cleaned, flags=re.IGNORECASE)
        
        # Nettoyer les doubles points et espaces
        cleaned = re.sub(r'\.+', '.', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = cleaned.strip()
        
        # Si c'est une question de poids et que c'est encore long, extraire la phrase principale
        if any(word in question.lower() for word in ['poids', 'weight', 'peso']) and len(cleaned) > 100:
            weight_sentence = self._extract_weight_sentence(cleaned)
            if weight_sentence:
                return weight_sentence
        
        return cleaned
    
    def _remove_excessive_advice(self, response: str, language: str = "fr") -> str:
        """EnlÃ¨ve seulement les conseils excessifs (mode standard)"""
        
        # D'abord nettoyer les rÃ©fÃ©rences aux documents
        cleaned = self._clean_document_references_only(response)
        
        # Patterns de conseils excessifs seulement
        excessive_patterns = [
            r'\.?\s*N\'hÃ©sitez pas Ã [^.]*\.',
            r'\.?\s*Pour des conseils plus personnalisÃ©s[^.]*\.',
            r'\.?\s*Don\'t hesitate to[^.]*\.',
            r'\.?\s*For more personalized advice[^.]*\.',
            r'\.?\s*No dude en[^.]*\.',
            r'\.?\s*Para consejos mÃ¡s personalizados[^.]*\.',
        ]
        
        for pattern in excessive_patterns:
            cleaned = re.sub(pattern, '.', cleaned, flags=re.IGNORECASE)
        
        return re.sub(r'\.+', '.', cleaned).replace(r'\s+', ' ').strip()
    
    def _clean_document_references_only(self, response_text: str) -> str:
        """Nettoie uniquement les rÃ©fÃ©rences aux documents (version originale)"""
        
        if not response_text:
            return response_text
        
        # Patterns de rÃ©fÃ©rences aux documents Ã  nettoyer
        patterns_to_remove = [
            # FranÃ§ais
            r'selon le document \d+,?\s*',
            r'd\'aprÃ¨s le document \d+,?\s*',
            r'le document \d+ indique que\s*',
            r'comme mentionnÃ© dans le document \d+,?\s*',
            r'tel que dÃ©crit dans le document \d+,?\s*',
            
            # Anglais
            r'according to document \d+,?\s*',
            r'as stated in document \d+,?\s*',
            r'document \d+ indicates that\s*',
            r'as mentioned in document \d+,?\s*',
            
            # Espagnol
            r'segÃºn el documento \d+,?\s*',
            r'como se indica en el documento \d+,?\s*',
            r'el documento \d+ menciona que\s*',
            
            # Patterns gÃ©nÃ©riques
            r'\(document \d+\)',
            r'\[document \d+\]',
            r'source:\s*document \d+',
            r'ref:\s*document \d+'
        ]
        
        cleaned_response = response_text
        
        # Nettoyer chaque pattern de document
        for pattern in patterns_to_remove:
            cleaned_response = re.sub(
                pattern, 
                '', 
                cleaned_response, 
                flags=re.IGNORECASE
            )
        
        # Nettoyer les doubles espaces et capitaliser
        cleaned_response = re.sub(r'\s+', ' ', cleaned_response)
        cleaned_response = cleaned_response.strip()
        
        # Capitaliser la premiÃ¨re lettre si nÃ©cessaire
        if cleaned_response and cleaned_response[0].islower():
            cleaned_response = cleaned_response[0].upper() + cleaned_response[1:]
        
        return cleaned_response
    
    def _extract_weight_sentence(self, text: str) -> Optional[str]:
        """Extrait la phrase principale contenant l'information de poids"""
        
        # Chercher la premiÃ¨re phrase avec des chiffres + unitÃ©s de poids
        weight_patterns = [
            r'[^.]*\d+[^.]*(?:grammes?|g\b|kg|livres?|pounds?)[^.]*\.',
            r'[^.]*(?:entre|between|entre)\s+\d+[^.]*\d+[^.]*\.',
            r'[^.]*(?:poids|weight|peso)[^.]*\d+[^.]*\.'
        ]
        
        for pattern in weight_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                sentence = match.group(0).strip()
                # Nettoyer la phrase trouvÃ©e
                sentence = re.sub(r'^\W+', '', sentence)  # Supprimer ponctuation dÃ©but
                if sentence and sentence[0].islower():
                    sentence = sentence[0].upper() + sentence[1:]
                return sentence
        
        # Si aucun pattern trouvÃ©, prendre la premiÃ¨re phrase
        sentences = text.split('.')
        if sentences:
            first_sentence = sentences[0].strip() + '.'
            return first_sentence
        
        return None

# =============================================================================
# ðŸ”„ CLASSES EXISTANTES AVEC CONCISION INTÃ‰GRÃ‰E
# =============================================================================

class RAGContextEnhancer:
    """AmÃ©liore le contexte conversationnel pour optimiser les requÃªtes RAG"""
    
    def __init__(self):
        # Patterns pour dÃ©tecter les rÃ©fÃ©rences contextuelles
        self.pronoun_patterns = {
            "fr": [
                r'\b(son|sa|ses|leur|leurs)\s+(poids|Ã¢ge|croissance|dÃ©veloppement)',
                r'\b(ils|elles)\s+(pÃ¨sent|grandissent|se dÃ©veloppent)',
                r'\b(qu\'?est-ce que|quel est)\s+(son|sa|ses|leur)',
                r'\b(combien)\s+(pÃ¨sent-ils|font-ils|mesurent-ils)'
            ],
            "en": [
                r'\b(their|its)\s+(weight|age|growth|development)',
                r'\b(they)\s+(weigh|grow|develop)',
                r'\b(what is|how much is)\s+(their|its)',
                r'\b(how much do they)\s+(weigh|measure)'
            ],
            "es": [
                r'\b(su|sus)\s+(peso|edad|crecimiento|desarrollo)',
                r'\b(ellos|ellas)\s+(pesan|crecen|se desarrollan)',
                r'\b(cuÃ¡l es|cuÃ¡nto es)\s+(su|sus)',
                r'\b(cuÃ¡nto)\s+(pesan|miden)'
            ]
        }
    
    def enhance_question_for_rag(
        self, 
        question: str, 
        conversation_context: str, 
        language: str = "fr"
    ) -> Tuple[str, Dict[str, any]]:
        """AmÃ©liore une question pour le RAG en utilisant le contexte conversationnel"""
        
        enhancement_info = {
            "pronoun_detected": False,
            "context_entities_used": [],
            "question_enriched": False,
            "original_question": question
        }
        
        # 1. DÃ©tecter les pronoms/rÃ©fÃ©rences contextuelles
        has_pronouns = self._detect_contextual_references(question, language)
        if has_pronouns:
            enhancement_info["pronoun_detected"] = True
            logger.info(f"ðŸ” [RAG Context] Pronoms dÃ©tectÃ©s dans: '{question}'")
        
        # 2. Extraire entitÃ©s du contexte
        context_entities = self._extract_context_entities(conversation_context)
        if context_entities:
            enhancement_info["context_entities_used"] = list(context_entities.keys())
            logger.info(f"ðŸ“Š [RAG Context] EntitÃ©s contextuelles: {context_entities}")
        
        # 3. Enrichir la question si nÃ©cessaire
        enriched_question = question
        
        if has_pronouns and context_entities:
            enriched_question = self._build_enriched_question(
                question, context_entities, language
            )
            enhancement_info["question_enriched"] = True
            logger.info(f"âœ¨ [RAG Context] Question enrichie: '{enriched_question}'")
        
        # 4. Ajouter contexte technique si pertinent
        if context_entities or has_pronouns:
            technical_context = self._build_technical_context(context_entities, language)
            if technical_context:
                enriched_question += f"\n\nContexte technique: {technical_context}"
        
        return enriched_question, enhancement_info
    
    def _detect_contextual_references(self, question: str, language: str) -> bool:
        """DÃ©tecte si la question contient des pronoms/rÃ©fÃ©rences contextuelles"""
        
        patterns = self.pronoun_patterns.get(language, self.pronoun_patterns["fr"])
        question_lower = question.lower()
        
        for pattern in patterns:
            if re.search(pattern, question_lower, re.IGNORECASE):
                logger.debug(f"ðŸŽ¯ [RAG Context] Pattern trouvÃ©: {pattern}")
                return True
        
        return False
    
    def _extract_context_entities(self, context: str) -> Dict[str, str]:
        """Extrait les entitÃ©s importantes du contexte conversationnel"""
        
        if not context:
            return {}
        
        entities = {}
        context_lower = context.lower()
        
        # Extraire race
        breed_patterns = [
            r'race[:\s]+([a-zA-Z0-9\s]+?)(?:\n|,|\.|\s|$)',
            r'breed[:\s]+([a-zA-Z0-9\s]+?)(?:\n|,|\.|\s|$)',
            r'(ross\s*308|cobb\s*500|hubbard|arbor\s*acres)',
            r'poulets?\s+(ross\s*308|cobb\s*500)',
            r'chickens?\s+(ross\s*308|cobb\s*500)'
        ]
        
        for pattern in breed_patterns:
            match = re.search(pattern, context_lower, re.IGNORECASE)
            if match:
                entities["breed"] = match.group(1).strip()
                break
        
        # Extraire sexe
        sex_patterns = [
            r'sexe[:\s]+([a-zA-Z\s]+?)(?:\n|,|\.|\s|$)',
            r'sex[:\s]+([a-zA-Z\s]+?)(?:\n|,|\.|\s|$)',
            r'\b(mÃ¢les?|femelles?|males?|females?|mixte|mixed)\b'
        ]
        
        for pattern in sex_patterns:
            match = re.search(pattern, context_lower, re.IGNORECASE)
            if match:
                entities["sex"] = match.group(1).strip()
                break
        
        # Extraire Ã¢ge
        age_patterns = [
            r'Ã¢ge[:\s]+(\d+\s*(?:jour|semaine|day|week)s?)',
            r'age[:\s]+(\d+\s*(?:jour|semaine|day|week)s?)',
            r'(\d+)\s*(?:jour|day)s?',
            r'(\d+)\s*(?:semaine|week)s?'
        ]
        
        for pattern in age_patterns:
            match = re.search(pattern, context_lower, re.IGNORECASE)
            if match:
                entities["age"] = match.group(1).strip()
                break
        
        return entities
    
    def _build_enriched_question(
        self, 
        question: str, 
        context_entities: Dict[str, str], 
        language: str
    ) -> str:
        """Construit une question enrichie en remplaÃ§ant les pronoms par les entitÃ©s contextuelles"""
        
        enriched = question
        
        # Templates par langue
        templates = {
            "fr": {
                "breed_sex_age": "Pour des {breed} {sex} de {age}",
                "breed_age": "Pour des {breed} de {age}",
                "breed_sex": "Pour des {breed} {sex}",
                "breed_only": "Pour des {breed}",
                "age_only": "Pour des poulets de {age}"
            },
            "en": {
                "breed_sex_age": "For {breed} {sex} chickens at {age}",
                "breed_age": "For {breed} chickens at {age}",
                "breed_sex": "For {breed} {sex} chickens",
                "breed_only": "For {breed} chickens", 
                "age_only": "For chickens at {age}"
            },
            "es": {
                "breed_sex_age": "Para pollos {breed} {sex} de {age}",
                "breed_age": "Para pollos {breed} de {age}",
                "breed_sex": "Para pollos {breed} {sex}",
                "breed_only": "Para pollos {breed}",
                "age_only": "Para pollos de {age}"
            }
        }
        
        template_set = templates.get(language, templates["fr"])
        
        # Construire le prÃ©fixe contextuel
        context_prefix = ""
        if "breed" in context_entities and "sex" in context_entities and "age" in context_entities:
            context_prefix = template_set["breed_sex_age"].format(
                breed=context_entities["breed"],
                sex=context_entities["sex"],
                age=context_entities["age"]
            )
        elif "breed" in context_entities and "age" in context_entities:
            context_prefix = template_set["breed_age"].format(
                breed=context_entities["breed"],
                age=context_entities["age"]
            )
        elif "breed" in context_entities and "sex" in context_entities:
            context_prefix = template_set["breed_sex"].format(
                breed=context_entities["breed"],
                sex=context_entities["sex"]
            )
        elif "breed" in context_entities:
            context_prefix = template_set["breed_only"].format(
                breed=context_entities["breed"]
            )
        elif "age" in context_entities:
            context_prefix = template_set["age_only"].format(age=context_entities["age"])
        
        if context_prefix:
            # Remplacer ou prÃ©fixer selon la structure de la question
            if any(word in question.lower() for word in ["son", "sa", "ses", "leur", "leurs", "their", "its", "su", "sus"]):
                enriched = f"{context_prefix}, {question.lower()}"
            else:
                enriched = f"{context_prefix}: {question}"
        
        return enriched
    
    def _build_technical_context(self, entities: Dict[str, str], language: str) -> str:
        """Construit un contexte technique pour aider le RAG"""
        
        if not entities:
            return ""
        
        context_parts = []
        
        if "breed" in entities:
            context_parts.append(f"Race: {entities['breed']}")
        
        if "sex" in entities:
            context_parts.append(f"Sexe: {entities['sex']}")
        
        if "age" in entities:
            context_parts.append(f"Ã‚ge: {entities['age']}")
        
        return " | ".join(context_parts)

class ExpertService:
    """Service principal pour le systÃ¨me expert avec concision intÃ©grÃ©e"""
    
    def __init__(self):
        self.integrations = IntegrationsManager()
        self.rag_enhancer = RAGContextEnhancer()
        self.enhancement_service = APIEnhancementService()
        
        # ðŸ†• NOUVEAU: Processeur de concision
        self.concision_processor = ResponseConcisionProcessor()
        
        logger.info("âœ… [Expert Service] Service expert initialisÃ© avec systÃ¨me de concision")
    
    def get_current_user_dependency(self):
        """Retourne la dÃ©pendance pour l'authentification"""
        return self.integrations.get_current_user_dependency()
    
    async def process_expert_question(
        self,
        request_data: EnhancedQuestionRequest,
        request: Request,
        current_user: Optional[Dict[str, Any]],
        start_time: float
    ) -> EnhancedExpertResponse:
        """Traite une question expert avec systÃ¨me de clarification ET concision"""
        
        processing_steps = []
        ai_enhancements_used = []
        debug_info = {}
        performance_breakdown = {"start": int(time.time() * 1000)}
        
        # Initialisation
        processing_steps.append("initialization")
        
        # === AUTHENTIFICATION ===
        if current_user is None and self.integrations.auth_available:
            raise HTTPException(status_code=401, detail="Authentification requise")
        
        user_id = self._extract_user_id(current_user, request_data, request)
        user_email = current_user.get("email") if current_user else None
        request_ip = request.client.host if request.client else "unknown"
        
        processing_steps.append("authentication")
        performance_breakdown["auth_complete"] = int(time.time() * 1000)
        
        # === GESTION CONVERSATION ID ===
        conversation_id = self._get_or_create_conversation_id(request_data)
        
        # === VALIDATION QUESTION ===
        question_text = request_data.text.strip()
        if not question_text:
            raise HTTPException(status_code=400, detail="Question text is required")
        
        processing_steps.append("question_validation")
        
        # === MÃ‰MOIRE CONVERSATIONNELLE ===
        conversation_context = None
        if self.integrations.intelligent_memory_available:
            try:
                conversation_context = self.integrations.add_message_to_conversation(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message=question_text,
                    role="user",
                    language=request_data.language,
                    message_type="clarification_response" if request_data.is_clarification_response else "question"
                )
                ai_enhancements_used.append("intelligent_memory")
                processing_steps.append("memory_storage")
                logger.info(f"ðŸ’¾ [Expert Service] Message ajoutÃ© Ã  la mÃ©moire: {question_text[:50]}...")
            except Exception as e:
                logger.warning(f"âš ï¸ [Expert Service] Erreur mÃ©moire: {e}")
        
        performance_breakdown["memory_complete"] = int(time.time() * 1000)
        
        # === VALIDATION AGRICOLE ===
        validation_result = await self._validate_agricultural_question(
            question_text, request_data.language, user_id, request_ip, conversation_id
        )
        
        processing_steps.append("agricultural_validation")
        performance_breakdown["validation_complete"] = int(time.time() * 1000)
        
        if not validation_result.is_valid:
            return self._create_rejection_response(
                question_text, validation_result, conversation_id, 
                user_email, request_data.language, start_time,
                processing_steps, ai_enhancements_used, None
            )
        
        # === SYSTÃˆME DE CLARIFICATION INTELLIGENT ===
        clarification_result = await self._handle_clarification_corrected(
            request_data, question_text, user_id, conversation_id,
            processing_steps, ai_enhancements_used
        )
        
        if clarification_result:
            return clarification_result
        
        # DÃ©tection vagueness aprÃ¨s clarifications spÃ©cialisÃ©es
        vagueness_result = None
        if request_data.enable_vagueness_detection:
            vagueness_result = self.enhancement_service.detect_vagueness(
                question_text, request_data.language
            )
            
            ai_enhancements_used.append("vagueness_detection")
            performance_breakdown["vagueness_check"] = int(time.time() * 1000)
            
            if vagueness_result.is_vague and vagueness_result.vagueness_score > 0.6:
                logger.info(f"ðŸŽ¯ [Expert Service] Question floue dÃ©tectÃ©e (score: {vagueness_result.vagueness_score})")
                return self._create_vagueness_response(
                    vagueness_result, question_text, conversation_id, 
                    request_data.language, start_time, processing_steps, ai_enhancements_used
                )
        
        performance_breakdown["clarification_complete"] = int(time.time() * 1000)
        
        # === TRAITEMENT EXPERT AVEC RAG-FIRST + AMÃ‰LIORATIONS ===
        expert_result = await self._process_expert_response_enhanced_corrected(
            question_text, request_data, request, current_user,
            conversation_id, processing_steps, ai_enhancements_used,
            debug_info, performance_breakdown, vagueness_result
        )
        
        # ðŸ†• === NOUVEAU: APPLICATION DU SYSTÃˆME DE CONCISION ===
        if expert_result["answer"] and self.concision_processor.config.ENABLE_CONCISE_RESPONSES:
            
            # DÃ©tecter le niveau de concision optimal (peut Ãªtre overridÃ© par prÃ©fÃ©rence utilisateur)
            user_concision_preference = getattr(request_data, 'concision_level', None)
            
            original_answer = expert_result["answer"]
            processed_answer = self.concision_processor.process_response(
                response=original_answer,
                question=question_text,
                concision_level=user_concision_preference,
                language=request_data.language
            )
            
            if processed_answer != original_answer:
                expert_result["answer"] = processed_answer
                expert_result["original_answer"] = original_answer  # Garder l'original
                expert_result["concision_applied"] = True
                ai_enhancements_used.append("response_concision")
                processing_steps.append("concision_processing")
                
                logger.info(f"âœ‚ï¸ [Expert Service] Concision appliquÃ©e: {len(original_answer)} â†’ {len(processed_answer)} chars")
            else:
                expert_result["concision_applied"] = False
        
        performance_breakdown["concision_complete"] = int(time.time() * 1000)
        
        # === ENREGISTREMENT RÃ‰PONSE ===
        if self.integrations.intelligent_memory_available and expert_result["answer"]:
            try:
                self.integrations.add_message_to_conversation(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message=expert_result["answer"],
                    role="assistant",
                    language=request_data.language,
                    message_type="response"
                )
            except Exception as e:
                logger.warning(f"âš ï¸ [Expert Service] Erreur enregistrement rÃ©ponse: {e}")
        
        processing_steps.append("response_storage")
        performance_breakdown["final"] = int(time.time() * 1000)
        
        # === CONSTRUCTION RÃ‰PONSE FINALE AMÃ‰LIORÃ‰E ===
        response_time_ms = int((time.time() - start_time) * 1000)
        
        return self._build_final_enhanced_response(
            question_text, expert_result["answer"], conversation_id,
            user_email, request_data.language, response_time_ms,
            expert_result, validation_result, conversation_context,
            processing_steps, ai_enhancements_used, request_data,
            debug_info, performance_breakdown
        )
    
    # ===========================================================================================
    # âœ… SYSTÃˆME DE CLARIFICATION CORRIGÃ‰ - VERSION FINALE (INCHANGÃ‰)
    # ===========================================================================================
    
    async def _handle_clarification_corrected(
        self, request_data, question_text, user_id, conversation_id, 
        processing_steps, ai_enhancements_used
    ):
        """âœ… SYSTÃˆME DE CLARIFICATION PARFAITEMENT CORRIGÃ‰"""
        
        # 1. âœ… TRAITEMENT DES RÃ‰PONSES DE CLARIFICATION CORRIGÃ‰
        if request_data.is_clarification_response:
            return await self._process_clarification_response_corrected(
                request_data, question_text, conversation_id,
                processing_steps, ai_enhancements_used
            )
        
        # 2. DÃ‰TECTION QUESTIONS NÃ‰CESSITANT CLARIFICATION
        clarification_needed = self._detect_performance_question_needing_clarification(
            question_text, request_data.language
        )
        
        if not clarification_needed:
            return None
        
        logger.info(f"ðŸŽ¯ [Expert Service] Clarification nÃ©cessaire: {clarification_needed['type']}")
        processing_steps.append("automatic_clarification_triggered")
        ai_enhancements_used.append("smart_performance_clarification")
        
        # 3. âœ… SAUVEGARDE FORCÃ‰E AVEC MÃ‰MOIRE INTELLIGENTE
        if self.integrations.intelligent_memory_available:
            try:
                # Utiliser la fonction dÃ©diÃ©e du systÃ¨me de mÃ©moire
                from .conversation_memory_enhanced import mark_question_for_clarification
                
                question_id = mark_question_for_clarification(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    original_question=question_text,
                    language=request_data.language
                )
                
                logger.info(f"ðŸ’¾ [Expert Service] Question originale marquÃ©e: {question_id}")
                processing_steps.append("original_question_marked")
                ai_enhancements_used.append("intelligent_memory_clarification_marking")
                
            except Exception as e:
                logger.error(f"âŒ [Expert Service] Erreur marquage question: {e}")
                # Fallback: marquer manuellement
                self.integrations.add_message_to_conversation(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message=f"ORIGINAL_QUESTION_FOR_CLARIFICATION: {question_text}",
                    role="system",
                    language=request_data.language,
                    message_type="original_question_marker"
                )
        
        # 4. GÃ©nÃ©rer la demande de clarification
        clarification_response = self._generate_performance_clarification_response(
            question_text, clarification_needed, request_data.language, conversation_id
        )
        
        return clarification_response
    
    async def _process_clarification_response_corrected(
        self, request_data, question_text, conversation_id, 
        processing_steps, ai_enhancements_used
    ):
        """âœ… TRAITEMENT DES RÃ‰PONSES DE CLARIFICATION - VERSION CORRIGÃ‰E FINALE"""
        
        # âœ… RÃ‰CUPÃ‰RATION FORCÃ‰E DE LA QUESTION ORIGINALE
        original_question = request_data.original_question
        clarification_context = request_data.clarification_context
        
        # Si pas de contexte fourni, rÃ©cupÃ©rer depuis la mÃ©moire intelligente
        if (not original_question or not clarification_context) and self.integrations.intelligent_memory_available:
            try:
                from .conversation_memory_enhanced import find_original_question
                
                original_msg = find_original_question(conversation_id)
                
                if original_msg:
                    original_question = original_msg.message
                    clarification_context = {
                        "missing_information": ["breed", "sex"],
                        "clarification_type": "performance_breed_sex"
                    }
                    logger.info(f"âœ… [Expert Service] Question originale rÃ©cupÃ©rÃ©e: {original_question}")
                    ai_enhancements_used.append("intelligent_memory_original_question_recovery")
                else:
                    logger.warning("âš ï¸ [Expert Service] Question originale non trouvÃ©e dans la mÃ©moire")
                    
            except Exception as e:
                logger.error(f"âŒ [Expert Service] Erreur rÃ©cupÃ©ration question originale: {e}")
        
        # Si toujours pas de question originale, utiliser fallback
        if not original_question:
            logger.warning("âš ï¸ [Expert Service] Fallback: crÃ©ation question par dÃ©faut")
            original_question = "Quel est le poids de rÃ©fÃ©rence pour ces poulets ?"
            clarification_context = {
                "missing_information": ["breed", "sex"],
                "clarification_type": "performance_breed_sex_fallback"
            }
        
        # âœ… EXTRACTION AMÃ‰LIORÃ‰E DES INFORMATIONS DE CLARIFICATION
        missing_info = clarification_context.get("missing_information", [])
        
        # Validation de la complÃ©tude avec extraction amÃ©liorÃ©e
        validation = validate_clarification_completeness(
            question_text, missing_info, request_data.language
        )
        
        # Gestion des rÃ©ponses partielles
        if not validation["is_complete"]:
            logger.info(f"ðŸ”„ [Expert Service] Clarification incomplÃ¨te: {validation['still_missing']}")
            return self._generate_follow_up_clarification(
                question_text, validation, request_data.language, conversation_id
            )
        
        # âœ… EXTRACTION RACE/SEXE DEPUIS CLARIFICATION
        breed = validation["extracted_info"].get("breed")
        sex = validation["extracted_info"].get("sex")
        
        # ðŸš¨ EXTRACTION Ã‚GE DEPUIS QUESTION ORIGINALE
        age_info = self._extract_age_from_original_question(original_question, request_data.language)
        
        # âœ… ENRICHISSEMENT AUTOMATIQUE COMPLET (race + sexe + Ã¢ge)
        enriched_original_question = self._build_complete_enriched_question(
            original_question, breed, sex, age_info, request_data.language
        )
        
        logger.info(f"âœ… [Expert Service] Question COMPLÃˆTEMENT enrichie: {enriched_original_question}")
        
        # âœ… FORCER LE REMPLACEMENT DE LA QUESTION POUR LE RAG
        request_data.text = enriched_original_question
        request_data.is_clarification_response = False  # Traiter comme nouvelle question
        request_data.original_question = original_question  # Garder rÃ©fÃ©rence
        
        processing_steps.append("clarification_processed_successfully_with_age")
        ai_enhancements_used.append("breed_sex_age_extraction_complete")
        ai_enhancements_used.append("complete_question_enrichment")
        ai_enhancements_used.append("forced_question_replacement_with_age")
        
        return None  # Continuer le traitement normal avec question enrichie
    
    def _detect_performance_question_needing_clarification(
        self, question: str, language: str = "fr"
    ) -> Optional[Dict[str, Any]]:
        """DÃ©tection amÃ©liorÃ©e des questions techniques nÃ©cessitant race/sexe"""
        
        question_lower = question.lower()
        
        # Patterns de questions sur poids/performance avec Ã¢ge mais sans race/sexe
        weight_age_patterns = {
            "fr": [
                r'(?:poids|pÃ¨se)\s+.*?(\d+)\s*(?:jour|semaine)s?',
                r'(\d+)\s*(?:jour|semaine)s?.*?(?:poids|pÃ¨se)',
                r'(?:quel|combien)\s+.*?(?:poids|pÃ¨se).*?(\d+)',
                r'(?:croissance|dÃ©veloppement).*?(\d+)\s*(?:jour|semaine)',
                r'(\d+)\s*(?:jour|semaine).*?(?:normal|rÃ©fÃ©rence|standard)'
            ],
            "en": [
                r'(?:weight|weigh)\s+.*?(\d+)\s*(?:day|week)s?',
                r'(\d+)\s*(?:day|week)s?.*?(?:weight|weigh)',
                r'(?:what|how much)\s+.*?(?:weight|weigh).*?(\d+)',
                r'(?:growth|development).*?(\d+)\s*(?:day|week)',
                r'(\d+)\s*(?:day|week).*?(?:normal|reference|standard)'
            ],
            "es": [
                r'(?:peso|pesa)\s+.*?(\d+)\s*(?:dÃ­a|semana)s?',
                r'(\d+)\s*(?:dÃ­a|semana)s?.*?(?:peso|pesa)',
                r'(?:cuÃ¡l|cuÃ¡nto)\s+.*?(?:peso|pesa).*?(\d+)',
                r'(?:crecimiento|desarrollo).*?(\d+)\s*(?:dÃ­a|semana)',
                r'(\d+)\s*(?:dÃ­a|semana).*?(?:normal|referencia|estÃ¡ndar)'
            ]
        }
        
        patterns = weight_age_patterns.get(language, weight_age_patterns["fr"])
        
        # VÃ©rifier si c'est une question poids+Ã¢ge
        age_detected = None
        for pattern in patterns:
            match = re.search(pattern, question_lower)
            if match:
                age_detected = match.group(1)
                break
        
        if not age_detected:
            return None
        
        # VÃ©rifier si race/sexe sont ABSENTS
        breed_patterns = [
            r'\b(ross\s*308|ross\s*708|cobb\s*500|cobb\s*700|hubbard|arbor\s*acres)\b',
            r'\b(broiler|poulet|chicken|pollo)\s+(ross|cobb|hubbard)',
            r'\brace\s*[:\-]?\s*(ross|cobb|hubbard)'
        ]
        
        sex_patterns = [
            r'\b(mÃ¢le|male|macho)s?\b',
            r'\b(femelle|female|hembra)s?\b',
            r'\b(coq|hen|poule|gallina)\b',
            r'\b(mixte|mixed|misto)\b'
        ]
        
        has_breed = any(re.search(pattern, question_lower, re.IGNORECASE) for pattern in breed_patterns)
        has_sex = any(re.search(pattern, question_lower, re.IGNORECASE) for pattern in sex_patterns)
        
        # Clarification nÃ©cessaire si poids+Ã¢ge MAIS pas de race NI sexe
        if not has_breed and not has_sex:
            return {
                "type": "performance_question_missing_breed_sex",
                "age_detected": age_detected,
                "question_type": "weight_performance",
                "missing_info": ["breed", "sex"],
                "confidence": 0.95
            }
        
        # Clarification partielle si seulement un des deux manque
        elif not has_breed or not has_sex:
            missing = []
            if not has_breed:
                missing.append("breed")
            if not has_sex:
                missing.append("sex")
            
            return {
                "type": "performance_question_partial_info",
                "age_detected": age_detected,
                "question_type": "weight_performance", 
                "missing_info": missing,
                "confidence": 0.8
            }
        
        return None

    def _generate_performance_clarification_response(
        self, question: str, clarification_info: Dict, language: str, conversation_id: str
    ) -> EnhancedExpertResponse:
        """GÃ©nÃ¨re la demande de clarification optimisÃ©e"""
        
        age = clarification_info.get("age_detected", "X")
        missing_info = clarification_info.get("missing_info", [])
        
        # Messages de clarification par langue
        clarification_messages = {
            "fr": {
                "both_missing": f"Pour vous donner le poids de rÃ©fÃ©rence exact d'un poulet de {age} jours, j'ai besoin de :\n\nâ€¢ **Race/souche** : Ross 308, Cobb 500, Hubbard, etc.\nâ€¢ **Sexe** : MÃ¢les, femelles, ou troupeau mixte\n\nPouvez-vous prÃ©ciser ces informations ?",
                "breed_missing": f"Pour le poids exact Ã  {age} jours, quelle est la **race/souche** (Ross 308, Cobb 500, Hubbard, etc.) ?",
                "sex_missing": f"Pour le poids exact Ã  {age} jours, s'agit-il de **mÃ¢les, femelles, ou d'un troupeau mixte** ?"
            },
            "en": {
                "both_missing": f"To give you the exact reference weight for a {age}-day chicken, I need:\n\nâ€¢ **Breed/strain**: Ross 308, Cobb 500, Hubbard, etc.\nâ€¢ **Sex**: Males, females, or mixed flock\n\nCould you specify this information?",
                "breed_missing": f"For the exact weight at {age} days, what is the **breed/strain** (Ross 308, Cobb 500, Hubbard, etc.)?",
                "sex_missing": f"For the exact weight at {age} days, are these **males, females, or a mixed flock**?"
            },
            "es": {
                "both_missing": f"Para darle el peso de referencia exacto de un pollo de {age} dÃ­as, necesito:\n\nâ€¢ **Raza/cepa**: Ross 308, Cobb 500, Hubbard, etc.\nâ€¢ **Sexo**: Machos, hembras, o lote mixto\n\nÂ¿PodrÃ­a especificar esta informaciÃ³n?",
                "breed_missing": f"Para el peso exacto a los {age} dÃ­as, Â¿cuÃ¡l es la **raza/cepa** (Ross 308, Cobb 500, Hubbard, etc.)?",
                "sex_missing": f"Para el peso exacto a los {age} dÃ­as, Â¿son **machos, hembras, o un lote mixto**?"
            }
        }
        
        messages = clarification_messages.get(language, clarification_messages["fr"])
        
        # SÃ©lectionner le message appropriÃ©
        if len(missing_info) >= 2:
            response_text = messages["both_missing"]
        elif "breed" in missing_info:
            response_text = messages["breed_missing"]
        else:
            response_text = messages["sex_missing"]
        
        # Ajouter exemples de rÃ©ponse
        examples = {
            "fr": "\n\n**Exemples de rÃ©ponses :**\nâ€¢ \"Ross 308 mÃ¢les\"\nâ€¢ \"Cobb 500 femelles\"\nâ€¢ \"Hubbard troupeau mixte\"",
            "en": "\n\n**Example responses:**\nâ€¢ \"Ross 308 males\"\nâ€¢ \"Cobb 500 females\"\nâ€¢ \"Hubbard mixed flock\"",
            "es": "\n\n**Ejemplos de respuestas:**\nâ€¢ \"Ross 308 machos\"\nâ€¢ \"Cobb 500 hembras\"\nâ€¢ \"Hubbard lote mixto\""
        }
        
        response_text += examples.get(language, examples["fr"])
        
        return EnhancedExpertResponse(
            question=question,
            response=response_text,
            conversation_id=conversation_id,
            rag_used=False,
            rag_score=None,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=50,
            mode="smart_performance_clarification_corrected",
            user=None,
            logged=True,
            validation_passed=True,
            clarification_result={
                "clarification_requested": True,
                "clarification_type": "performance_breed_sex",
                "missing_information": missing_info,
                "age_detected": age,
                "confidence": clarification_info.get("confidence", 0.9)
            },
            processing_steps=["smart_clarification_triggered"],
            ai_enhancements_used=["performance_question_detection", "targeted_clarification"]
        )
    
    def _generate_follow_up_clarification(
        self, question: str, validation: Dict, language: str, conversation_id: str
    ) -> EnhancedExpertResponse:
        """GÃ©nÃ¨re une clarification de suivi si premiÃ¨re rÃ©ponse incomplÃ¨te"""
        
        still_missing = validation["still_missing"]
        
        messages = {
            "fr": {
                "breed": "Il me manque encore la **race/souche**. Ross 308, Cobb 500, ou autre ?",
                "sex": "Il me manque encore le **sexe**. MÃ¢les, femelles, ou troupeau mixte ?",  
                "both": "Il me manque encore la **race et le sexe**. Exemple : \"Ross 308 mÃ¢les\""
            },
            "en": {
                "breed": "I still need the **breed/strain**. Ross 308, Cobb 500, or other?",
                "sex": "I still need the **sex**. Males, females, or mixed flock?",
                "both": "I still need the **breed and sex**. Example: \"Ross 308 males\""
            },
            "es": {
                "breed": "AÃºn necesito la **raza/cepa**. Â¿Ross 308, Cobb 500, u otra?",
                "sex": "AÃºn necesito el **sexo**. Â¿Machos, hembras, o lote mixto?",
                "both": "AÃºn necesito la **raza y sexo**. Ejemplo: \"Ross 308 machos\""
            }
        }
        
        lang_messages = messages.get(language, messages["fr"])
        
        if len(still_missing) >= 2:
            message = lang_messages["both"]
        elif "breed" in still_missing:
            message = lang_messages["breed"]
        else:
            message = lang_messages["sex"]
        
        return EnhancedExpertResponse(
            question=question,
            response=message,
            conversation_id=conversation_id,
            rag_used=False,
            rag_score=None,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=30,
            mode="follow_up_clarification_corrected",
            user=None,
            logged=True,
            validation_passed=True,
            clarification_result={
                "clarification_requested": True,
                "clarification_type": "follow_up_incomplete",
                "still_missing_information": still_missing,
                "confidence": validation["confidence"]
            },
            processing_steps=["follow_up_clarification_triggered"],
            ai_enhancements_used=["incomplete_clarification_handling"]
        )
    
    # === MÃ‰THODES D'ENRICHISSEMENT COMPLET (INCHANGÃ‰ES) ===
    
    def _extract_age_from_original_question(self, original_question: str, language: str = "fr") -> Dict[str, Any]:
        """Extrait l'Ã¢ge depuis la question originale"""
        
        age_info = {"days": None, "weeks": None, "text": None, "detected": False}
        
        if not original_question:
            return age_info
        
        question_lower = original_question.lower()
        
        # Patterns d'extraction d'Ã¢ge multilingues
        age_patterns = {
            "fr": [
                (r'(\d+)\s*jours?', "days"),
                (r'(\d+)\s*semaines?', "weeks"),
                (r'de\s+(\d+)\s*jours?', "days"),
                (r'de\s+(\d+)\s*semaines?', "weeks"),
                (r'Ã \s+(\d+)\s*jours?', "days"),
                (r'Ã \s+(\d+)\s*semaines?', "weeks")
            ],
            "en": [
                (r'(\d+)\s*days?', "days"),
                (r'(\d+)\s*weeks?', "weeks"),
                (r'of\s+(\d+)\s*days?', "days"),
                (r'of\s+(\d+)\s*weeks?', "weeks"),
                (r'at\s+(\d+)\s*days?', "days"),
                (r'at\s+(\d+)\s*weeks?', "weeks")
            ],
            "es": [
                (r'(\d+)\s*dÃ­as?', "days"),
                (r'(\d+)\s*semanas?', "weeks"),
                (r'de\s+(\d+)\s*dÃ­as?', "days"),
                (r'de\s+(\d+)\s*semanas?', "weeks"),
                (r'a\s+(\d+)\s*dÃ­as?', "days"),
                (r'a\s+(\d+)\s*semanas?', "weeks")
            ]
        }
        
        patterns = age_patterns.get(language, age_patterns["fr"])
        
        for pattern, unit in patterns:
            match = re.search(pattern, question_lower, re.IGNORECASE)
            if match:
                value = int(match.group(1))
                
                if unit == "days":
                    age_info["days"] = value
                    age_info["weeks"] = round(value / 7, 1)
                    age_info["text"] = f"{value} jour{'s' if value > 1 else ''}"
                else:  # weeks
                    age_info["weeks"] = value
                    age_info["days"] = value * 7
                    age_info["text"] = f"{value} semaine{'s' if value > 1 else ''}"
                
                age_info["detected"] = True
                
                logger.info(f"ðŸ• [Age Extraction] Ã‚ge dÃ©tectÃ©: {age_info['text']} ({age_info['days']} jours)")
                break
        
        if not age_info["detected"]:
            logger.warning(f"âš ï¸ [Age Extraction] Aucun Ã¢ge dÃ©tectÃ© dans: {original_question}")
        
        return age_info

    def _build_complete_enriched_question(
        self, 
        original_question: str, 
        breed: Optional[str], 
        sex: Optional[str], 
        age_info: Dict[str, Any], 
        language: str = "fr"
    ) -> str:
        """Construit une question complÃ¨tement enrichie"""
        
        # Templates d'enrichissement complet par langue
        templates = {
            "fr": {
                "complete": "Pour des poulets {breed} {sex} de {age}",
                "breed_age": "Pour des poulets {breed} de {age}",
                "sex_age": "Pour des poulets {sex} de {age}",
                "breed_sex": "Pour des poulets {breed} {sex}",
                "age_only": "Pour des poulets de {age}",
                "breed_only": "Pour des poulets {breed}",
                "sex_only": "Pour des poulets {sex}"
            },
            "en": {
                "complete": "For {breed} {sex} chickens at {age}",
                "breed_age": "For {breed} chickens at {age}",
                "sex_age": "For {sex} chickens at {age}",
                "breed_sex": "For {breed} {sex} chickens",
                "age_only": "For chickens at {age}",
                "breed_only": "For {breed} chickens",
                "sex_only": "For {sex} chickens"
            },
            "es": {
                "complete": "Para pollos {breed} {sex} de {age}",
                "breed_age": "Para pollos {breed} de {age}",
                "sex_age": "Para pollos {sex} de {age}",
                "breed_sex": "Para pollos {breed} {sex}",
                "age_only": "Para pollos de {age}",
                "breed_only": "Para pollos {breed}",
                "sex_only": "Para pollos {sex}"
            }
        }
        
        template_set = templates.get(language, templates["fr"])
        
        # Construire le prÃ©fixe contextuel avec prioritÃ© Ã  l'Ã¢ge
        context_prefix = ""
        age_text = age_info.get("text") if age_info.get("detected") else None
        
        # PRIORITÃ‰ Ã€ L'ENRICHISSEMENT COMPLET
        if breed and sex and age_text:
            context_prefix = template_set["complete"].format(
                breed=breed, sex=sex, age=age_text
            )
            logger.info(f"ðŸŒŸ [Complete Enrichment] Contexte COMPLET: {context_prefix}")
            
        elif breed and age_text:
            context_prefix = template_set["breed_age"].format(
                breed=breed, age=age_text
            )
            logger.info(f"ðŸ·ï¸ [Breed+Age] Contexte: {context_prefix}")
            
        elif sex and age_text:
            context_prefix = template_set["sex_age"].format(
                sex=sex, age=age_text
            )
            logger.info(f"âš§ [Sex+Age] Contexte: {context_prefix}")
            
        elif breed and sex:
            context_prefix = template_set["breed_sex"].format(
                breed=breed, sex=sex
            )
            logger.info(f"ðŸ·ï¸âš§ [Breed+Sex] Contexte: {context_prefix}")
            
        elif age_text:
            context_prefix = template_set["age_only"].format(age=age_text)
            logger.info(f"ðŸ• [Age Only] Contexte: {context_prefix}")
            
        elif breed:
            context_prefix = template_set["breed_only"].format(breed=breed)
            logger.info(f"ðŸ·ï¸ [Breed Only] Contexte: {context_prefix}")
            
        elif sex:
            context_prefix = template_set["sex_only"].format(sex=sex)
            logger.info(f"âš§ [Sex Only] Contexte: {context_prefix}")
        
        # Construire la question finale enrichie
        if context_prefix:
            # DÃ©tecter le type de question originale pour intÃ©gration naturelle
            original_lower = original_question.lower().strip()
            
            if "quel est" in original_lower or "what is" in original_lower or "cuÃ¡l es" in original_lower:
                # Questions directes â†’ prÃ©fixer
                enriched_question = f"{context_prefix}, {original_lower}"
            elif "comment" in original_lower or "how" in original_lower or "cÃ³mo" in original_lower:
                # Questions de mÃ©thode â†’ deux points
                enriched_question = f"{context_prefix}: {original_question}"
            else:
                # Autres questions â†’ deux points
                enriched_question = f"{context_prefix}: {original_question}"
            
            logger.info(f"âœ¨ [Final Enrichment] Question finale: {enriched_question}")
            return enriched_question
        
        else:
            logger.warning("âš ï¸ [Enrichment] Pas d'enrichissement possible, question originale conservÃ©e")
            return original_question
    
    # === TRAITEMENT EXPERT AVEC RAG-FIRST + AMÃ‰LIORATIONS CORRIGÃ‰ ===
    
    async def _process_expert_response_enhanced_corrected(
        self, question_text: str, request_data: EnhancedQuestionRequest,
        request: Request, current_user: Optional[Dict], conversation_id: str,
        processing_steps: list, ai_enhancements_used: list,
        debug_info: Dict, performance_breakdown: Dict, vagueness_result = None
    ) -> Dict[str, Any]:
        """Version RAG parfaitement corrigÃ©e avec mÃ©moire intelligente"""
        
        # === 1. RÃ‰CUPÃ‰RATION FORCÃ‰E DU CONTEXTE CONVERSATIONNEL ===
        conversation_context_str = ""
        extracted_entities = {}
        
        if self.integrations.intelligent_memory_available:
            try:
                # RÃ©cupÃ©ration forcÃ©e du contexte depuis la mÃ©moire intelligente
                context_obj = self.integrations.get_conversation_context(conversation_id)
                if context_obj:
                    conversation_context_str = context_obj.get_context_for_rag(max_chars=800)
                    
                    # Enrichissement spÃ©cial si clarification
                    if request_data.is_clarification_response or request_data.original_question:
                        # Ajouter explicitement le contexte de clarification
                        if request_data.original_question:
                            conversation_context_str = f"Question originale: {request_data.original_question}. " + conversation_context_str
                        
                        # Rechercher les infos breed/sex dans les messages rÃ©cents
                        if hasattr(context_obj, 'messages'):
                            for msg in reversed(context_obj.messages[-5:]):
                                if msg.role == "user" and any(word in msg.message.lower() for word in ["ross", "cobb", "hubbard", "mÃ¢le", "femelle", "male", "female"]):
                                    conversation_context_str += f" | Clarification: {msg.message}"
                                    break
                    
                    # EntitÃ©s consolidÃ©es
                    if hasattr(context_obj, 'consolidated_entities'):
                        extracted_entities = context_obj.consolidated_entities.to_dict()
                    
                    logger.info(f"ðŸ§  [Expert Service] Contexte enrichi rÃ©cupÃ©rÃ©: {conversation_context_str[:150]}...")
                    ai_enhancements_used.append("intelligent_memory_context_retrieval")
                else:
                    logger.warning(f"âš ï¸ [Expert Service] Aucun contexte trouvÃ© pour: {conversation_id}")
                    
            except Exception as e:
                logger.error(f"âŒ [Expert Service] Erreur rÃ©cupÃ©ration contexte: {e}")
        
        performance_breakdown["context_retrieved"] = int(time.time() * 1000)
        
        # === 2. AMÃ‰LIORATION INTELLIGENTE DE LA QUESTION ===
        enriched_question, enhancement_info = self.rag_enhancer.enhance_question_for_rag(
            question=question_text,
            conversation_context=conversation_context_str,
            language=request_data.language
        )
        
        # Enrichissement supplÃ©mentaire si vient d'une clarification
        if request_data.original_question and request_data.is_clarification_response:
            logger.info(f"âœ¨ [Expert Service] Question dÃ©jÃ  enrichie par clarification: {question_text[:100]}...")
            ai_enhancements_used.append("clarification_based_enrichment")
        
        if enhancement_info["question_enriched"]:
            ai_enhancements_used.append("intelligent_question_enhancement")
            logger.info(f"âœ¨ [Expert Service] Question amÃ©liorÃ©e: {enriched_question[:150]}...")
        
        if enhancement_info["pronoun_detected"]:
            ai_enhancements_used.append("contextual_pronoun_resolution")
            logger.info(f"ðŸŽ¯ [Expert Service] Pronoms contextuels rÃ©solus: {enhancement_info['context_entities_used']}")
        
        processing_steps.append("intelligent_question_enhancement")
        performance_breakdown["question_enhanced"] = int(time.time() * 1000)
        
        # === 3. VÃ‰RIFICATION RAG DISPONIBLE ===
        app = request.app
        process_rag = getattr(app.state, 'process_question_with_rag', None)
        
        if not process_rag:
            logger.error("âŒ [Expert Service] SystÃ¨me RAG indisponible - Erreur critique")
            raise HTTPException(
                status_code=503, 
                detail="Service RAG indisponible - Le systÃ¨me expert nÃ©cessite l'accÃ¨s Ã  la base documentaire"
            )
        
        # === 4. APPEL RAG AVEC CONTEXTE FORCÃ‰ ===
        try:
            logger.info("ðŸ” [Expert Service] Appel RAG avec contexte intelligent...")
            
            if request_data.debug_mode:
                debug_info["original_question"] = question_text
                debug_info["enriched_question"] = enriched_question
                debug_info["conversation_context"] = conversation_context_str
                debug_info["enhancement_info"] = enhancement_info
            
            # StratÃ©gie multi-tentative pour RAG avec contexte
            result = None
            rag_call_method = "unknown"
            
            # ðŸŽ¯ NOUVEAU: Construire prompt structurÃ© avec contexte
            rag_context = extract_context_from_entities(extracted_entities)
            rag_context["lang"] = request_data.language
            
            # Tentative 1: Avec paramÃ¨tre context si supportÃ©
            try:
                # ðŸŽ¯ Appliquer prompt structurÃ©
                structured_question = build_structured_prompt(
                    documents="[DOCUMENTS_WILL_BE_INSERTED_BY_RAG]",
                    question=enriched_question,
                    context=rag_context
                )
                
                # ðŸ“Š LOGGING: Debug du prompt final
                logger.debug(f"ðŸ” [Prompt Final RAG] Contexte: {rag_context}")
                logger.debug(f"ðŸ” [Prompt Final RAG]\n{structured_question[:500]}...")
                
                result = await process_rag(
                    question=structured_question,
                    user=current_user,
                    language=request_data.language,
                    speed_mode=request_data.speed_mode,
                    context=conversation_context_str
                )
                rag_call_method = "context_parameter_structured"
                logger.info("âœ… [Expert Service] RAG appelÃ© avec prompt structurÃ© + contexte")
            except TypeError as te:
                logger.info(f"â„¹ï¸ [Expert Service] ParamÃ¨tre context non supportÃ©: {te}")
                
                # Tentative 2: Injection du contexte dans la question
                if conversation_context_str:
                    structured_question = build_structured_prompt(
                        documents="[DOCUMENTS_WILL_BE_INSERTED_BY_RAG]",
                        question=enriched_question,
                        context=rag_context
                    )
                    
                    # ðŸ“Š LOGGING: Debug du prompt injectÃ©
                    logger.debug(f"ðŸ” [Prompt Final RAG - InjectÃ©]\n{structured_question[:500]}...")
                    
                    contextual_question = f"{structured_question}\n\nContexte: {conversation_context_str}"
                    result = await process_rag(
                        question=contextual_question,
                        user=current_user,
                        language=request_data.language,
                        speed_mode=request_data.speed_mode
                    )
                    rag_call_method = "context_injected_structured"
                    logger.info("âœ… [Expert Service] RAG appelÃ© avec prompt structurÃ© + contexte injectÃ©")
                else:
                    # Tentative 3: Question enrichie avec prompt structurÃ©
                    structured_question = build_structured_prompt(
                        documents="[DOCUMENTS_WILL_BE_INSERTED_BY_RAG]",
                        question=enriched_question,
                        context=rag_context
                    )
                    
                    # ðŸ“Š LOGGING: Debug du prompt seul
                    logger.debug(f"ðŸ” [Prompt Final RAG - Seul]\n{structured_question[:500]}...")
                    
                    result = await process_rag(
                        question=structured_question,
                        user=current_user,
                        language=request_data.language,
                        speed_mode=request_data.speed_mode
                    )
                    rag_call_method = "structured_only"
                    logger.info("âœ… [Expert Service] RAG appelÃ© avec prompt structurÃ© seul")
            
            performance_breakdown["rag_complete"] = int(time.time() * 1000)
            
            # === 5. TRAITEMENT RÃ‰SULTAT RAG ===
            answer = str(result.get("response", ""))
            
            # ðŸ§¹ IMPORTANT: Ici on ne nettoie que les rÃ©fÃ©rences documents
            # La concision sera appliquÃ©e plus tard dans le processus principal
            answer = self.concision_processor._clean_document_references_only(answer)
            
            rag_score = result.get("score", 0.0)
            original_mode = result.get("mode", "rag_processing")
            
            # Validation qualitÃ©
            quality_check = self._validate_rag_response_quality(
                answer, enriched_question, enhancement_info
            )
            
            if not quality_check["valid"]:
                logger.warning(f"âš ï¸ [Expert Service] QualitÃ© RAG insuffisante: {quality_check['reason']}")
                ai_enhancements_used.append("quality_validation_failed")
            
            logger.info(f"âœ… [Expert Service] RAG rÃ©ponse reÃ§ue: {len(answer)} caractÃ¨res, score: {rag_score}")
            
            # Mode enrichi avec mÃ©thode d'appel
            mode = f"enhanced_contextual_{original_mode}_{rag_call_method}_corrected_with_concision"
            
            processing_steps.append("mandatory_rag_with_intelligent_context")
            
            return {
                "answer": answer,
                "rag_used": True,
                "rag_score": rag_score,
                "mode": mode,
                "context_used": bool(conversation_context_str),
                "question_enriched": enhancement_info["question_enriched"] or bool(request_data.original_question),
                "enhancement_info": enhancement_info,
                "quality_check": quality_check,
                "extracted_entities": extracted_entities,
                "rag_call_method": rag_call_method
            }
            
        except Exception as rag_error:
            logger.error(f"âŒ [Expert Service] Erreur critique RAG: {rag_error}")
            processing_steps.append("rag_error")
            
            error_details = {
                "error": "Erreur RAG",
                "message": "Impossible d'interroger la base documentaire",
                "question_original": question_text,
                "question_enriched": enriched_question,
                "context_available": bool(conversation_context_str),
                "technical_error": str(rag_error)
            }
            
            raise HTTPException(status_code=503, detail=error_details)
    
    # === MÃ‰THODES UTILITAIRES AVEC CONCISION ===
    
    def _create_vagueness_response(
        self, vagueness_result, question_text: str, conversation_id: str,
        language: str, start_time: float, processing_steps: list, ai_enhancements_used: list
    ) -> EnhancedExpertResponse:
        """CrÃ©e une rÃ©ponse spÃ©cialisÃ©e pour questions floues"""
        
        clarification_messages = {
            "fr": f"Votre question semble manquer de prÃ©cision. {vagueness_result.suggested_clarification or 'Pouvez-vous Ãªtre plus spÃ©cifique ?'}",
            "en": f"Your question seems to lack precision. {vagueness_result.suggested_clarification or 'Could you be more specific?'}",
            "es": f"Su pregunta parece carecer de precisiÃ³n. {vagueness_result.suggested_clarification or 'Â¿PodrÃ­a ser mÃ¡s especÃ­fico?'}"
        }
        
        response_message = clarification_messages.get(language, clarification_messages["fr"])
        
        # Ajouter des exemples de questions
        if vagueness_result.question_clarity in ["very_unclear", "unclear"]:
            examples = {
                "fr": "\n\nExemples de questions prÃ©cises:\nâ€¢ Quel est le poids normal d'un Ross 308 de 21 jours?\nâ€¢ Comment traiter la mortalitÃ© Ã©levÃ©e chez des poulets de 3 semaines?\nâ€¢ Quelle tempÃ©rature maintenir pour des poussins de 7 jours?",
                "en": "\n\nExamples of precise questions:\nâ€¢ What is the normal weight of a 21-day Ross 308?\nâ€¢ How to treat high mortality in 3-week-old chickens?\nâ€¢ What temperature to maintain for 7-day chicks?",
                "es": "\n\nEjemplos de preguntas precisas:\nâ€¢ Â¿CuÃ¡l es el peso normal de un Ross 308 de 21 dÃ­as?\nâ€¢ Â¿CÃ³mo tratar la alta mortalidad en pollos de 3 semanas?\nâ€¢ Â¿QuÃ© temperatura mantener para pollitos de 7 dÃ­as?"
            }
            response_message += examples.get(language, examples["fr"])
        
        response_time_ms = int((time.time() - start_time) * 1000)
        
        return EnhancedExpertResponse(
            question=question_text,
            response=response_message,
            conversation_id=conversation_id,
            rag_used=False,
            rag_score=None,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=response_time_ms,
            mode="vagueness_clarification",
            user=None,
            logged=True,
            validation_passed=True,
            vagueness_detection=vagueness_result,
            processing_steps=processing_steps,
            ai_enhancements_used=ai_enhancements_used
        )
    
    def _build_final_enhanced_response(
        self, question_text: str, answer: str, conversation_id: str,
        user_email: Optional[str], language: str, response_time_ms: int,
        expert_result: Dict, validation_result: ValidationResult,
        conversation_context: Any, processing_steps: list,
        ai_enhancements_used: list, request_data: EnhancedQuestionRequest,
        debug_info: Dict, performance_breakdown: Dict
    ) -> EnhancedExpertResponse:
        """Construit la rÃ©ponse finale avec toutes les amÃ©liorations + concision"""
        
        # MÃ©triques finales
        extracted_entities = expert_result.get("extracted_entities")
        confidence_overall = None
        conversation_state = None
        
        if conversation_context and hasattr(conversation_context, 'consolidated_entities'):
            if not extracted_entities:
                extracted_entities = conversation_context.consolidated_entities.to_dict()
            confidence_overall = conversation_context.consolidated_entities.confidence_overall
            conversation_state = conversation_context.conversation_urgency
        
        # Informations de debug si activÃ©es
        final_debug_info = None
        final_performance = None
        
        if request_data.debug_mode:
            final_debug_info = {
                **debug_info,
                "total_processing_time_ms": response_time_ms,
                "ai_enhancements_count": len(ai_enhancements_used),
                "processing_steps_count": len(processing_steps),
                "concision_applied": expert_result.get("concision_applied", False)
            }
            
            final_performance = performance_breakdown
        
        # ðŸ†• Informations de concision dans la rÃ©ponse
        concision_info = {
            "concision_applied": expert_result.get("concision_applied", False),
            "original_response_available": "original_answer" in expert_result,
            "detected_question_type": None,
            "applied_concision_level": None
        }
        
        if expert_result.get("concision_applied"):
            concision_info["detected_question_type"] = self.concision_processor.detect_question_type(question_text)
            concision_info["applied_concision_level"] = self.concision_processor.detect_optimal_concision_level(question_text).value
            
        return EnhancedExpertResponse(
            # Champs existants
            question=str(question_text),
            response=str(answer),
            conversation_id=conversation_id,
            rag_used=expert_result["rag_used"],
            rag_score=expert_result["rag_score"],
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=response_time_ms,
            mode=expert_result["mode"],
            user=user_email,
            logged=True,
            validation_passed=True,
            validation_confidence=validation_result.confidence,
            reprocessed_after_clarification=request_data.is_clarification_response,
            conversation_state=conversation_state,
            extracted_entities=extracted_entities,
            confidence_overall=confidence_overall,
            processing_steps=processing_steps,
            ai_enhancements_used=ai_enhancements_used,
            
            # Nouvelles fonctionnalitÃ©s
            document_relevance=expert_result.get("document_relevance"),
            context_coherence=expert_result.get("context_coherence"),
            vagueness_detection=None,
            fallback_details=None,
            response_format_applied=request_data.expected_response_format.value,
            quality_metrics=expert_result.get("quality_metrics"),
            debug_info=final_debug_info,
            performance_breakdown=final_performance,
            
            # ðŸ†• NOUVEAU: Informations de concision
            concision_info=concision_info,
            original_response=expert_result.get("original_answer")  # RÃ©ponse originale si concision appliquÃ©e
        )
    
    # === MÃ‰THODES UTILITAIRES IDENTIQUES ===
    
    def _extract_user_id(self, current_user: Optional[Dict], request_data: EnhancedQuestionRequest, request: Request) -> str:
        if current_user:
            return current_user.get("user_id") or request_data.user_id or "authenticated_user"
        return request_data.user_id or get_user_id_from_request(request)
    
    def _get_or_create_conversation_id(self, request_data: EnhancedQuestionRequest) -> str:
        if request_data.conversation_id and request_data.conversation_id.strip():
            conversation_id = request_data.conversation_id.strip()
            logger.info(f"ðŸ”„ [Expert Service] CONTINUATION: {conversation_id}")
            return conversation_id
        else:
            conversation_id = str(uuid.uuid4())
            logger.info(f"ðŸ†• [Expert Service] NOUVELLE: {conversation_id}")
            return conversation_id
    
    def _validate_rag_response_quality(
        self, answer: str, enriched_question: str, enhancement_info: Dict
    ) -> Dict[str, any]:
        """Valide la qualitÃ© de la rÃ©ponse RAG"""
        
        if not answer or len(answer.strip()) < 20:
            return {
                "valid": False,
                "reason": "RÃ©ponse trop courte",
                "answer_length": len(answer) if answer else 0
            }
        
        negative_responses = [
            "je ne sais pas", "i don't know", "no sÃ©",
            "pas d'information", "no information", "sin informaciÃ³n"
        ]
        
        answer_lower = answer.lower()
        for negative in negative_responses:
            if negative in answer_lower:
                return {
                    "valid": False,
                    "reason": f"RÃ©ponse nÃ©gative dÃ©tectÃ©e: {negative}",
                    "answer_length": len(answer)
                }
        
        if any(word in enriched_question.lower() for word in ["poids", "weight", "peso"]):
            if not re.search(r'\d+', answer):
                return {
                    "valid": False,
                    "reason": "Question numÃ©rique mais pas de chiffres dans la rÃ©ponse",
                    "answer_length": len(answer)
                }
        
        return {
            "valid": True,
            "reason": "RÃ©ponse valide",
            "answer_length": len(answer)
        }
    
    # Autres mÃ©thodes (validation, feedback, etc.) identiques...
    async def _validate_agricultural_question(self, question: str, language: str, user_id: str, request_ip: str, conversation_id: str) -> ValidationResult:
        if not self.integrations.agricultural_validator_available:
            return ValidationResult(is_valid=False, rejection_message="Service temporairement indisponible")
        
        try:
            enriched_question = question
            if self.integrations.intelligent_memory_available:
                try:
                    rag_context = self.integrations.get_context_for_rag(conversation_id)
                    if rag_context:
                        enriched_question = f"{question}\n\nContexte: {rag_context}"
                except Exception:
                    pass
            
            validation_result = self.integrations.validate_agricultural_question(
                question=enriched_question, language=language, user_id=user_id, request_ip=request_ip
            )
            
            return ValidationResult(
                is_valid=validation_result.is_valid,
                rejection_message=validation_result.reason or "Question hors domaine agricole",
                confidence=validation_result.confidence
            )
            
        except Exception as e:
            logger.error(f"âŒ [Expert Service] Erreur validateur: {e}")
            return ValidationResult(is_valid=False, rejection_message="Erreur de validation")
    
    def _create_rejection_response(self, question_text, validation_result, conversation_id, user_email, language, start_time, processing_steps, ai_enhancements_used, vagueness_result=None):
        response_time_ms = int((time.time() - start_time) * 1000)
        
        return EnhancedExpertResponse(
            question=str(question_text),
            response=str(validation_result.rejection_message),
            conversation_id=conversation_id,
            rag_used=False,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=response_time_ms,
            mode="enhanced_agricultural_validation_rejected",
            user=user_email,
            logged=True,
            validation_passed=False,
            validation_confidence=validation_result.confidence,
            processing_steps=processing_steps,
            ai_enhancements_used=ai_enhancements_used,
            vagueness_detection=vagueness_result
        )
    
    async def process_feedback(self, feedback_data: FeedbackRequest) -> Dict[str, Any]:
        feedback_updated = False
        
        if feedback_data.conversation_id and self.integrations.logging_available:
            try:
                rating_numeric = {"positive": 1, "negative": -1, "neutral": 0}.get(feedback_data.rating, 0)
                feedback_updated = await self.integrations.update_feedback(feedback_data.conversation_id, rating_numeric)
            except Exception as e:
                logger.error(f"âŒ [Expert Service] Erreur feedback: {e}")
        
        return {
            "success": True,
            "message": "Feedback enregistrÃ© avec succÃ¨s (Enhanced + Concision)",
            "rating": feedback_data.rating,
            "comment": feedback_data.comment,
            "conversation_id": feedback_data.conversation_id,
            "feedback_updated_in_db": feedback_updated,
            "enhanced_features_used": True,
            "concision_system_active": self.concision_processor.config.ENABLE_CONCISE_RESPONSES,
            "timestamp": datetime.now().isoformat()
        }
    
    async def get_suggested_topics(self, language: str) -> Dict[str, Any]:
        lang = language.lower() if language else "fr"
        if lang not in ["fr", "en", "es"]:
            lang = "fr"
        
        topics_by_language = get_enhanced_topics_by_language()
        topics = topics_by_language.get(lang, topics_by_language["fr"])
        
        return {
            "topics": topics,
            "language": lang,
            "count": len(topics),
            "enhanced_features": {
                "vagueness_detection_available": True,
                "context_coherence_available": True,
                "detailed_rag_scoring_available": True,
                "quality_metrics_available": True,
                "smart_clarification_available": True,
                "intelligent_memory_available": self.integrations.intelligent_memory_available,
                
                # ðŸ†• NOUVEAU: Informations systÃ¨me de concision
                "response_concision_available": True,
                "concision_levels": [level.value for level in ConcisionLevel],
                "auto_concision_detection": True,
                "concision_enabled": self.concision_processor.config.ENABLE_CONCISE_RESPONSES
            },
            "system_status": {
                "validation_enabled": self.integrations.is_agricultural_validation_enabled(),
                "enhanced_clarification_enabled": self.integrations.is_enhanced_clarification_enabled(),
                "intelligent_memory_enabled": self.integrations.intelligent_memory_available,
                "api_enhancements_enabled": True,
                "concision_processor_enabled": True
            },
            
            # ðŸ†• NOUVEAU: Configuration concision par dÃ©faut
            "concision_config": {
                "default_level": self.concision_processor.config.DEFAULT_CONCISION_LEVEL.value,
                "auto_detect_enabled": True,
                "max_lengths": self.concision_processor.config.MAX_RESPONSE_LENGTH,
                "ultra_concise_keywords": self.concision_processor.config.ULTRA_CONCISE_KEYWORDS,
                "complex_keywords": self.concision_processor.config.COMPLEX_KEYWORDS
            }
        }

# =============================================================================
# ðŸ†• API ENDPOINT POUR CONTRÃ”LER LA CONCISION (OPTIONNEL)
# =============================================================================

# Cette fonction peut Ãªtre ajoutÃ©e Ã  votre router expert pour permettre 
# le contrÃ´le dynamique de la concision

def create_concision_control_endpoint():
    """
    Endpoint optionnel pour contrÃ´ler la concision cÃ´tÃ© backend
    (Ã  ajouter dans votre router expert si souhaitÃ©)
    """
    
    from fastapi import APIRouter
    from pydantic import BaseModel
    
    router = APIRouter()
    
    class ConcisionSettingsRequest(BaseModel):
        enabled: bool = True
        default_level: ConcisionLevel = ConcisionLevel.CONCISE
        max_lengths: Optional[Dict[str, int]] = None
    
    class ConcisionSettingsResponse(BaseModel):
        success: bool
        current_settings: Dict[str, Any]
        message: str
    
    @router.post("/concision/settings", response_model=ConcisionSettingsResponse)
    async def update_concision_settings(request: ConcisionSettingsRequest):
        """Mettre Ã  jour les paramÃ¨tres de concision du systÃ¨me"""
        
        try:
            # Mettre Ã  jour la configuration globale
            ConcisionConfig.ENABLE_CONCISE_RESPONSES = request.enabled
            ConcisionConfig.DEFAULT_CONCISION_LEVEL = request.default_level
            
            if request.max_lengths:
                ConcisionConfig.MAX_RESPONSE_LENGTH.update(request.max_lengths)
            
            return ConcisionSettingsResponse(
                success=True,
                current_settings={
                    "enabled": ConcisionConfig.ENABLE_CONCISE_RESPONSES,
                    "default_level": ConcisionConfig.DEFAULT_CONCISION_LEVEL.value,
                    "max_lengths": ConcisionConfig.MAX_RESPONSE_LENGTH
                },
                message="ParamÃ¨tres de concision mis Ã  jour avec succÃ¨s"
            )
        except Exception as e:
            return ConcisionSettingsResponse(
                success=False,
                current_settings={},
                message=f"Erreur lors de la mise Ã  jour: {str(e)}"
            )
    
    @router.get("/concision/settings", response_model=Dict[str, Any])
    async def get_concision_settings():
        """RÃ©cupÃ©rer les paramÃ¨tres actuels de concision"""
        
        return {
            "enabled": ConcisionConfig.ENABLE_CONCISE_RESPONSES,
            "default_level": ConcisionConfig.DEFAULT_CONCISION_LEVEL.value,
            "available_levels": [level.value for level in ConcisionLevel],
            "max_lengths": ConcisionConfig.MAX_RESPONSE_LENGTH,
            "ultra_concise_keywords": ConcisionConfig.ULTRA_CONCISE_KEYWORDS,
            "complex_keywords": ConcisionConfig.COMPLEX_KEYWORDS
        }
    
    return router

# =============================================================================
# CONFIGURATION FINALE AVEC CONCISION
# =============================================================================

logger.info("âœ… [Expert Service] Services mÃ©tier EXPERT SYSTEM + SYSTÃˆME DE CONCISION intÃ©grÃ©")
logger.info("ðŸš€ [Expert Service] NOUVELLES FONCTIONNALITÃ‰S:")
logger.info("   - âœ… SystÃ¨me de concision intelligent multi-niveaux")
logger.info("   - âœ… DÃ©tection automatique type de question")
logger.info("   - âœ… Nettoyage avancÃ© verbositÃ© + rÃ©fÃ©rences documents")
logger.info("   - âœ… Configuration flexible par type de question")
logger.info("   - âœ… Conservation rÃ©ponse originale si concision appliquÃ©e")
logger.info("ðŸ”§ [Expert Service] FONCTIONNALITÃ‰S CONSERVÃ‰ES:")
logger.info("   - âœ… SystÃ¨me de clarification intelligent complet")
logger.info("   - âœ… MÃ©moire conversationnelle enrichie")
logger.info("   - âœ… RAG avec contexte et prompt structurÃ©")
logger.info("   - âœ… Multi-LLM support et validation agricole")
logger.info("   - âœ… Support multilingue FR/EN/ES")
logger.info("ðŸŽ¯ [Expert Service] RÃ‰SULTAT ATTENDU:")
logger.info('   - Question: "Quel est le poids d\'un poulet Ross 308 mÃ¢le de 18 jours ?"')
logger.info('   - RÃ©ponse ultra-concise: "410-450g"')
logger.info('   - RÃ©ponse concise: "Le poids se situe entre 410g et 450g."')
logger.info('   - RÃ©ponse standard: Normale sans conseils excessifs')
logger.info('   - RÃ©ponse dÃ©taillÃ©e: Version complÃ¨te actuelle')
logger.info("âœ… [Expert Service] SYSTÃˆME DE CONCISION PARFAITEMENT INTÃ‰GRÃ‰!")