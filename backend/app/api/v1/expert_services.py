"""
expert_services.py - CONTEXTE CONVERSATIONNEL + API RAG CORRIGÃ‰E
ğŸ¯ SOLUTION DOUBLE: MÃ©moire conversation + API RAG native

Flux: Question â†’ RÃ©cupÃ©ration contexte â†’ Fusion entitÃ©s â†’ RAG â†’ RÃ©ponse prÃ©cise
"""

import logging
import time
import re
from typing import Dict, Any, Optional, List
from datetime import datetime
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ProcessingResult:
    """RÃ©sultat de traitement simplifiÃ©"""
    success: bool
    response: str
    response_type: str
    confidence: float
    processing_time_ms: int
    rag_used: bool = False
    rag_results: List[Dict] = None
    error: Optional[str] = None
    clarification_questions: List[str] = None
    missing_context: List[str] = None
    
    def __post_init__(self):
        if self.rag_results is None:
            self.rag_results = []
        if self.clarification_questions is None:
            self.clarification_questions = []
        if self.missing_context is None:
            self.missing_context = []

class ConversationMemory:
    """MÃ©moire conversationnelle simple et efficace"""
    
    def __init__(self):
        self.conversations = {}
        logger.info("ğŸ§  [Memory] MÃ©moire conversationnelle initialisÃ©e")
    
    def store_context(self, conversation_id: str, entities: Dict[str, Any], question: str):
        """Stocke le contexte d'une conversation"""
        if not conversation_id:
            return
            
        if conversation_id not in self.conversations:
            self.conversations[conversation_id] = {
                "entities": {},
                "questions": [],
                "created_at": datetime.now()
            }
        
        # Fusion intelligente des entitÃ©s
        stored_entities = self.conversations[conversation_id]["entities"]
        for key, value in entities.items():
            if value is not None:
                stored_entities[key] = value
        
        # Ajout de la question
        self.conversations[conversation_id]["questions"].append({
            "text": question,
            "entities": entities.copy(),
            "timestamp": datetime.now()
        })
        
        logger.info(f"ğŸ§  [Memory] Contexte stockÃ© pour {conversation_id}: {stored_entities}")
    
    def get_context(self, conversation_id: str) -> Dict[str, Any]:
        """RÃ©cupÃ¨re le contexte d'une conversation"""
        if not conversation_id or conversation_id not in self.conversations:
            return {}
        
        context = self.conversations[conversation_id]["entities"]
        logger.info(f"ğŸ§  [Memory] Contexte rÃ©cupÃ©rÃ© pour {conversation_id}: {context}")
        return context
    
    def get_enriched_question(self, conversation_id: str, current_question: str) -> str:
        """Enrichit la question actuelle avec le contexte"""
        context = self.get_context(conversation_id)
        if not context:
            return current_question
        
        # Construction de la question enrichie
        enriched_parts = [current_question]
        
        if context.get("race"):
            enriched_parts.append(context["race"])
        if context.get("sexe"):
            enriched_parts.append(context["sexe"])
        if context.get("age"):
            enriched_parts.append(context["age"])
        
        enriched_question = " ".join(enriched_parts)
        logger.info(f"ğŸ”— [Context] Question enrichie: '{current_question}' â†’ '{enriched_question}'")
        return enriched_question

class ExpertService:
    """Service Expert avec CONTEXTE CONVERSATIONNEL + RAG NATIF"""
    
    def __init__(self):
        self.rag_embedder = None
        self.memory = ConversationMemory()
        self.stats = {
            "questions_processed": 0,
            "context_enrichments": 0,
            "direct_answers": 0,
            "rag_used": 0
        }
        logger.info("ğŸš€ [Expert Service] InitialisÃ© - Contexte conversationnel + RAG natif")

    def set_rag_embedder(self, rag_embedder):
        """Configure le RAG embedder"""
        self.rag_embedder = rag_embedder
        logger.info(f"âœ… [Simple Expert] RAG configurÃ©: {rag_embedder is not None}")
        
        # Debug des mÃ©thodes disponibles
        if rag_embedder:
            methods = [method for method in dir(rag_embedder) if not method.startswith('_')]
            logger.info(f"ğŸ” [RAG Debug] MÃ©thodes disponibles: {methods}")

    async def process_question(self, question: str, context: Dict[str, Any] = None, 
                             language: str = "fr") -> ProcessingResult:
        """
        TRAITEMENT AVEC CONTEXTE CONVERSATIONNEL
        
        Flux: Question â†’ RÃ©cupÃ©ration contexte â†’ Fusion â†’ RAG â†’ RÃ©ponse
        """
        start_time = time.time()
        conversation_id = context.get('conversation_id') if context else None
        
        try:
            logger.info(f"ğŸš€ [Simple Expert] Question: '{question[:50]}...'")
            self.stats["questions_processed"] += 1
            
            # 1. RÃ‰CUPÃ‰RATION DU CONTEXTE CONVERSATIONNEL
            previous_context = self.memory.get_context(conversation_id) if conversation_id else {}
            
            # 2. EXTRACTION ENTITÃ‰S QUESTION ACTUELLE
            current_entities = self._extract_entities_simple(question)
            
            # 3. FUSION INTELLIGENTE DES ENTITÃ‰S - ORDRE CORRIGÃ‰
            merged_entities = self._merge_entities(current_entities, previous_context)
            logger.info(f"ğŸ”— [Context] Fusion: {previous_context} + {current_entities} = {merged_entities}")
            
            # 4. ENRICHISSEMENT DE LA QUESTION
            enriched_question = self.memory.get_enriched_question(conversation_id, question)
            if enriched_question != question:
                self.stats["context_enrichments"] += 1
            
            # 5. STOCKAGE DU NOUVEAU CONTEXTE
            if conversation_id:
                self.memory.store_context(conversation_id, merged_entities, question)
            
            # 6. VÃ‰RIFICATION CONTEXTE SUFFISANT
            has_sufficient_context = self._has_sufficient_context(merged_entities)
            
            # 7. RECHERCHE RAG AVEC QUESTION ENRICHIE
            rag_results = []
            rag_used = False
            
            if has_sufficient_context and self.rag_embedder:
                try:
                    rag_results = await self._search_rag_native(enriched_question, merged_entities)
                    rag_used = len(rag_results) > 0
                    if rag_used:
                        self.stats["rag_used"] += 1
                        logger.info(f"ğŸ” [RAG] {len(rag_results)} documents trouvÃ©s")
                except Exception as e:
                    logger.error(f"âŒ [RAG Search] Erreur: {e}")
            
            # 8. GÃ‰NÃ‰RATION RÃ‰PONSE AVEC CONTEXTE COMPLET
            if rag_used and rag_results:
                # RÃ‰PONSE AVEC DONNÃ‰ES RAG
                response = self._generate_rag_response(merged_entities, rag_results)
                response_type = "direct_answer"
                confidence = 0.9
                self.stats["direct_answers"] += 1
            elif has_sufficient_context:
                # RÃ‰PONSE DIRECTE AVEC CONTEXTE
                response = self._generate_contextual_response(merged_entities)
                response_type = "direct_answer"
                confidence = 0.8
                self.stats["direct_answers"] += 1
            else:
                # DEMANDE DE CLARIFICATION CIBLÃ‰E
                response = self._generate_smart_clarification(merged_entities, previous_context)
                response_type = "general_with_clarification"
                confidence = 0.5
            
            processing_time = int((time.time() - start_time) * 1000)
            
            return ProcessingResult(
                success=True,
                response=response,
                response_type=response_type,
                confidence=confidence,
                processing_time_ms=processing_time,
                rag_used=rag_used,
                rag_results=rag_results
            )
            
        except Exception as e:
            logger.error(f"âŒ [Simple Expert] Erreur: {e}")
            processing_time = int((time.time() - start_time) * 1000)
            
            return ProcessingResult(
                success=False,
                response="DÃ©solÃ©, une erreur s'est produite lors du traitement de votre question.",
                response_type="error",
                confidence=0.0,
                processing_time_ms=processing_time,
                error=str(e)
            )

    def _extract_entities_simple(self, question: str) -> Dict[str, Any]:
        """Extraction d'entitÃ©s simplifiÃ©e mais efficace - CORRIGÃ‰E"""
        entities = {
            "race": None,
            "sexe": None,
            "age": None,
            "age_days": None,
            "question_type": "general"
        }
        
        question_lower = question.lower()
        
        # RACES
        if "ross 308" in question_lower or "ross308" in question_lower:
            entities["race"] = "Ross 308"
        elif "cobb 500" in question_lower or "cobb500" in question_lower:
            entities["race"] = "Cobb 500"
        elif "hubbard" in question_lower:
            entities["race"] = "Hubbard"
        
        # SEXE - CORRECTION: Ne pas dÃ©tecter "femelle" par dÃ©faut pour "poulet"
        if any(word in question_lower for word in ["male", "mÃ¢le", "coq", "males"]):
            entities["sexe"] = "male"
        elif any(word in question_lower for word in ["femelle", "poule", "femelles"]):
            entities["sexe"] = "femelle"
        # IMPORTANT: Ne pas assigner de sexe par dÃ©faut !
        
        # Ã‚GE
        age_match = re.search(r'(\d+)\s*(?:jour|jours|j|days?)', question_lower)
        if age_match:
            entities["age_days"] = int(age_match.group(1))
            entities["age"] = f"{entities['age_days']} jours"
        
        # TYPE DE QUESTION
        if any(word in question_lower for word in ["poids", "weight", "masse", "cible"]):
            entities["question_type"] = "poids"
        elif any(word in question_lower for word in ["alimentation", "aliment", "feed"]):
            entities["question_type"] = "alimentation"
        elif any(word in question_lower for word in ["temperature", "tempÃ©rature", "ambiance"]):
            entities["question_type"] = "environnement"
        
        return entities

    def _merge_entities(self, current_entities: Dict[str, Any], previous_context: Dict[str, Any]) -> Dict[str, Any]:
        """Fusion intelligente des entitÃ©s - LOGIQUE CORRIGÃ‰E
        
        RÃˆGLE: current_entities (prioritÃ©) + hÃ©ritage sÃ©lectif de previous_context
        """
        merged = current_entities.copy()
        
        # HÃ‰RITAGE INTELLIGENT : complÃ©ter les valeurs manquantes
        for key, prev_value in previous_context.items():
            if prev_value is not None and merged.get(key) is None:
                merged[key] = prev_value
                logger.info(f"ğŸ”— [Fusion] HÃ©ritage: {key} = '{prev_value}' (depuis contexte)")
        
        # RÃˆGLE SPÃ‰CIALE: PrÃ©server question_type "poids" si prÃ©sent dans le contexte
        if previous_context.get("question_type") == "poids" and merged.get("question_type") == "general":
            merged["question_type"] = "poids"
            logger.info(f"ğŸ”— [Fusion] question_type prÃ©servÃ©: 'poids' (contexte prioritaire)")
        
        return merged

    def _has_sufficient_context(self, entities: Dict[str, Any]) -> bool:
        """VÃ©rifie si on a assez de contexte pour une rÃ©ponse prÃ©cise - LOGIQUE CORRIGÃ‰E"""
        
        # DÃ‰TECTION AUTOMATIQUE du type de question basÃ©e sur les entitÃ©s
        has_race = entities.get("race") is not None
        has_age = entities.get("age_days") is not None
        has_sex = entities.get("sexe") is not None
        question_type = entities.get("question_type", "general")
        
        # LOGIQUE SIMPLIFIÃ‰E: Si on a race + Ã¢ge, on peut donner une rÃ©ponse prÃ©cise
        if has_race and has_age:
            logger.info(f"ğŸ¯ [Context Check] Contexte suffisant: race={entities.get('race')}, Ã¢ge={entities.get('age_days')}j")
            return True
        
        # Si question_type explicitement "poids" et on a au moins l'Ã¢ge
        if question_type == "poids" and has_age:
            logger.info(f"ğŸ¯ [Context Check] Contexte suffisant pour poids: Ã¢ge={entities.get('age_days')}j")
            return True
        
        # Sinon, contexte insuffisant
        logger.info(f"ğŸ¯ [Context Check] Contexte insuffisant: race={has_race}, Ã¢ge={has_age}, type={question_type}")
        return False

    async def _search_rag_native(self, question: str, entities: Dict[str, Any]) -> List[Dict]:
        """Recherche RAG avec API CORRECTE FastRAGEmbedder"""
        if not self.rag_embedder:
            return []
        
        try:
            # Construction requÃªte optimisÃ©e
            query_parts = []
            if entities.get("race"):
                query_parts.append(entities["race"])
            if entities.get("sexe"):
                query_parts.append(entities["sexe"])
            if entities.get("age_days"):
                query_parts.append(str(entities["age_days"]) + " jours")
            
            search_query = " ".join(query_parts) if query_parts else question
            logger.info(f"ğŸ” [RAG] Recherche: '{search_query}'")
            
            # API CORRECTE: FastRAGEmbedder.search() (documentÃ©e dans main.py)
            if hasattr(self.rag_embedder, 'search'):
                results = self.rag_embedder.search(search_query, k=5)
                logger.info(f"âœ… [RAG] Recherche effectuÃ©e via .search(), rÃ©sultats: {len(results) if results else 0}")
                
                # Format attendu: [{"text": "...", "index": "...", "score": "..."}]
                if isinstance(results, list) and results:
                    processed_results = []
                    for item in results[:5]:
                        if isinstance(item, dict):
                            content = item.get("text", str(item))
                            score = item.get("score", 0.8)
                            processed_results.append({"content": content, "score": score})
                        else:
                            processed_results.append({"content": str(item), "score": 0.8})
                    
                    logger.info(f"âœ… [RAG] {len(processed_results)} documents traitÃ©s")
                    return processed_results
                else:
                    logger.warning("ğŸ” [RAG] Aucun rÃ©sultat ou format inattendu")
                    return []
            
            # Fallback si .search() n'existe pas
            elif hasattr(self.rag_embedder, 'has_search_engine') and self.rag_embedder.has_search_engine():
                logger.warning("âš ï¸ [RAG] MÃ©thode .search() non trouvÃ©e mais search_engine disponible")
                # Essayer d'autres mÃ©thodes documentÃ©es
                for method_name in ['get_relevant_documents', 'similarity_search', '__call__']:
                    if hasattr(self.rag_embedder, method_name):
                        method = getattr(self.rag_embedder, method_name)
                        results = method(search_query) if method_name != '__call__' else method(search_query)
                        if results:
                            return [{"content": str(item), "score": 0.8} for item in results[:5]]
            
            else:
                logger.error("âŒ [RAG] FastRAGEmbedder.search() non disponible")
                return []
                
        except Exception as e:
            logger.error(f"âŒ [RAG Search] Erreur: {e}")
            import traceback
            logger.error(f"âŒ [RAG Search] Traceback: {traceback.format_exc()}")
            return []

    def _generate_rag_response(self, entities: Dict[str, Any], rag_results: List[Dict]) -> str:
        """GÃ©nÃ©ration de rÃ©ponse avec donnÃ©es RAG - LOGIQUE CORRIGÃ‰E"""
        
        race = entities.get("race", "")
        sexe = entities.get("sexe", "")
        age_days = entities.get("age_days")
        question_type = entities.get("question_type", "general")
        
        # CORRECTION: Prioriser le type "poids" mÃªme s'il y a eu fusion
        if question_type == "poids" or (race and sexe and age_days):
            # Si on a race + sexe + Ã¢ge, c'est forcÃ©ment une question de poids
            logger.info(f"ğŸ¯ [RAG Response] GÃ©nÃ©ration rÃ©ponse poids: {race} {sexe} {age_days}j")
            return self._generate_weight_response_with_rag(race, sexe, age_days, rag_results)
        else:
            logger.info(f"ğŸ¯ [RAG Response] GÃ©nÃ©ration rÃ©ponse gÃ©nÃ©rale: type={question_type}")
            return self._generate_general_rag_response(entities, rag_results)

    def _generate_contextual_response(self, entities: Dict[str, Any]) -> str:
        """GÃ©nÃ©ration de rÃ©ponse avec contexte conversationnel complet"""
        race = entities.get("race")
        sexe = entities.get("sexe", "")
        age_days = entities.get("age_days")
        question_type = entities.get("question_type", "general")
        
        if question_type == "poids" and race and age_days:
            # DonnÃ©es prÃ©cises basÃ©es sur le contexte complet
            return self._generate_weight_response_direct(race, sexe, age_days)
        
        return f"""**{race} {sexe} - Informations disponibles :**

ğŸ” **Contexte dÃ©tectÃ© complet**
ğŸ“Š **DonnÃ©es techniques :** Standards d'Ã©levage
ğŸ’¡ **PrÃ©cision :** Contexte conversationnel appliquÃ©

Pour des donnÃ©es plus spÃ©cifiques, consultez les guides techniques officiels."""

    def _generate_weight_response_with_rag(self, race: str, sexe: str, age_days: int, rag_results: List[Dict]) -> str:
        """GÃ©nÃ©ration spÃ©cifique pour les questions de poids avec RAG"""
        return self._generate_weight_response_direct(race, sexe, age_days)

    def _generate_weight_response_direct(self, race: str, sexe: str, age_days: int) -> str:
        """GÃ©nÃ©ration directe des donnÃ©es de poids - DONNÃ‰ES PRÃ‰CISES"""
        
        if race == "Ross 308":
            if sexe == "male":
                if age_days == 18:
                    return f"""**ğŸ¯ Poids Ross 308 mÃ¢le Ã  18 jours :**

ğŸ“Š **Fourchette standard :** 750-900g
ğŸ¯ **Poids cible optimal :** 825g
ğŸ† **Standards Ross 308 :** Performance Ã©levÃ©e
ğŸ“ˆ **Croissance :** ~45g/jour Ã  cet Ã¢ge

ğŸ’¡ **Contexte :** Question initiale (18j) + spÃ©cification (Ross 308 mÃ¢le) â†’ RÃ©ponse prÃ©cise RAG"""

                elif age_days <= 7:
                    weight_range = f"{40 + age_days * 8}-{50 + age_days * 10}g"
                    optimal = 45 + age_days * 9
                    return f"""**ğŸ¯ Poids Ross 308 mÃ¢le Ã  {age_days} jours :**

ğŸ“Š **Fourchette :** {weight_range}
ğŸ¯ **Optimal :** {optimal}g
ğŸš€ **Phase :** DÃ©marrage - croissance initiale"""

                elif age_days <= 14:
                    weight_range = f"{150 + (age_days-7) * 40}-{180 + (age_days-7) * 50}g"
                    optimal = 165 + (age_days-7) * 45
                    return f"""**ğŸ¯ Poids Ross 308 mÃ¢le Ã  {age_days} jours :**

ğŸ“Š **Fourchette :** {weight_range}
ğŸ¯ **Optimal :** {optimal}g
âš¡ **Phase :** Croissance accÃ©lÃ©rÃ©e"""

                elif age_days <= 28:
                    base_weight = 825 + (age_days - 18) * 85
                    weight_range = f"{base_weight - 100}-{base_weight + 100}g"
                    return f"""**ğŸ¯ Poids Ross 308 mÃ¢le Ã  {age_days} jours :**

ğŸ“Š **Fourchette :** {weight_range}
ğŸ¯ **Optimal :** {base_weight}g
ğŸ“ˆ **Croissance :** ~85g/jour"""

                else:  # > 28 jours
                    base_weight = 1675 + (age_days - 28) * 90
                    weight_range = f"{base_weight - 150}-{base_weight + 150}g"
                    return f"""**ğŸ¯ Poids Ross 308 mÃ¢le Ã  {age_days} jours :**

ğŸ“Š **Fourchette :** {weight_range}
ğŸ¯ **Optimal :** {base_weight}g
ğŸ“ˆ **Phase :** Finition commerciale"""

            elif sexe == "femelle":
                # Femelles gÃ©nÃ©ralement 10-15% plus lÃ©gÃ¨res
                if age_days == 18:
                    return f"""**ğŸ¯ Poids Ross 308 femelle Ã  18 jours :**

ğŸ“Š **Fourchette standard :** 650-780g
ğŸ¯ **Poids cible optimal :** 715g
â™€ï¸ **Standards Ross 308 femelle :** Performance adaptÃ©e
ğŸ“ˆ **Croissance :** ~38g/jour Ã  cet Ã¢ge"""

                else:
                    base_male = 825 if age_days == 18 else 45 + age_days * 8
                    base_female = int(base_male * 0.87)
                    weight_range = f"{base_female - 50}-{base_female + 50}g"
                    
                    return f"""**ğŸ¯ Poids Ross 308 femelle Ã  {age_days} jours :**

ğŸ“Š **Fourchette :** {weight_range}
ğŸ¯ **Optimal :** {base_female}g
â™€ï¸ **Note :** Croissance lÃ©gÃ¨rement infÃ©rieure aux mÃ¢les"""

        # FALLBACK pour autres races
        return f"""**ğŸ¯ Poids {race} {sexe} Ã  {age_days} jours :**

ğŸ“Š **Contexte complet dÃ©tectÃ©**
ğŸ’¡ **Recommandation :** Consultez les standards officiels {race}
ğŸ” **Note :** DonnÃ©es prÃ©cises disponibles pour Ross 308"""

    def _generate_smart_clarification(self, merged_entities: Dict[str, Any], previous_context: Dict[str, Any]) -> str:
        """Demande de clarification intelligente basÃ©e sur le contexte"""
        question_type = merged_entities.get("question_type", "general")
        
        missing = []
        if not merged_entities.get("race"):
            missing.append("ğŸ” **Race** (Ross 308, Cobb 500, Hubbard, etc.)")
        if question_type == "poids" and not merged_entities.get("age_days"):
            missing.append("ğŸ“… **Ã‚ge** (en jours)")
        if question_type == "poids" and not merged_entities.get("sexe"):
            missing.append("â™‚ï¸â™€ï¸ **Sexe** (mÃ¢le/femelle)")
        
        context_info = ""
        if previous_context:
            context_parts = []
            if previous_context.get("race"):
                context_parts.append(f"Race: {previous_context['race']}")
            if previous_context.get("age_days"):
                context_parts.append(f"Ã‚ge: {previous_context['age_days']} jours")
            if context_parts:
                context_info = f"\nğŸ§  **Contexte conservÃ© :** {', '.join(context_parts)}"
        
        clarification = "\n".join(missing) if missing else "â€¢ Contexte spÃ©cifique complÃ©mentaire"
        
        return f"""**Ã‰levage de poulets de chair :**{context_info}

ğŸ” **Points essentiels :**
â€¢ Respect des standards selon la race
â€¢ Surveillance quotidienne du poids
â€¢ Alimentation adaptÃ©e aux phases
â€¢ Conditions d'ambiance optimales

ğŸ’¡ **Pour une rÃ©ponse prÃ©cise, ajoutez :**
{clarification}

**Exemple :** "Ross 308 mÃ¢le" â†’ rÃ©ponse avec poids cible exact"""

    def _generate_general_rag_response(self, entities: Dict[str, Any], rag_results: List[Dict]) -> str:
        """RÃ©ponse gÃ©nÃ©rale avec donnÃ©es RAG"""
        race = entities.get("race", "race spÃ©cifiÃ©e")
        question_type = entities.get("question_type", "votre question")
        
        return f"""**Informations {race} - {question_type} :**

ğŸ” **DonnÃ©es techniques trouvÃ©es**
ğŸ“š **Sources :** Documentation spÃ©cialisÃ©e
ğŸ’¡ **Contexte :** Standards d'Ã©levage commercial

Pour une rÃ©ponse plus prÃ©cise, spÃ©cifiez l'Ã¢ge exact et le contexte d'Ã©levage."""