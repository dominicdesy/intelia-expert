"""
app/api/v1/expert_services.py - SERVICES MÃ‰TIER EXPERT SYSTEM

VERSION FINALE CORRIGÃ‰E PARFAITE : RAG-First + SystÃ¨me de clarification RÃ‰PARÃ‰
CORRECTIONS CRITIQUES:
1. âœ… ORDRE DE PRIORITÃ‰ CORRIGÃ‰ : Clarification spÃ©cialisÃ©e AVANT vagueness gÃ©nÃ©rale
2. Sauvegarde forcÃ©e question originale dans mÃ©moire conversationnelle
3. RÃ©cupÃ©ration intelligente du contexte pour rÃ©ponses clarification
4. DÃ©tection amÃ©liorÃ©e des rÃ©ponses courtes ("Ross 308")
5. Contexte forcÃ© pour RAG aprÃ¨s clarification
"""

import os
import logging
import uuid
import time
import re
from datetime import datetime
from typing import Optional, Dict, Any, Tuple

from fastapi import HTTPException, Request

from .expert_models import (
    EnhancedQuestionRequest, EnhancedExpertResponse, FeedbackRequest,
    ValidationResult, ProcessingContext, VaguenessResponse, ResponseFormat
)
from .expert_utils import (
    get_user_id_from_request, 
    build_enriched_question_from_clarification,
    get_enhanced_topics_by_language,
    save_conversation_auto_enhanced,
    extract_breed_and_sex_from_clarification,
    build_enriched_question_with_breed_sex,
    validate_clarification_completeness
)
from .expert_integrations import IntegrationsManager
from .api_enhancement_service import APIEnhancementService

logger = logging.getLogger(__name__)

class RAGContextEnhancer:
    """AmÃ©liore le contexte conversationnel pour optimiser les requÃªtes RAG"""
    
    def __init__(self):
        # Patterns pour dÃ©tecter les rÃ©fÃ©rences contextuelles
        self.pronoun_patterns = {
            "fr": [
                r'\b(son|sa|ses|leur|leurs)\s+(poids|Ã¢ge|croissance|dÃ©veloppement)',
                r'\b(ils|elles)\s+(pÃ¨sent|grandissent|se dÃ©veloppent)',
                r'\b(qu\'?est-ce que|quel est)\s+(son|sa|ses|leur)',
                r'\b(combien)\s+(pÃ¨sent-ils|font-ils|mesurent-ils)'
            ],
            "en": [
                r'\b(their|its)\s+(weight|age|growth|development)',
                r'\b(they)\s+(weigh|grow|develop)',
                r'\b(what is|how much is)\s+(their|its)',
                r'\b(how much do they)\s+(weigh|measure)'
            ],
            "es": [
                r'\b(su|sus)\s+(peso|edad|crecimiento|desarrollo)',
                r'\b(ellos|ellas)\s+(pesan|crecen|se desarrollan)',
                r'\b(cuÃ¡l es|cuÃ¡nto es)\s+(su|sus)',
                r'\b(cuÃ¡nto)\s+(pesan|miden)'
            ]
        }
    
    def enhance_question_for_rag(
        self, 
        question: str, 
        conversation_context: str, 
        language: str = "fr"
    ) -> Tuple[str, Dict[str, any]]:
        """AmÃ©liore une question pour le RAG en utilisant le contexte conversationnel"""
        
        enhancement_info = {
            "pronoun_detected": False,
            "context_entities_used": [],
            "question_enriched": False,
            "original_question": question
        }
        
        # 1. DÃ©tecter les pronoms/rÃ©fÃ©rences contextuelles
        has_pronouns = self._detect_contextual_references(question, language)
        if has_pronouns:
            enhancement_info["pronoun_detected"] = True
            logger.info(f"ğŸ” [RAG Context] Pronoms dÃ©tectÃ©s dans: '{question}'")
        
        # 2. Extraire entitÃ©s du contexte
        context_entities = self._extract_context_entities(conversation_context)
        if context_entities:
            enhancement_info["context_entities_used"] = list(context_entities.keys())
            logger.info(f"ğŸ“Š [RAG Context] EntitÃ©s contextuelles: {context_entities}")
        
        # 3. Enrichir la question si nÃ©cessaire
        enriched_question = question
        
        if has_pronouns and context_entities:
            enriched_question = self._build_enriched_question(
                question, context_entities, language
            )
            enhancement_info["question_enriched"] = True
            logger.info(f"âœ¨ [RAG Context] Question enrichie: '{enriched_question}'")
        
        # 4. Ajouter contexte technique si pertinent
        if context_entities or has_pronouns:
            technical_context = self._build_technical_context(context_entities, language)
            if technical_context:
                enriched_question += f"\n\nContexte technique: {technical_context}"
        
        return enriched_question, enhancement_info
    
    def _detect_contextual_references(self, question: str, language: str) -> bool:
        """DÃ©tecte si la question contient des pronoms/rÃ©fÃ©rences contextuelles"""
        
        patterns = self.pronoun_patterns.get(language, self.pronoun_patterns["fr"])
        question_lower = question.lower()
        
        for pattern in patterns:
            if re.search(pattern, question_lower, re.IGNORECASE):
                logger.debug(f"ğŸ¯ [RAG Context] Pattern trouvÃ©: {pattern}")
                return True
        
        return False
    
    def _extract_context_entities(self, context: str) -> Dict[str, str]:
        """Extrait les entitÃ©s importantes du contexte conversationnel"""
        
        if not context:
            return {}
        
        entities = {}
        context_lower = context.lower()
        
        # Extraire race
        breed_patterns = [
            r'race[:\s]+([a-zA-Z0-9\s]+?)(?:\n|,|\.|\s|$)',
            r'breed[:\s]+([a-zA-Z0-9\s]+?)(?:\n|,|\.|\s|$)',
            r'(ross\s*308|cobb\s*500|hubbard|arbor\s*acres)',
            r'poulets?\s+(ross\s*308|cobb\s*500)',
            r'chickens?\s+(ross\s*308|cobb\s*500)'
        ]
        
        for pattern in breed_patterns:
            match = re.search(pattern, context_lower, re.IGNORECASE)
            if match:
                entities["breed"] = match.group(1).strip()
                break
        
        # Extraire Ã¢ge
        age_patterns = [
            r'Ã¢ge[:\s]+(\d+\s*(?:jour|semaine|day|week)s?)',
            r'age[:\s]+(\d+\s*(?:jour|semaine|day|week)s?)',
            r'(\d+)\s*(?:jour|day)s?',
            r'(\d+)\s*(?:semaine|week)s?'
        ]
        
        for pattern in age_patterns:
            match = re.search(pattern, context_lower, re.IGNORECASE)
            if match:
                entities["age"] = match.group(1).strip()
                break
        
        return entities
    
    def _build_enriched_question(
        self, 
        question: str, 
        context_entities: Dict[str, str], 
        language: str
    ) -> str:
        """Construit une question enrichie en remplaÃ§ant les pronoms par les entitÃ©s contextuelles"""
        
        enriched = question
        
        # Templates par langue
        templates = {
            "fr": {
                "breed_age": "Pour des {breed} de {age}",
                "breed_only": "Pour des {breed}",
                "age_only": "Pour des poulets de {age}"
            },
            "en": {
                "breed_age": "For {breed} chickens at {age}",
                "breed_only": "For {breed} chickens", 
                "age_only": "For chickens at {age}"
            },
            "es": {
                "breed_age": "Para pollos {breed} de {age}",
                "breed_only": "Para pollos {breed}",
                "age_only": "Para pollos de {age}"
            }
        }
        
        template_set = templates.get(language, templates["fr"])
        
        # Construire le prÃ©fixe contextuel
        context_prefix = ""
        if "breed" in context_entities and "age" in context_entities:
            context_prefix = template_set["breed_age"].format(
                breed=context_entities["breed"],
                age=context_entities["age"]
            )
        elif "breed" in context_entities:
            context_prefix = template_set["breed_only"].format(
                breed=context_entities["breed"]
            )
        elif "age" in context_entities:
            context_prefix = template_set["age_only"].format(
                age=context_entities["age"]
            )
        
        if context_prefix:
            # Remplacer ou prÃ©fixer selon la structure de la question
            if any(word in question.lower() for word in ["son", "sa", "ses", "leur", "leurs", "their", "its", "su", "sus"]):
                enriched = f"{context_prefix}, {question.lower()}"
            else:
                enriched = f"{context_prefix}: {question}"
        
        return enriched
    
    def _build_technical_context(self, entities: Dict[str, str], language: str) -> str:
        """Construit un contexte technique pour aider le RAG"""
        
        if not entities:
            return ""
        
        context_parts = []
        
        if "breed" in entities:
            context_parts.append(f"Race: {entities['breed']}")
        
        if "age" in entities:
            context_parts.append(f"Ã‚ge: {entities['age']}")
        
        return " | ".join(context_parts)

class ExpertService:
    """Service principal pour le systÃ¨me expert avec toutes les amÃ©liorations"""
    
    def __init__(self):
        self.integrations = IntegrationsManager()
        self.rag_enhancer = RAGContextEnhancer()
        self.enhancement_service = APIEnhancementService()
        logger.info("âœ… [Expert Service] Service expert initialisÃ© avec amÃ©liorations complÃ¨tes")
    
    def get_current_user_dependency(self):
        """Retourne la dÃ©pendance pour l'authentification"""
        return self.integrations.get_current_user_dependency()
    
    async def process_expert_question(
        self,
        request_data: EnhancedQuestionRequest,
        request: Request,
        current_user: Optional[Dict[str, Any]],
        start_time: float
    ) -> EnhancedExpertResponse:
        """Traite une question expert avec toutes les fonctionnalitÃ©s amÃ©liorÃ©es"""
        
        processing_steps = []
        ai_enhancements_used = []
        debug_info = {}
        performance_breakdown = {"start": int(time.time() * 1000)}
        
        # Initialisation
        processing_steps.append("initialization")
        
        # === AUTHENTIFICATION ===
        if current_user is None and self.integrations.auth_available:
            raise HTTPException(status_code=401, detail="Authentification requise")
        
        user_id = self._extract_user_id(current_user, request_data, request)
        user_email = current_user.get("email") if current_user else None
        request_ip = request.client.host if request.client else "unknown"
        
        processing_steps.append("authentication")
        performance_breakdown["auth_complete"] = int(time.time() * 1000)
        
        # === GESTION CONVERSATION ID ===
        conversation_id = self._get_or_create_conversation_id(request_data)
        
        # === VALIDATION QUESTION ===
        question_text = request_data.text.strip()
        if not question_text:
            raise HTTPException(status_code=400, detail="Question text is required")
        
        processing_steps.append("question_validation")
        
        # === ENREGISTREMENT DANS MÃ‰MOIRE INTELLIGENTE ===
        conversation_context = None
        if self.integrations.intelligent_memory_available:
            try:
                conversation_context = self.integrations.add_message_to_conversation(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message=question_text,
                    role="user",
                    language=request_data.language,
                    message_type="clarification_response" if request_data.is_clarification_response else "question"
                )
                ai_enhancements_used.append("intelligent_memory")
                processing_steps.append("memory_storage")
            except Exception as e:
                logger.warning(f"âš ï¸ [Expert Service] Erreur mÃ©moire: {e}")
        
        performance_breakdown["memory_complete"] = int(time.time() * 1000)
        
        # === VALIDATION AGRICOLE ===
        validation_result = await self._validate_agricultural_question(
            question_text, request_data.language, user_id, request_ip, conversation_id
        )
        
        processing_steps.append("agricultural_validation")
        performance_breakdown["validation_complete"] = int(time.time() * 1000)
        
        if not validation_result.is_valid:
            return self._create_rejection_response(
                question_text, validation_result, conversation_id, 
                user_email, request_data.language, start_time,
                processing_steps, ai_enhancements_used, None
            )
        
        # âœ… === SYSTÃˆME DE CLARIFICATION INTELLIGENT CORRIGÃ‰ - ORDRE PRIORITÃ‰ FIXÃ‰ ===
        clarification_result = await self._handle_clarification_fixed(
            request_data, question_text, user_id, conversation_id,
            processing_steps, ai_enhancements_used
        )
        
        if clarification_result:
            return clarification_result
        
        # âœ… NOUVEAU: DÃ‰TECTION VAGUENESS APRÃˆS clarifications spÃ©cialisÃ©es
        vagueness_result = None
        if request_data.enable_vagueness_detection:
            vagueness_result = self.enhancement_service.detect_vagueness(
                question_text, request_data.language
            )
            
            ai_enhancements_used.append("vagueness_detection")
            performance_breakdown["vagueness_check"] = int(time.time() * 1000)
            
            # âœ… CORRECTION: RÃ©duire le seuil de 0.7 Ã  0.6 pour dÃ©clencher plus facilement
            if vagueness_result.is_vague and vagueness_result.vagueness_score > 0.6:
                logger.info(f"ğŸ¯ [Expert Service] Question floue dÃ©tectÃ©e (score: {vagueness_result.vagueness_score})")
                return self._create_vagueness_response(
                    vagueness_result, question_text, conversation_id, 
                    request_data.language, start_time, processing_steps, ai_enhancements_used
                )
        
        performance_breakdown["clarification_complete"] = int(time.time() * 1000)
        
        # === TRAITEMENT EXPERT AVEC RAG-FIRST + AMÃ‰LIORATIONS ===
        expert_result = await self._process_expert_response_enhanced_fixed(
            question_text, request_data, request, current_user,
            conversation_id, processing_steps, ai_enhancements_used,
            debug_info, performance_breakdown, vagueness_result
        )
        
        # === ENREGISTREMENT RÃ‰PONSE ===
        if self.integrations.intelligent_memory_available and expert_result["answer"]:
            try:
                self.integrations.add_message_to_conversation(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message=expert_result["answer"],
                    role="assistant",
                    language=request_data.language,
                    message_type="response"
                )
            except Exception as e:
                logger.warning(f"âš ï¸ [Expert Service] Erreur enregistrement rÃ©ponse: {e}")
        
        processing_steps.append("response_storage")
        performance_breakdown["final"] = int(time.time() * 1000)
        
        # === CONSTRUCTION RÃ‰PONSE FINALE AMÃ‰LIORÃ‰E ===
        response_time_ms = int((time.time() - start_time) * 1000)
        
        return self._build_final_enhanced_response(
            question_text, expert_result["answer"], conversation_id,
            user_email, request_data.language, response_time_ms,
            expert_result, validation_result, conversation_context,
            processing_steps, ai_enhancements_used, request_data,
            debug_info, performance_breakdown
        )
    
    # ===========================================================================================
    # âœ… NOUVELLES FONCTIONS DE CLARIFICATION INTELLIGENTE - VERSION CORRIGÃ‰E
    # ===========================================================================================
    
    async def _handle_clarification_fixed(
        self, request_data, question_text, user_id, conversation_id, 
        processing_steps, ai_enhancements_used
    ):
        """
        âœ… SYSTÃˆME DE CLARIFICATION PARFAITEMENT CORRIGÃ‰
        
        CORRECTIONS CRITIQUES:
        1. Sauvegarde forcÃ©e de la question originale
        2. RÃ©cupÃ©ration intelligente du contexte conversationnel
        3. DÃ©tection amÃ©liorÃ©e des rÃ©ponses courtes
        """
        
        # 1. âœ… TRAITEMENT DES RÃ‰PONSES DE CLARIFICATION AMÃ‰LIORÃ‰
        if request_data.is_clarification_response:
            return await self._process_clarification_response_fixed(
                request_data, question_text, conversation_id,
                processing_steps, ai_enhancements_used
            )
        
        # 2. âœ… DÃ‰TECTION QUESTIONS NÃ‰CESSITANT CLARIFICATION
        clarification_needed = self._detect_performance_question_needing_clarification(
            question_text, request_data.language
        )
        
        if not clarification_needed:
            return None
        
        logger.info(f"ğŸ¯ [Expert Service] Clarification nÃ©cessaire: {clarification_needed['type']}")
        processing_steps.append("automatic_clarification_triggered")
        ai_enhancements_used.append("smart_performance_clarification")
        
        # 3. âœ… SAUVEGARDE FORCÃ‰E DE LA QUESTION ORIGINALE
        if self.integrations.intelligent_memory_available:
            try:
                # Marquer la question originale avec un tag spÃ©cial
                self.integrations.add_message_to_conversation(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message=f"ORIGINAL_QUESTION_FOR_CLARIFICATION: {question_text}",
                    role="system",
                    language=request_data.language,
                    message_type="original_question_marker"
                )
                logger.info(f"ğŸ’¾ [Expert Service] Question originale sauvegardÃ©e: {question_text}")
                processing_steps.append("original_question_saved")
            except Exception as e:
                logger.error(f"âŒ [Expert Service] Impossible de sauvegarder question originale: {e}")
        
        # 4. GÃ©nÃ©rer la demande de clarification
        clarification_response = self._generate_performance_clarification_response(
            question_text, clarification_needed, request_data.language, conversation_id
        )
        
        return clarification_response
    
    async def _process_clarification_response_fixed(
        self, request_data, question_text, conversation_id, 
        processing_steps, ai_enhancements_used
    ):
        """
        âœ… TRAITEMENT DES RÃ‰PONSES DE CLARIFICATION - VERSION PARFAITE
        
        CORRECTIONS CRITIQUES:
        1. RÃ©cupÃ©ration forcÃ©e de la question originale depuis la mÃ©moire
        2. DÃ©tection amÃ©liorÃ©e des rÃ©ponses courtes ("Ross 308")
        3. Enrichissement automatique de la question pour RAG
        """
        
        # âœ… RÃ‰CUPÃ‰RATION FORCÃ‰E DE LA QUESTION ORIGINALE
        original_question = request_data.original_question
        clarification_context = request_data.clarification_context
        
        # Si pas de contexte fourni, rÃ©cupÃ©rer depuis la mÃ©moire conversationnelle
        if (not original_question or not clarification_context) and self.integrations.intelligent_memory_available:
            try:
                context = self.integrations.get_conversation_context(conversation_id)
                if context and context.messages:
                    # Chercher la question originale dans les messages rÃ©cents
                    for msg in reversed(context.messages[-10:]):  # 10 derniers messages
                        if msg.role == "system" and "ORIGINAL_QUESTION_FOR_CLARIFICATION:" in msg.message:
                            original_question = msg.message.replace("ORIGINAL_QUESTION_FOR_CLARIFICATION: ", "")
                            clarification_context = {
                                "missing_information": ["breed", "sex"],
                                "clarification_type": "performance_breed_sex"
                            }
                            logger.info(f"ğŸ”„ [Expert Service] Question originale rÃ©cupÃ©rÃ©e: {original_question}")
                            break
                        elif msg.role == "user" and any(word in msg.message.lower() for word in ["poids", "weight", "jours", "days"]):
                            # Fallback: prendre la premiÃ¨re question poids/Ã¢ge trouvÃ©e
                            original_question = msg.message
                            clarification_context = {
                                "missing_information": ["breed", "sex"],
                                "clarification_type": "performance_breed_sex"
                            }
                            logger.info(f"ğŸ”„ [Expert Service] Question fallback rÃ©cupÃ©rÃ©e: {original_question}")
                            break
            except Exception as e:
                logger.error(f"âŒ [Expert Service] Erreur rÃ©cupÃ©ration contexte: {e}")
        
        # Si toujours pas de question originale, crÃ©er une par dÃ©faut
        if not original_question:
            logger.warning("âš ï¸ [Expert Service] Pas de question originale trouvÃ©e - utilisation par dÃ©faut")
            original_question = "Quel est le poids de rÃ©fÃ©rence pour ces poulets ?"
            clarification_context = {
                "missing_information": ["breed", "sex"],
                "clarification_type": "performance_breed_sex_fallback"
            }
        
        # âœ… EXTRACTION AMÃ‰LIORÃ‰E DES INFORMATIONS DE CLARIFICATION
        missing_info = clarification_context.get("missing_information", [])
        
        # Validation de la complÃ©tude avec extraction amÃ©liorÃ©e
        validation = validate_clarification_completeness(
            question_text, missing_info, request_data.language
        )
        
        # âœ… GESTION DES RÃ‰PONSES PARTIELLES
        if not validation["is_complete"]:
            logger.info(f"ğŸ”„ [Expert Service] Clarification incomplÃ¨te: {validation['still_missing']}")
            return self._generate_follow_up_clarification(
                question_text, validation, request_data.language, conversation_id
            )
        
        # âœ… ENRICHISSEMENT AUTOMATIQUE DE LA QUESTION POUR RAG
        breed = validation["extracted_info"].get("breed")
        sex = validation["extracted_info"].get("sex")
        
        enriched_original_question = build_enriched_question_with_breed_sex(
            original_question, breed, sex, request_data.language
        )
        
        logger.info(f"âœ… [Expert Service] Question enrichie par clarification: {enriched_original_question}")
        
        # âœ… FORCER LE REMPLACEMENT DE LA QUESTION POUR LE RAG
        request_data.text = enriched_original_question
        request_data.is_clarification_response = False  # Traiter comme nouvelle question
        request_data.original_question = original_question  # Garder rÃ©fÃ©rence
        
        processing_steps.append("clarification_processed_successfully")
        ai_enhancements_used.append("breed_sex_extraction")
        ai_enhancements_used.append("question_enrichment_from_clarification")
        ai_enhancements_used.append("forced_question_replacement")
        
        return None  # Continuer le traitement normal avec question enrichie
    
    def _detect_performance_question_needing_clarification(
        self, question: str, language: str = "fr"
    ) -> Optional[Dict[str, Any]]:
        """
        âœ… DÃ‰TECTION AMÃ‰LIORÃ‰E DES QUESTIONS TECHNIQUES NÃ‰CESSITANT RACE/SEXE
        """
        
        question_lower = question.lower()
        
        # Patterns de questions sur poids/performance avec Ã¢ge mais sans race/sexe
        weight_age_patterns = {
            "fr": [
                r'(?:poids|pÃ¨se)\s+.*?(\d+)\s*(?:jour|semaine)s?',
                r'(\d+)\s*(?:jour|semaine)s?.*?(?:poids|pÃ¨se)',
                r'(?:quel|combien)\s+.*?(?:poids|pÃ¨se).*?(\d+)',
                r'(?:croissance|dÃ©veloppement).*?(\d+)\s*(?:jour|semaine)',
                r'(\d+)\s*(?:jour|semaine).*?(?:normal|rÃ©fÃ©rence|standard)'
            ],
            "en": [
                r'(?:weight|weigh)\s+.*?(\d+)\s*(?:day|week)s?',
                r'(\d+)\s*(?:day|week)s?.*?(?:weight|weigh)',
                r'(?:what|how much)\s+.*?(?:weight|weigh).*?(\d+)',
                r'(?:growth|development).*?(\d+)\s*(?:day|week)',
                r'(\d+)\s*(?:day|week).*?(?:normal|reference|standard)'
            ],
            "es": [
                r'(?:peso|pesa)\s+.*?(\d+)\s*(?:dÃ­a|semana)s?',
                r'(\d+)\s*(?:dÃ­a|semana)s?.*?(?:peso|pesa)',
                r'(?:cuÃ¡l|cuÃ¡nto)\s+.*?(?:peso|pesa).*?(\d+)',
                r'(?:crecimiento|desarrollo).*?(\d+)\s*(?:dÃ­a|semana)',
                r'(\d+)\s*(?:dÃ­a|semana).*?(?:normal|referencia|estÃ¡ndar)'
            ]
        }
        
        patterns = weight_age_patterns.get(language, weight_age_patterns["fr"])
        
        # VÃ©rifier si c'est une question poids+Ã¢ge
        age_detected = None
        for pattern in patterns:
            match = re.search(pattern, question_lower)
            if match:
                age_detected = match.group(1)
                break
        
        if not age_detected:
            return None
        
        # VÃ©rifier si race/sexe sont ABSENTS
        breed_patterns = [
            r'\b(ross\s*308|ross\s*708|cobb\s*500|cobb\s*700|hubbard|arbor\s*acres)\b',
            r'\b(broiler|poulet|chicken|pollo)\s+(ross|cobb|hubbard)',
            r'\brace\s*[:\-]?\s*(ross|cobb|hubbard)'
        ]
        
        sex_patterns = [
            r'\b(mÃ¢le|male|macho)s?\b',
            r'\b(femelle|female|hembra)s?\b',
            r'\b(coq|hen|poule|gallina)\b',
            r'\b(mixte|mixed|misto)\b'
        ]
        
        has_breed = any(re.search(pattern, question_lower, re.IGNORECASE) for pattern in breed_patterns)
        has_sex = any(re.search(pattern, question_lower, re.IGNORECASE) for pattern in sex_patterns)
        
        # âœ… CLARIFICATION NÃ‰CESSAIRE si poids+Ã¢ge MAIS pas de race NI sexe
        if not has_breed and not has_sex:
            return {
                "type": "performance_question_missing_breed_sex",
                "age_detected": age_detected,
                "question_type": "weight_performance",
                "missing_info": ["breed", "sex"],
                "confidence": 0.95  # â† AugmentÃ© pour garantir dÃ©clenchement
            }
        
        # Clarification partielle si seulement un des deux manque
        elif not has_breed or not has_sex:
            missing = []
            if not has_breed:
                missing.append("breed")
            if not has_sex:
                missing.append("sex")
            
            return {
                "type": "performance_question_partial_info",
                "age_detected": age_detected,
                "question_type": "weight_performance", 
                "missing_info": missing,
                "confidence": 0.8  # â† AugmentÃ© aussi
            }
        
        return None

    def _generate_performance_clarification_response(
        self, question: str, clarification_info: Dict, language: str, conversation_id: str
    ) -> EnhancedExpertResponse:
        """GÃ©nÃ¨re la demande de clarification optimisÃ©e"""
        
        age = clarification_info.get("age_detected", "X")
        missing_info = clarification_info.get("missing_info", [])
        
        # Messages de clarification par langue
        clarification_messages = {
            "fr": {
                "both_missing": f"Pour vous donner le poids de rÃ©fÃ©rence exact d'un poulet de {age} jours, j'ai besoin de :\n\nâ€¢ **Race/souche** : Ross 308, Cobb 500, Hubbard, etc.\nâ€¢ **Sexe** : MÃ¢les, femelles, ou troupeau mixte\n\nPouvez-vous prÃ©ciser ces informations ?",
                "breed_missing": f"Pour le poids exact Ã  {age} jours, quelle est la **race/souche** (Ross 308, Cobb 500, Hubbard, etc.) ?",
                "sex_missing": f"Pour le poids exact Ã  {age} jours, s'agit-il de **mÃ¢les, femelles, ou d'un troupeau mixte** ?"
            },
            "en": {
                "both_missing": f"To give you the exact reference weight for a {age}-day chicken, I need:\n\nâ€¢ **Breed/strain**: Ross 308, Cobb 500, Hubbard, etc.\nâ€¢ **Sex**: Males, females, or mixed flock\n\nCould you specify this information?",
                "breed_missing": f"For the exact weight at {age} days, what is the **breed/strain** (Ross 308, Cobb 500, Hubbard, etc.)?",
                "sex_missing": f"For the exact weight at {age} days, are these **males, females, or a mixed flock**?"
            },
            "es": {
                "both_missing": f"Para darle el peso de referencia exacto de un pollo de {age} dÃ­as, necesito:\n\nâ€¢ **Raza/cepa**: Ross 308, Cobb 500, Hubbard, etc.\nâ€¢ **Sexo**: Machos, hembras, o lote mixto\n\nÂ¿PodrÃ­a especificar esta informaciÃ³n?",
                "breed_missing": f"Para el peso exacto a los {age} dÃ­as, Â¿cuÃ¡l es la **raza/cepa** (Ross 308, Cobb 500, Hubbard, etc.)?",
                "sex_missing": f"Para el peso exacto a los {age} dÃ­as, Â¿son **machos, hembras, o un lote mixto**?"
            }
        }
        
        messages = clarification_messages.get(language, clarification_messages["fr"])
        
        # SÃ©lectionner le message appropriÃ©
        if len(missing_info) >= 2:
            response_text = messages["both_missing"]
        elif "breed" in missing_info:
            response_text = messages["breed_missing"]
        else:
            response_text = messages["sex_missing"]
        
        # Ajouter exemples de rÃ©ponse
        examples = {
            "fr": "\n\n**Exemples de rÃ©ponses :**\nâ€¢ \"Ross 308 mÃ¢les\"\nâ€¢ \"Cobb 500 femelles\"\nâ€¢ \"Hubbard troupeau mixte\"",
            "en": "\n\n**Example responses:**\nâ€¢ \"Ross 308 males\"\nâ€¢ \"Cobb 500 females\"\nâ€¢ \"Hubbard mixed flock\"",
            "es": "\n\n**Ejemplos de respuestas:**\nâ€¢ \"Ross 308 machos\"\nâ€¢ \"Cobb 500 hembras\"\nâ€¢ \"Hubbard lote mixto\""
        }
        
        response_text += examples.get(language, examples["fr"])
        
        return EnhancedExpertResponse(
            question=question,
            response=response_text,
            conversation_id=conversation_id,
            rag_used=False,
            rag_score=None,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=50,
            mode="smart_performance_clarification",
            user=None,
            logged=True,
            validation_passed=True,
            clarification_result={
                "clarification_requested": True,
                "clarification_type": "performance_breed_sex",
                "missing_information": missing_info,
                "age_detected": age,
                "confidence": clarification_info.get("confidence", 0.9)
            },
            processing_steps=["smart_clarification_triggered"],
            ai_enhancements_used=["performance_question_detection", "targeted_clarification"]
        )
    
    def _generate_follow_up_clarification(
        self, question: str, validation: Dict, language: str, conversation_id: str
    ) -> EnhancedExpertResponse:
        """GÃ©nÃ¨re une clarification de suivi si premiÃ¨re rÃ©ponse incomplÃ¨te"""
        
        still_missing = validation["still_missing"]
        
        messages = {
            "fr": {
                "breed": "Il me manque encore la **race/souche**. Ross 308, Cobb 500, ou autre ?",
                "sex": "Il me manque encore le **sexe**. MÃ¢les, femelles, ou troupeau mixte ?",  
                "both": "Il me manque encore la **race et le sexe**. Exemple : \"Ross 308 mÃ¢les\""
            },
            "en": {
                "breed": "I still need the **breed/strain**. Ross 308, Cobb 500, or other?",
                "sex": "I still need the **sex**. Males, females, or mixed flock?",
                "both": "I still need the **breed and sex**. Example: \"Ross 308 males\""
            },
            "es": {
                "breed": "AÃºn necesito la **raza/cepa**. Â¿Ross 308, Cobb 500, u otra?",
                "sex": "AÃºn necesito el **sexo**. Â¿Machos, hembras, o lote mixto?",
                "both": "AÃºn necesito la **raza y sexo**. Ejemplo: \"Ross 308 machos\""
            }
        }
        
        lang_messages = messages.get(language, messages["fr"])
        
        if len(still_missing) >= 2:
            message = lang_messages["both"]
        elif "breed" in still_missing:
            message = lang_messages["breed"]
        else:
            message = lang_messages["sex"]
        
        return EnhancedExpertResponse(
            question=question,
            response=message,
            conversation_id=conversation_id,
            rag_used=False,
            rag_score=None,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=30,
            mode="follow_up_clarification",
            user=None,
            logged=True,
            validation_passed=True,
            clarification_result={
                "clarification_requested": True,
                "clarification_type": "follow_up_incomplete",
                "still_missing_information": still_missing,
                "confidence": validation["confidence"]
            },
            processing_steps=["follow_up_clarification_triggered"],
            ai_enhancements_used=["incomplete_clarification_handling"]
        )
    
    # === TRAITEMENT EXPERT AVEC RAG-FIRST + AMÃ‰LIORATIONS CORRIGÃ‰ ===
    
    async def _process_expert_response_enhanced_fixed(
        self, question_text: str, request_data: EnhancedQuestionRequest,
        request: Request, current_user: Optional[Dict], conversation_id: str,
        processing_steps: list, ai_enhancements_used: list,
        debug_info: Dict, performance_breakdown: Dict, vagueness_result = None
    ) -> Dict[str, Any]:
        """
        âœ… VERSION RAG PARFAITEMENT CORRIGÃ‰E
        
        CORRECTIONS CRITIQUES:
        1. RÃ©cupÃ©ration forcÃ©e du contexte conversationnel  
        2. Enrichissement automatique si clarification
        3. Contexte forcÃ© pour RAG mÃªme si pas supportÃ© nativement
        """
        
        # === 1. RÃ‰CUPÃ‰RATION FORCÃ‰E DU CONTEXTE CONVERSATIONNEL ===
        conversation_context_str = ""
        extracted_entities = {}
        
        if self.integrations.intelligent_memory_available:
            try:
                # âœ… RÃ‰CUPÃ‰RATION FORCÃ‰E DU CONTEXTE
                context_obj = self.integrations.get_conversation_context(conversation_id)
                if context_obj:
                    conversation_context_str = context_obj.get_context_for_rag(max_chars=800)
                    
                    # âœ… ENRICHISSEMENT SPÃ‰CIAL SI CLARIFICATION
                    if request_data.is_clarification_response or request_data.original_question:
                        # Ajouter explicitement le contexte de clarification
                        if request_data.original_question:
                            conversation_context_str = f"Question originale: {request_data.original_question}. " + conversation_context_str
                        
                        # Rechercher les infos breed/sex dans les messages rÃ©cents
                        for msg in reversed(context_obj.messages[-5:]):
                            if msg.role == "user" and any(word in msg.message.lower() for word in ["ross", "cobb", "hubbard", "mÃ¢le", "femelle"]):
                                conversation_context_str += f" | Clarification: {msg.message}"
                                break
                    
                    # EntitÃ©s consolidÃ©es
                    if hasattr(context_obj, 'consolidated_entities'):
                        extracted_entities = context_obj.consolidated_entities.to_dict()
                    
                    logger.info(f"ğŸ§  [Expert Service] Contexte enrichi rÃ©cupÃ©rÃ©: {conversation_context_str[:150]}...")
                    ai_enhancements_used.append("forced_contextual_rag")
                else:
                    logger.warning(f"âš ï¸ [Expert Service] Aucun contexte trouvÃ© pour: {conversation_id}")
                    
            except Exception as e:
                logger.error(f"âŒ [Expert Service] Erreur rÃ©cupÃ©ration contexte: {e}")
        
        performance_breakdown["context_retrieved"] = int(time.time() * 1000)
        
        # === 2. AMÃ‰LIORATION INTELLIGENTE DE LA QUESTION ===
        enriched_question, enhancement_info = self.rag_enhancer.enhance_question_for_rag(
            question=question_text,
            conversation_context=conversation_context_str,
            language=request_data.language
        )
        
        # âœ… ENRICHISSEMENT SUPPLÃ‰MENTAIRE SI VIENT D'UNE CLARIFICATION
        if request_data.original_question and request_data.is_clarification_response:
            # La question est dÃ©jÃ  enrichie par _process_clarification_response_fixed
            logger.info(f"âœ¨ [Expert Service] Question dÃ©jÃ  enrichie par clarification: {question_text[:100]}...")
            ai_enhancements_used.append("clarification_based_enrichment")
        
        if enhancement_info["question_enriched"]:
            ai_enhancements_used.append("intelligent_question_enhancement")
            logger.info(f"âœ¨ [Expert Service] Question amÃ©liorÃ©e: {enriched_question[:150]}...")
        
        if enhancement_info["pronoun_detected"]:
            ai_enhancements_used.append("contextual_pronoun_resolution")
            logger.info(f"ğŸ¯ [Expert Service] Pronoms contextuels rÃ©solus: {enhancement_info['context_entities_used']}")
        
        processing_steps.append("intelligent_question_enhancement")
        performance_breakdown["question_enhanced"] = int(time.time() * 1000)
        
        # === 3. VÃ‰RIFICATION RAG DISPONIBLE ===
        app = request.app
        process_rag = getattr(app.state, 'process_question_with_rag', None)
        
        if not process_rag:
            logger.error("âŒ [Expert Service] SystÃ¨me RAG indisponible - Erreur critique")
            raise HTTPException(
                status_code=503, 
                detail="Service RAG indisponible - Le systÃ¨me expert nÃ©cessite l'accÃ¨s Ã  la base documentaire"
            )
        
        # === 4. APPEL RAG AVEC CONTEXTE FORCÃ‰ ===
        try:
            logger.info("ğŸ” [Expert Service] Appel RAG avec contexte forcÃ©...")
            
            if request_data.debug_mode:
                debug_info["original_question"] = question_text
                debug_info["enriched_question"] = enriched_question
                debug_info["conversation_context"] = conversation_context_str
                debug_info["enhancement_info"] = enhancement_info
            
            # âœ… STRATÃ‰GIE MULTI-TENTATIVE POUR RAG AVEC CONTEXTE
            result = None
            rag_call_method = "unknown"
            
            # Tentative 1: Avec paramÃ¨tre context si supportÃ©
            try:
                result = await process_rag(
                    question=enriched_question,
                    user=current_user,
                    language=request_data.language,
                    speed_mode=request_data.speed_mode,
                    context=conversation_context_str
                )
                rag_call_method = "context_parameter"
                logger.info("âœ… [Expert Service] RAG appelÃ© avec paramÃ¨tre context")
            except TypeError as te:
                logger.info(f"â„¹ï¸ [Expert Service] ParamÃ¨tre context non supportÃ©: {te}")
                
                # Tentative 2: Injection du contexte dans la question
                if conversation_context_str:
                    contextual_question = f"{enriched_question}\n\nContexte: {conversation_context_str}"
                    result = await process_rag(
                        question=contextual_question,
                        user=current_user,
                        language=request_data.language,
                        speed_mode=request_data.speed_mode
                    )
                    rag_call_method = "context_injected"
                    logger.info("âœ… [Expert Service] RAG appelÃ© avec contexte injectÃ©")
                else:
                    # Tentative 3: Question enrichie seule
                    result = await process_rag(
                        question=enriched_question,
                        user=current_user,
                        language=request_data.language,
                        speed_mode=request_data.speed_mode
                    )
                    rag_call_method = "enriched_only"
                    logger.info("âœ… [Expert Service] RAG appelÃ© avec question enrichie seule")
            
            performance_breakdown["rag_complete"] = int(time.time() * 1000)
            
            # === 5. TRAITEMENT RÃ‰SULTAT RAG ===
            answer = str(result.get("response", ""))
            rag_score = result.get("score", 0.0)
            original_mode = result.get("mode", "rag_processing")
            
            # Validation qualitÃ©
            quality_check = self._validate_rag_response_quality(
                answer, enriched_question, enhancement_info
            )
            
            if not quality_check["valid"]:
                logger.warning(f"âš ï¸ [Expert Service] QualitÃ© RAG insuffisante: {quality_check['reason']}")
                ai_enhancements_used.append("quality_validation_failed")
            
            logger.info(f"âœ… [Expert Service] RAG rÃ©ponse reÃ§ue: {len(answer)} caractÃ¨res, score: {rag_score}")
            
            # Mode enrichi avec mÃ©thode d'appel
            mode = f"enhanced_contextual_{original_mode}_{rag_call_method}"
            
            processing_steps.append("mandatory_rag_with_forced_context")
            
            return {
                "answer": answer,
                "rag_used": True,
                "rag_score": rag_score,
                "mode": mode,
                "context_used": bool(conversation_context_str),
                "question_enriched": enhancement_info["question_enriched"] or bool(request_data.original_question),
                "enhancement_info": enhancement_info,
                "quality_check": quality_check,
                "extracted_entities": extracted_entities,
                "rag_call_method": rag_call_method
            }
            
        except Exception as rag_error:
            logger.error(f"âŒ [Expert Service] Erreur critique RAG: {rag_error}")
            processing_steps.append("rag_error")
            
            error_details = {
                "error": "Erreur RAG",
                "message": "Impossible d'interroger la base documentaire",
                "question_original": question_text,
                "question_enriched": enriched_question,
                "context_available": bool(conversation_context_str),
                "technical_error": str(rag_error)
            }
            
            raise HTTPException(status_code=503, detail=error_details)
    
    # === MÃ‰THODES UTILITAIRES IDENTIQUES ===
    
    def _create_vagueness_response(
        self, vagueness_result, question_text: str, conversation_id: str,
        language: str, start_time: float, processing_steps: list, ai_enhancements_used: list
    ) -> EnhancedExpertResponse:
        """CrÃ©e une rÃ©ponse spÃ©cialisÃ©e pour questions floues"""
        
        clarification_messages = {
            "fr": f"Votre question semble manquer de prÃ©cision. {vagueness_result.suggested_clarification or 'Pouvez-vous Ãªtre plus spÃ©cifique ?'}",
            "en": f"Your question seems to lack precision. {vagueness_result.suggested_clarification or 'Could you be more specific?'}",
            "es": f"Su pregunta parece carecer de precisiÃ³n. {vagueness_result.suggested_clarification or 'Â¿PodrÃ­a ser mÃ¡s especÃ­fico?'}"
        }
        
        response_message = clarification_messages.get(language, clarification_messages["fr"])
        
        # Ajouter des exemples de questions
        if vagueness_result.question_clarity in ["very_unclear", "unclear"]:
            examples = {
                "fr": "\n\nExemples de questions prÃ©cises:\nâ€¢ Quel est le poids normal d'un Ross 308 de 21 jours?\nâ€¢ Comment traiter la mortalitÃ© Ã©levÃ©e chez des poulets de 3 semaines?\nâ€¢ Quelle tempÃ©rature maintenir pour des poussins de 7 jours?",
                "en": "\n\nExamples of precise questions:\nâ€¢ What is the normal weight of a 21-day Ross 308?\nâ€¢ How to treat high mortality in 3-week-old chickens?\nâ€¢ What temperature to maintain for 7-day chicks?",
                "es": "\n\nEjemplos de preguntas precisas:\nâ€¢ Â¿CuÃ¡l es el peso normal de un Ross 308 de 21 dÃ­as?\nâ€¢ Â¿CÃ³mo tratar la alta mortalidad en pollos de 3 semanas?\nâ€¢ Â¿QuÃ© temperatura mantener para pollitos de 7 dÃ­as?"
            }
            response_message += examples.get(language, examples["fr"])
        
        response_time_ms = int((time.time() - start_time) * 1000)
        
        return EnhancedExpertResponse(
            question=question_text,
            response=response_message,
            conversation_id=conversation_id,
            rag_used=False,
            rag_score=None,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=response_time_ms,
            mode="vagueness_clarification",
            user=None,
            logged=True,
            validation_passed=True,
            vagueness_detection=vagueness_result,
            processing_steps=processing_steps,
            ai_enhancements_used=ai_enhancements_used
        )
    
    def _build_final_enhanced_response(
        self, question_text: str, answer: str, conversation_id: str,
        user_email: Optional[str], language: str, response_time_ms: int,
        expert_result: Dict, validation_result: ValidationResult,
        conversation_context: Any, processing_steps: list,
        ai_enhancements_used: list, request_data: EnhancedQuestionRequest,
        debug_info: Dict, performance_breakdown: Dict
    ) -> EnhancedExpertResponse:
        """Construit la rÃ©ponse finale avec toutes les amÃ©liorations"""
        
        # MÃ©triques finales
        extracted_entities = expert_result.get("extracted_entities")
        confidence_overall = None
        conversation_state = None
        
        if conversation_context and hasattr(conversation_context, 'consolidated_entities'):
            if not extracted_entities:
                extracted_entities = conversation_context.consolidated_entities.to_dict()
            confidence_overall = conversation_context.consolidated_entities.confidence_overall
            conversation_state = conversation_context.conversation_urgency
        
        # Informations de debug si activÃ©es
        final_debug_info = None
        final_performance = None
        
        if request_data.debug_mode:
            final_debug_info = {
                **debug_info,
                "total_processing_time_ms": response_time_ms,
                "ai_enhancements_count": len(ai_enhancements_used),
                "processing_steps_count": len(processing_steps)
            }
            
            final_performance = performance_breakdown
            
        return EnhancedExpertResponse(
            # Champs existants
            question=str(question_text),
            response=str(answer),
            conversation_id=conversation_id,
            rag_used=expert_result["rag_used"],
            rag_score=expert_result["rag_score"],
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=response_time_ms,
            mode=expert_result["mode"],
            user=user_email,
            logged=True,
            validation_passed=True,
            validation_confidence=validation_result.confidence,
            reprocessed_after_clarification=request_data.is_clarification_response,
            conversation_state=conversation_state,
            extracted_entities=extracted_entities,
            confidence_overall=confidence_overall,
            processing_steps=processing_steps,
            ai_enhancements_used=ai_enhancements_used,
            
            # Nouvelles fonctionnalitÃ©s
            document_relevance=expert_result.get("document_relevance"),
            context_coherence=expert_result.get("context_coherence"),
            vagueness_detection=None,
            fallback_details=None,
            response_format_applied=request_data.expected_response_format.value,
            quality_metrics=expert_result.get("quality_metrics"),
            debug_info=final_debug_info,
            performance_breakdown=final_performance
        )
    
    # === MÃ‰THODES UTILITAIRES ===
    
    def _extract_user_id(self, current_user: Optional[Dict], request_data: EnhancedQuestionRequest, request: Request) -> str:
        if current_user:
            return current_user.get("user_id") or request_data.user_id or "authenticated_user"
        return request_data.user_id or get_user_id_from_request(request)
    
    def _get_or_create_conversation_id(self, request_data: EnhancedQuestionRequest) -> str:
        if request_data.conversation_id and request_data.conversation_id.strip():
            conversation_id = request_data.conversation_id.strip()
            logger.info(f"ğŸ”„ [Expert Service] CONTINUATION: {conversation_id}")
            return conversation_id
        else:
            conversation_id = str(uuid.uuid4())
            logger.info(f"ğŸ†• [Expert Service] NOUVELLE: {conversation_id}")
            return conversation_id
    
    def _validate_rag_response_quality(
        self, answer: str, enriched_question: str, enhancement_info: Dict
    ) -> Dict[str, any]:
        """Valide la qualitÃ© de la rÃ©ponse RAG"""
        
        if not answer or len(answer.strip()) < 20:
            return {
                "valid": False,
                "reason": "RÃ©ponse trop courte",
                "answer_length": len(answer) if answer else 0
            }
        
        negative_responses = [
            "je ne sais pas", "i don't know", "no sÃ©",
            "pas d'information", "no information", "sin informaciÃ³n"
        ]
        
        answer_lower = answer.lower()
        for negative in negative_responses:
            if negative in answer_lower:
                return {
                    "valid": False,
                    "reason": f"RÃ©ponse nÃ©gative dÃ©tectÃ©e: {negative}",
                    "answer_length": len(answer)
                }
        
        if any(word in enriched_question.lower() for word in ["poids", "weight", "peso"]):
            if not re.search(r'\d+', answer):
                return {
                    "valid": False,
                    "reason": "Question numÃ©rique mais pas de chiffres dans la rÃ©ponse",
                    "answer_length": len(answer)
                }
        
        return {
            "valid": True,
            "reason": "RÃ©ponse valide",
            "answer_length": len(answer)
        }
    
    # Autres mÃ©thodes (validation, feedback, etc.) identiques...
    async def _validate_agricultural_question(self, question: str, language: str, user_id: str, request_ip: str, conversation_id: str) -> ValidationResult:
        if not self.integrations.agricultural_validator_available:
            return ValidationResult(is_valid=False, rejection_message="Service temporairement indisponible")
        
        try:
            enriched_question = question
            if self.integrations.intelligent_memory_available:
                try:
                    rag_context = self.integrations.get_context_for_rag(conversation_id)
                    if rag_context:
                        enriched_question = f"{question}\n\nContexte: {rag_context}"
                except Exception:
                    pass
            
            validation_result = self.integrations.validate_agricultural_question(
                question=enriched_question, language=language, user_id=user_id, request_ip=request_ip
            )
            
            return ValidationResult(
                is_valid=validation_result.is_valid,
                rejection_message=validation_result.reason or "Question hors domaine agricole",
                confidence=validation_result.confidence
            )
            
        except Exception as e:
            logger.error(f"âŒ [Expert Service] Erreur validateur: {e}")
            return ValidationResult(is_valid=False, rejection_message="Erreur de validation")
    
    def _create_rejection_response(self, question_text, validation_result, conversation_id, user_email, language, start_time, processing_steps, ai_enhancements_used, vagueness_result=None):
        response_time_ms = int((time.time() - start_time) * 1000)
        
        return EnhancedExpertResponse(
            question=str(question_text),
            response=str(validation_result.rejection_message),
            conversation_id=conversation_id,
            rag_used=False,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=response_time_ms,
            mode="enhanced_agricultural_validation_rejected",
            user=user_email,
            logged=True,
            validation_passed=False,
            validation_confidence=validation_result.confidence,
            processing_steps=processing_steps,
            ai_enhancements_used=ai_enhancements_used,
            vagueness_detection=vagueness_result
        )
    
    async def process_feedback(self, feedback_data: FeedbackRequest) -> Dict[str, Any]:
        feedback_updated = False
        
        if feedback_data.conversation_id and self.integrations.logging_available:
            try:
                rating_numeric = {"positive": 1, "negative": -1, "neutral": 0}.get(feedback_data.rating, 0)
                feedback_updated = await self.integrations.update_feedback(feedback_data.conversation_id, rating_numeric)
            except Exception as e:
                logger.error(f"âŒ [Expert Service] Erreur feedback: {e}")
        
        return {
            "success": True,
            "message": "Feedback enregistrÃ© avec succÃ¨s (Enhanced)",
            "rating": feedback_data.rating,
            "comment": feedback_data.comment,
            "conversation_id": feedback_data.conversation_id,
            "feedback_updated_in_db": feedback_updated,
            "enhanced_features_used": True,
            "timestamp": datetime.now().isoformat()
        }
    
    async def get_suggested_topics(self, language: str) -> Dict[str, Any]:
        lang = language.lower() if language else "fr"
        if lang not in ["fr", "en", "es"]:
            lang = "fr"
        
        topics_by_language = get_enhanced_topics_by_language()
        topics = topics_by_language.get(lang, topics_by_language["fr"])
        
        return {
            "topics": topics,
            "language": lang,
            "count": len(topics),
            "enhanced_features": {
                "vagueness_detection_available": True,
                "context_coherence_available": True,
                "detailed_rag_scoring_available": True,
                "quality_metrics_available": True,
                "smart_clarification_available": True
            },
            "system_status": {
                "validation_enabled": self.integrations.is_agricultural_validation_enabled(),
                "enhanced_clarification_enabled": self.integrations.is_enhanced_clarification_enabled(),
                "intelligent_memory_enabled": self.integrations.intelligent_memory_available,
                "api_enhancements_enabled": True
            }
        }

# =============================================================================
# CONFIGURATION FINALE
# =============================================================================

logger.info("âœ… [Expert Service] Services mÃ©tier PARFAITEMENT CORRIGÃ‰S avec CLARIFICATION INTELLIGENTE")
logger.info("ğŸš€ [Expert Service] CORRECTIONS CRITIQUES APPLIQUÃ‰ES:")
logger.info("   - âœ… ORDRE DE PRIORITÃ‰ CORRIGÃ‰ : Clarification spÃ©cialisÃ©e AVANT vagueness gÃ©nÃ©rale")
logger.info("   - ğŸ’¾ Sauvegarde forcÃ©e question originale dans mÃ©moire conversationnelle")
logger.info("   - ğŸ”„ RÃ©cupÃ©ration intelligente contexte pour rÃ©ponses clarification")
logger.info("   - ğŸ¯ DÃ©tection amÃ©liorÃ©e rÃ©ponses courtes (Ross 308)")
logger.info("   - ğŸ§  Contexte forcÃ© pour RAG aprÃ¨s clarification")
logger.info("   - âš¡ StratÃ©gie multi-tentative appel RAG avec contexte")
logger.info("   - ğŸ”§ Gestion d'erreur robuste et fallback intelligent")
logger.info("âœ… [Expert Service] SYSTÃˆME DE CLARIFICATION MAINTENANT PARFAIT!")