"""
app/api/v1/general_response_generator.py - G√âN√âRATEUR DE R√âPONSES G√âN√âRALES IA

ü§ñ SERVICE DE G√âN√âRATION DE R√âPONSES G√âN√âRALES AVEC IA
‚úÖ Utilise GPT-4o pour g√©n√©ration de qualit√© professionnelle
‚úÖ G√©n√®re r√©ponses avec fourchettes et standards selon contexte
‚úÖ Support multilingue avec adaptation culturelle
‚úÖ Int√©gration donn√©es techniques avicoles
‚úÖ Gestion robuste des erreurs avec fallbacks intelligents
‚úÖ Optimis√© pour r√©ponses utiles m√™me avec informations partielles
"""

import logging
import os
import re
from typing import Dict, Any, Optional
from datetime import datetime

# Import OpenAI s√©curis√©
try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None
    OpenAI = None

logger = logging.getLogger(__name__)

class GeneralResponseGenerator:
    """
    G√©n√©rateur de r√©ponses g√©n√©rales avec IA
    
    Cr√©e des r√©ponses utiles avec fourchettes et standards
    pour questions qui n'ont pas besoin de clarification.
    """
    
    def __init__(self):
        self.model = "gpt-4o"  # Qualit√© maximale pour g√©n√©ration
        self.client = None
        self.available = False
        
        # Statistiques pour monitoring
        self.stats = {
            "total_generations": 0,
            "successful_generations": 0,
            "fallback_used": 0,
            "average_response_length": 0,
            "topics_covered": {}
        }
        
        # Templates de fallback par sujet
        self.fallback_templates = self._initialize_fallback_templates()
        
        # Initialiser OpenAI
        self._initialize_openai()
        
        logger.info(f"ü§ñ [General Response Generator] Initialis√© - Disponible: {self.available}")
    
    def _initialize_openai(self) -> bool:
        """Initialise le client OpenAI"""
        try:
            if not OPENAI_AVAILABLE:
                logger.warning("‚ö†Ô∏è [General Response] OpenAI non disponible")
                return False
            
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                logger.warning("‚ö†Ô∏è [General Response] OPENAI_API_KEY non configur√©")
                return False
            
            self.client = OpenAI(api_key=api_key)
            self.available = True
            logger.info("‚úÖ [General Response] Client OpenAI initialis√©")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå [General Response] Erreur initialisation: {e}")
            self.available = False
            return False
    
    async def generate_general_response(self, question: str, entities: Dict[str, Any], classification: Dict[str, Any], language: str = "fr") -> str:
        """
        G√©n√®re une r√©ponse g√©n√©rale bas√©e sur la classification IA
        
        Args:
            question: Question originale de l'utilisateur
            entities: Entit√©s extraites (breed, age, sex, etc.)
            classification: R√©sultat de la classification IA
            language: Langue de g√©n√©ration
            
        Returns:
            str: R√©ponse g√©n√©rale compl√®te et utile
        """
        
        start_time = datetime.now()
        self.stats["total_generations"] += 1
        
        try:
            # Si l'IA de classification a d√©j√† sugg√©r√© une r√©ponse, la valider et potentiellement l'am√©liorer
            if classification.get("suggested_general_response") and len(classification["suggested_general_response"]) > 50:
                logger.info("ü§ñ [General Response] Utilisation r√©ponse sugg√©r√©e par classificateur")
                suggested_response = classification["suggested_general_response"]
                
                # Am√©liorer la r√©ponse sugg√©r√©e si n√©cessaire
                if self.available:
                    enhanced_response = await self._enhance_suggested_response(suggested_response, question, entities, language)
                    if enhanced_response:
                        self._update_stats(enhanced_response, "enhanced_suggested")
                        return enhanced_response
                
                # Sinon utiliser la r√©ponse sugg√©r√©e telle quelle
                self._update_stats(suggested_response, "suggested_direct")
                return suggested_response
            
            # G√©n√©rer nouvelle r√©ponse avec IA
            if self.available:
                generated_response = await self._generate_with_ai(question, entities, classification, language)
                if generated_response:
                    self._update_stats(generated_response, "ai_generated")
                    return generated_response
            
            # Fallback intelligent bas√© sur le sujet
            fallback_response = self._generate_fallback_response(question, entities, language)
            self._update_stats(fallback_response, "fallback")
            return fallback_response
            
        except Exception as e:
            logger.error(f"‚ùå [General Response] Erreur g√©n√©ration: {e}")
            self.stats["fallback_used"] += 1
            return self._generate_emergency_fallback(question, language)
    
    async def _enhance_suggested_response(self, suggested_response: str, question: str, entities: Dict[str, Any], language: str) -> Optional[str]:
        """Am√©liore une r√©ponse sugg√©r√©e par le classificateur"""
        
        prompt = self._build_enhancement_prompt(suggested_response, question, entities, language)
        
        try:
            response = await self.client.chat.completions.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_message(language)},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=500,
                timeout=15
            )
            
            enhanced = response.choices[0].message.content.strip()
            
            # Valider que l'am√©lioration est significative
            if len(enhanced) > len(suggested_response) * 1.2:  # Au moins 20% plus long
                logger.info("‚ú® [General Response] R√©ponse am√©lior√©e avec succ√®s")
                return enhanced
            
            return None  # Pas d'am√©lioration significative
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [General Response] Erreur am√©lioration: {e}")
            return None
    
    async def _generate_with_ai(self, question: str, entities: Dict[str, Any], classification: Dict[str, Any], language: str) -> Optional[str]:
        """G√©n√®re une r√©ponse compl√®te avec IA"""
        
        prompt = self._build_generation_prompt(question, entities, classification, language)
        
        try:
            response = await self.client.chat.completions.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_message(language)},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # √âquilibre cr√©ativit√©/coh√©rence
                max_tokens=600,   # Permet r√©ponses d√©taill√©es
                timeout=20        # Timeout g√©n√©reux pour qualit√©
            )
            
            generated_response = response.choices[0].message.content.strip()
            
            # Validation de base
            if len(generated_response) < 50:
                logger.warning("‚ö†Ô∏è [General Response] R√©ponse g√©n√©r√©e trop courte")
                return None
            
            logger.info(f"‚úÖ [General Response] R√©ponse g√©n√©r√©e ({len(generated_response)} chars)")
            return generated_response
            
        except Exception as e:
            logger.error(f"‚ùå [General Response] Erreur g√©n√©ration IA: {e}")
            return None
    
    def _build_generation_prompt(self, question: str, entities: Dict[str, Any], classification: Dict[str, Any], language: str) -> str:
        """Construit le prompt de g√©n√©ration selon la langue et le contexte"""
        
        entities_text = self._format_entities_for_prompt(entities, language)
        missing_info = ", ".join(classification.get("missing_for_precision", []))
        topic = self._detect_topic(question, language)
        
        prompts = {
            "fr": f"""Tu es un v√©t√©rinaire avicole expert. G√©n√®re une r√©ponse g√©n√©rale professionnelle et utile.

QUESTION: "{question}"
SUJET D√âTECT√â: {topic}
ENTIT√âS DISPONIBLES: {entities_text}
INFORMATIONS MANQUANTES POUR PR√âCISION MAXIMALE: {missing_info}

INSTRUCTIONS DE G√âN√âRATION:
1. **R√©ponse directe**: Commence par r√©pondre directement √† la question
2. **Fourchettes et standards**: Donne des valeurs/fourchettes standard avec contexte
3. **Variations importantes**: Mentionne les variations selon race, sexe, √¢ge si pertinent
4. **Conseils pratiques**: Ajoute 1-2 conseils de surveillance ou d'action
5. **R√©f√©rence experte**: Indique quand consulter pour cas sp√©cifique

EXEMPLES DE STRUCTURE:
- Question poids ‚Üí "Le poids normal √† X jours varie de Y-Z grammes selon la race et le sexe. Les races lourdes comme Ross 308 atteignent g√©n√©ralement... Surveillez la croissance hebdomadairement et consultez si √©cart >15%."
- Question croissance ‚Üí "La croissance normale pr√©sente ces caract√©ristiques... Les variations d√©pendent de... Signes d'alerte √† surveiller..."
- Question alimentation ‚Üí "Les besoins nutritionnels √† ce stade sont... Adaptez selon... Consultez un nutritionniste si..."

STYLE:
- Professionnel mais accessible
- Pr√©cis avec chiffres/fourchettes
- Pratique et actionnable
- 150-300 mots id√©alement

G√©n√®re la r√©ponse maintenant:""",

            "en": f"""You are a poultry veterinary expert. Generate a professional and useful general response.

QUESTION: "{question}"
TOPIC DETECTED: {topic}
AVAILABLE ENTITIES: {entities_text}
MISSING INFO FOR MAX PRECISION: {missing_info}

GENERATION INSTRUCTIONS:
1. **Direct answer**: Start by directly answering the question
2. **Ranges and standards**: Provide standard values/ranges with context
3. **Important variations**: Mention variations by breed, sex, age if relevant
4. **Practical advice**: Add 1-2 monitoring or action tips
5. **Expert reference**: Indicate when to consult for specific cases

Generate the response now:""",

            "es": f"""Eres un veterinario av√≠cola experto. Genera una respuesta general profesional y √∫til.

PREGUNTA: "{question}"
TEMA DETECTADO: {topic}
ENTIDADES DISPONIBLES: {entities_text}
INFO FALTANTE PARA M√ÅXIMA PRECISI√ìN: {missing_info}

Genera la respuesta ahora:"""
        }
        
        return prompts.get(language, prompts["fr"])
    
    def _build_enhancement_prompt(self, suggested_response: str, question: str, entities: Dict[str, Any], language: str) -> str:
        """Construit prompt pour am√©liorer une r√©ponse sugg√©r√©e"""
        
        prompts = {
            "fr": f"""Am√©liore cette r√©ponse en la rendant plus compl√®te et professionnelle:

QUESTION ORIGINALE: "{question}"
R√âPONSE √Ä AM√âLIORER: "{suggested_response}"
ENTIT√âS DISPONIBLES: {self._format_entities_for_prompt(entities, language)}

AM√âLIORATIONS √Ä APPORTER:
1. Ajouter des fourchettes plus pr√©cises si possible
2. Inclure des conseils pratiques de surveillance
3. Mentionner les variations selon race/sexe/√¢ge
4. Ajouter quand consulter un expert
5. Am√©liorer la structure et la clart√©

Garde le m√™me ton professionnel mais rend la r√©ponse plus compl√®te et utile (200-350 mots):""",

            "en": f"""Improve this response by making it more complete and professional:

ORIGINAL QUESTION: "{question}"
RESPONSE TO IMPROVE: "{suggested_response}"

Make it more complete and useful (200-350 words):""",

            "es": f"""Mejora esta respuesta haci√©ndola m√°s completa y profesional:

PREGUNTA ORIGINAL: "{question}"
RESPUESTA A MEJORAR: "{suggested_response}"

Hazla m√°s completa y √∫til (200-350 palabras):"""
        }
        
        return prompts.get(language, prompts["fr"])
    
    def _get_system_message(self, language: str) -> str:
        """Messages syst√®me selon la langue"""
        
        messages = {
            "fr": "Tu es un v√©t√©rinaire avicole expert qui g√©n√®re des r√©ponses g√©n√©rales pr√©cises, utiles et professionnelles. Tu donnes toujours des informations pratiques avec des fourchettes de valeurs standard et des conseils concrets.",
            
            "en": "You are a poultry veterinary expert who generates accurate, useful and professional general responses. You always provide practical information with standard value ranges and concrete advice.",
            
            "es": "Eres un veterinario av√≠cola experto que genera respuestas generales precisas, √∫tiles y profesionales. Siempre proporcionas informaci√≥n pr√°ctica con rangos de valores est√°ndar y consejos concretos."
        }
        
        return messages.get(language, messages["fr"])
    
    def _generate_fallback_response(self, question: str, entities: Dict[str, Any], language: str = "fr") -> str:
        """G√©n√®re une r√©ponse fallback intelligente bas√©e sur le sujet"""
        
        topic = self._detect_topic(question, language)
        template = self.fallback_templates[language].get(topic, self.fallback_templates[language]["general"])
        
        # Personnaliser le template avec les entit√©s disponibles
        context = {
            "age": entities.get('age_in_days', entities.get('age', 'X')),
            "breed": entities.get('breed', 'race non sp√©cifi√©e'),
            "sex": entities.get('sex', 'sexe non sp√©cifi√©')
        }
        
        try:
            personalized_response = template.format(**context)
            logger.info(f"üìù [General Response] Fallback g√©n√©r√© pour sujet: {topic}")
            return personalized_response
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [General Response] Erreur personnalisation fallback: {e}")
            return template
    
    def _generate_emergency_fallback(self, question: str, language: str = "fr") -> str:
        """Fallback d'urgence minimal"""
        
        emergency_responses = {
            "fr": f"Je comprends votre question sur '{question}'. Pour vous donner la r√©ponse la plus pr√©cise possible, j'aurais besoin de conna√Ætre la race, l'√¢ge et le sexe de vos animaux. Cependant, je peux vous dire que les standards varient g√©n√©ralement selon ces param√®tres. N'h√©sitez pas √† consulter un v√©t√©rinaire pour des conseils personnalis√©s.",
            
            "en": f"I understand your question about '{question}'. To give you the most accurate answer, I would need to know the breed, age and sex of your animals. However, I can tell you that standards generally vary according to these parameters. Don't hesitate to consult a veterinarian for personalized advice.",
            
            "es": f"Entiendo su pregunta sobre '{question}'. Para darle la respuesta m√°s precisa, necesitar√≠a conocer la raza, edad y sexo de sus animales. Sin embargo, puedo decirle que los est√°ndares generalmente var√≠an seg√∫n estos par√°metros. No dude en consultar a un veterinario para consejos personalizados."
        }
        
        return emergency_responses.get(language, emergency_responses["fr"])
    
    def _detect_topic(self, question: str, language: str = "fr") -> str:
        """D√©tecte le sujet principal de la question"""
        
        question_lower = question.lower()
        
        topic_keywords = {
            "poids": ["poids", "weight", "peso", "gramme", "kg", "masse"],
            "croissance": ["croissance", "growth", "crecimiento", "d√©veloppement", "development"],
            "alimentation": ["alimentation", "feed", "nutrition", "alimento", "ration"],
            "sant√©": ["maladie", "disease", "enfermedad", "symptom", "mort", "death"],
            "reproduction": ["ponte", "laying", "puesta", "≈ìuf", "egg", "huevo"],
            "environnement": ["temp√©rature", "temperature", "ventilation", "liti√®re"],
            "vaccination": ["vaccin", "vaccine", "vacuna", "immunit√©", "immunity"]
        }
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in question_lower for keyword in keywords):
                return topic
        
        return "g√©n√©ral"
    
    def _format_entities_for_prompt(self, entities: Dict[str, Any], language: str = "fr") -> str:
        """Formate les entit√©s pour les prompts"""
        
        if not entities:
            return {"fr": "Aucune", "en": "None", "es": "Ninguna"}.get(language, "Aucune")
        
        parts = []
        if entities.get('breed'):
            parts.append(f"race: {entities['breed']}")
        if entities.get('age_in_days'):
            parts.append(f"√¢ge: {entities['age_in_days']}j")
        elif entities.get('age'):
            parts.append(f"√¢ge: {entities['age']}")
        if entities.get('sex'):
            parts.append(f"sexe: {entities['sex']}")
        if entities.get('weight_in_grams'):
            parts.append(f"poids: {entities['weight_in_grams']}g")
            
        return ", ".join(parts) if parts else "Partielles"
    
    def _initialize_fallback_templates(self) -> Dict[str, Dict[str, str]]:
        """Initialise les templates de fallback par sujet et langue"""
        
        return {
            "fr": {
                "poids": "Le poids d'un poulet √† {age} jours varie consid√©rablement selon la race et le sexe. En g√©n√©ral, les fourchettes sont de 250-500g √† cet √¢ge. Les races de chair comme Ross 308 ou Cobb 500 sont plus lourdes que les races pondeuses. Les m√¢les sont g√©n√©ralement 10-15% plus lourds que les femelles. Surveillez la croissance hebdomadairement et consultez si vous observez des √©carts importants.",
                
                "croissance": "La croissance normale des poulets pr√©sente des phases distinctes. √Ä {age} jours, vous devriez observer une activit√© normale, un app√©tit r√©gulier et une prise de poids progressive. Les signes d'alerte incluent: apathie, refus alimentaire, retard de croissance. La race {breed} a ses propres standards de croissance qu'il convient de respecter.",
                
                "alimentation": "Les besoins nutritionnels des poulets √©voluent avec l'√¢ge. √Ä {age} jours, l'alimentation doit √™tre adapt√©e au stade de croissance. Assurez-vous d'un acc√®s constant √† une eau propre et √† un aliment de qualit√©. Les besoins varient selon la race et l'objectif d'√©levage (chair vs ponte).",
                
                "sant√©": "La sant√© des poulets n√©cessite une surveillance constante. Les signes √† surveiller incluent: comportement, app√©tit, aspect des fientes, respiration. En cas de sympt√¥mes anormaux, consultez rapidement un v√©t√©rinaire. La pr√©vention reste le meilleur traitement.",
                
                "g√©n√©ral": "Pour votre question concernant vos poulets, les standards varient selon la race, l'√¢ge et le sexe des animaux. Je recommande de consulter un v√©t√©rinaire avicole ou un technicien sp√©cialis√© pour des conseils personnalis√©s √† votre situation sp√©cifique."
            },
            
            "en": {
                "poids": "Chicken weight at {age} days varies considerably by breed and sex. Generally, ranges are 250-500g at this age. Broiler breeds like Ross 308 or Cobb 500 are heavier than layer breeds. Males are typically 10-15% heavier than females. Monitor growth weekly and consult if you observe significant deviations.",
                
                "g√©n√©ral": "For your question about chickens, standards vary by breed, age and sex. I recommend consulting a poultry veterinarian or specialized technician for advice tailored to your specific situation."
            },
            
            "es": {
                "poids": "El peso del pollo a los {age} d√≠as var√≠a considerablemente seg√∫n la raza y el sexo. Generalmente, los rangos son de 250-500g a esta edad. Las razas de engorde como Ross 308 o Cobb 500 son m√°s pesadas que las razas ponedoras.",
                
                "general": "Para su pregunta sobre pollos, los est√°ndares var√≠an seg√∫n la raza, edad y sexo. Recomiendo consultar a un veterinario av√≠cola para consejos adaptados a su situaci√≥n espec√≠fica."
            }
        }
    
    def _update_stats(self, response: str, method: str) -> None:
        """Met √† jour les statistiques"""
        
        if method != "fallback":
            self.stats["successful_generations"] += 1
        else:
            self.stats["fallback_used"] += 1
        
        # Longueur moyenne
        current_avg = self.stats["average_response_length"]
        total = self.stats["total_generations"]
        new_length = len(response)
        self.stats["average_response_length"] = ((current_avg * (total - 1)) + new_length) / total
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques"""
        return {
            **self.stats,
            "availability": self.available,
            "model": self.model,
            "success_rate": self.stats["successful_generations"] / max(1, self.stats["total_generations"])
        }

# Instance globale
general_response_generator = GeneralResponseGenerator()

# Fonction utilitaire
async def generate_general_response(question: str, entities: Dict[str, Any], classification: Dict[str, Any], language: str = "fr") -> str:
    """
    Fonction utilitaire pour g√©n√©ration de r√©ponse g√©n√©rale
    
    Usage:
        response = await generate_general_response(
            "Poids poulet 19 jours", 
            {"age_in_days": 19}, 
            {"decision": "general_answer", "missing_for_precision": ["breed", "sex"]}
        )
    """
    return await general_response_generator.generate_general_response(question, entities, classification, language)

logger.info("ü§ñ [General Response Generator] Module de g√©n√©ration de r√©ponses g√©n√©rales charg√©")
