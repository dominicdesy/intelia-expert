"""
app/api/v1/conversation_memory_complete_rewrite.py - R√â√âCRITURE COMPL√àTE AVEC CORRECTIONS

üö® R√â√âCRITURE COMPL√àTE BAS√âE SUR L'ORIGINAL AVEC TOUTES LES CORRECTIONS:
‚úÖ Attribut 'weight' ajout√© et synchronis√© avec weight_grams
‚úÖ Gestion s√©curis√©e des types str/int dans toutes les comparaisons
‚úÖ Fallback robuste sans d√©pendances manquantes
‚úÖ Validation d'incoh√©rences avec enrichissement automatique
‚úÖ Tous les attributs requis pr√©sents et correctement typ√©s
‚úÖ Gestion d'erreurs renforc√©e pour extraction IA
‚úÖ Normalisation des types avant comparaison
‚úÖ Code totalement revu et test√©
"""

import os
import json
import logging
import sqlite3
import re
import asyncio
import weakref
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union, Callable, Protocol
from dataclasses import dataclass, asdict, field
from contextlib import contextmanager
import time
import threading
from threading import Lock, RLock
from copy import deepcopy

# Import OpenAI s√©curis√© pour extraction intelligente
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

logger = logging.getLogger(__name__)

# Protocol pour typage s√©curis√© des callbacks
class RAGCallbackProtocol(Protocol):
    """Protocol pour les callbacks de retraitement RAG"""
    async def __call__(
        self,
        question: str,
        conversation_id: str,
        user_id: str,
        language: str = "fr",
        is_reprocessing: bool = False
    ) -> Dict[str, Any]:
        ...

def safe_int_conversion(value: Any) -> Optional[int]:
    """Convertit une valeur en int de mani√®re s√©curis√©e"""
    if value is None:
        return None
    try:
        if isinstance(value, str):
            # Nettoyer la cha√Æne (espaces, caract√®res non num√©riques de base)
            cleaned = re.sub(r'[^\d.]', '', value)
            if cleaned:
                return int(float(cleaned))
        elif isinstance(value, (int, float)):
            return int(value)
    except (ValueError, TypeError):
        pass
    return None

def safe_float_conversion(value: Any) -> Optional[float]:
    """Convertit une valeur en float de mani√®re s√©curis√©e"""
    if value is None:
        return None
    try:
        if isinstance(value, str):
            cleaned = re.sub(r'[^\d.]', '', value)
            if cleaned:
                return float(cleaned)
        elif isinstance(value, (int, float)):
            return float(value)
    except (ValueError, TypeError):
        pass
    return None

@dataclass
class IntelligentEntities:
    """Entit√©s extraites intelligemment avec raisonnement contextuel - VERSION COMPL√àTEMENT CORRIG√âE"""
    
    # üîß FIX 1: TOUS LES ATTRIBUTS REQUIS AVEC TYPES CORRECTS
    # Informations de base
    breed: Optional[str] = None
    breed_confidence: float = 0.0
    breed_type: Optional[str] = None  # specific/generic
    
    # Sexe avec variations multilingues
    sex: Optional[str] = None
    sex_confidence: float = 0.0
    
    # üîß FIX 2: √ÇGE - Tous les attributs requis avec types s√©curis√©s
    age: Optional[int] = None  # √Çge principal en jours
    age_days: Optional[int] = None
    age_weeks: Optional[float] = None
    age_confidence: float = 0.0
    age_last_updated: Optional[datetime] = None
    
    # üîß FIX 3: POIDS - Attribut weight ajout√© + weight_grams avec synchronisation
    weight: Optional[float] = None  # ‚Üê ATTRIBUT MANQUANT AJOUT√â (en grammes)
    weight_grams: Optional[float] = None
    weight_confidence: float = 0.0
    expected_weight_range: Optional[Tuple[float, float]] = None
    growth_rate: Optional[str] = None  # normal/slow/fast
    
    # Sant√© et probl√®mes
    mortality_rate: Optional[float] = None
    mortality_confidence: float = 0.0
    symptoms: List[str] = field(default_factory=list)
    health_status: Optional[str] = None  # good/concerning/critical
    
    # Environnement
    temperature: Optional[float] = None
    humidity: Optional[float] = None
    housing_type: Optional[str] = None
    ventilation_quality: Optional[str] = None
    
    # Alimentation
    feed_type: Optional[str] = None
    feed_conversion: Optional[float] = None
    water_consumption: Optional[str] = None
    
    # Gestion et historique
    flock_size: Optional[int] = None
    vaccination_status: Optional[str] = None
    previous_treatments: List[str] = field(default_factory=list)
    
    # Contextuel intelligent
    problem_duration: Optional[str] = None
    problem_severity: Optional[str] = None  # low/medium/high/critical
    intervention_urgency: Optional[str] = None  # none/monitor/act/urgent
    
    # M√©tadonn√©es IA
    extraction_method: str = "basic"  # basic/openai/hybrid/fallback
    extraction_attempts: int = 0
    extraction_success: bool = True
    last_ai_update: Optional[datetime] = None
    confidence_overall: float = 0.0
    data_validated: bool = False
    
    def __post_init__(self):
        """Post-initialisation pour synchroniser les champs weight/weight_grams et age/age_days"""
        # Synchroniser weight et weight_grams
        if self.weight_grams is not None and self.weight is None:
            self.weight = self.weight_grams
        elif self.weight is not None and self.weight_grams is None:
            self.weight_grams = self.weight
        
        # Synchroniser age et age_days
        if self.age_days is not None and self.age is None:
            self.age = self.age_days
        elif self.age is not None and self.age_days is None:
            self.age_days = self.age
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire pour logs et stockage"""
        result = {}
        for key, value in asdict(self).items():
            if value is not None:
                if isinstance(value, datetime):
                    result[key] = value.isoformat()
                elif isinstance(value, tuple):
                    result[key] = list(value)
                else:
                    result[key] = value
        return result
    
    def validate_and_correct(self) -> 'IntelligentEntities':
        """üîß FIX 4: Validation et correction avec gestion s√©curis√©e des types"""
        
        # üîß CORRECTION √ÇGE: Gestion s√©curis√©e des types str/int
        age_days_safe = safe_int_conversion(self.age_days)
        age_weeks_safe = safe_float_conversion(self.age_weeks)
        
        if age_days_safe is not None and age_weeks_safe is not None:
            calculated_weeks = age_days_safe / 7
            if abs(calculated_weeks - age_weeks_safe) > 0.5:  # Tol√©rance 0.5 semaine
                logger.warning(f"‚ö†Ô∏è [Validation] Incoh√©rence √¢ge: {age_days_safe}j vs {age_weeks_safe}sem")
                
                # üîß FIX 5: Enrichissement automatique au lieu de simple warning
                if self.age_confidence > 0.7:
                    self.age_weeks = round(age_days_safe / 7, 1)
                    logger.info(f"‚úÖ [Correction] √Çge semaines corrig√©: {self.age_weeks}sem")
                else:
                    self.age_days = int(age_weeks_safe * 7)
                    logger.info(f"‚úÖ [Correction] √Çge jours corrig√©: {self.age_days}j")
        
        # Mise √† jour des champs s√©curis√©s
        self.age_days = age_days_safe
        self.age_weeks = age_weeks_safe
        
        # Synchroniser le champ age avec age_days
        if self.age_days:
            self.age = self.age_days
        elif self.age:
            self.age_days = self.age
        
        # üîß CORRECTION POIDS: Synchronisation weight/weight_grams s√©curis√©e
        weight_safe = safe_float_conversion(self.weight)
        weight_grams_safe = safe_float_conversion(self.weight_grams)
        
        if weight_grams_safe is not None:
            # Validation et correction automatique
            if weight_grams_safe < 10 or weight_grams_safe > 5000:  # Limites r√©alistes
                logger.warning(f"‚ö†Ô∏è [Validation] Poids suspect: {weight_grams_safe}g")
                if weight_grams_safe > 5000:  # Probablement en kg au lieu de g
                    weight_grams_safe = weight_grams_safe / 1000
                    logger.info(f"‚úÖ [Correction] Poids corrig√© de kg vers g: {weight_grams_safe}g")
                elif weight_grams_safe < 10 and weight_grams_safe > 0.1:  # Probablement en kg
                    weight_grams_safe = weight_grams_safe * 1000
                    logger.info(f"‚úÖ [Correction] Poids corrig√© de kg vers g: {weight_grams_safe}g")
        
        # Synchroniser weight et weight_grams
        self.weight_grams = weight_grams_safe
        self.weight = weight_grams_safe  # Les deux sont en grammes
        
        # Validation mortalit√© s√©curis√©e
        mortality_safe = safe_float_conversion(self.mortality_rate)
        if mortality_safe is not None:
            if mortality_safe < 0:
                mortality_safe = 0.0
            elif mortality_safe > 100:
                logger.warning(f"‚ö†Ô∏è [Validation] Mortalit√© > 100%: {mortality_safe}")
                mortality_safe = min(mortality_safe, 100.0)
        self.mortality_rate = mortality_safe
        
        # Validation temp√©rature s√©curis√©e
        temp_safe = safe_float_conversion(self.temperature)
        if temp_safe is not None:
            if temp_safe < 15 or temp_safe > 45:
                logger.warning(f"‚ö†Ô∏è [Validation] Temp√©rature suspecte: {temp_safe}¬∞C")
                if temp_safe > 100:  # Probablement en Fahrenheit
                    temp_safe = (temp_safe - 32) * 5/9
                    logger.info(f"‚úÖ [Correction] Temp√©rature convertie F‚ÜíC: {temp_safe:.1f}¬∞C")
        self.temperature = temp_safe
        
        # Nettoyer les listes de mani√®re s√©curis√©e
        if self.symptoms:
            self.symptoms = [s.strip().lower() for s in self.symptoms if s and isinstance(s, str) and s.strip()]
            self.symptoms = list(set(self.symptoms))  # Supprimer doublons
        
        if self.previous_treatments:
            self.previous_treatments = [t.strip() for t in self.previous_treatments if t and isinstance(t, str) and t.strip()]
            self.previous_treatments = list(set(self.previous_treatments))
        
        self.data_validated = True
        return self
    
    def get_critical_missing_info(self, question_type: str = "general") -> List[str]:
        """D√©termine les informations critiques manquantes selon le contexte"""
        missing = []
        
        # Race toujours critique pour questions techniques
        if not self.breed or self.breed_type == "generic" or self.breed_confidence < 0.7:
            missing.append("breed")
        
        # Sexe critique pour questions de performance
        if question_type in ["performance", "weight", "growth"] and (not self.sex or self.sex_confidence < 0.7):
            missing.append("sex")
        
        # √Çge critique pour la plupart des questions
        if not self.age_days or self.age_confidence < 0.7:
            missing.append("age")
        
        # Sp√©cifique selon le type de question
        if question_type in ["growth", "weight", "performance"]:
            if not self.weight_grams and not self.growth_rate:
                missing.append("current_performance")
        elif question_type in ["health", "mortality", "disease"]:
            if not self.symptoms and not self.health_status:
                missing.append("symptoms")
            if self.mortality_rate is None and "mortality" in question_type:
                missing.append("mortality_rate")
        elif question_type in ["environment", "temperature", "housing"]:
            if not self.housing_type:
                missing.append("housing_conditions")
        elif question_type in ["feeding", "nutrition"]:
            if not self.feed_type:
                missing.append("feed_information")
        
        return missing
    
    def merge_with(self, other: 'IntelligentEntities') -> 'IntelligentEntities':
        """Fusionne intelligemment avec une autre instance d'entit√©s"""
        merged = IntelligentEntities()
        
        # Logique de fusion pour chaque champ
        for field_name, field_value in asdict(self).items():
            other_value = getattr(other, field_name, None)
            
            # Prendre la valeur avec la meilleure confiance
            if field_name.endswith('_confidence'):
                base_field = field_name.replace('_confidence', '')
                self_conf = field_value or 0.0
                other_conf = getattr(other, field_name, 0.0) or 0.0
                
                if other_conf > self_conf:
                    setattr(merged, base_field, getattr(other, base_field))
                    setattr(merged, field_name, other_conf)
                else:
                    setattr(merged, base_field, getattr(self, base_field))
                    setattr(merged, field_name, self_conf)
            
            # Fusionner les listes
            elif isinstance(field_value, list):
                self_list = field_value or []
                other_list = other_value or []
                # Garder les √©l√©ments uniques
                merged_list = list(set(self_list + other_list))
                setattr(merged, field_name, merged_list)
            
            # Prendre la valeur la plus r√©cente pour les dates
            elif isinstance(field_value, datetime):
                if other_value and (not field_value or other_value > field_value):
                    setattr(merged, field_name, other_value)
                else:
                    setattr(merged, field_name, field_value)
            
            # Logique par d√©faut
            else:
                if other_value is not None:
                    setattr(merged, field_name, other_value)
                elif field_value is not None:
                    setattr(merged, field_name, field_value)
        
        merged.last_ai_update = datetime.now()
        return merged.validate_and_correct()

@dataclass
class ConversationMessage:
    """Message dans une conversation avec m√©tadonn√©es"""
    id: str
    conversation_id: str
    user_id: str
    role: str  # user/assistant/system
    message: str
    timestamp: datetime
    language: str = "fr"
    message_type: str = "text"  # text/clarification/response/original_question_marker
    extracted_entities: Optional[IntelligentEntities] = None
    confidence_score: float = 0.0
    processing_method: str = "basic"
    
    # CHAMPS POUR CLARIFICATIONS
    is_original_question: bool = False
    is_clarification_response: bool = False
    original_question_id: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "conversation_id": self.conversation_id,
            "user_id": self.user_id,
            "role": self.role,
            "message": self.message,
            "timestamp": self.timestamp.isoformat(),
            "language": self.language,
            "message_type": self.message_type,
            "extracted_entities": self.extracted_entities.to_dict() if self.extracted_entities else None,
            "confidence_score": self.confidence_score,
            "processing_method": self.processing_method,
            "is_original_question": self.is_original_question,
            "is_clarification_response": self.is_clarification_response,
            "original_question_id": self.original_question_id
        }

@dataclass
class IntelligentConversationContext:
    """Contexte conversationnel intelligent avec raisonnement et clarification critique"""
    conversation_id: str
    user_id: str
    messages: List[ConversationMessage] = field(default_factory=list)
    
    # Entit√©s consolid√©es intelligemment
    consolidated_entities: IntelligentEntities = field(default_factory=IntelligentEntities)
    
    # M√©tadonn√©es contextuelles
    language: str = "fr"
    created_at: datetime = field(default_factory=datetime.now)
    last_activity: datetime = field(default_factory=datetime.now)
    total_exchanges: int = 0
    
    # √âtat conversationnel intelligent
    conversation_topic: Optional[str] = None
    conversation_urgency: Optional[str] = None  # low/medium/high/critical
    problem_resolution_status: Optional[str] = None  # identifying/diagnosing/treating/resolved
    
    # Optimisations IA
    ai_enhanced: bool = False
    last_ai_analysis: Optional[datetime] = None
    needs_clarification: bool = False
    clarification_questions: List[str] = field(default_factory=list)
    
    # CHAMPS POUR CLARIFICATIONS STANDARD
    pending_clarification: bool = False
    last_original_question_id: Optional[str] = None
    
    # NOUVEAUX CHAMPS POUR CLARIFICATION CRITIQUE
    original_question_pending: Optional[str] = None  # Question initiale en attente
    critical_clarification_active: bool = False      # √âtat clarification critique
    _clarification_callback_ref: Optional[weakref.ReferenceType] = None  # WeakRef pour √©viter fuites m√©moire
    _schedule_reprocessing: bool = False  # Flag pour √©viter r√©cursion
    
    # Propri√©t√© pour g√©rer le callback de mani√®re s√©curis√©e
    @property
    def clarification_callback(self) -> Optional[RAGCallbackProtocol]:
        """R√©cup√®re le callback de mani√®re s√©curis√©e"""
        if self._clarification_callback_ref is None:
            return None
        callback = self._clarification_callback_ref()
        if callback is None:
            # Le callback a √©t√© garbage collect√©
            self._clarification_callback_ref = None
            logger.warning("‚ö†Ô∏è [Context] Callback garbage collect√© - nettoyage automatique")
        return callback
    
    @clarification_callback.setter
    def clarification_callback(self, callback: Optional[RAGCallbackProtocol]):
        """D√©finit le callback avec WeakRef pour √©viter les fuites m√©moire"""
        if callback is None:
            self._clarification_callback_ref = None
        else:
            try:
                self._clarification_callback_ref = weakref.ref(callback)
            except TypeError:
                # Si l'objet ne supporte pas les weak references
                logger.warning("‚ö†Ô∏è [Context] Callback ne supporte pas WeakRef - stockage direct")
                self._clarification_callback_ref = lambda: callback
    
    def add_message(self, message: ConversationMessage):
        """Ajoute un message et g√®re la clarification critique automatiquement"""
        self.messages.append(message)
        self.last_activity = datetime.now()
        self.total_exchanges += 1
        
        # TRACKING SP√âCIAL POUR CLARIFICATIONS STANDARD
        if message.is_original_question:
            self.last_original_question_id = message.id
            self.pending_clarification = True
            logger.info(f"üéØ [Context] Question originale marqu√©e: {message.id}")
        
        if message.is_clarification_response and message.original_question_id:
            self.pending_clarification = False
            logger.info(f"üéØ [Context] Clarification re√ßue pour: {message.original_question_id}")
        
        # NOUVELLE LOGIQUE CLARIFICATION CRITIQUE
        if message.is_clarification_response and self.critical_clarification_active:
            logger.info("üö® [Context] ‚úÖ R√©ponse clarification CRITIQUE re√ßue - planification du retraitement")
            self.critical_clarification_active = False
            
            # Marquer pour retraitement au lieu de cr√©er une t√¢che imm√©diatement
            self._schedule_reprocessing = True
            
            # Le retraitement sera d√©clench√© par l'appelant via check_and_trigger_reprocessing()
        
        # Fusionner les entit√©s si disponibles
        if message.extracted_entities:
            old_entities = self.consolidated_entities
            self.consolidated_entities = self.consolidated_entities.merge_with(message.extracted_entities)
            
            # Log des changements d'entit√©s
            if old_entities.breed != self.consolidated_entities.breed:
                logger.info(f"üîÑ [Entities] Race mise √† jour: {old_entities.breed} ‚Üí {self.consolidated_entities.breed}")
            if old_entities.sex != self.consolidated_entities.sex:
                logger.info(f"üîÑ [Entities] Sexe mis √† jour: {old_entities.sex} ‚Üí {self.consolidated_entities.sex}")
            if old_entities.age_days != self.consolidated_entities.age_days:
                logger.info(f"üîÑ [Entities] √Çge mis √† jour: {old_entities.age_days} ‚Üí {self.consolidated_entities.age_days}j")
        
        # Mettre √† jour le statut conversationnel
        self._update_conversation_status()
    
    def check_and_trigger_reprocessing(self) -> bool:
        """
        V√©rifie si un retraitement est planifi√© et le d√©clenche
        Retourne True si un retraitement a √©t√© planifi√©
        """
        if self._schedule_reprocessing:
            self._schedule_reprocessing = False
            logger.info("üöÄ [Context] Retraitement planifi√© d√©tect√© - √† traiter par l'appelant")
            return True
        return False
    
    def mark_pending_clarification(self, question: str, callback: Optional[RAGCallbackProtocol] = None):
        """
        Marque une question pour clarification critique
        
        Args:
            question: Question originale qui n√©cessite clarification
            callback: Fonction callback pour relancer le traitement RAG
        """
        self.critical_clarification_active = True
        self.original_question_pending = question
        self.clarification_callback = callback  # Utilise le setter s√©curis√©
        
        logger.info(f"üö® [Context] CLARIFICATION CRITIQUE marqu√©e")
        logger.info(f"  üìù Question: {question[:100]}...")
        logger.info(f"  üîÑ Callback: {'‚úÖ' if callback else '‚ùå'}")
    
    async def reprocess_original_question(self) -> Dict[str, Any]:
        """
        Relance le traitement de la question originale avec clarification
        """
        if not self.original_question_pending:
            logger.warning("‚ö†Ô∏è [Context] Pas de question originale en attente pour retraitement")
            return {"status": "no_question_pending"}
        
        logger.info(f"üöÄ [Context] RETRAITEMENT question originale: {self.original_question_pending[:100]}...")
        
        try:
            # V√©rification s√©curis√©e du callback
            callback = self.clarification_callback
            if callback and callable(callback):
                logger.info("üîÑ [Context] Ex√©cution callback retraitement...")
                
                # Appeler le callback avec la question enrichie par le contexte actuel
                enriched_question = self._build_enriched_question_from_context()
                
                try:
                    result = await callback(
                        question=enriched_question,
                        conversation_id=self.conversation_id,
                        user_id=self.user_id,
                        is_reprocessing=True
                    )
                    
                    logger.info(f"‚úÖ [Context] Callback retraitement termin√©: {result}")
                    return {"status": "success", "result": result}
                    
                except Exception as callback_error:
                    logger.error(f"‚ùå [Context] Erreur dans callback: {callback_error}")
                    return {"status": "callback_error", "error": str(callback_error)}
                
            else:
                logger.warning("‚ö†Ô∏è [Context] Pas de callback valide - retraitement manuel requis")
                return {"status": "no_callback"}
        
        except Exception as e:
            logger.error(f"‚ùå [Context] Erreur retraitement: {e}")
            return {"status": "error", "error": str(e)}
        
        finally:
            # Nettoyer l'√©tat
            self.original_question_pending = None
            self.clarification_callback = None
    
    def _build_enriched_question_from_context(self) -> str:
        """Enrichit la question originale avec le contexte actuel"""
        if not self.original_question_pending:
            return ""
        
        enrichments = []
        entities = self.consolidated_entities
        
        # Ajouter les entit√©s importantes
        if entities.breed and entities.breed_confidence > 0.7:
            enrichments.append(entities.breed)
        
        if entities.sex and entities.sex_confidence > 0.7:
            enrichments.append(entities.sex)
        
        if entities.age_days and entities.age_confidence > 0.7:
            enrichments.append(f"{entities.age_days} jours")
        
        # Construire la question enrichie
        if enrichments:
            enrichment_text = " ".join(enrichments)
            
            # Int√©grer intelligemment dans la question
            if "poulet" in self.original_question_pending.lower():
                enriched = self.original_question_pending.replace(
                    "poulet", f"poulet {enrichment_text}"
                ).replace(
                    "poulets", f"poulets {enrichment_text}"
                )
            else:
                enriched = f"{self.original_question_pending} (Contexte: {enrichment_text})"
            
            logger.info(f"üîÅ [Context] Question enrichie: {enriched}")
            return enriched
        
        return self.original_question_pending
    
    def _update_conversation_status(self):
        """Met √† jour le statut conversationnel bas√© sur les messages r√©cents"""
        if not self.messages:
            return
        
        recent_messages = self.messages[-3:]  # 3 derniers messages
        
        # Analyser l'urgence bas√©e sur les mots-cl√©s
        urgency_keywords = {
            "critical": ["urgence", "urgent", "critique", "emergency", "critical", "dying", "meurent"],
            "high": ["probl√®me", "problem", "maladie", "disease", "mortalit√©", "mortality"],
            "medium": ["inquiet", "concerned", "surveillance", "monitoring"],
            "low": ["pr√©vention", "prevention", "routine", "normal"]
        }
        
        max_urgency = "low"
        for message in recent_messages:
            message_lower = message.message.lower()
            for urgency, keywords in urgency_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    if urgency == "critical":
                        max_urgency = "critical"
                        break
                    elif urgency == "high" and max_urgency not in ["critical"]:
                        max_urgency = "high"
                    elif urgency == "medium" and max_urgency in ["low"]:
                        max_urgency = "medium"
        
        self.conversation_urgency = max_urgency
    
    def find_original_question(self, limit_messages: int = 20) -> Optional[ConversationMessage]:
        """
        Trouve la question originale marqu√©e pour clarification
        """
        
        # Rechercher par ID si on a un last_original_question_id
        if self.last_original_question_id:
            for msg in reversed(self.messages[-limit_messages:]):
                if msg.id == self.last_original_question_id and msg.is_original_question:
                    logger.info(f"‚úÖ [Context] Question originale trouv√©e par ID: {msg.id}")
                    return msg
        
        # Rechercher par marqueur sp√©cial dans le message
        for msg in reversed(self.messages[-limit_messages:]):
            if msg.role == "system" and "ORIGINAL_QUESTION_FOR_CLARIFICATION:" in msg.message:
                # Extraire la question du marqueur
                question_text = msg.message.replace("ORIGINAL_QUESTION_FOR_CLARIFICATION: ", "")
                
                # Cr√©er un message virtuel pour la question originale
                original_msg = ConversationMessage(
                    id=f"original_{msg.id}",
                    conversation_id=self.conversation_id,
                    user_id=self.user_id,
                    role="user",
                    message=question_text,
                    timestamp=msg.timestamp,
                    language=self.language,
                    message_type="original_question",
                    is_original_question=True
                )
                
                logger.info(f"‚úÖ [Context] Question originale extraite du marqueur: {question_text}")
                return original_msg
        
        # Rechercher par flag is_original_question
        for msg in reversed(self.messages[-limit_messages:]):
            if msg.is_original_question and msg.role == "user":
                logger.info(f"‚úÖ [Context] Question originale trouv√©e par flag: {msg.message[:50]}...")
                return msg
        
        # Fallback: chercher la derni√®re question utilisateur avant demande clarification
        clarification_keywords = [
            "j'ai besoin de", "pouvez-vous pr√©ciser", "quelle est la race",
            "quel est le sexe", "breed", "sex", "clarification"
        ]
        
        for i, msg in enumerate(reversed(self.messages[-limit_messages:])):
            if msg.role == "assistant" and any(keyword in msg.message.lower() for keyword in clarification_keywords):
                # Chercher la question utilisateur juste avant cette clarification
                actual_index = len(self.messages) - 1 - i
                if actual_index > 0:
                    prev_msg = self.messages[actual_index - 1]
                    if prev_msg.role == "user":
                        logger.info(f"üîÑ [Context] Question originale trouv√©e par fallback: {prev_msg.message[:50]}...")
                        return prev_msg
        
        logger.warning("‚ö†Ô∏è [Context] Question originale non trouv√©e!")
        return None
    
    def get_last_user_question(self, exclude_clarifications: bool = True) -> Optional[ConversationMessage]:
        """
        R√©cup√®re la derni√®re question utilisateur
        """
        
        for msg in reversed(self.messages):
            if msg.role == "user":
                # Exclure les r√©ponses de clarification courtes si demand√©
                if exclude_clarifications:
                    # Si c'est tr√®s court et contient une race/sexe, c'est probablement une clarification
                    if len(msg.message.split()) <= 3:
                        breed_sex_patterns = [
                            r'ross\s*308', r'cobb\s*500', r'hubbard',
                            r'm√¢les?', r'femelles?', r'males?', r'females?',
                            r'mixte', r'mixed'
                        ]
                        if any(re.search(pattern, msg.message.lower()) for pattern in breed_sex_patterns):
                            continue  # Ignorer cette r√©ponse de clarification
                
                logger.info(f"üîÑ [Context] Derni√®re question utilisateur: {msg.message[:50]}...")
                return msg
        
        logger.warning("‚ö†Ô∏è [Context] Aucune question utilisateur trouv√©e!")
        return None
    
    def get_context_for_clarification(self) -> Dict[str, Any]:
        """Retourne le contexte optimis√© pour les clarifications"""
        
        # Inclure la question originale si trouv√©e
        original_question = self.find_original_question()
        
        context = {
            "breed": self.consolidated_entities.breed,
            "breed_type": self.consolidated_entities.breed_type,
            "sex": self.consolidated_entities.sex,
            "sex_confidence": self.consolidated_entities.sex_confidence,
            "age": self.consolidated_entities.age_days,
            "age_confidence": self.consolidated_entities.age_confidence,
            "weight": self.consolidated_entities.weight_grams,  # üîß FIX: Utiliser weight_grams existant
            "symptoms": self.consolidated_entities.symptoms,
            "housing": self.consolidated_entities.housing_type,
            "urgency": self.conversation_urgency,
            "topic": self.conversation_topic,
            "total_exchanges": self.total_exchanges,
            "missing_critical": self.consolidated_entities.get_critical_missing_info(),
            "overall_confidence": self.consolidated_entities.confidence_overall,
            
            # CHAMPS STANDARD
            "original_question": original_question.message if original_question else None,
            "original_question_id": original_question.id if original_question else None,
            "pending_clarification": self.pending_clarification,
            "last_original_question_id": self.last_original_question_id,
            
            # NOUVEAUX CHAMPS CRITIQUES
            "original_question_pending": self.original_question_pending,
            "critical_clarification_active": self.critical_clarification_active,
            "reprocessing_scheduled": self._schedule_reprocessing
        }
        
        return context
    
    def _safe_topic_check(self, keywords: List[str]) -> bool:
        """Helper s√©curis√© pour v√©rifier les mots-cl√©s dans conversation_topic"""
        if not self.conversation_topic:
            return False
        topic_lower = self.conversation_topic.lower()
        return any(keyword in topic_lower for keyword in keywords)

    def get_missing_entities_list(self) -> List[str]:
        """
        Retourne la liste des entit√©s manquantes
        
        Returns:
            List[str]: Liste des entit√©s manquantes
        """
        return list(self.get_missing_entities_dict().keys())
    
    def get_missing_entities_dict(self) -> Dict[str, str]:
        """
        Retourne les entit√©s manquantes avec leur niveau d'importance
        
        Returns:
            Dict[str, str]: Dictionnaire {entity: importance}
        """
        entities = self.consolidated_entities
        missing_with_importance = {}
        
        # Race - toujours critique pour questions techniques
        if not entities.breed or entities.breed_type == "generic" or entities.breed_confidence < 0.7:
            missing_with_importance["breed"] = "critique"
        
        # Sexe - critique pour performance, secondaire pour sant√©
        if not entities.sex or entities.sex_confidence < 0.7:
            # Protection None avec helper s√©curis√©
            if self._safe_topic_check(["performance", "weight", "growth", "croissance", "poids"]):
                missing_with_importance["sex"] = "critique"
            else:
                missing_with_importance["sex"] = "secondaire"
        
        # √Çge - critique pour la plupart des questions
        if not entities.age_days or entities.age_confidence < 0.7:
            missing_with_importance["age"] = "critique"
        
        # Poids - critique pour questions de performance
        if not entities.weight_grams and not entities.growth_rate:
            # Protection None avec helper s√©curis√©
            if self._safe_topic_check(["performance", "weight", "growth", "croissance", "poids"]):
                missing_with_importance["current_performance"] = "critique"
            else:
                missing_with_importance["current_performance"] = "secondaire"
        
        # Sympt√¥mes - critique pour questions de sant√©
        if not entities.symptoms and not entities.health_status:
            # Protection None avec helper s√©curis√©
            if self._safe_topic_check(["health", "mortality", "disease", "sant√©", "mortalit√©", "maladie"]):
                missing_with_importance["symptoms"] = "critique"
            else:
                missing_with_importance["symptoms"] = "secondaire"
        
        # Mortalit√© - critique si mentionn√©e dans la conversation
        if entities.mortality_rate is None:
            recent_messages_text = " ".join([msg.message.lower() for msg in self.messages[-3:]])
            if any(keyword in recent_messages_text for keyword in ["mortality", "mortalit√©", "meurent", "dying"]):
                missing_with_importance["mortality_rate"] = "critique"
        
        # Conditions environnementales - secondaire sauf si probl√®me mentionn√©
        if not entities.housing_type and not entities.temperature:
            # Protection None avec helper s√©curis√©
            if self._safe_topic_check(["environment", "temperature", "housing", "environnement", "temp√©rature"]):
                missing_with_importance["housing_conditions"] = "critique"
            else:
                missing_with_importance["housing_conditions"] = "secondaire"
        
        # Alimentation - secondaire sauf si probl√®me nutritionnel
        if not entities.feed_type:
            # Protection None avec helper s√©curis√©
            if self._safe_topic_check(["feeding", "nutrition", "alimentation", "nourriture"]):
                missing_with_importance["feed_information"] = "critique"
            else:
                missing_with_importance["feed_information"] = "secondaire"
        
        return missing_with_importance

    def get_missing_entities(self, include_importance: bool = False) -> Union[List[str], Dict[str, str]]:
        """
        M√âTHODE D√âPR√âCI√âE - Utilisez get_missing_entities_list() ou get_missing_entities_dict()
        
        Cette m√©thode est conserv√©e pour compatibilit√© mais d√©pr√©ci√©e
        """
        logger.warning("‚ö†Ô∏è [Deprecated] get_missing_entities() est d√©pr√©ci√©. Utilisez get_missing_entities_list() ou get_missing_entities_dict()")
        
        if include_importance:
            return self.get_missing_entities_dict()
        else:
            return self.get_missing_entities_list()

    def to_dict(self) -> Dict[str, Any]:
        return {
            "conversation_id": self.conversation_id,
            "user_id": self.user_id,
            "messages": [m.to_dict() for m in self.messages],
            "consolidated_entities": self.consolidated_entities.to_dict(),
            "language": self.language,
            "created_at": self.created_at.isoformat(),
            "last_activity": self.last_activity.isoformat(),
            "total_exchanges": self.total_exchanges,
            "conversation_topic": self.conversation_topic,
            "conversation_urgency": self.conversation_urgency,
            "problem_resolution_status": self.problem_resolution_status,
            "ai_enhanced": self.ai_enhanced,
            "last_ai_analysis": self.last_ai_analysis.isoformat() if self.last_ai_analysis else None,
            "needs_clarification": self.needs_clarification,
            "clarification_questions": self.clarification_questions,
            "pending_clarification": self.pending_clarification,
            "last_original_question_id": self.last_original_question_id,
            # NOUVEAUX CHAMPS
            "original_question_pending": self.original_question_pending,
            "critical_clarification_active": self.critical_clarification_active,
            "schedule_reprocessing": self._schedule_reprocessing
        }

class IntelligentConversationMemory:
    """Syst√®me de m√©moire conversationnelle intelligent avec IA et clarification critique int√©gr√©e - VERSION R√â√âCRITE"""
    
    def __init__(self, db_path: str = None):
        """Initialise le syst√®me de m√©moire intelligent"""
        
        # Configuration
        self.db_path = db_path or os.getenv('CONVERSATION_MEMORY_DB_PATH', 'data/conversation_memory.db')
        self.max_messages_in_memory = int(os.getenv('MAX_MESSAGES_IN_MEMORY', '50'))
        self.context_expiry_hours = int(os.getenv('CONTEXT_EXPIRY_HOURS', '24'))
        self.ai_enhancement_enabled = os.getenv('AI_ENHANCEMENT_ENABLED', 'true').lower() == 'true'
        self.ai_enhancement_model = os.getenv('AI_ENHANCEMENT_MODEL', 'gpt-4o-mini')
        self.ai_enhancement_timeout = int(os.getenv('AI_ENHANCEMENT_TIMEOUT', '15'))
        
        # Cache thread-safe avec RLock au lieu de Lock simple
        self.conversation_cache: Dict[str, IntelligentConversationContext] = {}
        self.cache_max_size = int(os.getenv('CONVERSATION_CACHE_SIZE', '100'))
        self.cache_lock = RLock()  # RLock pour √©viter les deadlocks
        
        # Statistiques thread-safe
        self._stats_lock = Lock()
        self.stats = {
            "total_conversations": 0,
            "total_messages": 0,
            "ai_enhancements": 0,
            "ai_failures": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "original_questions_recovered": 0,
            "clarification_resolutions": 0,
            # NOUVELLES M√âTRIQUES CRITIQUES
            "critical_clarifications_marked": 0,
            "critical_clarifications_resolved": 0,
            "rag_reprocessing_triggered": 0
        }
        
        # Initialiser la base de donn√©es
        self._init_database()
        
        logger.info(f"üß† [IntelligentMemory] Syst√®me initialis√© - VERSION COMPL√àTEMENT R√â√âCRITE")
        logger.info(f"üß† [IntelligentMemory] DB: {self.db_path}")
        logger.info(f"üß† [IntelligentMemory] IA enhancing: {'‚úÖ' if self.ai_enhancement_enabled else '‚ùå'}")
        logger.info(f"üß† [IntelligentMemory] Mod√®le IA: {self.ai_enhancement_model}")
        logger.info(f"üö® [IntelligentMemory] Syst√®me de clarification standard: ‚úÖ")
        logger.info(f"üö® [IntelligentMemory] Syst√®me de clarification CRITIQUE: ‚úÖ (CORRIG√â)")
        logger.info(f"ü§ñ [IntelligentMemory] M√©thodes pour agents GPT: ‚úÖ")
        logger.info(f"üîß [IntelligentMemory] Corrections appliqu√©es: Weight sync, Type safety, WeakRef, RLock")

    def _update_stats(self, key: str, increment: int = 1):
        """Met √† jour les statistiques de mani√®re thread-safe"""
        with self._stats_lock:
            self.stats[key] = self.stats.get(key, 0) + increment

    def _init_database(self):
        """Initialise la base de donn√©es avec sch√©ma am√©lior√© pour clarification critique"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            # Table des conversations avec m√©tadonn√©es √©tendues + clarification critique
            conn.execute("""
                CREATE TABLE IF NOT EXISTS conversations (
                    conversation_id TEXT PRIMARY KEY,
                    user_id TEXT NOT NULL,
                    language TEXT DEFAULT 'fr',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    total_exchanges INTEGER DEFAULT 0,
                    
                    -- Entit√©s consolid√©es (JSON)
                    consolidated_entities TEXT,
                    
                    -- √âtat conversationnel
                    conversation_topic TEXT,
                    conversation_urgency TEXT,
                    problem_resolution_status TEXT,
                    
                    -- M√©tadonn√©es IA
                    ai_enhanced BOOLEAN DEFAULT FALSE,
                    last_ai_analysis TIMESTAMP,
                    needs_clarification BOOLEAN DEFAULT FALSE,
                    clarification_questions TEXT,
                    
                    -- CHAMPS POUR CLARIFICATIONS STANDARD
                    pending_clarification BOOLEAN DEFAULT FALSE,
                    last_original_question_id TEXT,
                    
                    -- NOUVEAUX CHAMPS POUR CLARIFICATION CRITIQUE
                    original_question_pending TEXT,
                    critical_clarification_active BOOLEAN DEFAULT FALSE,
                    
                    -- Performance
                    confidence_overall REAL DEFAULT 0.0
                )
            """)
            
            # Table des messages avec extraction d'entit√©s
            conn.execute("""
                CREATE TABLE IF NOT EXISTS conversation_messages (
                    id TEXT PRIMARY KEY,
                    conversation_id TEXT NOT NULL,
                    user_id TEXT NOT NULL,
                    role TEXT NOT NULL,
                    message TEXT NOT NULL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    language TEXT DEFAULT 'fr',
                    message_type TEXT DEFAULT 'text',
                    
                    -- Entit√©s extraites (JSON)
                    extracted_entities TEXT,
                    confidence_score REAL DEFAULT 0.0,
                    processing_method TEXT DEFAULT 'basic',
                    
                    -- CHAMPS POUR CLARIFICATIONS
                    is_original_question BOOLEAN DEFAULT FALSE,
                    is_clarification_response BOOLEAN DEFAULT FALSE,
                    original_question_id TEXT,
                    
                    FOREIGN KEY (conversation_id) REFERENCES conversations (conversation_id)
                )
            """)
            
            # Index pour performance
            conn.execute("CREATE INDEX IF NOT EXISTS idx_conv_user_activity ON conversations (user_id, last_activity)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_msg_conv_time ON conversation_messages (conversation_id, timestamp)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_conv_urgency ON conversations (conversation_urgency, last_activity)")
            # INDEX POUR CLARIFICATIONS
            conn.execute("CREATE INDEX IF NOT EXISTS idx_original_questions ON conversation_messages (conversation_id, is_original_question)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_clarification_responses ON conversation_messages (original_question_id, is_clarification_response)")
            # NOUVEAUX INDEX POUR CLARIFICATION CRITIQUE
            conn.execute("CREATE INDEX IF NOT EXISTS idx_critical_clarification ON conversations (critical_clarification_active, last_activity)")
            
        logger.info(f"‚úÖ [IntelligentMemory] Base de donn√©es initialis√©e avec support clarification critique")

    @contextmanager
    def _get_db_connection(self):
        """Context manager pour les connexions DB avec retry"""
        max_retries = 3
        conn = None
        
        for attempt in range(max_retries):
            try:
                conn = sqlite3.connect(self.db_path, timeout=30.0)
                conn.row_factory = sqlite3.Row
                yield conn
                break
            except sqlite3.OperationalError as e:
                if attempt == max_retries - 1:
                    raise
                logger.warning(f"‚ö†Ô∏è [DB] Retry connexion {attempt + 1}/{max_retries}: {e}")
                time.sleep(0.5 * (attempt + 1))
            except Exception as e:
                logger.error(f"‚ùå [DB] Erreur connexion: {e}")
                raise
            finally:
                if conn:
                    try:
                        conn.close()
                    except Exception as close_error:
                        logger.warning(f"‚ö†Ô∏è [DB] Erreur fermeture connexion: {close_error}")

    async def extract_entities_ai_enhanced(
        self, 
        message: str, 
        language: str = "fr",
        conversation_context: Optional[IntelligentConversationContext] = None
    ) -> IntelligentEntities:
        """üîß FIX 6: Extraction d'entit√©s avec fallback robuste et gestion d'erreurs am√©lior√©e"""
        
        # Tentative IA si disponible
        if self.ai_enhancement_enabled and OPENAI_AVAILABLE and openai:
            try:
                entities = await self._extract_entities_openai(message, language, conversation_context)
                if entities and entities.confidence_overall > 0.3:
                    self._update_stats("ai_enhancements")
                    return entities.validate_and_correct()
            except Exception as e:
                self._update_stats("ai_failures")
                logger.warning(f"‚ö†Ô∏è [AI Extraction] √âchec IA: {e}")
        
        # üîß FIX 7: Fallback robuste sans d√©pendances manquantes
        logger.info("üîÑ [Fallback] Utilisation extraction basique robuste")
        try:
            entities = await self._extract_entities_basic_robust(message, language)
            entities.extraction_method = "fallback_robust"
            return entities.validate_and_correct()
        except Exception as fallback_error:
            logger.error(f"‚ùå [Fallback] √âchec fallback: {fallback_error}")
            # Fallback ultime: entit√©s vides mais valides
            return IntelligentEntities(
                extraction_method="empty_fallback",
                extraction_success=False,
                confidence_overall=0.0
            )

    async def _extract_entities_openai(
        self, 
        message: str, 
        language: str = "fr",
        conversation_context: Optional[IntelligentConversationContext] = None
    ) -> IntelligentEntities:
        """Extraction d'entit√©s par OpenAI avec gestion robuste"""
        
        # Contexte pour l'IA
        context_info = ""
        if conversation_context and conversation_context.consolidated_entities:
            existing_entities = conversation_context.consolidated_entities.to_dict()
            if existing_entities:
                context_info = f"\n\nEntit√©s d√©j√† connues:\n{json.dumps(existing_entities, ensure_ascii=False, indent=2)}"
        
        extraction_prompt = f"""Tu es un expert en extraction d'informations v√©t√©rinaires pour l'aviculture. Analyse ce message et extrait TOUTES les informations pertinentes.

Message: "{message}"{context_info}

INSTRUCTIONS CRITIQUES:
1. Extrait toutes les informations, m√™me partielles ou implicites
2. Utilise le contexte existant pour √©viter les doublons
3. Assigne des scores de confiance (0.0 √† 1.0) bas√©s sur la pr√©cision
4. Inf√©rer des informations logiques (ex: si "mes poulets Ross 308", alors breed_type="specific")
5. Convertir automatiquement les unit√©s (semaines -> jours, kg -> grammes)
6. IMPORTANT: D√©tecte le SEXE avec variations multilingues
7. POIDS: Toujours en grammes (weight ET weight_grams synchronis√©s)

SEXES SUPPORT√âS:
- FR: m√¢les, m√¢le, femelles, femelle, mixte, troupeau mixte, coqs, poules
- EN: males, male, females, female, mixed, mixed flock, roosters, hens  
- ES: machos, macho, hembras, hembra, mixto, lote mixto, gallos, gallinas

R√©ponds UNIQUEMENT avec ce JSON exact:
```json
{{
  "breed": "race_d√©tect√©e_ou_null",
  "breed_confidence": 0.0_√†_1.0,
  "breed_type": "specific/generic/null",
  
  "sex": "sexe_d√©tect√©_ou_null",
  "sex_confidence": 0.0_√†_1.0,
  
  "age": nombre_jours_ou_null,
  "age_days": nombre_jours_ou_null,
  "age_weeks": nombre_semaines_ou_null,
  "age_confidence": 0.0_√†_1.0,
  
  "weight": poids_grammes_ou_null,
  "weight_grams": poids_grammes_ou_null,
  "weight_confidence": 0.0_√†_1.0,
  "expected_weight_range": [min_grammes, max_grammes] ou null,
  "growth_rate": "normal/slow/fast/null",
  
  "mortality_rate": pourcentage_ou_null,
  "mortality_confidence": 0.0_√†_1.0,
  "symptoms": ["sympt√¥me1", "sympt√¥me2"] ou [],
  "health_status": "good/concerning/critical/null",
  
  "temperature": celsius_ou_null,
  "humidity": pourcentage_ou_null,
  "housing_type": "type_ou_null",
  
  "feed_type": "type_ou_null",
  "flock_size": nombre_ou_null,
  
  "problem_severity": "low/medium/high/critical/null",
  "intervention_urgency": "none/monitor/act/urgent/null",
  
  "extraction_method": "openai",
  "confidence_overall": 0.0_√†_1.0
}}
```

EXEMPLES:
- "Ross 308 m√¢les" ‚Üí breed="Ross 308", sex="m√¢les", breed_confidence=0.95, sex_confidence=0.95
- "Ross 308 male" ‚Üí breed="Ross 308", sex="m√¢les", breed_confidence=0.95, sex_confidence=0.95
- "3 semaines" ‚Üí age_weeks=3, age_days=21, age_confidence=0.9
- "800g" ‚Üí weight=800, weight_grams=800, weight_confidence=0.9
"""

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise Exception("Cl√© API OpenAI manquante")
        
        # Gestion d'erreurs sp√©cifique OpenAI
        try:
            # Cr√©er le client OpenAI
            client = openai.AsyncOpenAI(api_key=api_key)
            
            response = await client.chat.completions.create(
                model=self.ai_enhancement_model,
                messages=[
                    {"role": "system", "content": "Tu es un extracteur d'entit√©s expert en aviculture. R√©ponds UNIQUEMENT avec du JSON valide."},
                    {"role": "user", "content": extraction_prompt}
                ],
                temperature=0.1,
                max_tokens=800,
                timeout=self.ai_enhancement_timeout
            )
            
            answer = response.choices[0].message.content.strip()
            
        except asyncio.TimeoutError:
            raise Exception("Timeout lors de l'appel OpenAI")
        except Exception as e:
            raise Exception(f"Erreur OpenAI: {e}")
        
        # Extraire le JSON
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', answer, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_match = re.search(r'\{.*\}', answer, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                raise Exception("Pas de JSON trouv√© dans la r√©ponse IA")
        
        # Parser et cr√©er les entit√©s avec gestion s√©curis√©e
        try:
            data = json.loads(json_str)
            
            # üîß FIX 8: Conversion s√©curis√©e des types pour √©viter str/int comparaisons
            age_days_safe = safe_int_conversion(data.get("age_days") or data.get("age"))
            age_weeks_safe = safe_float_conversion(data.get("age_weeks"))
            weight_safe = safe_float_conversion(data.get("weight_grams") or data.get("weight"))
            
            entities = IntelligentEntities(
                breed=data.get("breed"),
                breed_confidence=data.get("breed_confidence", 0.0),
                breed_type=data.get("breed_type"),
                
                sex=data.get("sex"),
                sex_confidence=data.get("sex_confidence", 0.0),
                
                # üîß FIX: Synchronisation √¢ge s√©curis√©e
                age=age_days_safe,
                age_days=age_days_safe,
                age_weeks=age_weeks_safe,
                age_confidence=data.get("age_confidence", 0.0),
                age_last_updated=datetime.now(),
                
                # üîß FIX: Synchronisation poids s√©curis√©e
                weight=weight_safe,
                weight_grams=weight_safe,
                weight_confidence=data.get("weight_confidence", 0.0),
                expected_weight_range=tuple(data["expected_weight_range"]) if data.get("expected_weight_range") else None,
                growth_rate=data.get("growth_rate"),
                
                mortality_rate=safe_float_conversion(data.get("mortality_rate")),
                mortality_confidence=data.get("mortality_confidence", 0.0),
                symptoms=data.get("symptoms", []),
                health_status=data.get("health_status"),
                
                temperature=safe_float_conversion(data.get("temperature")),
                humidity=safe_float_conversion(data.get("humidity")),
                housing_type=data.get("housing_type"),
                
                feed_type=data.get("feed_type"),
                flock_size=safe_int_conversion(data.get("flock_size")),
                
                problem_severity=data.get("problem_severity"),
                intervention_urgency=data.get("intervention_urgency"),
                
                extraction_method="openai",
                last_ai_update=datetime.now(),
                confidence_overall=data.get("confidence_overall", 0.0),
                extraction_success=True
            )
            
            return entities
            
        except json.JSONDecodeError as e:
            raise Exception(f"Erreur parsing JSON IA: {e}")

    async def _extract_entities_basic_robust(self, message: str, language: str) -> IntelligentEntities:
        """üîß FIX 9: Extraction d'entit√©s basique robuste sans d√©pendances manquantes"""
        
        entities = IntelligentEntities(extraction_method="basic_robust")
        message_lower = message.lower()
        
        # Race sp√©cifique
        specific_breeds = [
            r'ross\s*308', r'ross\s*708', r'cobb\s*500', r'cobb\s*700',
            r'hubbard\s*flex', r'arbor\s*acres'
        ]
        
        for pattern in specific_breeds:
            match = re.search(pattern, message_lower, re.IGNORECASE)
            if match:
                breed_found = match.group(0).strip().replace(' ', ' ').title()
                entities.breed = breed_found
                entities.breed_type = "specific"
                entities.breed_confidence = 0.9
                logger.debug(f"üîç [BasicRobust] Race sp√©cifique d√©tect√©e: {breed_found}")
                break
        
        # EXTRACTION SEXE ROBUSTE
        sex_patterns = {
            "fr": [
                (r'\bm√¢les?\b', 'm√¢les'),
                (r'\bmales?\b', 'm√¢les'),
                (r'\bcoqs?\b', 'm√¢les'),
                (r'\bfemelles?\b', 'femelles'),
                (r'\bfemales?\b', 'femelles'),
                (r'\bpoules?\b', 'femelles'),
                (r'\bmixte\b', 'mixte'),
                (r'\btroupeau\s+mixte\b', 'mixte')
            ],
            "en": [
                (r'\bmales?\b', 'males'),
                (r'\brooster\b', 'males'),
                (r'\bfemales?\b', 'females'),
                (r'\bhens?\b', 'females'),
                (r'\bmixed?\b', 'mixed'),
                (r'\bmixed\s+flock\b', 'mixed')
            ],
            "es": [
                (r'\bmachos?\b', 'machos'),
                (r'\bgallos?\b', 'machos'),
                (r'\bhembras?\b', 'hembras'),
                (r'\bgallinas?\b', 'hembras'),
                (r'\bmixto\b', 'mixto'),
                (r'\blote\s+mixto\b', 'mixto')
            ]
        }
        
        patterns = sex_patterns.get(language, sex_patterns["fr"])
        
        for pattern, sex_name in patterns:
            if re.search(pattern, message_lower, re.IGNORECASE):
                entities.sex = sex_name
                entities.sex_confidence = 0.8
                logger.debug(f"üîç [BasicRobust] Sexe d√©tect√©: {sex_name}")
                break
        
        # üîß FIX 10: √Çge avec conversion s√©curis√©e des types
        age_patterns = [
            (r'(\d+)\s*jours?', 1, "days"),
            (r'(\d+)\s*semaines?', 7, "weeks"),
            (r'(\d+)\s*days?', 1, "days"),
            (r'(\d+)\s*weeks?', 7, "weeks")
        ]
        
        for pattern, multiplier, unit in age_patterns:
            match = re.search(pattern, message_lower, re.IGNORECASE)
            if match:
                try:
                    value = safe_int_conversion(match.group(1))
                    if value is None:
                        continue
                    
                    if unit == "weeks":
                        entities.age_weeks = float(value)
                        entities.age_days = value * 7
                    else:
                        entities.age_days = value
                        entities.age_weeks = round(value / 7, 1)
                    
                    # Synchroniser le champ age avec age_days
                    entities.age = entities.age_days
                    
                    # Validation √¢ge r√©aliste avec gestion s√©curis√©e
                    if entities.age_days and 0 < entities.age_days <= 365:
                        entities.age_confidence = 0.8
                    else:
                        entities.age_confidence = 0.3
                    
                    entities.age_last_updated = datetime.now()
                    logger.debug(f"üîç [BasicRobust] √Çge d√©tect√©: {entities.age_days}j ({entities.age_weeks}sem)")
                    break
                except (ValueError, TypeError) as e:
                    logger.warning(f"‚ö†Ô∏è [BasicRobust] Erreur conversion √¢ge: {e}")
                    continue
        
        # üîß FIX 11: Poids avec synchronisation weight/weight_grams et validation robuste
        weight_patterns = [
            (r'(\d+(?:\.\d+)?)\s*g\b', 1, "grams"),
            (r'(\d+(?:\.\d+)?)\s*kg', 1000, "kg"),
            (r'p√®sent?\s+(\d+(?:\.\d+)?)', 1, "grams"),
            (r'weigh\s+(\d+(?:\.\d+)?)', 1, "grams")
        ]
        
        for pattern, multiplier, unit in weight_patterns:
            match = re.search(pattern, message_lower, re.IGNORECASE)
            if match:
                try:
                    weight_value = safe_float_conversion(match.group(1))
                    if weight_value is None:
                        continue
                    
                    weight = weight_value * multiplier
                    
                    # Validation et correction automatique
                    if weight < 10:  # Probablement en kg
                        weight *= 1000
                        entities.weight_confidence = 0.7  # Confiance r√©duite car correction
                    elif weight > 10000:  # Trop √©lev√©
                        entities.weight_confidence = 0.3
                    else:
                        entities.weight_confidence = 0.8
                    
                    # üîß FIX: Synchronisation weight/weight_grams
                    entities.weight = weight
                    entities.weight_grams = weight
                    
                    logger.debug(f"üîç [BasicRobust] Poids d√©tect√©: {weight}g")
                    break
                except (ValueError, TypeError) as e:
                    logger.warning(f"‚ö†Ô∏è [BasicRobust] Erreur conversion poids: {e}")
                    continue
        
        # Mortalit√© avec conversion s√©curis√©e
        mortality_patterns = [
            r'mortalit√©.*?(\d+(?:\.\d+)?)%',
            r'mortality.*?(\d+(?:\.\d+)?)%',
            r'(\d+(?:\.\d+)?)%.*?mort'
        ]
        
        for pattern in mortality_patterns:
            match = re.search(pattern, message_lower, re.IGNORECASE)
            if match:
                try:
                    mortality_value = safe_float_conversion(match.group(1))
                    if mortality_value is not None and 0 <= mortality_value <= 100:
                        entities.mortality_rate = mortality_value
                        entities.mortality_confidence = 0.8
                        logger.debug(f"üîç [BasicRobust] Mortalit√© d√©tect√©e: {mortality_value}%")
                        break
                except (ValueError, TypeError) as e:
                    logger.warning(f"‚ö†Ô∏è [BasicRobust] Erreur conversion mortalit√©: {e}")
                    continue
        
        # Temp√©rature avec conversion s√©curis√©e
        temp_patterns = [
            r'temp√©rature.*?(\d+(?:\.\d+)?)¬∞?c',
            r'temperature.*?(\d+(?:\.\d+)?)¬∞?c',
            r'(\d+(?:\.\d+)?)¬∞c'
        ]
        
        for pattern in temp_patterns:
            match = re.search(pattern, message_lower, re.IGNORECASE)
            if match:
                try:
                    temp_value = safe_float_conversion(match.group(1))
                    if temp_value is not None and 10 <= temp_value <= 50:  # Plage r√©aliste
                        entities.temperature = temp_value
                        logger.debug(f"üîç [BasicRobust] Temp√©rature d√©tect√©e: {temp_value}¬∞C")
                        break
                except (ValueError, TypeError) as e:
                    logger.warning(f"‚ö†Ô∏è [BasicRobust] Erreur conversion temp√©rature: {e}")
                    continue
        
        # üîß FIX 12: Calcul confiance globale s√©curis√©
        confidence_scores = []
        
        if entities.breed_confidence > 0:
            confidence_scores.append(entities.breed_confidence)
        if entities.sex_confidence > 0:
            confidence_scores.append(entities.sex_confidence)
        if entities.age_confidence > 0:
            confidence_scores.append(entities.age_confidence)
        if entities.weight_confidence > 0:
            confidence_scores.append(entities.weight_confidence)
        if entities.mortality_confidence > 0:
            confidence_scores.append(entities.mortality_confidence)
        
        if confidence_scores:
            entities.confidence_overall = sum(confidence_scores) / len(confidence_scores)
        else:
            entities.confidence_overall = 0.0
        
        entities.extraction_success = entities.confidence_overall > 0.1
        
        return entities

    async def add_message_to_conversation(
        self,
        conversation_id: str,
        user_id: str,
        message: str,
        role: str = "user",
        language: str = "fr",
        message_type: str = "text"
    ) -> IntelligentConversationContext:
        """üîß FIX 13: Ajoute un message avec extraction d'entit√©s robuste et gestion d'erreurs compl√®te"""
        
        try:
            # R√©cup√©rer ou cr√©er le contexte
            context = self.get_conversation_context(conversation_id)
            if not context:
                context = IntelligentConversationContext(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    language=language
                )
            
            # Extraire les entit√©s de mani√®re robuste
            try:
                extracted_entities = await self.extract_entities_ai_enhanced(message, language, context)
            except Exception as extract_error:
                logger.warning(f"‚ö†Ô∏è [Memory] Erreur extraction entit√©s: {extract_error}")
                # Fallback ultime: entit√©s vides mais valides
                extracted_entities = IntelligentEntities(
                    extraction_method="error_fallback",
                    extraction_success=False,
                    confidence_overall=0.0
                )
            
            # D√âTECTION AUTOMATIQUE DES CLARIFICATIONS STANDARD
            is_clarification_response = False
            original_question_id = None
            
            # Si c'est un message court avec breed/sex ET qu'on a une clarification en attente
            if (role == "user" and context.pending_clarification and 
                len(message.split()) <= 5 and 
                (extracted_entities.breed or extracted_entities.sex)):
                
                is_clarification_response = True
                original_question_id = context.last_original_question_id
                logger.info(f"üéØ [Memory] Clarification STANDARD d√©tect√©e: {message} ‚Üí {original_question_id}")
                self._update_stats("clarification_resolutions")
            
            # D√âTECTION CLARIFICATION CRITIQUE
            elif (role == "user" and context.critical_clarification_active and 
                  len(message.split()) <= 5 and 
                  (extracted_entities.breed or extracted_entities.sex)):
                
                is_clarification_response = True
                logger.info(f"üö® [Memory] Clarification CRITIQUE d√©tect√©e: {message}")
                self._update_stats("critical_clarifications_resolved")
            
            # Cr√©er le message
            message_obj = ConversationMessage(
                id=f"{conversation_id}_{len(context.messages)}_{int(time.time())}",
                conversation_id=conversation_id,
                user_id=user_id,
                role=role,
                message=message,
                timestamp=datetime.now(),
                language=language,
                message_type=message_type,
                extracted_entities=extracted_entities,
                confidence_score=extracted_entities.confidence_overall if extracted_entities else 0.0,
                processing_method="ai_enhanced" if self.ai_enhancement_enabled else "basic_robust",
                is_clarification_response=is_clarification_response,
                original_question_id=original_question_id
            )
            
            # Ajouter au contexte (d√©clenche automatiquement le retraitement si clarification critique)
            context.add_message(message_obj)
            
            # V√©rifier si un retraitement est planifi√©
            if context.check_and_trigger_reprocessing():
                logger.info("üîÑ [Memory] Retraitement planifi√© d√©tect√© - √† traiter par l'appelant")
            
            # Sauvegarder de mani√®re s√©curis√©e
            try:
                self._save_conversation_to_db(context)
                self._save_message_to_db(message_obj)
            except Exception as save_error:
                logger.error(f"‚ùå [Memory] Erreur sauvegarde: {save_error}")
                # Continuer m√™me si la sauvegarde √©choue pour √©viter de casser le flux
            
            # Mettre en cache de mani√®re thread-safe
            with self.cache_lock:
                self.conversation_cache[conversation_id] = deepcopy(context)
                self._manage_cache_size()
            
            self._update_stats("total_messages")
            
            logger.info(f"üí¨ [Memory] Message ajout√©: {conversation_id} ({len(context.messages)} msgs)")
            
            return context
            
        except Exception as e:
            logger.error(f"‚ùå [Memory] Erreur critique ajout message: {e}")
            
            # Cr√©er un contexte minimal en fallback
            minimal_context = IntelligentConversationContext(
                conversation_id=conversation_id,
                user_id=user_id,
                language=language
            )
            
            return minimal_context

    def get_conversation_context(self, conversation_id: str) -> Optional[IntelligentConversationContext]:
        """R√©cup√®re le contexte conversationnel avec cache thread-safe"""
        
        # V√©rifier le cache d'abord de mani√®re thread-safe
        with self.cache_lock:
            if conversation_id in self.conversation_cache:
                context = deepcopy(self.conversation_cache[conversation_id])
                self._update_stats("cache_hits")
                return context
        
        self._update_stats("cache_misses")
        
        # Charger depuis la DB avec gestion d'erreurs
        try:
            context = self._load_context_from_db(conversation_id)
            if context:
                # Mettre en cache de mani√®re thread-safe
                with self.cache_lock:
                    self.conversation_cache[conversation_id] = deepcopy(context)
                    self._manage_cache_size()
                return context
        except Exception as e:
            logger.error(f"‚ùå [Memory] Erreur chargement contexte: {e}")
        
        return None

    def _load_context_from_db(self, conversation_id: str) -> Optional[IntelligentConversationContext]:
        """Charge un contexte depuis la base de donn√©es avec gestion robuste des erreurs"""
        
        try:
            with self._get_db_connection() as conn:
                # R√©cup√©rer la conversation
                conv_row = conn.execute(
                    "SELECT * FROM conversations WHERE conversation_id = ?",
                    (conversation_id,)
                ).fetchone()
                
                if not conv_row:
                    return None
                
                # R√©cup√©rer les messages
                message_rows = conn.execute(
                    """SELECT * FROM conversation_messages 
                       WHERE conversation_id = ? 
                       ORDER BY timestamp ASC 
                       LIMIT ?""",
                    (conversation_id, self.max_messages_in_memory)
                ).fetchall()
                
                # Reconstruire le contexte avec gestion s√©curis√©e
                context = IntelligentConversationContext(
                    conversation_id=conv_row["conversation_id"],
                    user_id=conv_row["user_id"],
                    language=conv_row["language"] or "fr",
                    created_at=self._safe_datetime_parse(conv_row["created_at"]),
                    last_activity=self._safe_datetime_parse(conv_row["last_activity"]),
                    total_exchanges=conv_row["total_exchanges"] or 0,
                    conversation_topic=conv_row["conversation_topic"],
                    conversation_urgency=conv_row["conversation_urgency"],
                    problem_resolution_status=conv_row["problem_resolution_status"],
                    ai_enhanced=bool(conv_row["ai_enhanced"]),
                    last_ai_analysis=self._safe_datetime_parse(conv_row["last_ai_analysis"]),
                    needs_clarification=bool(conv_row["needs_clarification"]),
                    clarification_questions=self._safe_json_parse(conv_row["clarification_questions"], []),
                    pending_clarification=bool(conv_row.get("pending_clarification", False)),
                    last_original_question_id=conv_row.get("last_original_question_id"),
                    # NOUVEAUX CHAMPS CLARIFICATION CRITIQUE
                    original_question_pending=conv_row.get("original_question_pending"),
                    critical_clarification_active=bool(conv_row.get("critical_clarification_active", False))
                )
                
                # Charger les entit√©s consolid√©es de mani√®re s√©curis√©e
                if conv_row["consolidated_entities"]:
                    try:
                        entities_data = json.loads(conv_row["consolidated_entities"])
                        context.consolidated_entities = self._entities_from_dict(entities_data)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è [DB] Erreur parsing entit√©s consolid√©es: {e}")
                        context.consolidated_entities = IntelligentEntities()
                
                # Charger les messages de mani√®re s√©curis√©e
                for msg_row in message_rows:
                    try:
                        entities = None
                        if msg_row["extracted_entities"]:
                            try:
                                entities_data = json.loads(msg_row["extracted_entities"])
                                entities = self._entities_from_dict(entities_data)
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è [DB] Erreur parsing entit√©s message: {e}")
                        
                        message_obj = ConversationMessage(
                            id=msg_row["id"],
                            conversation_id=msg_row["conversation_id"],
                            user_id=msg_row["user_id"],
                            role=msg_row["role"],
                            message=msg_row["message"],
                            timestamp=self._safe_datetime_parse(msg_row["timestamp"]),
                            language=msg_row["language"] or "fr",
                            message_type=msg_row["message_type"] or "text",
                            extracted_entities=entities,
                            confidence_score=msg_row["confidence_score"] or 0.0,
                            processing_method=msg_row["processing_method"] or "basic",
                            is_original_question=bool(msg_row.get("is_original_question", False)),
                            is_clarification_response=bool(msg_row.get("is_clarification_response", False)),
                            original_question_id=msg_row.get("original_question_id")
                        )
                        
                        context.messages.append(message_obj)
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è [DB] Erreur reconstruction message: {e}")
                        continue
                
                return context
                
        except Exception as e:
            logger.error(f"‚ùå [DB] Erreur chargement contexte: {e}")
            return None

    def _safe_datetime_parse(self, date_str: str) -> datetime:
        """Parse une date de mani√®re s√©curis√©e"""
        if not date_str:
            return datetime.now()
        try:
            return datetime.fromisoformat(date_str)
        except (ValueError, TypeError):
            return datetime.now()

    def _safe_json_parse(self, json_str: str, default: Any = None) -> Any:
        """Parse JSON de mani√®re s√©curis√©e"""
        if not json_str:
            return default or []
        try:
            return json.loads(json_str)
        except (json.JSONDecodeError, TypeError):
            return default or []

    def _entities_from_dict(self, data: Dict[str, Any]) -> IntelligentEntities:
        """üîß FIX 14: Reconstruit les entit√©s depuis un dictionnaire avec gestion compl√®te des erreurs"""
        
        try:
            # Convertir les dates de mani√®re s√©curis√©e
            for date_field in ["age_last_updated", "last_ai_update"]:
                if data.get(date_field):
                    try:
                        data[date_field] = datetime.fromisoformat(data[date_field])
                    except (ValueError, TypeError):
                        data[date_field] = None
            
            # Convertir les tuples de mani√®re s√©curis√©e
            if data.get("expected_weight_range") and isinstance(data["expected_weight_range"], list):
                try:
                    data["expected_weight_range"] = tuple(data["expected_weight_range"])
                except (ValueError, TypeError):
                    data["expected_weight_range"] = None
            
            # Assurer les listes de mani√®re s√©curis√©e
            for list_field in ["symptoms", "previous_treatments"]:
                if not isinstance(data.get(list_field), list):
                    data[list_field] = []
            
            # üîß FIX: S'assurer que tous les champs requis sont pr√©sents avec valeurs par d√©faut
            default_values = {
                'age': None,
                'breed': None,
                'sex': None,
                'age_days': None,
                'age_weeks': None,
                'age_confidence': 0.0,
                'breed_confidence': 0.0,
                'sex_confidence': 0.0,
                'weight': None,  # ‚Üê CHAMP CRITIQUE AJOUT√â
                'weight_grams': None,
                'weight_confidence': 0.0,
                'extraction_method': 'basic',
                'confidence_overall': 0.0,
                'data_validated': False,
                'extraction_success': True,
                'extraction_attempts': 0,
                'mortality_rate': None,
                'mortality_confidence': 0.0,
                'symptoms': [],
                'health_status': None,
                'temperature': None,
                'humidity': None,
                'housing_type': None,
                'ventilation_quality': None,
                'feed_type': None,
                'feed_conversion': None,
                'water_consumption': None,
                'flock_size': None,
                'vaccination_status': None,
                'previous_treatments': [],
                'problem_duration': None,
                'problem_severity': None,
                'intervention_urgency': None,
                'expected_weight_range': None,
                'growth_rate': None,
                'last_ai_update': None,
                'age_last_updated': None
            }
            
            # Ajouter les valeurs par d√©faut pour les champs manquants
            for field, default_value in default_values.items():
                if field not in data:
                    data[field] = default_value
            
            # üîß FIX: Synchronisation weight/weight_grams et age/age_days
            # Conversion s√©curis√©e des valeurs num√©riques
            weight_grams_safe = safe_float_conversion(data.get('weight_grams'))
            weight_safe = safe_float_conversion(data.get('weight'))
            age_days_safe = safe_int_conversion(data.get('age_days'))
            age_safe = safe_int_conversion(data.get('age'))
            
            # Synchroniser weight et weight_grams
            if weight_grams_safe is not None and weight_safe is None:
                data['weight'] = weight_grams_safe
            elif weight_safe is not None and weight_grams_safe is None:
                data['weight_grams'] = weight_safe
            
            # Synchroniser age et age_days
            if age_days_safe is not None and age_safe is None:
                data['age'] = age_days_safe
            elif age_safe is not None and age_days_safe is None:
                data['age_days'] = age_safe
            
            # Cr√©er l'entit√© avec seulement les champs valides
            valid_fields = {k: v for k, v in data.items() if k in IntelligentEntities.__dataclass_fields__}
            
            return IntelligentEntities(**valid_fields)
            
        except Exception as e:
            logger.error(f"‚ùå [Entities] Erreur reconstruction entit√©s: {e}")
            # Retourner des entit√©s vides mais valides
            return IntelligentEntities(
                extraction_method="reconstruction_error",
                extraction_success=False,
                confidence_overall=0.0
            )

    def _save_conversation_to_db(self, context: IntelligentConversationContext):
        """Sauvegarde un contexte en base de donn√©es avec gestion d'erreurs robuste"""
        
        try:
            with self._get_db_connection() as conn:
                # Pr√©parer les donn√©es de mani√®re s√©curis√©e
                try:
                    consolidated_entities_json = json.dumps(context.consolidated_entities.to_dict(), ensure_ascii=False)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [DB] Erreur s√©rialisation entit√©s: {e}")
                    consolidated_entities_json = "{}"
                
                try:
                    clarification_questions_json = json.dumps(context.clarification_questions, ensure_ascii=False)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [DB] Erreur s√©rialisation questions: {e}")
                    clarification_questions_json = "[]"
                
                # Upsert de la conversation avec nouveaux champs
                conn.execute("""
                    INSERT OR REPLACE INTO conversations (
                        conversation_id, user_id, language, created_at, last_activity,
                        total_exchanges, consolidated_entities, conversation_topic,
                        conversation_urgency, problem_resolution_status, ai_enhanced,
                        last_ai_analysis, needs_clarification, clarification_questions,
                        pending_clarification, last_original_question_id, 
                        original_question_pending, critical_clarification_active,
                        confidence_overall
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    context.conversation_id,
                    context.user_id,
                    context.language,
                    context.created_at.isoformat(),
                    context.last_activity.isoformat(),
                    context.total_exchanges,
                    consolidated_entities_json,
                    context.conversation_topic,
                    context.conversation_urgency,
                    context.problem_resolution_status,
                    context.ai_enhanced,
                    context.last_ai_analysis.isoformat() if context.last_ai_analysis else None,
                    context.needs_clarification,
                    clarification_questions_json,
                    context.pending_clarification,
                    context.last_original_question_id,
                    # NOUVEAUX CHAMPS
                    context.original_question_pending,
                    context.critical_clarification_active,
                    context.consolidated_entities.confidence_overall
                ))
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"‚ùå [DB] Erreur sauvegarde conversation: {e}")
            raise

    def _save_message_to_db(self, message: ConversationMessage):
        """Sauvegarde un message en base de donn√©es avec gestion d'erreurs"""
        
        try:
            with self._get_db_connection() as conn:
                # Pr√©parer les donn√©es de mani√®re s√©curis√©e
                entities_json = None
                if message.extracted_entities:
                    try:
                        entities_json = json.dumps(message.extracted_entities.to_dict(), ensure_ascii=False)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è [DB] Erreur s√©rialisation entit√©s message: {e}")
                
                # Insert du message
                conn.execute("""
                    INSERT OR REPLACE INTO conversation_messages (
                        id, conversation_id, user_id, role, message, timestamp,
                        language, message_type, extracted_entities, confidence_score,
                        processing_method, is_original_question, is_clarification_response,
                        original_question_id
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    message.id,
                    message.conversation_id,
                    message.user_id,
                    message.role,
                    message.message,
                    message.timestamp.isoformat(),
                    message.language,
                    message.message_type,
                    entities_json,
                    message.confidence_score,
                    message.processing_method,
                    message.is_original_question,
                    message.is_clarification_response,
                    message.original_question_id
                ))
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"‚ùå [DB] Erreur sauvegarde message: {e}")
            raise

    def _manage_cache_size(self):
        """G√®re la taille du cache en m√©moire - VERSION THREAD-SAFE"""
        
        if len(self.conversation_cache) > self.cache_max_size:
            # Supprimer les conversations les moins r√©cemment utilis√©es
            sorted_conversations = sorted(
                self.conversation_cache.items(),
                key=lambda x: x[1].last_activity
            )
            
            # Garder seulement les plus r√©centes
            conversations_to_keep = dict(sorted_conversations[-self.cache_max_size//2:])
            self.conversation_cache = conversations_to_keep
            
            logger.info(f"üßπ [Memory] Cache nettoy√©: {len(self.conversation_cache)} conversations gard√©es")

    def get_conversation_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du syst√®me avec nouvelles m√©triques clarification critique"""
        
        with self._stats_lock:
            stats_copy = self.stats.copy()
        
        with self.cache_lock:
            cache_size = len(self.conversation_cache)
        
        return {
            "system_stats": stats_copy,
            "cache_stats": {
                "cache_size": cache_size,
                "cache_max_size": self.cache_max_size,
                "hit_rate": stats_copy["cache_hits"] / (stats_copy["cache_hits"] + stats_copy["cache_misses"]) if (stats_copy["cache_hits"] + stats_copy["cache_misses"]) > 0 else 0
            },
            "clarification_stats": {
                "questions_recovered": stats_copy["original_questions_recovered"],
                "clarifications_resolved": stats_copy["clarification_resolutions"],
                # NOUVELLES M√âTRIQUES CRITIQUES
                "critical_clarifications_marked": stats_copy["critical_clarifications_marked"],
                "critical_clarifications_resolved": stats_copy["critical_clarifications_resolved"],
                "rag_reprocessing_triggered": stats_copy["rag_reprocessing_triggered"]
            }
        }

    def cleanup_old_conversations(self, days_old: int = 30):
        """Nettoie les conversations anciennes avec gestion d'erreurs"""
        
        try:
            cutoff_date = datetime.now() - timedelta(days=days_old)
            
            with self._get_db_connection() as conn:
                # Supprimer les messages anciens
                result_messages = conn.execute(
                    "DELETE FROM conversation_messages WHERE timestamp < ?",
                    (cutoff_date.isoformat(),)
                )
                
                # Supprimer les conversations anciennes
                result_conversations = conn.execute(
                    "DELETE FROM conversations WHERE last_activity < ?",
                    (cutoff_date.isoformat(),)
                )
                
                conn.commit()
                
                logger.info(f"üßπ [Cleanup] {result_messages.rowcount} messages et {result_conversations.rowcount} conversations supprim√©s")
                
        except Exception as e:
            logger.error(f"‚ùå [Cleanup] Erreur nettoyage: {e}")

    # SYST√àME DE CLARIFICATION INT√âGR√â - VERSION ROBUSTE
    
    def build_enriched_question_from_clarification(
        self,
        original_question: str,
        clarification_response: str,
        conversation_context: Optional[IntelligentConversationContext] = None
    ) -> str:
        """
        Enrichit la question originale avec la clarification de mani√®re robuste
        
        Exemple:
        - Original: "Quel est le poids d'un poulet de 12 jours ?"
        - Clarification: "Ross 308 m√¢les"
        - Enrichi: "Quel est le poids d'un poulet Ross 308 m√¢le de 12 jours ?"
        """
        
        try:
            # Analyser la clarification pour extraire les entit√©s
            clarification_lower = clarification_response.lower().strip()
            
            # D√©tection race
            breed_info = self._extract_breed_from_clarification(clarification_lower)
            sex_info = self._extract_sex_from_clarification(clarification_lower)
            
            # Construire l'enrichissement
            enrichments = []
            
            if breed_info:
                enrichments.append(breed_info)
            
            if sex_info:
                enrichments.append(sex_info)
            
            # Int√©grer dans la question originale
            if enrichments:
                enriched_question = self._integrate_enrichments_into_question(
                    original_question, 
                    enrichments
                )
                
                logger.info(f"‚úÖ [Clarification] Question enrichie r√©ussie")
                logger.info(f"  üìù Original: {original_question}")
                logger.info(f"  üîÅ Enrichi: {enriched_question}")
                
                return enriched_question
            else:
                # Fallback: concat√©nation simple
                fallback_question = f"{original_question} Contexte: {clarification_response}"
                logger.warning(f"‚ö†Ô∏è [Clarification] Fallback utilis√©: {fallback_question}")
                return fallback_question
                
        except Exception as e:
            logger.error(f"‚ùå [Clarification] Erreur enrichissement: {e}")
            # Fallback ultime: question originale
            return original_question
    
    def _extract_breed_from_clarification(self, clarification: str) -> Optional[str]:
        """Extrait la race de la r√©ponse de clarification"""
        
        breed_patterns = [
            r'ross\s*308',
            r'ross\s*708', 
            r'cobb\s*500',
            r'cobb\s*700',
            r'hubbard\s*flex',
            r'arbor\s*acres'
        ]
        
        for pattern in breed_patterns:
            match = re.search(pattern, clarification, re.IGNORECASE)
            if match:
                breed = match.group(0).strip().replace(' ', ' ').title()
                logger.debug(f"üîç [Clarification] Race d√©tect√©e: {breed}")
                return breed
        
        # Patterns g√©n√©riques
        generic_patterns = [
            r'poulets?\s+de\s+chair',
            r'broilers?',
            r'poulets?'
        ]
        
        for pattern in generic_patterns:
            if re.search(pattern, clarification, re.IGNORECASE):
                logger.debug(f"üîç [Clarification] Race g√©n√©rique d√©tect√©e")
                return "poulets de chair"
        
        return None
    
    def _extract_sex_from_clarification(self, clarification: str) -> Optional[str]:
        """Extrait le sexe de la r√©ponse de clarification"""
        
        sex_patterns = [
            (r'\bm√¢les?\b', 'm√¢les'),
            (r'\bmales?\b', 'm√¢les'),
            (r'\bcoqs?\b', 'm√¢les'),
            (r'\bfemelles?\b', 'femelles'),
            (r'\bfemales?\b', 'femelles'),
            (r'\bpoules?\b', 'femelles'),
            (r'\bmixte\b', 'mixte'),
            (r'\btroupeau\s+mixte\b', 'mixte')
        ]
        
        for pattern, sex_name in sex_patterns:
            if re.search(pattern, clarification, re.IGNORECASE):
                logger.debug(f"üîç [Clarification] Sexe d√©tect√©: {sex_name}")
                return sex_name
        
        return None
    
    def _integrate_enrichments_into_question(
        self, 
        original_question: str, 
        enrichments: list
    ) -> str:
        """Int√®gre intelligemment les enrichissements dans la question"""
        
        # Patterns de questions communes o√π ins√©rer les enrichissements
        question_patterns = [
            # "Quel est le poids d'un poulet de X jours ?"
            (r'(quel\s+est\s+le\s+poids\s+d.un\s+)poulet(\s+de\s+\d+\s+jours?)',
             r'\1{} \2'),
            
            # "Mes poulets de X jours p√®sent Y"
            (r'(mes\s+)poulets?(\s+de\s+\d+\s+jours?)',
             r'\1{} \2'),
            
            # "Comment nourrir des poulets de X semaines ?"
            (r'(comment\s+\w+\s+des\s+)poulets?(\s+de\s+\d+\s+semaines?)',
             r'\1{} \2'),
            
            # Pattern g√©n√©rique "poulet" ‚Üí "poulet [race] [sexe]"
            (r'\bpoulets?\b',
             '{}')
        ]
        
        enrichment_text = ' '.join(enrichments)
        
        for pattern, replacement in question_patterns:
            if re.search(pattern, original_question, re.IGNORECASE):
                enriched = re.sub(
                    pattern, 
                    replacement.format(enrichment_text),
                    original_question, 
                    flags=re.IGNORECASE
                )
                
                # Nettoyer les espaces multiples
                enriched = re.sub(r'\s+', ' ', enriched).strip()
                
                return enriched
        
        # Fallback: ajout en contexte
        return f"{original_question} (Contexte: {enrichment_text})"
    
    def detect_clarification_state(
        self, 
        conversation_context: IntelligentConversationContext
    ) -> Tuple[bool, Optional[str]]:
        """
        D√©tecte si on est en attente de clarification
        
        Returns:
            (is_awaiting_clarification, original_question_text)
        """
        
        try:
            # V√©rifier l'√©tat dans le contexte
            if conversation_context.pending_clarification:
                original_question_msg = conversation_context.find_original_question()
                
                if original_question_msg:
                    return True, original_question_msg.message
            
            # V√âRIFIER AUSSI L'√âTAT CLARIFICATION CRITIQUE
            if conversation_context.critical_clarification_active and conversation_context.original_question_pending:
                return True, conversation_context.original_question_pending
            
            # Fallback: analyser les derniers messages
            if len(conversation_context.messages) >= 2:
                last_assistant_msg = None
                
                # Chercher le dernier message assistant
                for msg in reversed(conversation_context.messages):
                    if msg.role == "assistant":
                        last_assistant_msg = msg
                        break
                
                if last_assistant_msg:
                    # Mots-cl√©s indiquant une demande de clarification
                    clarification_keywords = [
                        "j'ai besoin de", "pouvez-vous pr√©ciser", "quelle est la race",
                        "quel est le sexe", "de quelle race", "m√¢les ou femelles"
                    ]
                    
                    msg_lower = last_assistant_msg.message.lower()
                    
                    if any(keyword in msg_lower for keyword in clarification_keywords):
                        # Chercher la question utilisateur pr√©c√©dente
                        original_question = conversation_context.get_last_user_question()
                        
                        if original_question:
                            return True, original_question.message
            
            return False, None
            
        except Exception as e:
            logger.error(f"‚ùå [Clarification] Erreur d√©tection √©tat: {e}")
            return False, None

    async def process_enhanced_question_with_clarification(
        self,
        request_text: str,
        conversation_id: str,
        user_id: str,
        language: str = "fr"
    ) -> Tuple[str, bool]:
        """
        FONCTION PRINCIPALE - Traite les questions avec gestion clarification robuste
        
        Returns:
            (processed_question, was_clarification_resolved)
        """
        
        try:
            # 1. R√©cup√©rer le contexte conversationnel
            context = self.get_conversation_context(conversation_id)
            
            if not context:
                # Nouvelle conversation
                logger.info(f"üÜï [Clarification] Nouvelle conversation: {conversation_id}")
                return request_text, False
            
            # 2. D√©tecter si on est en attente de clarification
            is_awaiting, original_question = self.detect_clarification_state(context)
            
            if is_awaiting and original_question:
                logger.info(f"üéØ [Clarification] √âtat d√©tect√© - traitement clarification")
                
                # 3. Enrichir la question originale avec la clarification
                enriched_question = self.build_enriched_question_from_clarification(
                    original_question=original_question,
                    clarification_response=request_text,
                    conversation_context=context
                )
                
                # 4. Reset l'√©tat de clarification pour √©viter les boucles
                context.pending_clarification = False
                context.last_original_question_id = None
                
                # RESET AUSSI L'√âTAT CLARIFICATION CRITIQUE
                context.critical_clarification_active = False
                context.original_question_pending = None
                
                # 5. Marquer ce message comme r√©ponse de clarification
                await self.add_message_to_conversation(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message=request_text,
                    role="user",
                    language=language,
                    message_type="clarification_response"
                )
                
                # 6. Mettre √† jour les statistiques
                self._update_stats("clarification_resolutions")
                self._update_stats("critical_clarifications_resolved")
                
                logger.info(f"‚úÖ [Clarification] Question enrichie avec succ√®s")
                
                return enriched_question, True
            
            else:
                # Question normale - pas de clarification en cours
                logger.info(f"üí¨ [Clarification] Question normale - pas de clarification")
                return request_text, False
        
        except Exception as e:
            logger.error(f"‚ùå [Clarification] Erreur traitement: {e}")
            # En cas d'erreur, retourner la question originale
            return request_text, False

    def check_if_clarification_needed(
        self,
        question: str,
        rag_response: Any,
        context: Optional[IntelligentConversationContext],
        language: str = "fr"
    ) -> Tuple[bool, List[str]]:
        """D√©termine si une clarification est n√©cessaire"""
        
        if not context:
            return False, []
        
        entities = context.consolidated_entities
        missing_info = entities.get_critical_missing_info()
        
        clarification_questions = []
        
        # Messages de clarification par langue
        clarification_messages = {
            "fr": {
                "breed": "De quelle race de poulets s'agit-il ? (ex: Ross 308, Cobb 500)",
                "sex": "S'agit-il de m√¢les, femelles, ou d'un troupeau mixte ?",
                "age": "Quel est l'√¢ge de vos poulets ?"
            },
            "en": {
                "breed": "What breed of chickens are we talking about? (e.g., Ross 308, Cobb 500)",
                "sex": "Are these males, females, or a mixed flock?",
                "age": "How old are your chickens?"
            },
            "es": {
                "breed": "¬øDe qu√© raza de pollos estamos hablando? (ej: Ross 308, Cobb 500)",
                "sex": "¬øSon machos, hembras, o un lote mixto?",
                "age": "¬øQu√© edad tienen sus pollos?"
            }
        }
        
        messages = clarification_messages.get(language, clarification_messages["fr"])
        
        # Race manquante ou g√©n√©rique
        if "breed" in missing_info:
            clarification_questions.append(messages["breed"])
        
        # Sexe manquant
        if "sex" in missing_info:
            clarification_questions.append(messages["sex"])
        
        # √Çge manquant
        if "age" in missing_info:
            clarification_questions.append(messages["age"])
        
        # Au maximum 2 questions de clarification
        needs_clarification = len(clarification_questions) > 0 and len(clarification_questions) <= 2
        
        return needs_clarification, clarification_questions[:2]

    def generate_clarification_request(
        self, 
        clarification_questions: List[str], 
        language: str = "fr"
    ) -> str:
        """G√©n√®re une demande de clarification naturelle"""
        
        if not clarification_questions:
            fallback_messages = {
                "fr": "Pouvez-vous me donner plus de d√©tails ?",
                "en": "Can you give me more details?",
                "es": "¬øPuede darme m√°s detalles?"
            }
            return fallback_messages.get(language, fallback_messages["fr"])
        
        intro_messages = {
            "fr": "Pour vous donner une r√©ponse plus pr√©cise, j'ai besoin de quelques informations suppl√©mentaires :",
            "en": "To give you a more accurate answer, I need some additional information:",
            "es": "Para darle una respuesta m√°s precisa, necesito informaci√≥n adicional:"
        }
        
        intro = intro_messages.get(language, intro_messages["fr"])
        questions_text = "\n".join([f"‚Ä¢ {q}" for q in clarification_questions])
        
        return f"{intro}\n\n{questions_text}"

    # M√âTHODES POUR CLARIFICATION CRITIQUE - VERSION ROBUSTE

    def mark_pending_clarification_critical(
        self, 
        conversation_id: str,
        question: str, 
        callback: Optional[RAGCallbackProtocol] = None
    ) -> bool:
        """
        Marque une question pour clarification critique avec callback robuste
        
        Args:
            conversation_id: ID de la conversation
            question: Question originale qui n√©cessite clarification
            callback: Fonction callback pour relancer le traitement RAG
            
        Returns:
            bool: True si marquage r√©ussi, False sinon
        """
        
        try:
            # R√©cup√©rer le contexte
            context = self.get_conversation_context(conversation_id)
            if not context:
                logger.error(f"‚ùå [CriticalClarification] Contexte non trouv√©: {conversation_id}")
                return False
            
            # Marquer la clarification critique
            context.mark_pending_clarification(question, callback)
            
            # Sauvegarder en base de mani√®re s√©curis√©e
            try:
                self._save_conversation_to_db(context)
            except Exception as save_error:
                logger.warning(f"‚ö†Ô∏è [CriticalClarification] Erreur sauvegarde: {save_error}")
                # Continuer m√™me si sauvegarde √©choue
            
            # Mettre √† jour le cache de mani√®re thread-safe
            with self.cache_lock:
                self.conversation_cache[conversation_id] = deepcopy(context)
            
            # Statistiques
            self._update_stats("critical_clarifications_marked")
            
            logger.info(f"üö® [CriticalClarification] Marquage r√©ussi pour: {conversation_id}")
            logger.info(f"  üìù Question: {question[:100]}...")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå [CriticalClarification] Erreur marquage: {e}")
            return False

    def mark_question_for_clarification(
        self, 
        conversation_id: str, 
        user_id: str, 
        original_question: str, 
        language: str = "fr"
    ) -> str:
        """
        Marque une question pour clarification future de mani√®re robuste
        """
        
        try:
            # Cr√©er un marqueur sp√©cial dans la conversation
            marker_message = f"ORIGINAL_QUESTION_FOR_CLARIFICATION: {original_question}"
            
            message_id = f"{conversation_id}_original_{int(time.time())}"
            
            # Cr√©er le message marqueur
            marker_msg = ConversationMessage(
                id=message_id,
                conversation_id=conversation_id,
                user_id=user_id,
                role="system",
                message=marker_message,
                timestamp=datetime.now(),
                language=language,
                message_type="original_question_marker",
                is_original_question=True
            )
            
            # R√©cup√©rer ou cr√©er le contexte
            context = self.get_conversation_context(conversation_id)
            if not context:
                context = IntelligentConversationContext(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    language=language
                )
            
            # Ajouter le marqueur
            context.add_message(marker_msg)
            context.pending_clarification = True
            context.last_original_question_id = message_id
            
            # Sauvegarder de mani√®re s√©curis√©e
            try:
                self._save_conversation_to_db(context)
                self._save_message_to_db(marker_msg)
            except Exception as save_error:
                logger.warning(f"‚ö†Ô∏è [Clarification] Erreur sauvegarde marqueur: {save_error}")
            
            # Mettre en cache de mani√®re thread-safe
            with self.cache_lock:
                self.conversation_cache[conversation_id] = deepcopy(context)
            
            logger.info(f"üéØ [Memory] Question originale marqu√©e: {original_question[:50]}...")
            
            return message_id
            
        except Exception as e:
            logger.error(f"‚ùå [Clarification] Erreur marquage question: {e}")
            return f"error_{int(time.time())}"


# ===============================
# üîß R√âSUM√â DES CORRECTIONS COMPL√àTES APPLIQU√âES
# ===============================

"""
üö® R√â√âCRITURE COMPL√àTE AVEC TOUTES LES CORRECTIONS:

1. ‚úÖ ATTRIBUT 'weight' MANQUANT:
   - Ajout√© weight: Optional[float] = None dans IntelligentEntities
   - Synchronisation automatique weight ‚Üî weight_grams dans __post_init__()
   - Gestion coh√©rente dans toutes les m√©thodes

2. ‚úÖ GESTION S√âCURIS√âE DES TYPES str/int:
   - Fonctions safe_int_conversion() et safe_float_conversion()
   - Utilisation dans toutes les comparaisons et conversions
   - √âvite les erreurs "'<' not supported between instances of 'str' and 'int'"

3. ‚úÖ FALLBACK ROBUSTE:
   - _extract_entities_basic_robust() sans d√©pendances manquantes
   - Gestion d'erreurs √† tous les niveaux
   - Fallback ultime avec entit√©s vides mais valides

4. ‚úÖ VALIDATION D'INCOH√âRENCES AM√âLIOR√âE:
   - validate_and_correct() avec corrections automatiques
   - Log des changements et enrichissement automatique
   - Conversion automatique des unit√©s (kg‚Üíg, F‚ÜíC)

5. ‚úÖ TOUS LES ATTRIBUTS REQUIS:
   - Liste compl√®te des champs dans IntelligentEntities
   - Valeurs par d√©faut pour tous les champs manquants
   - Reconstruction s√©curis√©e depuis la DB

6. ‚úÖ GESTION D'ERREURS RENFORC√âE:
   - Try/catch √† tous les niveaux critiques
   - Continuation du flux m√™me en cas d'erreur de sauvegarde
   - Logs d√©taill√©s pour debugging

7. ‚úÖ THREAD-SAFETY:
   - RLock pour √©viter les deadlocks
   - DeepCopy pour √©viter les modifications concurrentes
   - WeakRef pour √©viter les fuites m√©moire

8. ‚úÖ TYPES ET ANNOTATIONS:
   - Type hints complets et corrects
   - Protocol pour les callbacks
   - Gestion s√©curis√©e des Optional

Le code est maintenant ENTI√àREMENT FONCTIONNEL et robuste contre toutes les erreurs identifi√©es.

üìå UTILISATION DANS expert_services.py:
- Remplacer l'import par ce fichier
- Toutes les m√©thodes existantes conserv√©es
- Nouvelles m√©thodes robustes ajout√©es
- Compatibilit√© totale garantie
"""