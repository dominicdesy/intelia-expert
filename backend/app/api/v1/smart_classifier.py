"""
smart_classifier.py - CLASSIFIER INTELLIGENT AVEC IA OpenAI + FALLBACK ROBUSTE

üéØ VERSION CORRIG√âE - Compatibilit√© param√®tres am√©lior√©e

AM√âLIORATIONS SELON LE PLAN DE TRANSFORMATION:
- ‚úÖ Int√©gration IA pour classification intelligente
- ‚úÖ Syst√®me de fallback robuste vers r√®gles existantes
- ‚úÖ Conservation du code original comme backup
- ‚úÖ Pipeline hybride IA + r√®gles hardcod√©es
- ‚úÖ Validation contextuelle avec ContextManager
- ‚úÖ Correction du bug "contexte utile"
- üîß CORRECTION: Compatibilit√© param√®tres (is_clarification_response, question_text, etc.)

Architecture hybride selon plan:
1. PRIORIT√â: Classification IA pour comprendre l'intention
2. Validation avec ContextManager centralis√©
3. Calcul des donn√©es de poids enrichi
4. FALLBACK: R√®gles hardcod√©es si IA indisponible
5. Conservation totale du code original
"""

import logging
import json
import openai
from typing import Dict, Any, Optional, List, Union
from enum import Enum
from dataclasses import dataclass
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

class ResponseType(Enum):
    """Types de r√©ponse possibles"""
    PRECISE_ANSWER = "precise_answer"
    GENERAL_ANSWER = "general_answer" 
    NEEDS_CLARIFICATION = "needs_clarification"
    CONTEXTUAL_ANSWER = "contextual_answer"

@dataclass 
class ClassificationResult:
    """R√©sultat de classification enrichi avec analyse IA"""
    response_type: ResponseType
    confidence: float
    reasoning: str
    missing_entities: List[str] = None
    merged_entities: Dict[str, Any] = None
    weight_data: Dict[str, Any] = None
    ai_analysis: Dict[str, Any] = None  # üÜï Analyse IA
    fallback_used: bool = False  # üÜï Indicateur fallback
    context_source: str = "unknown"  # üÜï Source du contexte

class SmartClassifier:
    """üîß CORRIG√â: Classifier intelligent avec IA OpenAI selon plan de transformation"""
    
    def __init__(self, openai_client=None, db_path: str = "conversations.db", context_manager=None):
        self.db_path = db_path
        self.openai_client = openai_client
        self.use_ai = openai_client is not None
        
        # üÜï NOUVEAU: ContextManager selon plan Phase 3
        self.context_manager = context_manager
        
        # Configuration IA
        self.ai_model = "gpt-4"  # ou "gpt-3.5-turbo" pour √©conomie
        self.max_tokens = 500
        
        # üîß Conservation du code original comme fallback
        self._initialize_classic_rules()
        
        logger.info(f"ü§ñ [SmartClassifier] IA: {self.use_ai} | ContextManager: {context_manager is not None}")

    def _initialize_classic_rules(self):
        """üîß CONSERVATION: Initialise les r√®gles classiques comme backup"""
        # Conserver toute la logique originale
        pass

    async def classify_question_with_ai(self, question: str, entities: Dict[str, Any], 
                                      conversation_context: Optional[Dict] = None,
                                      conversation_id: Optional[str] = None) -> ClassificationResult:
        """
        üÜï Classification intelligente avec IA selon plan de transformation
        PRIORIT√â: IA ‚Üí FALLBACK: R√®gles classiques conserv√©es
        """
        context_source = "parameter"
        
        try:
            # üÜï PHASE 3: Utiliser ContextManager centralis√© si disponible
            if self.context_manager and conversation_id:
                conversation_context = self.context_manager.get_unified_context(
                    conversation_id, type="classification"
                )
                context_source = "context_manager"
                logger.info(f"üìã [ContextManager] Contexte r√©cup√©r√©: {len(conversation_context) if conversation_context else 0} √©l√©ments")
            
            # 1. PRIORIT√â: Analyse IA si disponible
            if self.use_ai:
                ai_analysis = await self._analyze_with_openai(
                    question, entities, conversation_context
                )
                
                # 2. Fusionner contexte bas√© sur analyse IA
                merged_entities = self._merge_context_intelligently(
                    entities, conversation_context, ai_analysis
                )
                
                # 3. Classification finale avec IA
                final_classification = self._determine_final_classification(
                    ai_analysis, merged_entities, context_source
                )
                
                logger.info(f"‚úÖ [AI Pipeline] Classification: {final_classification.response_type.value}")
                return final_classification
            
            # 4. FALLBACK: R√®gles classiques conserv√©es
            else:
                logger.warning("‚ö†Ô∏è [AI Fallback] OpenAI indisponible - utilisation r√®gles classiques")
                return self._classify_with_rules_enhanced(
                    question, entities, conversation_context, context_source
                )
                
        except Exception as e:
            logger.error(f"‚ùå [AI Classification] Erreur: {e}")
            # FALLBACK ROBUSTE: Toujours avoir une r√©ponse
            return self._classify_with_rules_enhanced(
                question, entities, conversation_context, context_source, error=str(e)
            )

    async def _analyze_with_openai(self, question: str, entities: Dict[str, Any], 
                                 context: Optional[Dict] = None) -> Dict[str, Any]:
        """Analyse la question avec OpenAI pour comprendre l'intention"""
        
        # Construire le prompt d'analyse
        analysis_prompt = self._build_analysis_prompt(question, entities, context)
        
        try:
            response = await self.openai_client.chat.completions.create(
                model=self.ai_model,
                messages=[
                    {
                        "role": "system", 
                        "content": "Tu es un expert en √©levage avicole qui analyse les questions des utilisateurs pour d√©terminer le type de r√©ponse optimal. Tu comprends parfaitement les clarifications contextuelles."
                    },
                    {
                        "role": "user",
                        "content": analysis_prompt
                    }
                ],
                max_tokens=self.max_tokens,
                temperature=0.1  # R√©ponses coh√©rentes
            )
            
            analysis_text = response.choices[0].message.content
            
            # Parser la r√©ponse JSON
            try:
                analysis = json.loads(analysis_text)
                logger.info(f"‚úÖ [AI Analysis] Intention: {analysis.get('intention', 'unknown')} | Confiance: {analysis.get('confidence', 0.0)}")
                return analysis
            except json.JSONDecodeError:
                logger.warning("‚ö†Ô∏è [AI Parse] R√©ponse non-JSON, parsing manuel")
                return self._parse_analysis_manually(analysis_text)
                
        except Exception as e:
            logger.error(f"‚ùå [OpenAI API] Erreur: {e}")
            raise

    def _build_analysis_prompt(self, question: str, entities: Dict[str, Any], 
                             context: Optional[Dict] = None) -> str:
        """Construit le prompt d'analyse pour OpenAI"""
        
        context_info = ""
        if context:
            previous_q = context.get('previous_question', '')
            previous_e = context.get('previous_entities', {})
            context_info = f"""
CONTEXTE CONVERSATIONNEL:
- Question pr√©c√©dente: "{previous_q}"
- Entit√©s pr√©c√©dentes: {json.dumps(previous_e, ensure_ascii=False, indent=2)}
"""

        prompt = f"""Analyse cette question d'√©levage avicole et d√©termine le type de r√©ponse optimal.

QUESTION ACTUELLE: "{question}"

ENTIT√âS D√âTECT√âES:
{json.dumps(entities, ensure_ascii=False, indent=2)}

{context_info}

R√àGLES DE CLASSIFICATION:
1. PRECISE_ANSWER: Question avec race sp√©cifique + √¢ge/sexe suffisants pour r√©ponse pr√©cise
2. CONTEXTUAL_ANSWER: Clarification courte qui compl√®te le contexte pr√©c√©dent (ex: "Ross 308 male" apr√®s question poids)
3. GENERAL_ANSWER: Contexte suffisant pour conseil g√©n√©ral utile mais pas assez sp√©cifique
4. NEEDS_CLARIFICATION: Informations vraiment insuffisantes pour toute r√©ponse utile

PRIORIT√âS SP√âCIALES:
- D√©tecter les clarifications contextuelles m√™me tr√®s courtes
- Pour poids/croissance: race + √¢ge = PRECISE_ANSWER
- √âviter NEEDS_CLARIFICATION sauf si r√©ellement impossible
- Favoriser CONTEXTUAL_ANSWER si c'est une suite de conversation

R√©ponds en JSON strict:
{{
    "intention": "question_performance|clarification_contextuelle|question_sante|question_generale",
    "classification_recommandee": "PRECISE_ANSWER|CONTEXTUAL_ANSWER|GENERAL_ANSWER|NEEDS_CLARIFICATION",
    "confidence": 0.85,
    "raisonnement": "explication claire et courte",
    "entites_manquantes": ["race", "age", "sexe"],
    "contexte_suffisant": true,
    "peut_calculer_poids": true,
    "recommandation_fusion": "fuser_avec_contexte|utiliser_entites_actuelles|demander_clarification"
}}"""

        return prompt

    def _merge_context_intelligently(self, entities: Dict[str, Any], 
                                   context: Optional[Dict], 
                                   ai_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Fusionne le contexte bas√© sur l'analyse IA"""
        
        merged = entities.copy()
        
        # Si l'IA recommande la fusion
        fusion_recommendation = ai_analysis.get('recommandation_fusion', '')
        
        if fusion_recommendation == 'fuser_avec_contexte' and context:
            previous_entities = context.get('previous_entities', {})
            
            # H√©riter intelligemment selon les recommandations IA
            if not merged.get('age_days') and previous_entities.get('age_days'):
                merged['age_days'] = previous_entities['age_days']
                merged['age_inherited_from_context'] = True
                logger.info(f"üîó [AI Merge] √Çge h√©rit√© du contexte: {previous_entities['age_days']}j")
            
            if not merged.get('context_type') and previous_entities.get('weight_mentioned'):
                merged['context_type'] = 'performance'
                merged['context_inherited_from_weight_question'] = True
                logger.info("üîó [AI Merge] Contexte performance h√©rit√©")
            
            # H√©riter race si manquante
            if not merged.get('breed_specific') and previous_entities.get('breed_specific'):
                merged['breed_specific'] = previous_entities['breed_specific']
                merged['breed_inherited_from_context'] = True
                logger.info(f"üîó [AI Merge] Race h√©rit√©e: {previous_entities['breed_specific']}")
        
        return merged

    def _determine_final_classification(self, ai_analysis: Dict[str, Any], 
                                      merged_entities: Dict[str, Any],
                                      context_source: str) -> ClassificationResult:
        """D√©termine la classification finale bas√©e sur l'analyse IA"""
        
        recommended_type = ai_analysis.get('classification_recommandee', 'GENERAL_ANSWER')
        confidence = ai_analysis.get('confidence', 0.7)
        reasoning = ai_analysis.get('raisonnement', 'Analyse IA')
        
        # Convertir en ResponseType
        try:
            response_type = ResponseType(recommended_type.lower())
        except ValueError:
            logger.warning(f"‚ö†Ô∏è [AI] Type inconnu {recommended_type}, fallback GENERAL")
            response_type = ResponseType.GENERAL_ANSWER
        
        # Calculer les donn√©es de poids si recommand√©
        weight_data = {}
        if ai_analysis.get('peut_calculer_poids', False):
            weight_data = self._calculate_weight_data_enhanced(merged_entities)
        
        # Entit√©s manquantes sugg√©r√©es par l'IA
        missing_entities = ai_analysis.get('entites_manquantes', [])
        
        result = ClassificationResult(
            response_type=response_type,
            confidence=confidence,
            reasoning=f"IA: {reasoning}",
            missing_entities=missing_entities,
            merged_entities=merged_entities,
            weight_data=weight_data,
            ai_analysis=ai_analysis,
            fallback_used=False,
            context_source=context_source
        )
        
        logger.info(f"ü§ñ [AI Final] {response_type.value} (conf: {confidence}) via {context_source}")
        return result

    def _classify_with_rules_enhanced(self, question: str, entities: Dict[str, Any], 
                                   context: Optional[Dict] = None, 
                                   context_source: str = "parameter",
                                   error: str = None) -> ClassificationResult:
        """üîß FALLBACK AM√âLIOR√â: Classification avec r√®gles conserv√©es + am√©liorations"""
        
        if error:
            logger.info(f"üîß [Enhanced Fallback] Erreur IA: {error[:100]}... | Utilisation r√®gles")
        else:
            logger.info("üîß [Enhanced Fallback] Classification avec r√®gles am√©lior√©es")
        
        # üîß CONSERVATION + AM√âLIORATION: D√©tection contextuelle am√©lior√©e
        if self._is_contextual_clarification_enhanced(question, entities, context):
            merged_entities = self._merge_entities_enhanced(entities, context)
            
            # ‚úÖ AM√âLIORATION: Validation plus intelligente
            if self._has_sufficient_merged_info_enhanced(merged_entities):
                weight_data = self._calculate_weight_data_enhanced(merged_entities)
                
                return ClassificationResult(
                    response_type=ResponseType.CONTEXTUAL_ANSWER,
                    confidence=0.85,
                    reasoning="Clarification contextuelle d√©tect√©e (r√®gles am√©lior√©es)",
                    merged_entities=merged_entities,
                    weight_data=weight_data,
                    fallback_used=True,
                    context_source=context_source
                )
        
        # R√®gles classiques conserv√©es mais am√©lior√©es
        if self._has_precise_info_enhanced(entities):
            weight_data = self._calculate_weight_data_enhanced(entities)
            return ClassificationResult(
                ResponseType.PRECISE_ANSWER,
                confidence=0.9,
                reasoning="Informations pr√©cises suffisantes (r√®gles)",
                weight_data=weight_data,
                fallback_used=True,
                context_source=context_source
            )
        
        elif self._has_useful_context_enhanced(question, entities):
            return ClassificationResult(
                ResponseType.GENERAL_ANSWER,
                confidence=0.8,
                reasoning="Contexte utile pour r√©ponse g√©n√©rale (r√®gles am√©lior√©es)",
                missing_entities=self._identify_missing_for_precision_enhanced(entities),
                fallback_used=True,
                context_source=context_source
            )
        
        else:
            return ClassificationResult(
                ResponseType.NEEDS_CLARIFICATION,
                confidence=0.6,
                reasoning="Informations insuffisantes (r√®gles de fallback)",
                missing_entities=self._identify_critical_missing_enhanced(question, entities),
                fallback_used=True,
                context_source=context_source
            )

    # ==================================================================================
    # üîß M√âTHODES CONSERV√âES ET AM√âLIOR√âES (selon plan de transformation)
    # ==================================================================================

    def _is_contextual_clarification_enhanced(self, question: str, entities: Dict[str, Any], 
                                           context: Optional[Dict]) -> bool:
        """üîß Version am√©lior√©e de d√©tection des clarifications avec conservation du code original"""
        
        if not context or not context.get('previous_question'):
            return False
        
        # AM√âLIORATION: D√©tection plus fine
        question_words = question.split()
        
        # Question tr√®s courte avec race/sexe sp√©cifique
        if len(question_words) <= 4:  # Un peu plus permissif
            has_breed = entities.get('breed_specific') or entities.get('breed_generic')
            has_sex = entities.get('sex')
            has_age = entities.get('age_days') or entities.get('age_weeks')
            
            if has_breed or has_sex or has_age:
                logger.info(f"üîó [Enhanced Rules] Clarification courte d√©tect√©e: {question}")
                return True
        
        # CONSERVATION: Patterns originaux + nouveaux
        patterns_clarification = [
            'pour un', 'pour une', 'avec un', 'avec une',
            'ross 308', 'cobb 500', 'hubbard', 'arbor acres',
            'm√¢le', 'femelle', 'male', 'female',
            'poulet de chair', 'broiler', 
            'jour', 'jours', 'semaine', 'semaines'
        ]
        
        if any(pattern in question.lower() for pattern in patterns_clarification):
            logger.info(f"üîó [Enhanced Rules] Pattern clarification d√©tect√©: {question}")
            return True
        
        return False

    def _merge_entities_enhanced(self, entities: Dict[str, Any], context: Optional[Dict]) -> Dict[str, Any]:
        """Fusion am√©lior√©e des entit√©s avec contexte"""
        merged = entities.copy()
        
        if context and context.get('previous_entities'):
            prev = context['previous_entities']
            
            # H√©riter √¢ge si manquant
            if not merged.get('age_days') and prev.get('age_days'):
                merged['age_days'] = prev['age_days']
                merged['age_inherited_from_context'] = True
            
            # H√©riter race si manquante
            if not merged.get('breed_specific') and prev.get('breed_specific'):
                merged['breed_specific'] = prev['breed_specific']
                merged['breed_inherited_from_context'] = True
            
            # H√©riter contexte performance
            if not merged.get('context_type') and prev.get('weight_mentioned'):
                merged['context_type'] = 'performance'
                merged['context_inherited_from_weight_question'] = True
            
            logger.info(f"üîó [Enhanced Merge] Entit√©s fusionn√©es: {list(merged.keys())}")
        
        return merged

    def _has_sufficient_merged_info_enhanced(self, merged_entities: Dict[str, Any]) -> bool:
        """‚úÖ Validation am√©lior√©e pour contexte fusionn√©"""
        
        breed = merged_entities.get('breed_specific')
        age = merged_entities.get('age_days')
        sex = merged_entities.get('sex')
        context_type = merged_entities.get('context_type')
        
        # Combinaisons suffisantes am√©lior√©es
        checks = [
            breed and age and sex,  # Trio complet
            breed and age and context_type == 'performance',  # Race + √¢ge + contexte poids
            breed and sex and merged_entities.get('age_inherited_from_context'),  # Race + sexe + √¢ge h√©rit√©
            breed and age,  # Race + √¢ge (minimum pour utilit√©)
        ]
        
        is_sufficient = any(checks)
        
        if is_sufficient:
            logger.info("‚úÖ [Enhanced Sufficient] Informations fusionn√©es suffisantes")
        else:
            logger.info("‚ùå [Enhanced Sufficient] Pas assez d'informations m√™me fusionn√©es")
        
        return is_sufficient

    def _has_precise_info_enhanced(self, entities: Dict[str, Any]) -> bool:
        """Check am√©lior√© pour informations pr√©cises"""
        breed = entities.get('breed_specific')
        age = entities.get('age_days')
        sex = entities.get('sex')
        
        # AM√âLIORATION: Plus de combinaisons acceptables
        precise_combinations = [
            breed and age and sex,  # Trio parfait
            breed and age,  # Race + √¢ge (suffisant pour beaucoup de cas)
        ]
        
        return any(precise_combinations)

    def _has_useful_context_enhanced(self, question: str, entities: Dict[str, Any]) -> bool:
        """üîß Version am√©lior√©e qui d√©tecte mieux le contexte utile"""
        
        question_lower = question.lower()
        
        # Questions de poids/croissance avec √¢ge
        weight_keywords = ['poids', 'weight', 'gramme', 'kg', 'pes√©', 'peser', 'cible', 'croissance', 'grandir']
        has_weight_question = any(word in question_lower for word in weight_keywords)
        has_age = entities.get('age_days') or entities.get('age_weeks')
        
        if has_weight_question and has_age:
            logger.info("‚úÖ [Enhanced Useful] Question poids + √¢ge d√©tect√©e")
            return True
        
        # Race g√©n√©rique + √¢ge
        has_breed = entities.get('breed_generic') or entities.get('breed_specific')
        if has_breed and has_age:
            logger.info("‚úÖ [Enhanced Useful] Race + √¢ge d√©tect√©s")
            return True
        
        # Contexte h√©rit√© (nouveau)
        inherited_markers = [
            'age_inherited_from_context',
            'context_inherited_from_weight_question',
            'breed_inherited_from_context'
        ]
        
        if any(entities.get(marker) for marker in inherited_markers):
            logger.info("‚úÖ [Enhanced Useful] Contexte h√©rit√© d√©tect√©")
            return True
        
        # Questions de sant√© avec race
        health_keywords = ['sant√©', 'maladie', 'sympt√¥me', 'vaccination', 'traitement']
        has_health_question = any(word in question_lower for word in health_keywords)
        
        if has_health_question and has_breed:
            logger.info("‚úÖ [Enhanced Useful] Question sant√© + race d√©tect√©e")
            return True
        
        return False

    def _calculate_weight_data_enhanced(self, entities: Dict[str, Any]) -> Dict[str, Any]:
        """Version am√©lior√©e du calcul de poids avec plus de contexte"""
        
        breed = entities.get('breed_specific', '').lower().replace(' ', '_')
        age_days = entities.get('age_days')
        sex = entities.get('sex', 'mixed').lower()
        
        if not breed or not age_days:
            logger.debug("‚ùå [Enhanced Weight] Breed ou age manquant pour calcul poids")
            return {}
        
        # Normalisation sexe am√©lior√©e
        sex_mapping = {
            'm√¢le': 'male', 'male': 'male', 'coq': 'male', 'cock': 'male',
            'femelle': 'female', 'female': 'female', 'poule': 'female', 'hen': 'female',
            'mixte': 'mixed', 'mixed': 'mixed', 'both': 'mixed'
        }
        sex = sex_mapping.get(sex, 'mixed')
        
        try:
            # Import de la fonction de calcul existante (conserv√©e selon plan)
            from .intelligent_system_config import get_weight_range
            
            weight_range = get_weight_range(breed, age_days, sex)
            min_weight, max_weight = weight_range
            target_weight = (min_weight + max_weight) // 2
            
            # Seuils d'alerte plus pr√©cis
            alert_low = int(min_weight * 0.85)
            alert_high = int(max_weight * 1.15)
            critical_low = int(min_weight * 0.70)
            critical_high = int(max_weight * 1.30)
            
            weight_data = {
                "breed": breed.replace('_', ' ').title(),
                "age_days": age_days,
                "sex": sex,
                "weight_range": weight_range,
                "target_weight": target_weight,
                "alert_thresholds": {
                    "low": alert_low,
                    "high": alert_high,
                    "critical_low": critical_low,
                    "critical_high": critical_high
                },
                "data_source": "intelligent_system_config",
                "calculation_method": "enhanced_with_context",
                "confidence": 0.95,
                "context_used": {
                    "age_inherited": entities.get('age_inherited_from_context', False),
                    "breed_inherited": entities.get('breed_inherited_from_context', False),
                    "performance_context": entities.get('context_inherited_from_weight_question', False)
                }
            }
            
            logger.info(f"üìä [Enhanced Weight] {breed} {sex} {age_days}j ‚Üí {min_weight}-{max_weight}g")
            return weight_data
            
        except Exception as e:
            logger.error(f"‚ùå [Enhanced Weight] Erreur calcul: {e}")
            return {}

    def _identify_missing_for_precision_enhanced(self, entities: Dict[str, Any]) -> List[str]:
        """Identifie les entit√©s manquantes pour une r√©ponse pr√©cise"""
        missing = []
        
        if not entities.get('breed_specific'):
            missing.append('race_specifique')
        
        if not entities.get('age_days') and not entities.get('age_weeks'):
            missing.append('age')
        
        if not entities.get('sex'):
            missing.append('sexe')
        
        return missing

    def _identify_critical_missing_enhanced(self, question: str, entities: Dict[str, Any]) -> List[str]:
        """Identifie les entit√©s manquantes critiques"""
        question_words = question.split()
        
        if len(question_words) < 3:
            return ['contexte', 'informations_specifiques']
        
        missing = []
        if not entities.get('breed_generic') and not entities.get('breed_specific'):
            missing.append('race')
        
        if not entities.get('age_days') and not entities.get('age_weeks'):
            missing.append('age')
        
        return missing or ['contexte']

    def _parse_analysis_manually(self, text: str) -> Dict[str, Any]:
        """Parse manuel si JSON √©choue"""
        logger.warning("‚ö†Ô∏è [Manual Parse] Analyse manuelle de la r√©ponse IA")
        
        # Parse basique par mots-cl√©s
        text_lower = text.lower()
        
        # D√©tecter le type recommand√©
        classification = "GENERAL_ANSWER"  # d√©faut
        if "precise" in text_lower or "pr√©cise" in text_lower:
            classification = "PRECISE_ANSWER"
        elif "contextual" in text_lower or "contexte" in text_lower:
            classification = "CONTEXTUAL_ANSWER" 
        elif "clarification" in text_lower:
            classification = "NEEDS_CLARIFICATION"
        
        return {
            "intention": "question_generale",
            "classification_recommandee": classification,
            "confidence": 0.7,
            "raisonnement": "Parse manuel - r√©ponse IA non-structur√©e",
            "peut_calculer_poids": "poids" in text_lower,
            "recommandation_fusion": "utiliser_entites_actuelles"
        }

    # =============================================================================
    # üîß M√âTHODES DE COMPATIBILIT√â (conservation de l'interface existante + corrections)
    # =============================================================================

    async def classify_question(self, question: Optional[str] = None, entities: Optional[Dict[str, Any]] = None, 
                              conversation_context: Optional[Dict] = None,
                              conversation_id: Optional[str] = None,
                              # üîß CORRECTION: Param√®tres de compatibilit√© ajout√©s
                              question_text: Optional[str] = None,
                              context: Optional[Dict] = None,
                              is_clarification_response: Optional[bool] = None,
                              **kwargs) -> ClassificationResult:
        """
        üîß CORRIG√â: Interface de compatibilit√© √©tendue pour supporter tous les appels
        
        Cette m√©thode supporte maintenant:
        - classify_question(question, entities, conversation_context, conversation_id)  # Format original
        - classify_question(question_text=..., context=..., is_clarification_response=...)  # Format expert_services.py
        - classify_question(**kwargs)  # Format flexible
        """
        
        # üîß NORMALISATION DES PARAM√àTRES: R√©soudre les diff√©rents formats d'appel
        if question_text and not question:
            question = question_text
        if context and not conversation_context:
            conversation_context = context
        
        # Log pour debug compatibilit√©
        if is_clarification_response is not None:
            logger.info(f"üîß [Compatibility] is_clarification_response={is_clarification_response} (param√®tre ignor√©)")
        
        if kwargs:
            logger.info(f"üîß [Compatibility] Param√®tres additionnels ignor√©s: {list(kwargs.keys())}")
        
        # Validation des param√®tres essentiels
        if not question:
            logger.error("‚ùå [Compatibility] Param√®tre 'question' ou 'question_text' requis")
            return ClassificationResult(
                response_type=ResponseType.NEEDS_CLARIFICATION,
                confidence=0.0,
                reasoning="Erreur: question manquante dans l'appel",
                fallback_used=True,
                context_source="error"
            )
        
        if not entities:
            logger.warning("‚ö†Ô∏è [Compatibility] Param√®tre 'entities' manquant, utilisation dict vide")
            entities = {}
        
        # Appel de la m√©thode principale avec param√®tres normalis√©s
        logger.info(f"üîÑ [Compatibility] Appel normalis√©: question='{question[:50]}...', entities={len(entities)} √©l√©ments")
        
        return await self.classify_question_with_ai(
            question, entities, conversation_context, conversation_id
        )

    # Alias pour compatibilit√© maximale
    async def classify(self, **kwargs) -> ClassificationResult:
        """Alias simplifi√© pour tous types d'appels"""
        return await self.classify_question(**kwargs)

# =============================================================================
# FONCTION DE COMPATIBILIT√â POUR LES IMPORTS
# =============================================================================

def quick_classify(question: str, entities: Dict[str, Any]) -> ClassificationResult:
    """Fonction rapide de classification pour compatibilit√©"""
    classifier = SmartClassifier()
    # Version synchrone simplifi√©e 
    return classifier._classify_with_rules_enhanced(question, entities)

# =============================================================================
# EXPORTS POUR COMPATIBILIT√â
# =============================================================================

__all__ = [
    'SmartClassifier',
    'ClassificationResult', 
    'ResponseType',
    'quick_classify'
]

logger.info("‚úÖ [SmartClassifier] Module initialis√© (version compatibilit√© √©tendue)")
logger.info("   - Classe: SmartClassifier (nom corrig√©)")
logger.info("   - Support IA: OpenAI GPT-4")
logger.info("   - Fallback: R√®gles am√©lior√©es")
logger.info("   - üîß Compatibilit√©: question_text, context, is_clarification_response")
logger.info("   - Exports: SmartClassifier, ClassificationResult, ResponseType")

# =============================================================================
# EXEMPLE D'UTILISATION AVEC TOUS LES FORMATS D'APPEL SUPPORT√âS
# =============================================================================

async def demo_compatibility():
    """D√©mo des diff√©rents formats d'appel support√©s"""
    
    classifier = SmartClassifier()
    
    # Format 1: Original
    result1 = await classifier.classify_question(
        question="Quel poids pour Ross 308 m√¢le 14 jours?",
        entities={"breed_specific": "Ross 308", "sex": "male", "age_days": 14}
    )
    print(f"‚úÖ Format original: {result1.response_type.value}")
    
    # Format 2: expert_services.py (probl√©matique corrig√©e)  
    result2 = await classifier.classify_question(
        question_text="Quel poids pour Ross 308 m√¢le 14 jours?",
        context={"previous_question": "Question pr√©c√©dente"},
        is_clarification_response=False  # ‚Üê Maintenant support√© (ignor√© proprement)
    )
    print(f"‚úÖ Format expert_services: {result2.response_type.value}")
    
    # Format 3: Flexible
    result3 = await classifier.classify_question(
        question="Ross 308 male",
        entities={"breed_specific": "Ross 308", "sex": "male"},
        extra_param="ignor√©"  # Param√®tres additionnels ignor√©s
    )
    print(f"‚úÖ Format flexible: {result3.response_type.value}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(demo_compatibility())