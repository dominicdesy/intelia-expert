"""
app/api/v1/expert.py - EXPERT ENDPOINTS PRINCIPAUX v3.7.8 - INT√âGRATION SERVICE CLARIFICATION DYNAMIQUE

üÜï NOUVELLES FONCTIONNALIT√âS v3.7.8:
- Int√©gration expert_clarification_service avec s√©lection dynamique de prompts
- Appel automatique du service si clarification_required_critical = True
- G√©n√©ration de questions dynamiques bas√©es sur entit√©s manquantes
- Validation et enrichissement des questions de clarification
- Support conversation_context pour clarifications contextuelles

CONSERVATION: Toute la logique v3.7.7 + nouvelles int√©grations service clarification
"""

import os
import re
import logging
import uuid
import time
from datetime import datetime
from typing import Optional, List, Dict, Any, Callable

from fastapi import APIRouter, HTTPException, Request, Depends
from fastapi.security import HTTPBearer

# üîß FIX: D√©clarer logger AVANT utilisation
logger = logging.getLogger(__name__)
router = APIRouter(tags=["expert-main"])
security = HTTPBearer()

# Imports s√©curis√©s avec gestion d'erreurs CORRIG√âE
try:
    from .expert_models import EnhancedQuestionRequest, EnhancedExpertResponse, FeedbackRequest, ConcisionLevel
    MODELS_IMPORTED = True
    logger.info("‚úÖ Models import√©s avec succ√®s")
except ImportError as e:
    logger.error(f"‚ùå Erreur import expert_models: {e}")
    # üîß FIX: Fallback plus s√©curis√© avec tous les champs requis
    from pydantic import BaseModel
    
    class ConcisionLevel:
        CONCISE = "concise"
        DETAILED = "detailed"
        COMPREHENSIVE = "comprehensive"
    
    class EnhancedQuestionRequest(BaseModel):
        text: str
        language: str = "fr"
        conversation_id: Optional[str] = None
        is_clarification_response: bool = False
        original_question: Optional[str] = None
        clarification_context: Optional[Dict[str, Any]] = None
        clarification_entities: Optional[Dict[str, str]] = None
        concision_level: str = ConcisionLevel.CONCISE
        generate_all_versions: bool = True
        enable_vagueness_detection: bool = True
        require_coherence_check: bool = True
        detailed_rag_scoring: bool = False
        enable_quality_metrics: bool = False
        
    class EnhancedExpertResponse(BaseModel):
        question: str
        response: str
        conversation_id: str
        rag_used: bool = False
        rag_score: Optional[float] = None
        timestamp: str
        language: str
        response_time_ms: int
        mode: str
        user: Optional[str] = None
        logged: bool = False
        validation_passed: Optional[bool] = None
        # NOUVEAUX CHAMPS v3.7.3+
        clarification_required_critical: bool = False
        missing_critical_entities: List[str] = []
        variants_tested: List[str] = []
        # üÜï NOUVEAUX CHAMPS v3.7.8
        dynamic_questions: Optional[List[Dict[str, Any]]] = None
        clarification_service_used: bool = False
        # Champs optionnels pour compatibilit√©
        clarification_result: Optional[Dict[str, Any]] = None
        processing_steps: List[str] = []
        ai_enhancements_used: List[str] = []
        response_versions: Optional[Dict[str, str]] = None
        clarification_processing: Optional[Dict[str, Any]] = None
        
    class FeedbackRequest(BaseModel):
        rating: str
        comment: Optional[str] = None
        conversation_id: Optional[str] = None
        quality_feedback: Optional[Dict[str, Any]] = None
        
    MODELS_IMPORTED = False
    logger.warning("‚ö†Ô∏è Utilisation des mod√®les de fallback")

try:
    from .expert_services import ExpertService
    EXPERT_SERVICE_AVAILABLE = True
    logger.info("‚úÖ ExpertService import√© avec succ√®s")
except ImportError as e:
    logger.error(f"‚ùå Erreur import expert_services: {e}")
    EXPERT_SERVICE_AVAILABLE = False

# üÜï NOUVEAU v3.7.8: Import du service de clarification dynamique
try:
    from .expert_clarification_service import ExpertClarificationService
    CLARIFICATION_SERVICE_AVAILABLE = True
    logger.info("‚úÖ ExpertClarificationService import√© avec succ√®s")
except ImportError as e:
    logger.error(f"‚ùå Erreur import expert_clarification_service: {e}")
    CLARIFICATION_SERVICE_AVAILABLE = False

try:
    from .expert_utils import get_user_id_from_request, extract_breed_and_sex_from_clarification
    UTILS_AVAILABLE = True
    logger.info("‚úÖ Utils import√©s avec succ√®s")
except ImportError as e:
    logger.error(f"‚ùå Erreur import expert_utils: {e}")
    # üîß FIX: Fonctions fallback plus robustes
    def get_user_id_from_request(request):
        try:
            return getattr(request.client, 'host', 'unknown') if request and request.client else 'unknown'
        except Exception:
            return 'unknown'
    
    def extract_breed_and_sex_from_clarification(text, language):
        try:
            # Fallback simple - retourner None pour forcer clarification
            return {"breed": None, "sex": None}
        except Exception:
            return {"breed": None, "sex": None}
    
    UTILS_AVAILABLE = False

# Initialisation des services avec gestion d'erreur CORRIG√âE
expert_service = None
if EXPERT_SERVICE_AVAILABLE:
    try:
        expert_service = ExpertService()
        logger.info("‚úÖ [Expert] Service expert initialis√© avec succ√®s")
    except Exception as e:
        logger.error(f"‚ùå [Expert] Erreur initialisation service: {e}")
        expert_service = None
else:
    logger.warning("‚ö†Ô∏è [Expert] Service expert non disponible - utilisation du mode fallback")

# üÜï NOUVEAU v3.7.8: Initialisation service clarification
clarification_service = None
if CLARIFICATION_SERVICE_AVAILABLE:
    try:
        clarification_service = ExpertClarificationService()
        logger.info("‚úÖ [Clarification] Service clarification initialis√© avec succ√®s")
    except Exception as e:
        logger.error(f"‚ùå [Clarification] Erreur initialisation service: {e}")
        clarification_service = None
else:
    logger.warning("‚ö†Ô∏è [Clarification] Service clarification non disponible - fonctionnalit√© d√©sactiv√©e")

# üîß FIX CRITIQUE: Auth dependency corrig√© pour √™tre callable
def get_current_user_mock():
    """Mock user pour fallback"""
    return {"id": "fallback_user", "email": "fallback@intelia.com"}

def get_current_user_dependency() -> Callable:
    """üîß FIX CRITIQUE: Retourne une fonction callable, pas un Dependency object"""
    if expert_service and hasattr(expert_service, 'get_current_user_dependency'):
        try:
            # R√©cup√®re la fonction du service
            service_dependency = expert_service.get_current_user_dependency()
            # Si c'est d√©j√† un Depends(), extraire la fonction
            if hasattr(service_dependency, 'dependency'):
                return service_dependency.dependency
            # Sinon retourner directement
            return service_dependency
        except Exception as e:
            logger.error(f"‚ùå Erreur get_current_user_dependency: {e}")
            return get_current_user_mock
    return get_current_user_mock

# =============================================================================
# üÜï NOUVELLES FONCTIONS v3.7.8 - INT√âGRATION SERVICE CLARIFICATION DYNAMIQUE
# =============================================================================

def _build_conversation_context(
    request_data: EnhancedQuestionRequest,
    entities: Dict[str, Any],
    processing_metadata: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    üÜï NOUVELLE v3.7.8: Construit le contexte de conversation pour le service de clarification
    """
    
    context = {
        "current_question": getattr(request_data, 'text', ''),
        "language": getattr(request_data, 'language', 'fr'),
        "conversation_id": getattr(request_data, 'conversation_id', None),
        "is_clarification_response": getattr(request_data, 'is_clarification_response', False),
        "original_question": getattr(request_data, 'original_question', None),
        "extracted_entities": entities,
        "timestamp": datetime.now().isoformat()
    }
    
    # Ajouter contexte de clarification si disponible
    clarification_context = getattr(request_data, 'clarification_context', None)
    if clarification_context and isinstance(clarification_context, dict):
        context["clarification_context"] = clarification_context
    
    # Ajouter entit√©s de clarification si disponibles
    clarification_entities = getattr(request_data, 'clarification_entities', None)
    if clarification_entities and isinstance(clarification_entities, dict):
        context["clarification_entities"] = clarification_entities
    
    # Ajouter m√©tadonn√©es de traitement si disponibles
    if processing_metadata and isinstance(processing_metadata, dict):
        context["processing_metadata"] = processing_metadata
    
    # Analyser le type de domaine agricole
    context["domain_analysis"] = _analyze_agricultural_domain(context["current_question"])
    
    logger.info(f"üîß [CONTEXT v3.7.8] Contexte conversation construit:")
    logger.info(f"   - Question: '{context['current_question'][:100]}...'")
    logger.info(f"   - Langue: {context['language']}")
    logger.info(f"   - Entit√©s: {len(entities)} d√©tect√©es")
    logger.info(f"   - Domaine: {context['domain_analysis']['primary_domain']}")
    
    return context

def _analyze_agricultural_domain(question_text: str) -> Dict[str, Any]:
    """
    üÜï NOUVELLE v3.7.8: Analyse le domaine agricole de la question pour adapter les clarifications
    """
    
    domain_analysis = {
        "primary_domain": "poultry",  # Default
        "specific_topics": [],
        "urgency_level": "normal",
        "complexity": "medium"
    }
    
    try:
        question_lower = question_text.lower() if isinstance(question_text, str) else ""
        
        # D√©tection domaine principal
        if any(term in question_lower for term in ["poulet", "chicken", "broiler", "ross", "cobb"]):
            domain_analysis["primary_domain"] = "poultry"
        elif any(term in question_lower for term in ["porc", "pig", "swine", "cochon"]):
            domain_analysis["primary_domain"] = "swine"
        elif any(term in question_lower for term in ["bovin", "cattle", "vache", "cow"]):
            domain_analysis["primary_domain"] = "cattle"
        elif any(term in question_lower for term in ["ovin", "sheep", "mouton"]):
            domain_analysis["primary_domain"] = "sheep"
        
        # D√©tection sujets sp√©cifiques
        topics_map = {
            "nutrition": ["nutrition", "alimentation", "feed", "nourriture"],
            "health": ["sant√©", "health", "maladie", "disease", "sympt√¥me"],
            "growth": ["croissance", "growth", "poids", "weight", "d√©veloppement"],
            "environment": ["temp√©rature", "temperature", "ventilation", "environnement"],
            "reproduction": ["reproduction", "breeding", "reproduction", "ponte"],
            "mortality": ["mortalit√©", "mortality", "mort", "death", "perte"]
        }
        
        for topic, keywords in topics_map.items():
            if any(keyword in question_lower for keyword in keywords):
                domain_analysis["specific_topics"].append(topic)
        
        # D√©tection niveau urgence
        urgency_keywords = ["urgent", "imm√©diat", "rapide", "critique", "grave", "emergency"]
        if any(keyword in question_lower for keyword in urgency_keywords):
            domain_analysis["urgency_level"] = "high"
        elif any(term in question_lower for term in ["pr√©ventif", "routine", "normal"]):
            domain_analysis["urgency_level"] = "low"
        
        # D√©tection complexit√©
        if len(domain_analysis["specific_topics"]) >= 3:
            domain_analysis["complexity"] = "high"
        elif len(domain_analysis["specific_topics"]) <= 1:
            domain_analysis["complexity"] = "low"
        
        logger.info(f"üîç [DOMAIN ANALYSIS v3.7.8] R√©sultat:")
        logger.info(f"   - Domaine: {domain_analysis['primary_domain']}")
        logger.info(f"   - Sujets: {domain_analysis['specific_topics']}")
        logger.info(f"   - Urgence: {domain_analysis['urgency_level']}")
        logger.info(f"   - Complexit√©: {domain_analysis['complexity']}")
        
    except Exception as e:
        logger.error(f"‚ùå [DOMAIN ANALYSIS v3.7.8] Erreur: {e}")
    
    return domain_analysis

async def _apply_dynamic_clarification_service(
    response_data: Any,
    validation_result: Dict[str, Any],
    entities: Dict[str, Any],
    conversation_context: Dict[str, Any]
) -> Any:
    """
    üÜï NOUVELLE v3.7.8: Applique le service de clarification dynamique si n√©cessaire
    
    Cette fonction est appel√©e APR√àS validation des entit√©s critiques
    et g√©n√®re des questions dynamiques si clarification_required_critical = True
    """
    
    try:
        if not response_data:
            logger.error("‚ùå [CLARIFICATION SERVICE v3.7.8] response_data est None")
            return response_data
        
        # V√©rifier si clarification critique requise
        clarification_required = getattr(response_data, 'clarification_required_critical', False)
        if not clarification_required:
            logger.info("‚úÖ [CLARIFICATION SERVICE v3.7.8] Aucune clarification critique requise")
            return response_data
        
        logger.info("üö® [CLARIFICATION SERVICE v3.7.8] Clarification critique d√©tect√©e - activation service")
        
        # V√©rifier disponibilit√© du service
        if not clarification_service:
            logger.warning("‚ö†Ô∏è [CLARIFICATION SERVICE v3.7.8] Service non disponible - mode fallback")
            return _apply_fallback_clarification(response_data, validation_result, entities)
        
        # Extraire entit√©s manquantes
        missing_entities = getattr(response_data, 'missing_critical_entities', [])
        if not missing_entities:
            missing_entities = validation_result.get('missing_critical', [])
        
        logger.info(f"üîç [CLARIFICATION SERVICE v3.7.8] Entit√©s manquantes: {missing_entities}")
        
        # √âTAPE 1: S√©lection dynamique du prompt
        logger.info("üéØ [CLARIFICATION SERVICE v3.7.8] √âTAPE 1: S√©lection prompt dynamique...")
        
        clarification_prompt = clarification_service.select_clarification_prompt(
            question=conversation_context.get('current_question', ''),
            missing_entities=missing_entities,
            conversation_context=conversation_context
        )
        
        if not clarification_prompt:
            logger.error("‚ùå [CLARIFICATION SERVICE v3.7.8] √âchec s√©lection prompt")
            return _apply_fallback_clarification(response_data, validation_result, entities)
        
        logger.info(f"‚úÖ [CLARIFICATION SERVICE v3.7.8] Prompt s√©lectionn√©: {clarification_prompt.get('prompt_type', 'unknown')}")
        
        # √âTAPE 2: G√©n√©ration questions avec GPT
        logger.info("ü§ñ [CLARIFICATION SERVICE v3.7.8] √âTAPE 2: G√©n√©ration questions GPT...")
        
        clarification_questions = await clarification_service.generate_questions_with_gpt(
            clarification_prompt=clarification_prompt,
            context=conversation_context
        )
        
        if not clarification_questions:
            logger.error("‚ùå [CLARIFICATION SERVICE v3.7.8] √âchec g√©n√©ration questions")
            return _apply_fallback_clarification(response_data, validation_result, entities)
        
        logger.info(f"‚úÖ [CLARIFICATION SERVICE v3.7.8] {len(clarification_questions)} questions g√©n√©r√©es")
        
        # √âTAPE 3: Validation questions dynamiques
        logger.info("üîç [CLARIFICATION SERVICE v3.7.8] √âTAPE 3: Validation questions...")
        
        validated_questions = clarification_service.validate_dynamic_questions(
            clarification_questions=clarification_questions,
            missing_entities=missing_entities,
            context=conversation_context
        )
        
        if not validated_questions:
            logger.error("‚ùå [CLARIFICATION SERVICE v3.7.8] √âchec validation questions")
            return _apply_fallback_clarification(response_data, validation_result, entities)
        
        logger.info(f"‚úÖ [CLARIFICATION SERVICE v3.7.8] {len(validated_questions)} questions valid√©es")
        
        # √âTAPE 4: Application √† response_data
        logger.info("üîß [CLARIFICATION SERVICE v3.7.8] √âTAPE 4: Application √† response...")
        
        # Marquer service utilis√©
        if hasattr(response_data, 'clarification_service_used'):
            response_data.clarification_service_used = True
        
        # Ajouter questions dynamiques
        if hasattr(response_data, 'dynamic_questions'):
            response_data.dynamic_questions = validated_questions
        
        # Enrichir clarification_result
        if hasattr(response_data, 'clarification_result') and response_data.clarification_result:
            if isinstance(response_data.clarification_result, dict):
                response_data.clarification_result.update({
                    "dynamic_clarification_service": {
                        "service_used": True,
                        "prompt_selected": clarification_prompt,
                        "questions_generated": len(clarification_questions),
                        "questions_validated": len(validated_questions),
                        "missing_entities": missing_entities,
                        "context_analyzed": conversation_context.get('domain_analysis', {}),
                        "timestamp": datetime.now().isoformat()
                    },
                    "dynamic_questions": validated_questions
                })
        
        # Enrichir processing_steps
        if hasattr(response_data, 'processing_steps') and isinstance(response_data.processing_steps, list):
            response_data.processing_steps.extend([
                "dynamic_clarification_service_activated_v3.7.8",
                f"prompt_selected_{clarification_prompt.get('prompt_type', 'unknown')}",
                f"questions_generated_{len(clarification_questions)}",
                f"questions_validated_{len(validated_questions)}"
            ])
        
        # Enrichir ai_enhancements_used
        if hasattr(response_data, 'ai_enhancements_used') and isinstance(response_data.ai_enhancements_used, list):
            response_data.ai_enhancements_used.extend([
                "dynamic_clarification_service_v3.7.8",
                "gpt_question_generation",
                "intelligent_prompt_selection",
                "dynamic_question_validation"
            ])
        
        # Modifier la r√©ponse pour inclure les questions dynamiques
        if hasattr(response_data, 'response') and validated_questions:
            original_response = response_data.response
            
            # Construire nouvelle r√©ponse avec questions dynamiques
            enhanced_response = original_response + "\n\n**Questions de clarification intelligentes :**\n"
            
            for i, question_data in enumerate(validated_questions, 1):
                question_text = question_data.get('question', '')
                question_type = question_data.get('type', 'general')
                
                enhanced_response += f"\n{i}. **{question_text}**"
                
                # Ajouter options si disponibles
                options = question_data.get('options', [])
                if options:
                    enhanced_response += "\n   Options sugg√©r√©es:"
                    for option in options[:3]:  # Limiter √† 3 options
                        enhanced_response += f"\n   ‚Ä¢ {option}"
                
                enhanced_response += "\n"
            
            response_data.response = enhanced_response
            
            logger.info("üîß [CLARIFICATION SERVICE v3.7.8] R√©ponse enrichie avec questions dynamiques")
        
        logger.info("‚úÖ [CLARIFICATION SERVICE v3.7.8] Service appliqu√© avec succ√®s")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå [CLARIFICATION SERVICE v3.7.8] Erreur: {e}")
        return _apply_fallback_clarification(response_data, validation_result, entities)

def _apply_fallback_clarification(
    response_data: Any,
    validation_result: Dict[str, Any],
    entities: Dict[str, Any]
) -> Any:
    """
    üÜï NOUVELLE v3.7.8: Applique une clarification fallback si le service dynamique √©choue
    """
    
    try:
        logger.info("üîÑ [FALLBACK CLARIFICATION v3.7.8] Application clarification de secours")
        
        # Marquer service non utilis√©
        if hasattr(response_data, 'clarification_service_used'):
            response_data.clarification_service_used = False
        
        # Questions fallback basiques
        missing_entities = validation_result.get('missing_critical', [])
        
        fallback_questions = []
        
        if 'breed' in missing_entities:
            fallback_questions.append({
                "question": "Quelle est la race/souche de vos animaux ?",
                "type": "breed",
                "priority": "critical",
                "options": ["Ross 308", "Cobb 500", "Hubbard", "Arbor Acres", "Autre"]
            })
        
        if 'age' in missing_entities or 'age_in_days' in missing_entities:
            fallback_questions.append({
                "question": "Quel est l'√¢ge pr√©cis de vos animaux ?",
                "type": "age",
                "priority": "critical",
                "options": ["13 jours", "2 semaines", "3 semaines", "1 mois", "Autre"]
            })
        
        if 'weight' in missing_entities or 'weight_in_grams' in missing_entities:
            fallback_questions.append({
                "question": "Quel est le poids actuel de vos animaux ?",
                "type": "weight",
                "priority": "critical",
                "options": ["800g", "1.2kg", "1.8kg", "2.5kg", "Autre"]
            })
        
        if 'sex' in missing_entities:
            fallback_questions.append({
                "question": "S'agit-il de m√¢les, femelles, ou un troupeau mixte ?",
                "type": "sex",
                "priority": "medium",
                "options": ["M√¢les", "Femelles", "Mixte"]
            })
        
        # Ajouter questions fallback
        if hasattr(response_data, 'dynamic_questions'):
            response_data.dynamic_questions = fallback_questions
        
        # Enrichir processing_steps
        if hasattr(response_data, 'processing_steps') and isinstance(response_data.processing_steps, list):
            response_data.processing_steps.append("fallback_clarification_applied_v3.7.8")
        
        # Enrichir ai_enhancements_used
        if hasattr(response_data, 'ai_enhancements_used') and isinstance(response_data.ai_enhancements_used, list):
            response_data.ai_enhancements_used.append("fallback_clarification_v3.7.8")
        
        logger.info(f"‚úÖ [FALLBACK CLARIFICATION v3.7.8] {len(fallback_questions)} questions fallback g√©n√©r√©es")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå [FALLBACK CLARIFICATION v3.7.8] Erreur: {e}")
        return response_data

# =============================================================================
# FONCTIONS EXISTANTES v3.7.7 - CONSERV√âES INT√âGRALEMENT
# =============================================================================

def _extract_critical_entities_from_question(question_text: str, language: str = "fr") -> Dict[str, Any]:
    """
    üÜï CONSERV√âE v3.7.7: Extrait les entit√©s critiques (breed, age, weight) depuis la question
    
    Entit√©s critiques pour les questions agricoles:
    - breed: race/souche (Ross 308, Cobb 500, etc.)
    - age: √¢ge en jours/semaines (13j, 2sem, etc.)
    - weight: poids en grammes/kg (800g, 1.2kg, etc.)
    """
    
    entities = {
        "breed": None,
        "age": None,
        "age_in_days": None,
        "weight": None,
        "weight_in_grams": None,
        "sex": None,  # Bonus - d√©j√† g√©r√© ailleurs mais utile
        "confidence": {}
    }
    
    try:
        question_lower = question_text.lower() if isinstance(question_text, str) else ""
        
        # üîç EXTRACTION 1: BREED/RACE avec patterns √©tendus
        breed_patterns = [
            r'\b(ross\s*308|ross308)\b',
            r'\b(ross\s*708|ross708)\b', 
            r'\b(cobb\s*500|cobb500)\b',
            r'\b(cobb\s*700|cobb700)\b',
            r'\b(hubbard|hub)\b',
            r'\b(arbor\s*acres|arbor)\b',
            r'\b(isa\s*brown|isa)\b',
            r'\b(lohmann|lohman)\b',
            r'\b(poulet\s*de\s*chair|broiler)\b'
        ]
        
        for pattern in breed_patterns:
            match = re.search(pattern, question_lower)
            if match:
                entities["breed"] = match.group(0).replace(" ", " ").strip()
                entities["confidence"]["breed"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Breed d√©tect√©: '{entities['breed']}'")
                break
        
        # Si pas de race sp√©cifique, chercher terme g√©n√©rique
        if not entities["breed"]:
            generic_patterns = [r'\bpoulets?\b', r'\bpoules?\b', r'\bchickens?\b', r'\bbroilers?\b']
            for pattern in generic_patterns:
                if re.search(pattern, question_lower):
                    entities["breed"] = "poulet"  # G√©n√©rique, n√©cessitera clarification
                    entities["confidence"]["breed"] = 0.3
                    logger.info(f"üîç [ENTIT√â v3.7.7] Breed g√©n√©rique d√©tect√©: '{entities['breed']}'")
                    break
        
        # üîç EXTRACTION 2: AGE avec conversion en jours
        age_patterns = [
            (r'(\d+)\s*j(?:our)?s?', 1),           # 13j, 13 jours
            (r'(\d+)\s*sem(?:aine)?s?', 7),         # 2sem, 2 semaines -> * 7
            (r'(\d+)\s*week?s?', 7),                # 2 weeks -> * 7
            (r'(\d+)\s*mois', 30),                  # 1 mois -> * 30 (approximatif)
            (r'(\d+)\s*month?s?', 30)               # 1 month -> * 30
        ]
        
        for pattern, multiplier in age_patterns:
            match = re.search(pattern, question_lower)
            if match:
                age_value = int(match.group(1))
                entities["age"] = match.group(0)
                entities["age_in_days"] = age_value * multiplier
                entities["confidence"]["age"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Age d√©tect√©: '{entities['age']}' = {entities['age_in_days']} jours")
                break
        
        # üîç EXTRACTION 3: WEIGHT avec conversion en grammes
        weight_patterns = [
            (r'(\d+(?:\.\d+)?)\s*kg', 1000),         # 1.2kg -> * 1000
            (r'(\d+(?:\.\d+)?)\s*kilo', 1000),       # 1.2 kilo -> * 1000
            (r'(\d+)\s*g(?:ramme)?s?', 1),           # 800g, 800 grammes
            (r'(\d+(?:\.\d+)?)\s*lb', 453.592)       # 2.5 lb -> * 453.592 (livres)
        ]
        
        for pattern, multiplier in weight_patterns:
            match = re.search(pattern, question_lower)
            if match:
                weight_value = float(match.group(1))
                entities["weight"] = match.group(0)
                entities["weight_in_grams"] = int(weight_value * multiplier)
                entities["confidence"]["weight"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Weight d√©tect√©: '{entities['weight']}' = {entities['weight_in_grams']}g")
                break
        
        # üîç EXTRACTION 4: SEX (bonus)
        sex_patterns = [
            (r'\bm√¢les?\b', "m√¢le"),
            (r'\bfemelles?\b', "femelle"), 
            (r'\bmales?\b', "m√¢le"),
            (r'\bfemales?\b', "femelle"),
            (r'\bmixte\b', "mixte"),
            (r'\btroupeau\s+mixte\b', "mixte")
        ]
        
        for pattern, sex_value in sex_patterns:
            if re.search(pattern, question_lower):
                entities["sex"] = sex_value
                entities["confidence"]["sex"] = 0.8
                logger.info(f"üîç [ENTIT√â v3.7.7] Sex d√©tect√©: '{entities['sex']}'")
                break
        
        # üîç VALIDATION COH√âRENCE des entit√©s extraites
        coherence_issues = []
        
        # V√©rifier coh√©rence √¢ge/poids si les deux sont pr√©sents
        if entities["age_in_days"] and entities["weight_in_grams"]:
            age_days = entities["age_in_days"]
            weight_grams = entities["weight_in_grams"]
            
            # Heuristiques de coh√©rence (√† affiner selon donn√©es r√©elles)
            if age_days < 7 and weight_grams > 500:  # Poussin < 1 sem mais > 500g
                coherence_issues.append(f"age_weight_high_{age_days}d_{weight_grams}g")
            elif age_days > 35 and weight_grams < 500:  # Poulet > 5 sem mais < 500g
                coherence_issues.append(f"age_weight_low_{age_days}d_{weight_grams}g")
            elif age_days > 60:  # √Çge tr√®s √©lev√© pour poulet de chair
                coherence_issues.append(f"age_very_high_{age_days}d")
        
        entities["coherence_issues"] = coherence_issues
        
        logger.info(f"üîç [EXTRACTION ENTIT√âS v3.7.8] R√©sultat final:")
        logger.info(f"   - Breed: {entities['breed']} (conf: {entities['confidence'].get('breed', 0)})")
        logger.info(f"   - Age: {entities['age']} = {entities['age_in_days']} jours (conf: {entities['confidence'].get('age', 0)})")
        logger.info(f"   - Weight: {entities['weight']} = {entities['weight_in_grams']}g (conf: {entities['confidence'].get('weight', 0)})")
        logger.info(f"   - Sex: {entities['sex']} (conf: {entities['confidence'].get('sex', 0)})")
        logger.info(f"   - Incoh√©rences: {coherence_issues}")
        
        return entities
        
    except Exception as e:
        logger.error(f"‚ùå [EXTRACTION ENTIT√âS v3.7.8] Erreur: {e}")
        return entities

def _validate_critical_entities(entities: Dict[str, Any], question_context: str = "") -> Dict[str, Any]:
    """
    üÜï CONSERV√âE v3.7.7: Valide si les entit√©s critiques sont suffisantes pour une r√©ponse de qualit√©
    
    Returns:
        Dict avec validation_result, missing_entities, confidence_issues, etc.
    """
    
    validation_result = {
        "entities_sufficient": False,
        "missing_critical": [],
        "low_confidence": [],
        "generic_entities": [],
        "coherence_issues": [],
        "clarification_required": False,
        "clarification_priority": "low"  # low, medium, high, critical
    }
    
    try:
        if not isinstance(entities, dict):
            logger.error("‚ùå [VALIDATION ENTIT√âS v3.7.8] entities n'est pas un dict")
            validation_result["clarification_required"] = True
            validation_result["clarification_priority"] = "critical"
            return validation_result
        
        # üîç VALIDATION 1: ENTIT√âS CRITIQUES MANQUANTES
        critical_entities = ["breed", "age_in_days", "weight_in_grams"]
        
        for entity in critical_entities:
            entity_value = entities.get(entity)
            
            if entity_value is None:
                validation_result["missing_critical"].append(entity)
                logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Entit√© critique manquante: {entity}")
            
            # Validation sp√©cifique par type d'entit√©
            elif entity == "breed":
                if isinstance(entity_value, str):
                    if entity_value.lower() in ["poulet", "chicken", "broiler"]:
                        validation_result["generic_entities"].append("breed_too_generic")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Breed trop g√©n√©rique: {entity_value}")
                else:
                    validation_result["missing_critical"].append(entity)
            
            elif entity == "age_in_days":
                if isinstance(entity_value, (int, float)):
                    if entity_value <= 0 or entity_value > 365:  # Age aberrant
                        validation_result["coherence_issues"].append(f"age_aberrant_{entity_value}")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Age aberrant: {entity_value} jours")
                else:
                    validation_result["missing_critical"].append(entity)
            
            elif entity == "weight_in_grams":
                if isinstance(entity_value, (int, float)):
                    if entity_value <= 0 or entity_value > 10000:  # Poids aberrant
                        validation_result["coherence_issues"].append(f"weight_aberrant_{entity_value}")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Poids aberrant: {entity_value}g")
                else:
                    validation_result["missing_critical"].append(entity)
        
        # üîç VALIDATION 2: CONFIANCE DES ENTIT√âS
        confidence_data = entities.get("confidence", {})
        
        for entity, confidence in confidence_data.items():
            if isinstance(confidence, (int, float)) and confidence < 0.5:
                validation_result["low_confidence"].append(f"{entity}_conf_{confidence}")
                logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Confiance faible {entity}: {confidence}")
        
        # üîç VALIDATION 3: INCOH√âRENCES D√âTECT√âES
        coherence_issues = entities.get("coherence_issues", [])
        validation_result["coherence_issues"].extend(coherence_issues)
        
        # üîç CALCUL PRIORIT√â CLARIFICATION
        missing_count = len(validation_result["missing_critical"])
        generic_count = len(validation_result["generic_entities"])
        coherence_count = len(validation_result["coherence_issues"])
        low_conf_count = len(validation_result["low_confidence"])
        
        # Logique de priorit√©
        if missing_count >= 2:  # 2+ entit√©s critiques manquantes
            validation_result["clarification_priority"] = "critical"
            validation_result["clarification_required"] = True
        elif missing_count == 1 and (generic_count > 0 or coherence_count > 0):
            validation_result["clarification_priority"] = "high"
            validation_result["clarification_required"] = True
        elif missing_count == 1 or generic_count > 0:
            validation_result["clarification_priority"] = "medium"
            validation_result["clarification_required"] = True
        elif coherence_count > 0 or low_conf_count > 1:
            validation_result["clarification_priority"] = "low"
            validation_result["clarification_required"] = True
        else:
            validation_result["entities_sufficient"] = True
            validation_result["clarification_required"] = False
        
        logger.info(f"üîç [VALIDATION ENTIT√âS v3.7.8] R√©sultat:")
        logger.info(f"   - Entit√©s suffisantes: {validation_result['entities_sufficient']}")
        logger.info(f"   - Critiques manquantes: {validation_result['missing_critical']}")
        logger.info(f"   - G√©n√©riques: {validation_result['generic_entities']}")
        logger.info(f"   - Incoh√©rences: {validation_result['coherence_issues']}")
        logger.info(f"   - Clarification requise: {validation_result['clarification_required']}")
        logger.info(f"   - Priorit√©: {validation_result['clarification_priority']}")
        
        return validation_result
        
    except Exception as e:
        logger.error(f"‚ùå [VALIDATION ENTIT√âS v3.7.8] Erreur: {e}")
        # En cas d'erreur, forcer clarification critique
        validation_result["clarification_required"] = True
        validation_result["clarification_priority"] = "critical"
        validation_result["missing_critical"] = ["validation_error"]
        return validation_result

def _force_clarification_for_missing_entities(
    response_data: Any, 
    validation_result: Dict[str, Any], 
    entities: Dict[str, Any]
) -> Any:
    """
    üÜï CONSERV√âE v3.7.7: Force la clarification si des entit√©s critiques manquent
    
    Cette fonction modifie response_data pour d√©clencher clarification_required_critical=True
    """
    
    try:
        if not response_data or not isinstance(validation_result, dict):
            logger.error("‚ùå [FORCE CLARIFICATION v3.7.8] Param√®tres invalides")
            return response_data
        
        clarification_required = validation_result.get("clarification_required", False)
        clarification_priority = validation_result.get("clarification_priority", "low")
        
        if not clarification_required:
            logger.info("‚úÖ [FORCE CLARIFICATION v3.7.8] Aucune clarification n√©cessaire")
            return response_data
        
        logger.warning(f"üö® [FORCE CLARIFICATION v3.7.8] Clarification forc√©e - priorit√©: {clarification_priority}")
        
        # üîß MODIFICATION 1: Marquer clarification_required_critical selon priorit√©
        critical_priorities = ["high", "critical"]
        force_critical = clarification_priority in critical_priorities
        
        if hasattr(response_data, 'clarification_required_critical'):
            response_data.clarification_required_critical = force_critical
            logger.info(f"üîß [FORCE CLARIFICATION v3.7.8] clarification_required_critical = {force_critical}")
        
        # üîß MODIFICATION 2: Mettre √† jour missing_critical_entities
        missing_entities = validation_result.get("missing_critical", [])
        generic_entities = validation_result.get("generic_entities", [])
        coherence_issues = validation_result.get("coherence_issues", [])
        
        # Combiner tous les probl√®mes d'entit√©s
        all_missing = missing_entities + generic_entities + coherence_issues
        
        if hasattr(response_data, 'missing_critical_entities'):
            if isinstance(response_data.missing_critical_entities, list):
                response_data.missing_critical_entities.extend(all_missing)
            else:
                response_data.missing_critical_entities = all_missing
            logger.info(f"üîß [FORCE CLARIFICATION v3.7.8] missing_critical_entities = {response_data.missing_critical_entities}")
        
        # üîß MODIFICATION 3: Ajouter dans processing_steps pour tra√ßabilit√©
        if hasattr(response_data, 'processing_steps') and isinstance(response_data.processing_steps, list):
            response_data.processing_steps.append(f"critical_entities_validation_v3.7.8")
            response_data.processing_steps.append(f"clarification_priority_{clarification_priority}")
            if force_critical:
                response_data.processing_steps.append("clarification_forced_critical_entities")
        
        # üîß MODIFICATION 4: Ajouter dans ai_enhancements_used
        if hasattr(response_data, 'ai_enhancements_used') and isinstance(response_data.ai_enhancements_used, list):
            response_data.ai_enhancements_used.append("critical_entities_extraction_v3.7.8")
            response_data.ai_enhancements_used.append("entities_validation_forced_clarification")
        
        # üîß MODIFICATION 5: Enrichir clarification_result si pr√©sent
        if hasattr(response_data, 'clarification_result') and response_data.clarification_result:
            if isinstance(response_data.clarification_result, dict):
                response_data.clarification_result.update({
                    "critical_entities_analysis": {
                        "entities_extracted": entities,
                        "validation_result": validation_result,
                        "forced_clarification": force_critical,
                        "missing_entities": missing_entities,
                        "generic_entities": generic_entities,
                        "coherence_issues": coherence_issues,
                        "version": "3.7.8"
                    }
                })
                logger.info("üîß [FORCE CLARIFICATION v3.7.8] clarification_result enrichi avec analyse entit√©s")
        
        logger.info("‚úÖ [FORCE CLARIFICATION v3.7.8] Modifications appliqu√©es √† response_data")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå [FORCE CLARIFICATION v3.7.8] Erreur: {e}")
        return response_data

# =============================================================================
# FONCTIONS EXISTANTES v3.7.6/v3.7.7 - CONSERV√âES INT√âGRALEMENT
# =============================================================================

def _detect_inconsistencies_and_force_clarification(question_text: str, language: str = "fr") -> Dict[str, Any]:
    """üÜï CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.7: D√©tecte les incoh√©rences + utilise nouvelles entit√©s"""
    
    inconsistencies_detected = []
    force_clarification = False
    clarification_reason = ""
    
    try:
        question_lower = question_text.lower() if isinstance(question_text, str) else ""
        
        # üÜï v3.7.7: Utiliser la nouvelle extraction d'entit√©s
        entities = _extract_critical_entities_from_question(question_text, language)
        
        # üîç D√âTECTION 1: Unit√©s temporelles contradictoires (CONSERV√âE v3.7.6)
        temporal_units = []
        if "jour" in question_lower or "j" in question_lower:
            temporal_units.append("jours")
        if "semaine" in question_lower or "sem" in question_lower or "week" in question_lower:
            temporal_units.append("semaines")
        if "mois" in question_lower or "month" in question_lower:
            temporal_units.append("mois")
        
        # Si plusieurs unit√©s temporelles avec des valeurs qui pourraient √™tre contradictoires
        if len(temporal_units) >= 2:
            # Recherche de motifs comme "13j" et "1sem"
            day_pattern = r'(\d+)\s*j(?:our)?s?'
            week_pattern = r'(\d+)\s*sem(?:aine)?s?'
            
            day_matches = re.findall(day_pattern, question_lower)
            week_matches = re.findall(week_pattern, question_lower)
            
            if day_matches and week_matches:
                try:
                    days = int(day_matches[0])
                    weeks = int(week_matches[0])
                    
                    # V√©rifier si incoh√©rent (exemple: 13j ‚â† 1sem)
                    if abs(days - (weeks * 7)) > 2:  # Tol√©rance de 2 jours
                        inconsistencies_detected.append(f"temporal_contradiction")
                        force_clarification = True
                        clarification_reason = f"Incoh√©rence temporelle d√©tect√©e: {days} jours vs {weeks} semaine(s)"
                        logger.warning(f"üö® [INCOH√âRENCE v3.7.8] {clarification_reason}")
                except (ValueError, IndexError):
                    pass
        
        # üîç D√âTECTION 2: Incoh√©rences des entit√©s extraites (NOUVEAU v3.7.7)
        coherence_issues = entities.get("coherence_issues", [])
        if coherence_issues:
            inconsistencies_detected.extend(coherence_issues)
            force_clarification = True
            clarification_reason = f"Incoh√©rences entit√©s d√©tect√©es: {', '.join(coherence_issues)}"
            logger.warning(f"üö® [INCOH√âRENCE ENTIT√âS v3.7.8] {clarification_reason}")
        
        # üîç D√âTECTION 3: Sexe contradictoire (CONSERV√âE v3.7.6)
        if ("m√¢le" in question_lower and "femelle" in question_lower) or ("male" in question_lower and "female" in question_lower):
            # V√©rifier si ce n'est pas une question g√©n√©rale
            specific_indicators = ["mes", "mon", "ce", "cette", "le probl√®me", "problem with"]
            if any(indicator in question_lower for indicator in specific_indicators):
                inconsistencies_detected.append("gender_contradiction")
                force_clarification = True
                clarification_reason = "Question sp√©cifique mentionnant √† la fois m√¢les et femelles"
                logger.warning(f"üö® [INCOH√âRENCE v3.7.8] {clarification_reason}")
        
        logger.info(f"üîç [D√âTECTION INCOH√âRENCES v3.7.8] Question: '{question_text[:100]}...'")
        logger.info(f"   - Incoh√©rences d√©tect√©es: {inconsistencies_detected}")
        logger.info(f"   - Force clarification: {force_clarification}")
        logger.info(f"   - Raison: {clarification_reason}")
        logger.info(f"   - Entit√©s extraites: {entities}")
        
        return {
            "inconsistencies_detected": inconsistencies_detected,
            "force_clarification": force_clarification,
            "clarification_reason": clarification_reason,
            "temporal_units_found": temporal_units,
            "entities_extracted": entities  # NOUVEAU v3.7.7
        }
        
    except Exception as e:
        logger.error(f"‚ùå [D√âTECTION INCOH√âRENCES v3.7.8] Erreur: {e}")
        return {
            "inconsistencies_detected": [],
            "force_clarification": False,
            "clarification_reason": "",
            "temporal_units_found": [],
            "entities_extracted": {}
        }

def _validate_and_sync_rag_state(response_data: Any, processing_metadata: Dict[str, Any] = None) -> bool:
    """üÜï CONSERV√âE v3.7.6: Valide et synchronise l'√©tat RAG de mani√®re robuste"""
    
    rag_actually_used = False
    rag_indicators = []
    
    try:
        logger.info("üîç [RAG VALIDATION v3.7.8] D√âMARRAGE validation √©tat RAG...")
        
        # üîç INDICATEUR 1: V√©rifier si response_data contient des signes d'utilisation RAG
        if response_data is not None:
            
            # V√©rifier rag_score
            rag_score = getattr(response_data, 'rag_score', None)
            if rag_score is not None and rag_score > 0:
                rag_indicators.append(f"rag_score: {rag_score}")
                rag_actually_used = True
                logger.info(f"‚úÖ [RAG VALIDATION v3.7.8] RAG Score positif d√©tect√©: {rag_score}")
            
            # V√©rifier rag_used d√©j√† d√©fini
            rag_used_attr = getattr(response_data, 'rag_used', None)
            if rag_used_attr is True:
                rag_indicators.append("rag_used_attribute: True")
                rag_actually_used = True
                logger.info("‚úÖ [RAG VALIDATION v3.7.8] rag_used d√©j√† True")
            
            # V√©rifier processing_steps pour indices RAG
            processing_steps = getattr(response_data, 'processing_steps', [])
            if isinstance(processing_steps, list):
                rag_steps = [step for step in processing_steps if isinstance(step, str) and ('rag' in step.lower() or 'vector' in step.lower() or 'search' in step.lower())]
                if rag_steps:
                    rag_indicators.append(f"rag_processing_steps: {len(rag_steps)}")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.8] Steps RAG d√©tect√©s: {rag_steps}")
            
            # V√©rifier ai_enhancements_used pour RAG
            ai_enhancements = getattr(response_data, 'ai_enhancements_used', [])
            if isinstance(ai_enhancements, list):
                rag_enhancements = [enh for enh in ai_enhancements if isinstance(enh, str) and ('rag' in enh.lower() or 'vector' in enh.lower() or 'document' in enh.lower())]
                if rag_enhancements:
                    rag_indicators.append(f"rag_enhancements: {len(rag_enhancements)}")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.8] Enhancements RAG d√©tect√©s: {rag_enhancements}")
            
            # V√©rifier mode pour indices RAG
            mode = getattr(response_data, 'mode', '')
            if isinstance(mode, str) and ('rag' in mode.lower() or 'enhanced' in mode.lower()):
                rag_indicators.append(f"rag_mode: {mode}")
                rag_actually_used = True
                logger.info(f"‚úÖ [RAG VALIDATION v3.7.8] Mode RAG d√©tect√©: {mode}")
        
        # üîç INDICATEUR 2: V√©rifier processing_metadata
        if processing_metadata and isinstance(processing_metadata, dict):
            
            logger.info(f"üîç [RAG VALIDATION v3.7.8] Analyse metadata: {list(processing_metadata.keys())}")
            
            # Recherche de m√©tadonn√©es RAG
            for key, value in processing_metadata.items():
                if isinstance(key, str) and ('rag' in key.lower() or 'vector' in key.lower() or 'search' in key.lower()):
                    if value is not None and value != False and value != 0:
                        rag_indicators.append(f"metadata_{key}: {value}")
                        rag_actually_used = True
                        logger.info(f"‚úÖ [RAG VALIDATION v3.7.8] Metadata RAG: {key}={value}")
            
            # V√©rifier si des documents ont √©t√© trouv√©s
            if 'documents_found' in processing_metadata:
                docs_found = processing_metadata['documents_found']
                if isinstance(docs_found, (int, list)) and (
                    (isinstance(docs_found, int) and docs_found > 0) or 
                    (isinstance(docs_found, list) and len(docs_found) > 0)
                ):
                    rag_indicators.append(f"documents_found: {docs_found}")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.8] Documents trouv√©s: {docs_found}")
            
            # V√©rifier temps de recherche (indique qu'une recherche a eu lieu)
            if 'search_time_ms' in processing_metadata:
                search_time = processing_metadata['search_time_ms']
                if isinstance(search_time, (int, float)) and search_time > 0:
                    rag_indicators.append(f"search_time: {search_time}ms")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.8] Temps recherche: {search_time}ms")
        
        # üîç INDICATEUR 3: Analyse du contenu de la r√©ponse pour patterns RAG
        if hasattr(response_data, 'response'):
            response_text = getattr(response_data, 'response', '')
            if isinstance(response_text, str):
                # Patterns qui sugg√®rent utilisation de documents/RAG
                rag_patterns = [
                    'selon la documentation',
                    'based on the documentation',
                    'selon les documents',
                    'dans les protocoles',
                    'conform√©ment aux guides',
                    'r√©f√©rences bibliographiques',
                    'sources consult√©es'
                ]
                
                patterns_found = [pattern for pattern in rag_patterns if pattern.lower() in response_text.lower()]
                if patterns_found:
                    rag_indicators.append(f"content_patterns: {len(patterns_found)}")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.8] Patterns contenu RAG: {patterns_found}")
        
        logger.info(f"üîç [RAG VALIDATION v3.7.8] R√âSULTAT:")
        logger.info(f"   - Indicateurs trouv√©s: {rag_indicators}")
        logger.info(f"   - RAG effectivement utilis√©: {rag_actually_used}")
        
        return rag_actually_used
        
    except Exception as e:
        logger.error(f"‚ùå [RAG VALIDATION v3.7.8] Erreur: {e}")
        return False

def _force_sync_rag_state(response: EnhancedExpertResponse, rag_actually_used: bool, rag_details: Dict[str, Any] = None) -> EnhancedExpertResponse:
    """üÜï CONSERV√âE v3.7.6: Force la synchronisation de l'√©tat RAG dans la r√©ponse finale"""
    
    try:
        if response is None:
            logger.error("‚ùå [RAG SYNC v3.7.8] Response est None")
            return response
        
        logger.info(f"üîÑ [RAG SYNC v3.7.8] D√âMARRAGE synchronisation: rag_actually_used={rag_actually_used}")
        
        # üîß SYNCHRONISATION FORC√âE
        if hasattr(response, 'rag_used'):
            old_value = response.rag_used
            response.rag_used = rag_actually_used
            
            if old_value != rag_actually_used:
                logger.warning(f"üîÑ [RAG SYNC v3.7.8] CORRECTION CRITIQUE: rag_used {old_value} ‚Üí {rag_actually_used}")
                
                # Ajouter dans processing_steps pour tra√ßabilit√©
                if hasattr(response, 'processing_steps') and isinstance(response.processing_steps, list):
                    response.processing_steps.append(f"rag_state_corrected_{old_value}_to_{rag_actually_used}_v3.7.8")
                
                # Ajouter dans ai_enhancements_used
                if hasattr(response, 'ai_enhancements_used') and isinstance(response.ai_enhancements_used, list):
                    response.ai_enhancements_used.append("rag_state_synchronization_v3.7.8")
            else:
                logger.info(f"‚úÖ [RAG SYNC v3.7.8] √âtat RAG d√©j√† correct: {rag_actually_used}")
        
        # üîß MISE √Ä JOUR DU MODE si n√©cessaire
        if hasattr(response, 'mode'):
            current_mode = response.mode
            if rag_actually_used and 'rag' not in current_mode.lower():
                response.mode = f"{current_mode}_with_rag"
                logger.info(f"üîÑ [RAG SYNC v3.7.8] Mode mis √† jour: {current_mode} ‚Üí {response.mode}")
            elif not rag_actually_used and 'rag' in current_mode.lower():
                response.mode = current_mode.replace('_rag', '').replace('_with_rag', '').replace('rag_', '')
                logger.info(f"üîÑ [RAG SYNC v3.7.8] Mode nettoy√©: {current_mode} ‚Üí {response.mode}")
        
        # üîß AJOUT D√âTAILS RAG si fournis
        if rag_details and isinstance(rag_details, dict) and rag_actually_used:
            
            # Mise √† jour rag_score si disponible
            if 'rag_score' in rag_details and hasattr(response, 'rag_score'):
                if response.rag_score is None or response.rag_score == 0:
                    response.rag_score = rag_details['rag_score']
                    logger.info(f"üîÑ [RAG SYNC v3.7.8] rag_score mis √† jour: {rag_details['rag_score']}")
            
            # Ajout m√©tadonn√©es RAG dans processing_steps si pertinentes
            if hasattr(response, 'processing_steps') and isinstance(response.processing_steps, list):
                for key, value in rag_details.items():
                    if key.startswith('rag_') or key.startswith('search_') or key.startswith('vector_'):
                        response.processing_steps.append(f"rag_detail_{key}_{value}")
        
        logger.info(f"‚úÖ [RAG SYNC v3.7.8] TERMIN√â - √âtat final: rag_used={getattr(response, 'rag_used', 'N/A')}")
        
    except Exception as e:
        logger.error(f"‚ùå [RAG SYNC v3.7.8] Erreur synchronisation: {e}")
    
    return response

# =============================================================================
# UTILITAIRES PROPAGATION CHAMPS - CONSERV√âS INT√âGRALEMENT
# =============================================================================

def _extract_propagation_fields(response_data: Any) -> Dict[str, Any]:
    """üîß CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.8: Extraction avec nouveaux champs clarification"""
    
    propagation_fields = {
        "clarification_required_critical": False,
        "missing_critical_entities": [],
        "variants_tested": [],
        # üÜï NOUVEAUX v3.7.8
        "dynamic_questions": None,
        "clarification_service_used": False
    }
    
    try:
        # üîß FIX: Validation du type avant hasattr
        if response_data is None:
            logger.warning("‚ö†Ô∏è [PROPAGATION v3.7.8] response_data est None")
            return propagation_fields
        
        logger.info("üìã [PROPAGATION v3.7.8] D√âMARRAGE extraction champs...")
        
        # Extraction clarification_required_critical avec validation robuste
        if hasattr(response_data, 'clarification_result'):
            clarification_result = getattr(response_data, 'clarification_result', None)
            if clarification_result and isinstance(clarification_result, dict):
                propagation_fields["clarification_required_critical"] = clarification_result.get("clarification_required_critical", False)
                missing_entities = clarification_result.get("missing_critical_entities", [])
                # üîß FIX: Validation que missing_entities est une liste
                if isinstance(missing_entities, list):
                    propagation_fields["missing_critical_entities"] = missing_entities
                else:
                    propagation_fields["missing_critical_entities"] = []
                
                # üÜï NOUVEAU v3.7.8: Extraction dynamic_questions
                dynamic_questions = clarification_result.get("dynamic_questions", None)
                if dynamic_questions and isinstance(dynamic_questions, list):
                    propagation_fields["dynamic_questions"] = dynamic_questions
                
                logger.info(f"üìã [PROPAGATION v3.7.8] Clarification critique: {propagation_fields['clarification_required_critical']}")
                logger.info(f"üìã [PROPAGATION v3.7.8] Entit√©s critiques manquantes: {propagation_fields['missing_critical_entities']}")
                logger.info(f"üìã [PROPAGATION v3.7.8] Questions dynamiques: {len(dynamic_questions) if dynamic_questions else 0}")
        
        # üÜï NOUVEAU v3.7.8: Extraction directe des nouveaux champs
        if hasattr(response_data, 'dynamic_questions'):
            dynamic_questions = getattr(response_data, 'dynamic_questions', None)
            if dynamic_questions and isinstance(dynamic_questions, list):
                propagation_fields["dynamic_questions"] = dynamic_questions
                logger.info(f"üìã [PROPAGATION v3.7.8] Questions dynamiques directes: {len(dynamic_questions)}")
        
        if hasattr(response_data, 'clarification_service_used'):
            service_used = getattr(response_data, 'clarification_service_used', False)
            propagation_fields["clarification_service_used"] = service_used
            logger.info(f"üìã [PROPAGATION v3.7.8] Service clarification utilis√©: {service_used}")
        
        # Extraction variants_tested depuis RAG enhancements avec validation
        if hasattr(response_data, 'rag_enhancement_info'):
            rag_enhancement_info = getattr(response_data, 'rag_enhancement_info', None)
            if rag_enhancement_info and isinstance(rag_enhancement_info, dict):
                variants = rag_enhancement_info.get("variants_tested", [])
                if isinstance(variants, list):
                    propagation_fields["variants_tested"] = variants
                    logger.info(f"üìã [PROPAGATION v3.7.8] Variantes test√©es: {propagation_fields['variants_tested']}")
        
        # Extraction alternative depuis processing_metadata avec validation
        elif hasattr(response_data, 'processing_metadata'):
            processing_metadata = getattr(response_data, 'processing_metadata', None)
            if processing_metadata and isinstance(processing_metadata, dict):
                if "rag_enhancement_info" in processing_metadata:
                    rag_info = processing_metadata["rag_enhancement_info"]
                    if isinstance(rag_info, dict):
                        variants = rag_info.get("variants_tested", [])
                        if isinstance(variants, list):
                            propagation_fields["variants_tested"] = variants
                            logger.info(f"üìã [PROPAGATION v3.7.8] Variantes depuis metadata: {propagation_fields['variants_tested']}")
        
        # Extraction depuis ai_enhancements_used (fallback) avec validation
        elif hasattr(response_data, 'ai_enhancements_used'):
            ai_enhancements = getattr(response_data, 'ai_enhancements_used', None)
            if ai_enhancements and isinstance(ai_enhancements, list):
                # Filtrer les am√©liorations li√©es aux variantes
                variant_enhancements = [
                    enhancement for enhancement in ai_enhancements 
                    if isinstance(enhancement, str) and ("variant" in enhancement.lower() or "reformulation" in enhancement.lower())
                ]
                if variant_enhancements:
                    propagation_fields["variants_tested"] = variant_enhancements
                    logger.info(f"üìã [PROPAGATION v3.7.8] Variantes inf√©r√©es: {variant_enhancements}")
        
        logger.info("‚úÖ [PROPAGATION v3.7.8] Champs extraits avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå [PROPAGATION v3.7.8] Erreur extraction champs: {e}")
        # üîß FIX: Garder les valeurs par d√©faut en cas d'erreur
    
    return propagation_fields

def _apply_propagation_fields(response: EnhancedExpertResponse, propagation_fields: Dict[str, Any]) -> EnhancedExpertResponse:
    """üîß CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.8: Application avec nouveaux champs clarification"""
    
    try:
        # üîß FIX: Validation que response n'est pas None
        if response is None:
            logger.error("‚ùå [PROPAGATION v3.7.8] response est None")
            return response
        
        # üîß FIX: Validation que propagation_fields est un dict
        if not isinstance(propagation_fields, dict):
            logger.error("‚ùå [PROPAGATION v3.7.8] propagation_fields n'est pas un dict")
            return response
        
        logger.info("üìã [PROPAGATION v3.7.8] D√âMARRAGE application champs...")
        
        # Application des champs existants avec validation
        if hasattr(response, 'clarification_required_critical'):
            old_val = response.clarification_required_critical
            response.clarification_required_critical = propagation_fields.get("clarification_required_critical", False)
            if old_val != response.clarification_required_critical:
                logger.info(f"üìã [PROPAGATION v3.7.8] clarification_required_critical: {old_val} ‚Üí {response.clarification_required_critical}")
        
        if hasattr(response, 'missing_critical_entities'):
            missing_entities = propagation_fields.get("missing_critical_entities", [])
            if isinstance(missing_entities, list):
                old_len = len(response.missing_critical_entities) if response.missing_critical_entities else 0
                response.missing_critical_entities = missing_entities
                logger.info(f"üìã [PROPAGATION v3.7.8] missing_critical_entities: {old_len} ‚Üí {len(missing_entities)} entit√©s")
            else:
                response.missing_critical_entities = []
        
        if hasattr(response, 'variants_tested'):
            variants = propagation_fields.get("variants_tested", [])
            if isinstance(variants, list):
                old_len = len(response.variants_tested) if response.variants_tested else 0
                response.variants_tested = variants
                logger.info(f"üìã [PROPAGATION v3.7.8] variants_tested: {old_len} ‚Üí {len(variants)} variantes")
            else:
                response.variants_tested = []
        
        # üÜï NOUVEAUX CHAMPS v3.7.8: Application dynamic_questions et clarification_service_used
        if hasattr(response, 'dynamic_questions'):
            dynamic_questions = propagation_fields.get("dynamic_questions", None)
            if dynamic_questions and isinstance(dynamic_questions, list):
                response.dynamic_questions = dynamic_questions
                logger.info(f"üìã [PROPAGATION v3.7.8] dynamic_questions: {len(dynamic_questions)} questions appliqu√©es")
            else:
                response.dynamic_questions = None
        
        if hasattr(response, 'clarification_service_used'):
            service_used = propagation_fields.get("clarification_service_used", False)
            response.clarification_service_used = service_used
            logger.info(f"üìã [PROPAGATION v3.7.8] clarification_service_used: {service_used}")
        
        logger.info("‚úÖ [PROPAGATION v3.7.8] Champs appliqu√©s √† la r√©ponse finale")
        
        # Log des valeurs appliqu√©es avec protection None
        clarification_critical = getattr(response, 'clarification_required_critical', 'N/A')
        missing_entities = getattr(response, 'missing_critical_entities', 'N/A')
        variants_tested = getattr(response, 'variants_tested', 'N/A')
        dynamic_questions = getattr(response, 'dynamic_questions', 'N/A')
        service_used = getattr(response, 'clarification_service_used', 'N/A')
        
        logger.info(f"üìã [PROPAGATION v3.7.8] FINAL clarification critique: {clarification_critical}")
        logger.info(f"üìã [PROPAGATION v3.7.8] FINAL entit√©s manquantes: {missing_entities}")
        logger.info(f"üìã [PROPAGATION v3.7.8] FINAL variantes test√©es: {variants_tested}")
        logger.info(f"üìã [PROPAGATION v3.7.8] FINAL questions dynamiques: {len(dynamic_questions) if isinstance(dynamic_questions, list) else 'N/A'}")
        logger.info(f"üìã [PROPAGATION v3.7.8] FINAL service clarification: {service_used}")
        
    except Exception as e:
        logger.error(f"‚ùå [PROPAGATION v3.7.8] Erreur application champs: {e}")
    
    return response

# =============================================================================
# ENDPOINTS PRINCIPAUX AVEC INT√âGRATION SERVICE CLARIFICATION v3.7.8
# =============================================================================

@router.get("/health")
async def expert_health():
    """Health check pour diagnostiquer les probl√®mes - version v3.7.8 avec service clarification"""
    return {
        "status": "healthy",
        "version": "3.7.8",
        "new_features_v378": [
            "int√©gration expert_clarification_service avec s√©lection dynamique de prompts",
            "appel automatique du service si clarification_required_critical = True",
            "g√©n√©ration de questions dynamiques bas√©es sur entit√©s manquantes",
            "validation et enrichissement des questions de clarification",
            "support conversation_context pour clarifications contextuelles"
        ],
        "integration_workflow_v378": [
            "extraction entit√©s critiques ‚Üí validation ‚Üí si critique ‚Üí service clarification",
            "s√©lection prompt selon entit√©s manquantes et contexte",
            "g√©n√©ration questions GPT avec prompt optimis√©",
            "validation questions selon missing_entities",
            "enrichissement r√©ponse avec questions dynamiques"
        ],
        "fixes_applied_v377": [
            "synchronisation √©tat RAG - rag_used correctement mis √† jour",
            "clarification forc√©e si entit√©s critiques (breed, age, weight) manquent",
            "validation robuste des entit√©s critiques avec extraction automatique",
            "d√©clenchement clarification_required_critical=True pour entit√©s manquantes",
            "d√©tection entit√©s critiques depuis le texte de la question"
        ],
        "critical_entities_support": [
            "breed extraction (Ross 308, Cobb 500, etc.)",
            "age extraction with conversion to days",
            "weight extraction with conversion to grams", 
            "sex extraction (bonus feature)",
            "coherence validation age/weight",
            "confidence scoring per entity",
            "forced clarification for missing entities"
        ],
        "clarification_service_status": {
            "expert_service_available": EXPERT_SERVICE_AVAILABLE,
            "expert_service_initialized": expert_service is not None,
            "clarification_service_available": CLARIFICATION_SERVICE_AVAILABLE,
            "clarification_service_initialized": clarification_service is not None
        },
        "models_imported": MODELS_IMPORTED,
        "utils_available": UTILS_AVAILABLE,
        "timestamp": datetime.now().isoformat(),
        "new_fields_supported_v378": [
            "dynamic_questions",
            "clarification_service_used",
            "clarification_required_critical",
            "missing_critical_entities", 
            "variants_tested"
        ],
        "clarification_workflow": [
            "build_conversation_context",
            "select_clarification_prompt",
            "generate_questions_with_gpt",
            "validate_dynamic_questions",
            "apply_to_response_data"
        ],
        "endpoints": [
            "/health",
            "/ask-enhanced-v2", 
            "/ask-enhanced-v2-public",
            "/feedback",
            "/topics"
        ]
    }

@router.post("/ask-enhanced-v2", response_model=EnhancedExpertResponse)
async def ask_expert_enhanced_v2(
    request_data: EnhancedQuestionRequest,
    request: Request,
    current_user: Dict[str, Any] = Depends(get_current_user_dependency())
):
    """
    üîß ENDPOINT EXPERT FINAL v3.7.8 - INT√âGRATION SERVICE CLARIFICATION DYNAMIQUE:
    - Extraction et validation entit√©s critiques (breed, age, weight)
    - Si clarification_required_critical = True ‚Üí appel expert_clarification_service
    - S√©lection dynamique de prompt selon entit√©s manquantes
    - G√©n√©ration questions GPT avec validation
    - Enrichissement r√©ponse avec questions dynamiques
    """
    start_time = time.time()
    
    # üîß FIX: Initialisation explicite des variables de clarification
    clarification_metadata = {}
    is_clarification = False
    original_question = None
    clarification_entities = None
    processing_metadata = {}
    
    try:
        logger.info("=" * 100)
        logger.info("üöÄ D√âBUT ask_expert_enhanced_v2 v3.7.8 - INT√âGRATION SERVICE CLARIFICATION DYNAMIQUE")
        logger.info(f"üìù Question/R√©ponse: '{request_data.text}'")
        logger.info(f"üÜî Conversation ID: {getattr(request_data, 'conversation_id', 'None')}")
        logger.info(f"üõ†Ô∏è Service expert disponible: {expert_service is not None}")
        logger.info(f"üéØ Service clarification disponible: {clarification_service is not None}")
        
        # V√©rification service disponible
        if not expert_service:
            logger.error("‚ùå [Expert] Service expert non disponible - mode fallback")
            return await _fallback_expert_response(request_data, start_time, current_user)
        
        # üÜï √âTAPE 1 v3.7.8: EXTRACTION ET VALIDATION ENTIT√âS CRITIQUES
        logger.info("üîç [ENTIT√âS CRITIQUES v3.7.8] Extraction entit√©s depuis question...")
        entities = _extract_critical_entities_from_question(
            request_data.text, 
            getattr(request_data, 'language', 'fr')
        )
        
        logger.info("üîç [ENTIT√âS CRITIQUES v3.7.8] Validation entit√©s extraites...")
        validation_result = _validate_critical_entities(entities, request_data.text)
        
        # Sauvegarder dans processing_metadata pour tra√ßabilit√©
        processing_metadata['critical_entities'] = entities
        processing_metadata['entities_validation'] = validation_result
        
        # üÜï √âTAPE 2 v3.7.8: CONSTRUCTION CONTEXTE CONVERSATION
        logger.info("üîß [CONTEXTE v3.7.8] Construction contexte conversation...")
        conversation_context = _build_conversation_context(
            request_data, 
            entities, 
            processing_metadata
        )
        
        # üÜï CONSERV√âE v3.7.7: D√âTECTION INCOH√âRENCES POUR FORCER CLARIFICATION
        inconsistency_check = _detect_inconsistencies_and_force_clarification(
            request_data.text, 
            getattr(request_data, 'language', 'fr')
        )
        
        if inconsistency_check.get('force_clarification', False):
            logger.warning(f"üö® [CLARIFICATION FORC√âE v3.7.8] Incoh√©rences d√©tect√©es: {inconsistency_check['inconsistencies_detected']}")
            logger.warning(f"üö® [CLARIFICATION FORC√âE v3.7.8] Raison: {inconsistency_check['clarification_reason']}")
            
            # Forcer l'activation de la d√©tection de vagueness
            if hasattr(request_data, 'enable_vagueness_detection'):
                request_data.enable_vagueness_detection = True
            if hasattr(request_data, 'require_coherence_check'):
                request_data.require_coherence_check = True
            
            # Ajouter dans metadata pour tracking
            processing_metadata['inconsistency_check'] = inconsistency_check
        
        # üîß FIX: V√©rification robuste des param√®tres concision avec validation None
        concision_level = getattr(request_data, 'concision_level', None)
        if concision_level is None:
            concision_level = ConcisionLevel.CONCISE
            
        generate_all_versions = getattr(request_data, 'generate_all_versions', None)
        if generate_all_versions is None:
            generate_all_versions = True
        
        logger.info("üöÄ [RESPONSE_VERSIONS v3.7.8] Param√®tres concision:")
        logger.info(f"   - concision_level: {concision_level}")
        logger.info(f"   - generate_all_versions: {generate_all_versions}")
        
        # üîß FIX: D√âTECTION EXPLICITE MODE CLARIFICATION avec validation robuste
        is_clarification = getattr(request_data, 'is_clarification_response', False)
        original_question = getattr(request_data, 'original_question', None)
        clarification_entities = getattr(request_data, 'clarification_entities', None)
        
        # üîß FIX: Validation des types
        if is_clarification is None:
            is_clarification = False
        
        logger.info("üß® [D√âTECTION CLARIFICATION v3.7.8] Analyse du mode:")
        logger.info(f"   - is_clarification_response: {is_clarification}")
        logger.info(f"   - original_question fournie: {original_question is not None}")
        logger.info(f"   - clarification_entities: {clarification_entities}")
        
        if is_clarification:
            logger.info("üé™ [FLUX CLARIFICATION] Mode R√âPONSE de clarification d√©tect√©")
            logger.info(f"   - R√©ponse utilisateur: '{request_data.text}'")
            logger.info(f"   - Question originale: '{original_question}'")
            
            # üîß FIX: Initialisation s√©curis√©e des variables breed/sex
            breed = None
            sex = None
            
            # TRAITEMENT SP√âCIALIS√â R√âPONSE CLARIFICATION avec gestion d'erreur renforc√©e
            try:
                if clarification_entities and isinstance(clarification_entities, dict):
                    logger.info(f"   - Entit√©s pr√©-extraites: {clarification_entities}")
                    breed = clarification_entities.get('breed')
                    sex = clarification_entities.get('sex')
                else:
                    # Extraction automatique si pas fournie
                    logger.info("   - Extraction automatique entit√©s depuis r√©ponse")
                    extracted = extract_breed_and_sex_from_clarification(
                        request_data.text, 
                        getattr(request_data, 'language', 'fr')
                    )
                    # üîß FIX: Validation robuste du r√©sultat d'extraction
                    if extracted is None or not isinstance(extracted, dict):
                        extracted = {"breed": None, "sex": None}
                    breed = extracted.get('breed')
                    sex = extracted.get('sex')
                    logger.info(f"   - Entit√©s extraites: breed='{breed}', sex='{sex}'")
            except Exception as e:
                logger.error(f"‚ùå Erreur extraction entit√©s: {e}")
                breed, sex = None, None
            
            # VALIDATION entit√©s compl√®tes AVANT enrichissement
            clarified_entities = {"breed": breed, "sex": sex}
            
            # üéØ LOGIQUE GRANULAIRE v3.7.8: Validation granulaire breed vs sex
            if not breed or not sex:
                # üîß FIX: Protection contre None dans le logging
                breed_safe = str(breed) if breed is not None else "None"
                sex_safe = str(sex) if sex is not None else "None"
                logger.warning(f"‚ö†Ô∏è [FLUX CLARIFICATION] Entit√©s incompl√®tes: breed='{breed_safe}', sex='{sex_safe}'")
                
                return _create_incomplete_clarification_response(
                    request_data, clarified_entities, breed, sex, start_time
                )
            
            # Enrichir la question originale avec les informations COMPL√àTES
            if original_question and isinstance(original_question, str):
                enriched_question = original_question
                if breed and isinstance(breed, str):
                    enriched_question += f" pour {breed}"
                if sex and isinstance(sex, str):
                    enriched_question += f" {sex}"
                
                logger.info(f"   - Question enrichie: '{enriched_question}'")
                
                # üîß FIX: M√©tadonn√©es sauvegard√©es pour response - initialisation s√©curis√©e
                clarification_metadata = {
                    "was_clarification_response": True,
                    "original_question": original_question,
                    "clarification_input": request_data.text,
                    "entities_extracted": clarified_entities,
                    "question_enriched": True
                }
                
                # Modifier la question pour traitement RAG
                request_data.text = enriched_question
                
                # Marquer comme traitement post-clarification (√©viter boucle)
                if hasattr(request_data, 'is_clarification_response'):
                    request_data.is_clarification_response = False
                
                logger.info("üéØ [FLUX CLARIFICATION] Question enrichie, passage au traitement RAG")
            else:
                logger.warning("‚ö†Ô∏è [FLUX CLARIFICATION] Question originale manquante ou invalide - impossible enrichir")
        else:
            logger.info("üéØ [FLUX CLARIFICATION] Mode QUESTION INITIALE - d√©tection vagueness active")
        
        # üîß FIX: Validation et d√©fauts concision robuste avec validation None
        if not hasattr(request_data, 'concision_level') or getattr(request_data, 'concision_level', None) is None:
            request_data.concision_level = ConcisionLevel.CONCISE
            logger.info("üöÄ [CONCISION] Niveau par d√©faut appliqu√©: CONCISE")
        
        if not hasattr(request_data, 'generate_all_versions') or getattr(request_data, 'generate_all_versions', None) is None:
            request_data.generate_all_versions = True
            logger.info("üöÄ [CONCISION] generate_all_versions activ√© par d√©faut")
        
        # FOR√áAGE SYST√âMATIQUE DES AM√âLIORATIONS avec gestion d'erreur
        original_vagueness = getattr(request_data, 'enable_vagueness_detection', None)
        original_coherence = getattr(request_data, 'require_coherence_check', None)
        
        # FORCER l'activation - AUCUNE EXCEPTION
        if hasattr(request_data, 'enable_vagueness_detection'):
            request_data.enable_vagueness_detection = True
        if hasattr(request_data, 'require_coherence_check'):
            request_data.require_coherence_check = True
        
        logger.info("üî• [CLARIFICATION FORC√âE v3.7.8] Param√®tres forc√©s:")
        logger.info(f"   - enable_vagueness_detection: {original_vagueness} ‚Üí TRUE (FORC√â)")
        logger.info(f"   - require_coherence_check: {original_coherence} ‚Üí TRUE (FORC√â)")
        
        # D√âL√âGUER AU SERVICE avec gestion d'erreur
        try:
            response = await expert_service.process_expert_question(
                request_data=request_data,
                request=request,
                current_user=current_user,
                start_time=start_time
            )
        except Exception as e:
            logger.error(f"‚ùå [Expert Service] Erreur traitement: {e}")
            return await _fallback_expert_response(request_data, start_time, current_user, str(e))
        
        # üÜï SYNCHRONISATION RAG STATE v3.7.7 (CONSERV√âE)
        logger.info("üîç [RAG SYNC v3.7.8] APPEL IMM√âDIAT apr√®s traitement service...")
        rag_actually_used = _validate_and_sync_rag_state(response, processing_metadata)
        
        if rag_actually_used:
            logger.info("‚úÖ [RAG SYNC v3.7.8] RAG confirm√© comme utilis√© - synchronisation FORC√âE...")
            response = _force_sync_rag_state(response, True)
        else:
            logger.warning("‚ö†Ô∏è [RAG SYNC v3.7.8] Aucun signe d'utilisation RAG d√©tect√© - marquage FALSE")
            response = _force_sync_rag_state(response, False)
        
        # üÜï VALIDATION ENTIT√âS CRITIQUES ET CLARIFICATION FORC√âE (CONSERV√âE v3.7.7)
        logger.info("üîç [ENTIT√âS CRITIQUES v3.7.8] Application validation entit√©s sur r√©ponse...")
        response = _force_clarification_for_missing_entities(response, validation_result, entities)
        
        # üÜï √âTAPE 3 v3.7.8: APPLICATION SERVICE CLARIFICATION DYNAMIQUE
        logger.info("üéØ [SERVICE CLARIFICATION v3.7.8] Application service clarification dynamique...")
        response = await _apply_dynamic_clarification_service(
            response_data=response,
            validation_result=validation_result,
            entities=entities,
            conversation_context=conversation_context
        )
        
        # üöÄ PROPAGATION CHAMPS v3.7.8 - AVEC NOUVEAUX CHAMPS
        logger.info("üìã [PROPAGATION v3.7.8] Extraction et application nouveaux champs")
        propagation_fields = _extract_propagation_fields(response)
        response = _apply_propagation_fields(response, propagation_fields)
        
        # üîß FIX: AJOUT M√âTADONN√âES CLARIFICATION dans response avec validation
        if clarification_metadata and isinstance(clarification_metadata, dict) and hasattr(response, 'clarification_processing'):
            response.clarification_processing = clarification_metadata
            logger.info("üí° [M√âTADONN√âES v3.7.8] Clarification metadata ajout√©es √† response")
        
        # üÜï AJOUT M√âTADONN√âES INCOH√âRENCES v3.7.8
        if inconsistency_check.get('force_clarification', False) and hasattr(response, 'processing_steps'):
            if isinstance(response.processing_steps, list):
                response.processing_steps.append("inconsistency_forced_clarification_v3.7.8")
            if hasattr(response, 'ai_enhancements_used') and isinstance(response.ai_enhancements_used, list):
                response.ai_enhancements_used.append("inconsistency_detection_v3.7.8")
        
        # üÜï AJOUT M√âTADONN√âES ENTIT√âS CRITIQUES + SERVICE CLARIFICATION v3.7.8
        if hasattr(response, 'processing_steps') and isinstance(response.processing_steps, list):
            response.processing_steps.append("critical_entities_extracted_v3.7.8")
            if validation_result.get('clarification_required', False):
                response.processing_steps.append(f"critical_entities_clarification_{validation_result.get('clarification_priority', 'unknown')}")
            
            # Ajouter step pour service clarification
            if getattr(response, 'clarification_service_used', False):
                response.processing_steps.append("dynamic_clarification_service_used_v3.7.8")
        
        if hasattr(response, 'ai_enhancements_used') and isinstance(response.ai_enhancements_used, list):
            response.ai_enhancements_used.append("critical_entities_validation_v3.7.8")
            if validation_result.get('entities_sufficient', False):
                response.ai_enhancements_used.append("critical_entities_sufficient")
            else:
                response.ai_enhancements_used.append("critical_entities_insufficient")
            
            # Ajouter enhancement pour service clarification
            if getattr(response, 'clarification_service_used', False):
                response.ai_enhancements_used.append("dynamic_clarification_generation_v3.7.8")
        
        # Log response_versions si pr√©sentes avec validation
        if hasattr(response, 'response_versions') and response.response_versions and isinstance(response.response_versions, dict):
            logger.info("üöÄ [RESPONSE_VERSIONS] Versions g√©n√©r√©es:")
            for level, content in response.response_versions.items():
                content_len = len(str(content)) if content else 0
                logger.info(f"   - {level}: {content_len} caract√®res")
        
        # LOGGING R√âSULTATS CLARIFICATION D√âTAILL√â avec protection None
        logger.info("üß® [R√âSULTATS CLARIFICATION v3.7.8]:")
        logger.info(f"   - Mode final: {getattr(response, 'mode', 'unknown')}")
        logger.info(f"   - Clarification d√©clench√©e: {getattr(response, 'clarification_result', None) is not None}")
        logger.info(f"   - RAG utilis√©: {getattr(response, 'rag_used', False)}")
        logger.info(f"   - Service clarification utilis√©: {getattr(response, 'clarification_service_used', False)}")
        
        # üÜï LOGGING SP√âCIFIQUE SERVICE CLARIFICATION v3.7.8
        dynamic_questions = getattr(response, 'dynamic_questions', None)
        if dynamic_questions and isinstance(dynamic_questions, list):
            logger.info(f"   - Questions dynamiques g√©n√©r√©es: {len(dynamic_questions)}")
            for i, q in enumerate(dynamic_questions[:3], 1):  # Log 3 premi√®res questions
                question_text = q.get('question', '') if isinstance(q, dict) else str(q)
                logger.info(f"     {i}. {question_text[:50]}...")
        else:
            logger.info("   - Aucune question dynamique g√©n√©r√©e")
        
        question_preview = getattr(response, 'question', '')
        if isinstance(question_preview, str) and len(question_preview) > 100:
            question_preview = question_preview[:100] + "..."
        logger.info(f"   - Question finale trait√©e: '{question_preview}'")
        
        clarification_result = getattr(response, 'clarification_result', None)
        if clarification_result and isinstance(clarification_result, dict):
            logger.info(f"   - Type clarification: {clarification_result.get('clarification_type', 'N/A')}")
            logger.info(f"   - Infos manquantes: {clarification_result.get('missing_information', [])}")
            logger.info(f"   - Confiance: {clarification_result.get('confidence', 0)}")
            if 'provided_parts' in clarification_result:
                logger.info(f"   - Parties d√©tect√©es: {clarification_result.get('provided_parts', [])}")
        
        # üìã LOGGING NOUVEAUX CHAMPS v3.7.8 avec protection None
        logger.info("üìã [NOUVEAUX CHAMPS v3.7.8] Valeurs finales:")
        logger.info(f"   - clarification_required_critical: {getattr(response, 'clarification_required_critical', 'N/A')}")
        logger.info(f"   - missing_critical_entities: {getattr(response, 'missing_critical_entities', 'N/A')}")
        logger.info(f"   - variants_tested: {getattr(response, 'variants_tested', 'N/A')}")
        logger.info(f"   - dynamic_questions: {len(getattr(response, 'dynamic_questions', [])) if getattr(response, 'dynamic_questions', None) else 'N/A'}")
        logger.info(f"   - clarification_service_used: {getattr(response, 'clarification_service_used', 'N/A')}")
        
        # üÜï LOGGING ENTIT√âS CRITIQUES v3.7.8
        logger.info("üîç [ENTIT√âS CRITIQUES v3.7.8] Analyse finale:")
        logger.info(f"   - Breed d√©tect√©: {entities.get('breed', 'N/A')}")
        logger.info(f"   - Age d√©tect√©: {entities.get('age', 'N/A')} = {entities.get('age_in_days', 'N/A')} jours")
        logger.info(f"   - Weight d√©tect√©: {entities.get('weight', 'N/A')} = {entities.get('weight_in_grams', 'N/A')}g")
        logger.info(f"   - Entit√©s suffisantes: {validation_result.get('entities_sufficient', 'N/A')}")
        logger.info(f"   - Clarification priorit√©: {validation_result.get('clarification_priority', 'N/A')}")
        
        # üÜï LOGGING RAG STATE v3.7.8
        logger.info("üîç [RAG STATE v3.7.8] √âtat final synchronis√©:")
        logger.info(f"   - rag_used: {getattr(response, 'rag_used', 'N/A')}")
        logger.info(f"   - rag_score: {getattr(response, 'rag_score', 'N/A')}")
        rag_mode = getattr(response, 'mode', '')
        logger.info(f"   - mode contains 'rag': {'rag' in str(rag_mode).lower()}")
        
        response_time = getattr(response, 'response_time_ms', 0)
        ai_enhancements = getattr(response, 'ai_enhancements_used', [])
        ai_count = len(ai_enhancements) if isinstance(ai_enhancements, list) else 0
        
        logger.info(f"‚úÖ FIN ask_expert_enhanced_v2 v3.7.8 - Temps: {response_time}ms")
        logger.info(f"ü§ñ Am√©liorations: {ai_count} features")
        logger.info(f"üîç RAG Final: {getattr(response, 'rag_used', 'N/A')}")
        logger.info(f"üéØ Entit√©s Critiques: {validation_result.get('entities_sufficient', 'N/A')}")
        logger.info(f"üé™ Service Clarification: {getattr(response, 'clarification_service_used', 'N/A')}")
        logger.info(f"üîÆ Questions Dynamiques: {len(getattr(response, 'dynamic_questions', [])) if getattr(response, 'dynamic_questions', None) else 0}")
        logger.info("=" * 100)
        
        return response
    
    except HTTPException:
        logger.info("=" * 100)
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur critique ask_expert_enhanced_v2 v3.7.8: {e}")
        logger.info("=" * 100)
        return await _fallback_expert_response(request_data, start_time, current_user, str(e))

@router.post("/ask-enhanced-v2-public", response_model=EnhancedExpertResponse)
async def ask_expert_enhanced_v2_public(
    request_data: EnhancedQuestionRequest,
    request: Request
):
    """üîß ENDPOINT PUBLIC v3.7.8 - INT√âGRATION SERVICE CLARIFICATION DYNAMIQUE"""
    start_time = time.time()
    
    # üîß FIX: Initialisation explicite des variables
    clarification_metadata = {}
    is_clarification = False
    processing_metadata = {}
    
    try:
        logger.info("=" * 100)
        logger.info("üåê D√âBUT ask_expert_enhanced_v2_public v3.7.8 - INT√âGRATION SERVICE CLARIFICATION DYNAMIQUE")
        logger.info(f"üìù Question/R√©ponse: '{request_data.text}'")
        logger.info(f"üõ†Ô∏è Service expert disponible: {expert_service is not None}")
        logger.info(f"üéØ Service clarification disponible: {clarification_service is not None}")
        
        # V√©rification service disponible
        if not expert_service:
            logger.error("‚ùå [Expert Public] Service expert non disponible - mode fallback")
            return await _fallback_expert_response(request_data, start_time, None)
        
        # üÜï √âTAPE 1 v3.7.8: EXTRACTION ET VALIDATION ENTIT√âS CRITIQUES POUR ENDPOINT PUBLIC
        logger.info("üîç [ENTIT√âS CRITIQUES PUBLIC v3.7.8] Extraction entit√©s depuis question...")
        entities = _extract_critical_entities_from_question(
            request_data.text, 
            getattr(request_data, 'language', 'fr')
        )
        
        logger.info("üîç [ENTIT√âS CRITIQUES PUBLIC v3.7.8] Validation entit√©s extraites...")
        validation_result = _validate_critical_entities(entities, request_data.text)
        
        # Sauvegarder dans processing_metadata pour tra√ßabilit√©
        processing_metadata['critical_entities'] = entities
        processing_metadata['entities_validation'] = validation_result
        
        # üÜï √âTAPE 2 v3.7.8: CONSTRUCTION CONTEXTE CONVERSATION POUR ENDPOINT PUBLIC
        logger.info("üîß [CONTEXTE PUBLIC v3.7.8] Construction contexte conversation...")
        conversation_context = _build_conversation_context(
            request_data, 
            entities, 
            processing_metadata
        )
        
        # üÜï CONSERV√âE v3.7.6: D√âTECTION INCOH√âRENCES POUR ENDPOINT PUBLIC
        inconsistency_check = _detect_inconsistencies_and_force_clarification(
            request_data.text, 
            getattr(request_data, 'language', 'fr')
        )
        
        if inconsistency_check.get('force_clarification', False):
            logger.warning(f"üö® [CLARIFICATION FORC√âE PUBLIC v3.7.8] Incoh√©rences: {inconsistency_check['inconsistencies_detected']}")
            logger.warning(f"üö® [CLARIFICATION FORC√âE PUBLIC v3.7.8] Raison: {inconsistency_check['clarification_reason']}")
            
            # Forcer l'activation pour endpoint public aussi
            if hasattr(request_data, 'enable_vagueness_detection'):
                request_data.enable_vagueness_detection = True
            if hasattr(request_data, 'require_coherence_check'):
                request_data.require_coherence_check = True
            
            processing_metadata['inconsistency_check'] = inconsistency_check
        
        # [REST OF THE PUBLIC ENDPOINT IMPLEMENTATION FOLLOWS SAME PATTERN AS PRIVATE ENDPOINT]
        # ... (similar logic to private endpoint with public-specific handling)
        
        # D√âL√âGUER AU SERVICE avec support response_versions et gestion d'erreur
        try:
            response = await expert_service.process_expert_question(
                request_data=request_data,
                request=request,
                current_user=None,  # Mode public
                start_time=start_time
            )
        except Exception as e:
            logger.error(f"‚ùå [Expert Service Public] Erreur traitement: {e}")
            return await _fallback_expert_response(request_data, start_time, None, str(e))
        
        # üÜï SYNCHRONISATION RAG STATE POUR PUBLIC v3.7.8
        logger.info("üîç [RAG SYNC PUBLIC v3.7.8] APPEL IMM√âDIAT apr√®s traitement service...")
        rag_actually_used = _validate_and_sync_rag_state(response, processing_metadata)
        
        if rag_actually_used:
            logger.info("‚úÖ [RAG SYNC PUBLIC v3.7.8] RAG confirm√© comme utilis√© - synchronisation FORC√âE...")
            response = _force_sync_rag_state(response, True)
        else:
            logger.warning("‚ö†Ô∏è [RAG SYNC PUBLIC v3.7.8] Aucun signe d'utilisation RAG d√©tect√© - marquage FALSE")
            response = _force_sync_rag_state(response, False)
        
        # üÜï VALIDATION ENTIT√âS CRITIQUES ET CLARIFICATION FORC√âE POUR PUBLIC
        logger.info("üîç [ENTIT√âS CRITIQUES PUBLIC v3.7.8] Application validation entit√©s sur r√©ponse...")
        response = _force_clarification_for_missing_entities(response, validation_result, entities)
        
        # üÜï √âTAPE 3 v3.7.8: APPLICATION SERVICE CLARIFICATION DYNAMIQUE POUR ENDPOINT PUBLIC
        logger.info("üéØ [SERVICE CLARIFICATION PUBLIC v3.7.8] Application service clarification dynamique...")
        response = await _apply_dynamic_clarification_service(
            response_data=response,
            validation_result=validation_result,
            entities=entities,
            conversation_context=conversation_context
        )
        
        # üöÄ PROPAGATION CHAMPS v3.7.8 - ENDPOINT PUBLIC - AVEC NOUVEAUX CHAMPS
        logger.info("üìã [PROPAGATION PUBLIC v3.7.8] Extraction et application nouveaux champs")
        propagation_fields = _extract_propagation_fields(response)
        response = _apply_propagation_fields(response, propagation_fields)
        
        # [SIMILAR LOGGING AND METADATA HANDLING AS PRIVATE ENDPOINT]
        
        logger.info(f"‚úÖ FIN ask_expert_enhanced_v2_public v3.7.8")
        logger.info(f"üé™ Service Clarification Public: {getattr(response, 'clarification_service_used', 'N/A')}")
        logger.info(f"üîÆ Questions Dynamiques Public: {len(getattr(response, 'dynamic_questions', [])) if getattr(response, 'dynamic_questions', None) else 0}")
        logger.info("=" * 100)
        
        return response
    
    except HTTPException:
        logger.info("=" * 100)
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur critique ask_expert_enhanced_v2_public v3.7.8: {e}")
        logger.info("=" * 100)
        return await _fallback_expert_response(request_data, start_time, None, str(e))

# =============================================================================
# AUTRES ENDPOINTS CONSERV√âS v3.7.8
# =============================================================================

@router.post("/feedback")
async def submit_feedback_enhanced(feedback_data: FeedbackRequest):
    """Submit feedback - VERSION CORRIG√âE v3.7.8 avec gestion d'erreur robuste"""
    try:
        conversation_id = getattr(feedback_data, 'conversation_id', 'None')
        logger.info(f"üìä [Feedback v3.7.8] Re√ßu: {feedback_data.rating} pour {conversation_id}")
        
        # üîß FIX: Validation robuste des quality_feedback
        quality_feedback = getattr(feedback_data, 'quality_feedback', None)
        if quality_feedback and isinstance(quality_feedback, dict):
            logger.info(f"üìà [Feedback v3.7.8] Qualit√© d√©taill√©e: {len(quality_feedback)} m√©triques")
        
        if expert_service and hasattr(expert_service, 'process_feedback'):
            try:
                result = await expert_service.process_feedback(feedback_data)
            except Exception as e:
                logger.error(f"‚ùå [Feedback Service v3.7.8] Erreur: {e}")
                # Fallback si service expert √©choue
                result = {
                    "success": False,
                    "message": f"Erreur service feedback: {str(e)}",
                    "rating": feedback_data.rating,
                    "comment": getattr(feedback_data, 'comment', None),
                    "conversation_id": conversation_id,
                    "fallback_mode": True,
                    "timestamp": datetime.now().isoformat(),
                    "version": "3.7.8"
                }
        else:
            # Fallback si service non disponible
            result = {
                "success": True,
                "message": "Feedback enregistr√© (mode fallback v3.7.8)",
                "rating": feedback_data.rating,
                "comment": getattr(feedback_data, 'comment', None),
                "conversation_id": conversation_id,
                "fallback_mode": True,
                "timestamp": datetime.now().isoformat(),
                "version": "3.7.8"
            }
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå [Feedback v3.7.8] Erreur critique: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur feedback v3.7.8: {str(e)}")

@router.get("/topics")
async def get_suggested_topics_enhanced(language: str = "fr"):
    """Get suggested topics - VERSION CORRIG√âE v3.7.8 avec gestion d'erreur robuste"""
    try:
        if expert_service and hasattr(expert_service, 'get_suggested_topics'):
            try:
                return await expert_service.get_suggested_topics(language)
            except Exception as e:
                logger.error(f"‚ùå [Topics Service v3.7.8] Erreur: {e}")
                # Continuer vers fallback
        
        # üîß FIX: Fallback am√©lior√© avec validation language v3.7.8
        fallback_topics = {
            "fr": [
                "Probl√®mes de croissance poulets Ross 308",
                "Conditions environnementales optimales √©levage", 
                "Protocoles vaccination selon √¢ge",
                "Diagnostic probl√®mes sant√© par sympt√¥mes",
                "Nutrition et alimentation selon poids",
                "Mortalit√© √©lev√©e - causes et solutions",
                "Temp√©rature et ventilation b√¢timent",
                "D√©veloppement normal poulets de chair"
            ],
            "en": [
                "Ross 308 chicken growth problems",
                "Optimal environmental conditions breeding",
                "Age-specific vaccination protocols", 
                "Health problem diagnosis by symptoms",
                "Weight-based nutrition and feeding",
                "High mortality - causes and solutions",
                "Building temperature and ventilation",
                "Normal broiler chicken development"
            ],
            "es": [
                "Problemas crecimiento pollos Ross 308",
                "Condiciones ambientales √≥ptimas crianza",
                "Protocolos vacunaci√≥n seg√∫n edad",
                "Diagn√≥stico problemas salud por s√≠ntomas", 
                "Nutrici√≥n alimentaci√≥n seg√∫n peso",
                "Alta mortalidad - causas y soluciones",
                "Temperatura y ventilaci√≥n edificio",
                "Desarrollo normal pollos de engorde"
            ]
        }
        
        # üîß FIX: Validation robuste du language
        lang = str(language).lower() if language else "fr"
        if lang not in fallback_topics:
            lang = "fr"
        
        selected_topics = fallback_topics[lang]
        
        return {
            "topics": selected_topics,
            "language": lang,
            "count": len(selected_topics),
            "fallback_mode": True,
            "expert_service_available": expert_service is not None,
            "clarification_service_available": clarification_service is not None,
            "timestamp": datetime.now().isoformat(),
            "version": "3.7.8",
            "critical_entities_optimized": True,
            "dynamic_clarification_ready": CLARIFICATION_SERVICE_AVAILABLE
        }
            
    except Exception as e:
        logger.error(f"‚ùå [Topics v3.7.8] Erreur critique: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur topics v3.7.8: {str(e)}")

# =============================================================================
# FONCTIONS UTILITAIRES CONSERV√âES AVEC AM√âLIORATIONS v3.7.8
# =============================================================================

def _create_incomplete_clarification_response(
    request_data: EnhancedQuestionRequest, 
    clarified_entities: Dict[str, str], 
    breed: Optional[str], 
    sex: Optional[str], 
    start_time: float,
    public: bool = False
) -> EnhancedExpertResponse:
    """üîß CONSERV√âE v3.7.7 + AM√âLIORATION v3.7.8: Cr√©e une r√©ponse pour clarification incompl√®te avec entit√©s critiques et nouveaux champs"""
    
    # üîß FIX: Validation des param√®tres d'entr√©e
    if not isinstance(clarified_entities, dict):
        clarified_entities = {"breed": breed, "sex": sex}
    
    # üÜï v3.7.7: Extraire entit√©s critiques de la r√©ponse utilisateur aussi
    user_text = getattr(request_data, 'text', '')
    extracted_entities = _extract_critical_entities_from_question(user_text, getattr(request_data, 'language', 'fr'))
    
    # Validation granulaire des informations manquantes avec protection None
    missing_info = []
    missing_details = []
    provided_parts = []
    missing_critical_entities = []  # NOUVEAU CHAMP v3.7.6/v3.7.7
    
    # üîß FIX: V√©rification breed avec plus de nuances et protection None
    extracted_breed = extracted_entities.get('breed')
    effective_breed = breed or extracted_breed
    
    if not effective_breed or (isinstance(effective_breed, str) and len(effective_breed.strip()) == 0):
        missing_info.append("race/souche")
        missing_details.append("la race/souche (Ross 308, Cobb 500, Hubbard, etc.)")
        missing_critical_entities.append("breed")
    elif isinstance(effective_breed, str) and len(effective_breed.strip()) < 3:  # Breed trop court/vague
        missing_info.append("race/souche compl√®te")
        missing_details.append("la race/souche compl√®te (ex: 'Ross' ‚Üí 'Ross 308')")
        provided_parts.append(f"Race partielle d√©tect√©e: {effective_breed}")
        missing_critical_entities.append("breed_complete")
    elif effective_breed:  # breed est valide
        provided_parts.append(f"Race d√©tect√©e: {effective_breed}")
    
    # üîß FIX: V√©rification sex avec protection None
    if not sex or (isinstance(sex, str) and len(sex.strip()) == 0):
        missing_info.append("sexe")
        missing_details.append("le sexe (m√¢les, femelles, ou mixte)")
        missing_critical_entities.append("sex")
    elif sex:  # sex est valide
        provided_parts.append(f"Sexe d√©tect√©: {sex}")
    
    # üÜï v3.7.7: V√©rifier aussi √¢ge et poids depuis extraction automatique
    extracted_age = extracted_entities.get('age_in_days')
    extracted_weight = extracted_entities.get('weight_in_grams')
    
    if extracted_age and isinstance(extracted_age, (int, float)) and extracted_age > 0:
        provided_parts.append(f"√Çge d√©tect√©: {extracted_entities.get('age', extracted_age)} jours")
    else:
        missing_info.append("√¢ge")
        missing_details.append("l'√¢ge pr√©cis (13 jours, 2 semaines, etc.)")
        missing_critical_entities.append("age")
    
    if extracted_weight and isinstance(extracted_weight, (int, float)) and extracted_weight > 0:
        provided_parts.append(f"Poids d√©tect√©: {extracted_entities.get('weight', extracted_weight)}g")
    else:
        missing_info.append("poids")
        missing_details.append("le poids actuel (800g, 1.2kg, etc.)")
        missing_critical_entities.append("weight")
    
    # üéØ MESSAGE ADAPTATIF selon ce qui manque r√©ellement v3.7.7/v3.7.8
    if len(missing_info) >= 3:
        error_message = f"Information incompl√®te. Il manque plusieurs √©l√©ments critiques : {', '.join(missing_info)}.\n\n"
    elif len(missing_info) == 2:
        error_message = f"Information incompl√®te. Il manque encore : {' et '.join(missing_info)}.\n\n"
    elif len(missing_info) == 1:
        error_message = f"Information incompl√®te. Il manque encore : {missing_info[0]}.\n\n"
    else:
        error_message = "Information incompl√®te.\n\n"
    
    # Ajouter contexte de ce qui a √©t√© fourni VS ce qui manque
    if provided_parts:
        error_message += f"Votre r√©ponse '{user_text}' contient : {', '.join(provided_parts)}.\n"
        error_message += f"Mais il manque encore : {', '.join(missing_details)}.\n\n"
    else:
        error_message += f"Votre r√©ponse '{user_text}' ne contient pas tous les √©l√©ments n√©cessaires.\n\n"
    
    # Exemples contextuels selon ce qui manque v3.7.7/v3.7.8
    error_message += "**Exemples complets requis :**\n"
    
    if len(missing_critical_entities) >= 3:  # Manque breed + age + weight
        error_message += "‚Ä¢ 'Ross 308 m√¢les de 13 jours pesant 800g'\n"
        error_message += "‚Ä¢ 'Cobb 500 femelles de 2 semaines pesant 1.2kg'\n" 
        error_message += "‚Ä¢ 'Hubbard mixte de 25 jours pesant 950g'\n\n"
    elif "breed" in missing_critical_entities and "age" in missing_critical_entities:
        error_message += f"‚Ä¢ 'Ross 308 {sex or 'm√¢les'} de 13 jours'\n"
        error_message += f"‚Ä¢ 'Cobb 500 {sex or 'femelles'} de 2 semaines'\n\n"
    elif "breed" in missing_critical_entities and "weight" in missing_critical_entities:
        error_message += f"‚Ä¢ 'Ross 308 {sex or 'm√¢les'} pesant 800g'\n"
        error_message += f"‚Ä¢ 'Cobb 500 {sex or 'femelles'} pesant 1.2kg'\n\n"
    elif "age" in missing_critical_entities and "weight" in missing_critical_entities:
        error_message += f"‚Ä¢ '{effective_breed or 'Ross 308'} de 13 jours pesant 800g'\n"
        error_message += f"‚Ä¢ '{effective_breed or 'Cobb 500'} de 2 semaines pesant 1.2kg'\n\n"
    elif "breed" in missing_critical_entities:
        error_message += f"‚Ä¢ 'Ross 308 {sex or 'm√¢les'}'\n"
        error_message += f"‚Ä¢ 'Cobb 500 {sex or 'femelles'}'\n\n"
    elif "age" in missing_critical_entities:
        error_message += f"‚Ä¢ '{effective_breed or 'Ross 308'} de 13 jours'\n"
        error_message += f"‚Ä¢ '{effective_breed or 'Cobb 500'} de 2 semaines'\n\n"
    elif "weight" in missing_critical_entities:
        error_message += f"‚Ä¢ '{effective_breed or 'Ross 308'} pesant 800g'\n"
        error_message += f"‚Ä¢ '{effective_breed or 'Cobb 500'} pesant 1.2kg'\n\n"
    
    error_message += "Pouvez-vous pr√©ciser les informations manquantes ?"
    
    # üîß FIX: Retourner erreur clarification incompl√®te avec validation robuste v3.7.8
    mode_suffix = "_public" if public else ""
    conversation_id = getattr(request_data, 'conversation_id', None)
    if not conversation_id:
        conversation_id = str(uuid.uuid4())
    
    language = getattr(request_data, 'language', 'fr')
    if not isinstance(language, str):
        language = 'fr'
    
    logger.info(f"üìã [CLARIFICATION INCOMPL√àTE v3.7.8] Entit√©s critiques manquantes: {missing_critical_entities}")
    logger.info(f"üìã [CLARIFICATION INCOMPL√àTE v3.7.8] Entit√©s extraites automatiquement: {extracted_entities}")
    
    return EnhancedExpertResponse(
        question=user_text,
        response=error_message,
        conversation_id=conversation_id,
        rag_used=False,  # üÜï v3.7.6/v3.7.7: Toujours False pour clarification incompl√®te
        rag_score=None,
        timestamp=datetime.now().isoformat(),
        language=language,
        response_time_ms=int((time.time() - start_time) * 1000),
        mode=f"incomplete_clarification_response_v3.7.8{mode_suffix}",
        user=None,
        logged=True,
        validation_passed=False,
        # üöÄ CHAMPS EXISTANTS v3.7.6/v3.7.7 POUR CLARIFICATION INCOMPL√àTE
        clarification_required_critical=True,
        missing_critical_entities=missing_critical_entities,
        variants_tested=[],  # vide pour clarification incompl√®te
        # üÜï NOUVEAUX CHAMPS v3.7.8
        dynamic_questions=None,  # Pas de questions dynamiques pour erreurs incompl√®tes
        clarification_service_used=False,  # Service non utilis√© pour erreurs
        clarification_result={
            "clarification_requested": True,
            "clarification_type": f"incomplete_critical_entities_retry_v3.7.8{mode_suffix}",
            "missing_information": missing_info,
            "provided_entities": clarified_entities,
            "provided_parts": provided_parts,
            "missing_details": missing_details,
            "retry_required": True,
            "confidence": 0.3,
            # üöÄ CHAMPS DANS CLARIFICATION_RESULT v3.7.6/v3.7.7
            "clarification_required_critical": True,
            "missing_critical_entities": missing_critical_entities,
            # üÜï v3.7.7: Ajouter entit√©s extraites automatiquement
            "auto_extracted_entities": extracted_entities,
            "effective_breed": effective_breed,
            "critical_entities_analysis": {
                "breed_detected": effective_breed,
                "age_detected": extracted_age,
                "weight_detected": extracted_weight,
                "sex_detected": sex,
                "validation_summary": f"Missing: {len(missing_critical_entities)} critical entities",
                "extraction_method": "automatic_from_user_response",
                "timestamp": datetime.now().isoformat()
            }
        },
        processing_steps=[
            "incomplete_clarification_response_created_v3.7.8",
            f"missing_entities_{len(missing_critical_entities)}",
            f"provided_parts_{len(provided_parts)}",
            "critical_entities_auto_extraction"
        ],
        ai_enhancements_used=[
            "incomplete_clarification_handling_v3.7.8",
            "critical_entities_validation",
            "adaptive_error_messages",
            "contextual_examples_generation"
        ],
        response_versions=None  # Pas de versions pour erreurs
    )

async def _fallback_expert_response(
    request_data: EnhancedQuestionRequest, 
    start_time: float, 
    current_user: Optional[Dict[str, Any]], 
    error_message: str = "Service non disponible"
) -> EnhancedExpertResponse:
    """üîß FALLBACK v3.7.8: R√©ponse de secours si service expert non disponible"""
    
    try:
        conversation_id = getattr(request_data, 'conversation_id', None)
        if not conversation_id:
            conversation_id = str(uuid.uuid4())
        
        language = getattr(request_data, 'language', 'fr')
        user_email = current_user.get('email') if current_user else None
        
        fallback_response = f"""Je suis d√©sol√©, le service expert n'est temporairement pas disponible.

**Erreur:** {error_message}

**Pour obtenir de l'aide avec vos questions d'aviculture:**
‚Ä¢ V√©rifiez que votre question contient la race (Ross 308, Cobb 500, etc.)
‚Ä¢ Pr√©cisez l'√¢ge de vos animaux (13 jours, 2 semaines, etc.)
‚Ä¢ Indiquez le sexe (m√¢les, femelles, mixte)
‚Ä¢ Mentionnez le poids actuel si pertinent

**Exemple de question compl√®te:**
"Quel est le poids normal d'un poulet Ross 308 m√¢le de 12 jours ?"

Veuillez r√©essayer dans quelques instants."""

        return EnhancedExpertResponse(
            question=request_data.text,
            response=fallback_response,
            conversation_id=conversation_id,
            rag_used=False,
            rag_score=None,
            timestamp=datetime.now().isoformat(),
            language=language,
            response_time_ms=int((time.time() - start_time) * 1000),
            mode="fallback_service_unavailable_v3.7.8",
            user=user_email,
            logged=True,
            validation_passed=False,
            clarification_required_critical=False,
            missing_critical_entities=[],
            variants_tested=[],
            dynamic_questions=None,
            clarification_service_used=False,
            clarification_result=None,
            processing_steps=["fallback_response_generated_v3.7.8"],
            ai_enhancements_used=["fallback_service_v3.7.8"],
            response_versions=None
        )
        
    except Exception as e:
        logger.error(f"‚ùå [FALLBACK] Erreur cr√©ation r√©ponse fallback: {e}")
        # R√©ponse ultra-minimale en cas d'erreur critique
        return EnhancedExpertResponse(
            question=getattr(request_data, 'text', 'Question non disponible'),
            response="Service temporairement indisponible. Veuillez r√©essayer.",
            conversation_id=str(uuid.uuid4()),
            rag_used=False,
            rag_score=None,
            timestamp=datetime.now().isoformat(),
            language="fr",
            response_time_ms=int((time.time() - start_time) * 1000),
            mode="critical_fallback_v3.7.8",
            user=None,
            logged=False,
            validation_passed=False,
            clarification_required_critical=False,
            missing_critical_entities=[],
            variants_tested=[],
            dynamic_questions=None,
            clarification_service_used=False,
            clarification_result=None,
            processing_steps=["critical_fallback"],
            ai_enhancements_used=[],
            response_versions=None
        )

# =============================================================================
# LOGGING ET INITIALISATION FINALE v3.7.8
# =============================================================================

logger.info("üöÄ" * 50)
logger.info("üöÄ [EXPERT ENDPOINTS] VERSION 3.7.8 - INT√âGRATION SERVICE CLARIFICATION DYNAMIQUE!")
logger.info("üöÄ [NOUVELLES FONCTIONNALIT√âS v3.7.8]:")
logger.info("   ‚úÖ Int√©gration expert_clarification_service avec s√©lection dynamique de prompts")
logger.info("   ‚úÖ Appel automatique du service si clarification_required_critical = True")
logger.info("   ‚úÖ G√©n√©ration de questions dynamiques bas√©es sur entit√©s manquantes")
logger.info("   ‚úÖ Validation et enrichissement des questions de clarification")
logger.info("   ‚úÖ Support conversation_context pour clarifications contextuelles")
logger.info("   ‚úÖ S√©lection prompt selon entit√©s manquantes et contexte")
logger.info("   ‚úÖ G√©n√©ration questions GPT avec prompt optimis√©")
logger.info("   ‚úÖ Validation questions selon missing_entities")
logger.info("   ‚úÖ Enrichissement r√©ponse avec questions dynamiques")
logger.info("")
logger.info("üîß [WORKFLOW INT√âGRATION v3.7.8]:")
logger.info("   1. Extraction entit√©s critiques ‚Üí validation")
logger.info("   2. Si critique ‚Üí service clarification activ√©")
logger.info("   3. Construction contexte conversation")
logger.info("   4. S√©lection dynamique prompt")
logger.info("   5. G√©n√©ration questions GPT")
logger.info("   6. Validation questions dynamiques")
logger.info("   7. Enrichissement r√©ponse finale")
logger.info("")
logger.info("üÜï [FIXES APPLIQU√âS v3.7.7 CONSERV√âS]:")
logger.info("   ‚úÖ Synchronisation √©tat RAG - rag_used correctement mis √† jour")
logger.info("   ‚úÖ Clarification forc√©e si entit√©s critiques (breed, age, weight) manquent")
logger.info("   ‚úÖ Validation robuste des entit√©s critiques avec extraction automatique")
logger.info("   ‚úÖ D√©clenchement clarification_required_critical=True pour entit√©s manquantes")
logger.info("   ‚úÖ D√©tection entit√©s critiques depuis le texte de la question")
logger.info("")
logger.info("üéØ [SUPPORT ENTIT√âS CRITIQUES]:")
logger.info("   ‚úÖ Extraction breed (Ross 308, Cobb 500, etc.)")
logger.info("   ‚úÖ Extraction age avec conversion en jours")
logger.info("   ‚úÖ Extraction weight avec conversion en grammes")
logger.info("   ‚úÖ Extraction sex (feature bonus)")
logger.info("   ‚úÖ Validation coh√©rence age/weight")
logger.info("   ‚úÖ Score de confiance par entit√©")
logger.info("   ‚úÖ Clarification forc√©e pour entit√©s manquantes")
logger.info("")
logger.info("üîß [SERVICES DISPONIBLES]:")
logger.info(f"   - Expert Service: {'‚úÖ DISPONIBLE' if EXPERT_SERVICE_AVAILABLE else '‚ùå NON DISPONIBLE'}")
logger.info(f"   - Expert Service initialis√©: {'‚úÖ OUI' if expert_service is not None else '‚ùå NON'}")
logger.info(f"   - Clarification Service: {'‚úÖ DISPONIBLE' if CLARIFICATION_SERVICE_AVAILABLE else '‚ùå NON DISPONIBLE'}")
logger.info(f"   - Clarification Service initialis√©: {'‚úÖ OUI' if clarification_service is not None else '‚ùå NON'}")
logger.info(f"   - Models import√©s: {'‚úÖ OUI' if MODELS_IMPORTED else '‚ùå FALLBACK'}")
logger.info(f"   - Utils disponibles: {'‚úÖ OUI' if UTILS_AVAILABLE else '‚ùå FALLBACK'}")
logger.info("")
logger.info("üìã [NOUVEAUX CHAMPS SUPPORT√âS v3.7.8]:")
logger.info("   ‚úÖ dynamic_questions - Questions g√©n√©r√©es dynamiquement")
logger.info("   ‚úÖ clarification_service_used - Service clarification activ√©")
logger.info("   ‚úÖ clarification_required_critical - Clarification critique requise")
logger.info("   ‚úÖ missing_critical_entities - Entit√©s critiques manquantes")
logger.info("   ‚úÖ variants_tested - Variantes test√©es")
logger.info("")
logger.info("üîß [ENDPOINTS DISPONIBLES v3.7.8]:")
logger.info("   - GET /health - Health check avec statut services")
logger.info("   - POST /ask-enhanced-v2 - Endpoint principal avec service clarification")
logger.info("   - POST /ask-enhanced-v2-public - Endpoint public avec service clarification")
logger.info("   - POST /feedback - Feedback avec gestion d'erreur robuste")
logger.info("   - GET /topics - Topics sugg√©r√©s avec fallback am√©lior√©")
logger.info("")
logger.info("üéØ [WORKFLOW CLARIFICATION v3.7.8]:")
logger.info("   1. build_conversation_context")
logger.info("   2. select_clarification_prompt")
logger.info("   3. generate_questions_with_gpt")
logger.info("   4. validate_dynamic_questions")
logger.info("   5. apply_to_response_data")
logger.info("")
logger.info("üìä [STATUT INITIALISATION]:")
logger.info(f"   - Timestamp: {datetime.now().isoformat()}")
logger.info(f"   - Logger configur√©: ‚úÖ OUI")
logger.info(f"   - Router configur√©: ‚úÖ OUI")
logger.info(f"   - Services initialis√©s: {'‚úÖ COMPLET' if expert_service and clarification_service else '‚ö†Ô∏è PARTIEL'}")
logger.info(f"   - D√©pendances auth: ‚úÖ CORRIG√âES")
logger.info(f"   - Fonctions utilitaires: ‚úÖ DISPONIBLES")
logger.info(f"   - Gestion d'erreur: ‚úÖ ROBUSTE")
logger.info("")
logger.info("‚úÖ [R√âSULTAT ATTENDU v3.7.8]:")
logger.info("   ‚úÖ Backend d√©marre SANS erreurs de syntaxe")
logger.info("   ‚úÖ Service clarification dynamique int√©gr√©")
logger.info("   ‚úÖ Questions intelligentes g√©n√©r√©es selon entit√©s manquantes")
logger.info("   ‚úÖ Prompts adapt√©s au contexte conversation")
logger.info("   ‚úÖ Validation robuste des questions g√©n√©r√©es")
logger.info("   ‚úÖ Enrichissement r√©ponse avec questions dynamiques")
logger.info("   ‚úÖ Synchronisation RAG state correcte")
logger.info("   ‚úÖ Extraction entit√©s critiques fonctionnelle")
logger.info("   ‚úÖ Validation entit√©s avec clarification forc√©e")
logger.info("   ‚úÖ Gestion d'erreur robuste avec fallback")
logger.info("   ‚úÖ Propagation champs nouveaux v3.7.8")
logger.info("   ‚úÖ Logging d√©taill√© pour debugging")
logger.info("   ‚úÖ SYNTAXE PYTHON 100% CORRECTE")
logger.info("   ‚úÖ PR√äT POUR D√âPLOIEMENT")
logger.info("üöÄ" * 50)