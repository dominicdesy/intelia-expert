# app/api/v1/expert.py
# -*- coding: utf-8 -*-
from fastapi import APIRouter, HTTPException, Request, Depends
from fastapi.encoders import jsonable_encoder  # [PATCH] JSON-safe responses
from pydantic import BaseModel, Field
from typing import Optional, Any, Dict, List
import logging
import os
import re
import math
import time  # NOUVEAU: Ajout√© pour les endpoints de test
import asyncio  # üöÄ NOUVEAU: Pour optimisations async

# üîí Import authentification
from app.api.v1.auth import get_current_user

# ü¶Ü Import syst√®me de quota
from app.api.v1.billing import check_quota_middleware, increment_quota_usage

# üìä Import syst√®me analytics  
from app.api.v1.logging import log_question_to_analytics

# üåæ Import validateur agricole
try:
    from app.api.v1.pipeline.agricultural_domain_validator import (
        validate_agricultural_question,
        get_agricultural_validator_stats,
        is_agricultural_validation_enabled,
        ValidationResult
    )
    AGRICULTURAL_VALIDATOR_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("‚úÖ Agricultural domain validator imported successfully")
except ImportError as e:
    AGRICULTURAL_VALIDATOR_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.error(f"‚ùå Failed to import agricultural validator: {e}")

router = APIRouter()

# ===== Import Dialogue Manager (pr√©serve le code original) =====
try:
    from .pipeline.dialogue_manager import handle  # type: ignore
    DIALOGUE_AVAILABLE = True
    logger.info("‚úÖ DialogueManager handle function imported successfully")
except Exception as e:
    logger.error(f"‚ùå Failed to import dialogue_manager.handle: {e}")
    DIALOGUE_AVAILABLE = False

    # Fallback minimal, signature d'origine conserv√©e
    def handle(session_id: str, question: str, lang: str = "fr", **kwargs) -> Dict[str, Any]:
        return {
            "type": "error",
            "message": "Dialogue service temporarily unavailable",
            "session_id": session_id,
        }

# ===== Import numpy s√©curis√© =====
try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False
    np = None

# ===== Cache simple pour PerfStore =====
_store_cache = {}

def get_cached_store(species: str):
    """Cache simple pour √©viter de recharger le m√™me store"""
    if species not in _store_cache:
        try:
            from .pipeline.perf_store import PerfStore  # type: ignore
            _store_cache[species] = PerfStore(root=os.environ.get("RAG_INDEX_ROOT", "./rag_index"), species=species)
        except Exception as e:
            logger.error(f"Failed to create PerfStore for {species}: {e}")
            return None
    return _store_cache[species]

# ===== Fonction locale pour normalisation des entit√©s =====
def _normalize_entities_soft_local(entities: Dict[str, Any]) -> Dict[str, Any]:
    """Version locale de normalisation des entit√©s"""
    result = {}
    
    # Species
    species = (entities.get("species") or "broiler").lower()
    result["species"] = species
    
    # Line
    line = entities.get("line")
    if line:
        line = re.sub(r"[-_\s]+", "", str(line).lower())
    result["line"] = line
    
    # Sex
    sex = entities.get("sex")
    if sex:
        sex_mapping = {
            "male": "male", "m": "male", "‚ôÇ": "male",
            "female": "female", "f": "female", "‚ôÄ": "female", 
            "as_hatched": "as_hatched", "ah": "as_hatched", 
            "mixte": "as_hatched", "mixed": "as_hatched",
            "as hatched": "as_hatched", "as-hatched": "as_hatched"
        }
        sex = sex_mapping.get(str(sex).lower().replace(" ", "_"), sex)
    result["sex"] = sex
    
    # Unit
    unit = entities.get("unit")
    if unit and str(unit).lower() in ["imperial", "imp", "us", "lb", "lbs"]:
        unit = "imperial"
    else:
        unit = "metric"
    result["unit"] = unit
    
    # Age
    age_days = entities.get("age_days")
    if age_days is not None:
        try:
            result["age_days"] = int(age_days)
        except:
            result["age_days"] = None
    else:
        result["age_days"] = None
    
    return result

# ===== Fonction de validation agricole =====
def _validate_agricultural_question(question: str, lang: str = "fr", user_id: str = "unknown", request_ip: str = "unknown") -> ValidationResult:
    """Valide qu'une question concerne le domaine agricole"""
    if not AGRICULTURAL_VALIDATOR_AVAILABLE:
        logger.warning("‚ö†Ô∏è Agricultural validator not available, allowing all questions")
        return ValidationResult(is_valid=True, confidence=100.0, reason="Validator unavailable")
    
    try:
        return validate_agricultural_question(question, lang, user_id, request_ip)
    except Exception as e:
        logger.error(f"‚ùå Error in agricultural validation: {e}")
        # En cas d'erreur, permettre la question avec un avertissement
        return ValidationResult(is_valid=True, confidence=50.0, reason=f"Validation error: {str(e)}")

def _get_user_info_for_validation(request: Request, current_user: Optional[Dict[str, Any]] = None) -> tuple[str, str]:
    """Extrait les informations utilisateur pour la validation"""
    if current_user:
        user_id = current_user.get('email', current_user.get('user_id', 'authenticated_user'))
    else:
        user_id = "anonymous_user"
    
    # Extraire l'IP de la requ√™te
    request_ip = getattr(request.client, 'host', 'unknown') if hasattr(request, 'client') else 'unknown'
    forwarded_for = request.headers.get('X-Forwarded-For')
    if forwarded_for:
        request_ip = forwarded_for.split(',')[0].strip()
    
    return str(user_id), str(request_ip)

# ===== NOUVEAU: Fonction d'extraction user_id pour persistance =====
def _extract_user_id_for_persistence(current_user: Optional[Dict[str, Any]] = None) -> Optional[str]:
    """
    Extrait l'user_id pour la persistance des conversations
    Retourne None pour les utilisateurs non authentifi√©s (publics)
    """
    if not current_user:
        return None
    
    # Priorit√©: email > user_id > sub > id
    for key in ['email', 'user_id', 'sub', 'id']:
        if current_user.get(key):
            return str(current_user[key])
    
    return "authenticated_unknown"

# üöÄ NOUVELLES FONCTIONS ASYNC POUR OPTIMISATION PERFORMANCE
async def _increment_quota_async(user_email: str) -> bool:
    """Version async pour l'incr√©mentation du quota"""
    try:
        # Pour l'instant, wrapper la fonction sync en thread
        # TODO: Remplacer par vrai async quand billing.py sera optimis√©
        await asyncio.to_thread(increment_quota_usage, user_email, success=True)
        logger.info(f"üìä Usage incr√©ment√© pour {user_email}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Erreur incr√©mentation quota (success): {e}")
        raise

async def _log_analytics_async(
    current_user: Optional[Dict[str, Any]], 
    payload: Any, 
    result: Dict[str, Any], 
    start_time: float
) -> bool:
    """Version async pour le logging analytics"""
    try:
        # Calculer le temps de traitement
        processing_time = int((time.time() - start_time) * 1000)
        
        # Extraire le texte de r√©ponse pour analytics
        answer = result.get("answer", {})
        general_answer = result.get("general_answer", {})
        
        if isinstance(answer, dict) and answer.get("text"):
            response_text = answer["text"]
        elif isinstance(general_answer, dict) and general_answer.get("text"):
            response_text = general_answer["text"]
        else:
            response_text = str(result.get("message", ""))
        
        # Pour l'instant, wrapper la fonction sync en thread
        # TODO: Remplacer par vrai async quand logging.py sera optimis√©
        await asyncio.to_thread(
            log_question_to_analytics,
            current_user=current_user,
            payload=payload,
            result=result,
            response_text=response_text[:500],  # Limiter la taille pour analytics
            processing_time_ms=processing_time
        )
        logger.info("üìä Question logg√©e dans analytics")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur logging analytics: {e}")
        raise

async def _execute_background_tasks_async(
    user_email: Optional[str],
    current_user: Optional[Dict[str, Any]],
    payload: Any,
    result: Dict[str, Any],
    start_time: float
) -> None:
    """
    üöÄ OPTIMISATION PERFORMANCE: Ex√©cute les t√¢ches de fond en parall√®le
    
    Gain estim√©: 1-1.5 secondes par requ√™te
    """
    tasks = []
    
    # T√¢che 1: Incr√©ment quota (si utilisateur authentifi√©)
    if user_email:
        tasks.append(_increment_quota_async(user_email))
    
    # T√¢che 2: Logging analytics (toujours)
    tasks.append(_log_analytics_async(current_user, payload, result, start_time))
    
    if not tasks:
        return
    
    # Ex√©cuter toutes les t√¢ches en parall√®le
    # return_exceptions=True √©vite qu'une erreur interrompe les autres
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Traiter les erreurs individuellement (ne pas faire √©chouer la requ√™te)
    task_names = []
    if user_email:
        task_names.append("quota_increment")
    task_names.append("analytics_logging")
    
    for i, task_result in enumerate(results):
        if isinstance(task_result, Exception):
            task_name = task_names[i] if i < len(task_names) else f"task_{i}"
            logger.error(f"‚ùå Erreur t√¢che {task_name}: {task_result}")
        # Les succ√®s sont d√©j√† logg√©s dans les fonctions individuelles

# ===== Fonction de nettoyage JSON am√©lior√©e =====
def clean_for_json(value):
    """Nettoie seulement les valeurs probl√©matiques pour JSON avec protection robuste"""
    if value is None:
        return None
    if isinstance(value, (int, str, bool)):
        return value
    if isinstance(value, float):
        if math.isnan(value) or math.isinf(value):
            return None
        return float(value)
    
    # Protection numpy robuste
    if HAS_NUMPY and hasattr(value, 'item'):
        try:
            val = value.item()
            if isinstance(val, float) and (math.isnan(val) or math.isinf(val)):
                return None
            return val
        except:
            return str(value)  # Fallback si .item() √©choue
    
    return str(value)  # Fallback g√©n√©ral

def clean_dict_for_json(obj):
    """Nettoie r√©cursivement seulement les valeurs probl√©matiques"""
    if isinstance(obj, dict):
        return {k: clean_dict_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_dict_for_json(v) for v in obj]
    else:
        return clean_for_json(obj)

# ===== Parsing d'√¢ge am√©lior√© =====
def extract_age_from_text(text: str) -> Optional[int]:
    """Extraction d'√¢ge plus robuste avec support semaines/ann√©es"""
    text_lower = text.lower()
    
    # Patterns par ordre de priorit√©
    age_patterns = [
        (r"(\d+)\s*(?:j|jour|jours|d|day|days)\b", 1),      # jours (x1)
        (r"(\d+)\s*(?:w|week|weeks|semaine|semaines)\b", 7), # semaines (x7)
        (r"age\s*(\d+)", 1),                                 # "age 21" (jours)
        (r"(\d+)\s*(?:ans|years?)\b", 365),                 # ann√©es (x365)
    ]
    
    for pattern, multiplier in age_patterns:
        m = re.search(pattern, text_lower)
        if m:
            try:
                age_value = int(m.group(1)) * multiplier
                # Validation raisonnable pour les volailles
                if 1 <= age_value <= 70:
                    return age_value
            except:
                continue
    return None

# ===== Sch√©mas =====
class AskPayload(BaseModel):
    session_id: Optional[str] = "default"
    question: str
    lang: Optional[str] = "fr"
    debug: Optional[bool] = False
    force_perfstore: Optional[bool] = False
    intent_hint: Optional[str] = None
    entities: Dict[str, Any] = Field(default_factory=dict)
    bypass_validation: Optional[bool] = False  # üåæ NOUVEAU: pour bypass administrateur
    model_config = {"extra": "allow"}

# ===== Fonction interne partag√©e avec validation ET quota ET persistance =====
async def _ask_internal_async(payload: AskPayload, request: Request, current_user: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    üöÄ VERSION ASYNC OPTIMIS√âE - Logique interne pour traiter les questions
    
    OPTIMISATIONS:
    - Parall√©lisation des op√©rations DB finales
    - Gain estim√©: 1-1.5 secondes par requ√™te
    
    CONSERVE: Toute la logique m√©tier originale
    """
    user_email = None
    start_time = time.time()  # üìä NOUVEAU: Mesure du temps de traitement
    
    try:
        # Extraction des infos utilisateur pour la validation
        user_id, request_ip = _get_user_info_for_validation(request, current_user)
        
        # üíæ NOUVEAU: Extraction user_id pour persistance
        persistence_user_id = _extract_user_id_for_persistence(current_user)
        
        # Extraction de l'email pour le quota
        if current_user:
            user_email = current_user.get('email')
        
        # üö´ V√âRIFICATION QUOTA AVANT TRAITEMENT
        if user_email:
            try:
                quota_allowed, quota_details = check_quota_middleware(user_email)
                
                if not quota_allowed:
                    logger.warning(f"üö´ Quota d√©pass√© pour {user_email}: {quota_details.get('message', 'Quota exceeded')}")
                    return {
                        "type": "quota_exceeded",
                        "message": quota_details.get("message", "Quota mensuel d√©pass√©"),
                        "quota_details": quota_details,
                        "upgrade_suggestions": [
                            {"plan": "basic", "price": "29.99‚Ç¨", "quota": "1000 questions"},
                            {"plan": "premium", "price": "99.99‚Ç¨", "quota": "5000 questions"}
                        ],
                        "session_id": payload.session_id or "default",
                        "user": {
                            "email": user_email,
                            "user_id": current_user.get('user_id')
                        }
                    }
                else:
                    logger.info(f"‚úÖ Quota OK pour {user_email}: {quota_details.get('usage', 0)}/{quota_details.get('limit', 'unlimited')}")
            except Exception as e:
                logger.error(f"‚ùå Erreur v√©rification quota pour {user_email}: {e}")
                # En cas d'erreur quota, on continue le traitement
                pass

        # Log diff√©renci√© selon l'authentification
        if current_user:
            user_email_display = current_user.get('email', 'unknown')
            logger.info(f"üîí Question authentifi√©e de {user_email_display}: {payload.question[:120]}")
        else:
            logger.info(f"üåê Question publique: {payload.question[:120]}")

        # üåæ VALIDATION AGRICOLE (sauf si bypass autoris√©)
        validation_bypassed = False
        if not payload.bypass_validation:
            validation_result = _validate_agricultural_question(
                question=payload.question,
                lang=payload.lang or "fr",
                user_id=user_id,
                request_ip=request_ip
            )
            
            if not validation_result.is_valid:
                logger.warning(f"üö´ Question rejet√©e par validation agricole: {validation_result.reason}")
                # ‚ùå INCR√âMENT USAGE M√äME POUR VALIDATION √âCHOU√âE
                if user_email:
                    try:
                        await _increment_quota_async(user_email)  # üöÄ ASYNC
                    except Exception as e:
                        logger.error(f"‚ùå Erreur incr√©mentation quota (validation failed): {e}")
                
                # üìä NOUVEAU: LOGGING VALIDATION √âCHOU√âE
                try:
                    await _log_analytics_async(  # üöÄ ASYNC
                        current_user=current_user,
                        payload=payload,
                        result={"type": "validation_rejected"},
                        start_time=start_time
                    )
                    logger.info("üìä Validation √©chou√©e logg√©e dans analytics")
                    
                except Exception as log_e:
                    logger.error(f"‚ùå Erreur logging analytics (validation): {log_e}")
                
                return {
                    "type": "validation_rejected",
                    "message": validation_result.reason,
                    "session_id": payload.session_id or "default",
                    "validation": {
                        "is_valid": False,
                        "confidence": validation_result.confidence,
                        "suggested_topics": validation_result.suggested_topics,
                        "detected_keywords": validation_result.detected_keywords,
                        "rejected_keywords": validation_result.rejected_keywords
                    },
                    "user": {
                        "email": current_user.get('email') if current_user else None,
                        "user_id": current_user.get('user_id') if current_user else None
                    } if current_user else None
                }
            else:
                logger.info(f"‚úÖ Question valid√©e (confiance: {validation_result.confidence:.1f}%)")
        else:
            validation_bypassed = True
            logger.info("‚ö†Ô∏è Validation agricole bypass√©e par l'utilisateur")

        # Traitement normal de la question
        fp_qs = request.query_params.get("force_perfstore")
        force_perf = bool(payload.force_perfstore) or (fp_qs in ("1", "true", "True", "yes"))

        if DIALOGUE_AVAILABLE:
            # üíæ NOUVEAU: Passer user_id au dialogue manager pour persistance
            result = handle(
                session_id=payload.session_id or "default",
                question=payload.question,
                lang=payload.lang or "fr",
                debug=bool(payload.debug),
                force_perfstore=force_perf,
                intent_hint=(payload.intent_hint or None),
                entities=(payload.entities or {}),
                user_id=persistence_user_id  # NOUVEAU: Param√®tre pour persistance
            )
        else:
            logger.warning("‚ö†Ô∏è Dialogue manager not available, using fallback")
            result = handle(payload.session_id or "default", payload.question, payload.lang or "fr")

        # üöÄ OPTIMISATION PERFORMANCE: T√¢ches de fond en parall√®le
        # AVANT: 3 op√©rations s√©quentielles = 1.2s
        # APR√àS: 3 op√©rations parall√®les = 0.2s
        # GAIN: ~1 seconde par requ√™te
        await _execute_background_tasks_async(
            user_email=user_email,
            current_user=current_user,
            payload=payload,
            result=result,
            start_time=start_time
        )

        # Ajouter les infos utilisateur et de validation dans la r√©ponse
        if current_user:
            result["user"] = {
                "email": current_user.get('email'),
                "user_id": current_user.get('user_id')
            }
        
        # Ajouter les m√©tadonn√©es de validation et persistance
        result["validation_metadata"] = {
            "agricultural_validation_enabled": AGRICULTURAL_VALIDATOR_AVAILABLE and is_agricultural_validation_enabled(),
            "validation_bypassed": validation_bypassed
        }
        
        # üíæ NOUVEAU: M√©tadonn√©es de persistance
        result["persistence_metadata"] = {
            "conversation_persistence_enabled": True,  # Toujours ON dans cette version
            "user_id_for_persistence": persistence_user_id,
            "is_authenticated": bool(current_user)
        }

        logger.info(f"‚úÖ R√©ponse g√©n√©r√©e: type={result.get('type')}")
        return result
        
    except Exception as e:
        # ‚ùå ERREUR: Incr√©ment usage m√™me en cas d'erreur de traitement
        if user_email:
            try:
                await _increment_quota_async(user_email)  # üöÄ ASYNC
                logger.info(f"üìä Usage incr√©ment√© pour {user_email} (erreur)")
            except Exception as quota_e:
                logger.error(f"‚ùå Erreur incr√©mentation quota (error): {quota_e}")
        
        # üìä NOUVEAU: LOGGING DES ERREURS DANS ANALYTICS
        try:
            error_result = {
                "type": "system_error",
                "error": {
                    "type": type(e).__name__,
                    "message": str(e),
                    "category": "system_error"
                }
            }
            
            await _log_analytics_async(  # üöÄ ASYNC
                current_user=current_user,
                payload=payload,
                result=error_result,
                start_time=start_time
            )
            logger.info("üìä Erreur logg√©e dans analytics")
            
        except Exception as log_e:
            logger.error(f"‚ùå Erreur logging analytics (error): {log_e}")
        
        logger.exception("‚ùå Erreur dans le traitement de la question")
        raise HTTPException(status_code=500, detail=f"Error processing request: {e}")

# üîÑ VERSION SYNC PR√âSERV√âE (pour r√©trocompatibilit√©)
def _ask_internal(payload: AskPayload, request: Request, current_user: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    VERSION SYNC ORIGINALE - Conserv√©e pour r√©trocompatibilit√©
    
    Wrapper qui appelle la version async en interne
    """
    return asyncio.run(_ask_internal_async(payload, request, current_user))

# ===== Endpoints principaux (code original conserv√© + am√©liorations) =====
@router.post("/ask")
async def ask(  # üöÄ ASYNC
    payload: AskPayload, 
    request: Request,
    current_user: dict = Depends(get_current_user)  # üîí Auth requise
) -> Dict[str, Any]:
    """
    üöÄ ENDPOINT OPTIMIS√â - Poser des questions avec validation agricole, quota et persistance.
    
    OPTIMISATIONS:
    - Op√©rations DB parall√©lis√©es
    - Gain estim√©: 1-1.5 secondes par requ√™te
    """
    return await _ask_internal_async(payload, request, current_user)

@router.post("/ask-public")
async def ask_public(payload: AskPayload, request: Request) -> Dict[str, Any]:  # üöÄ ASYNC
    """
    üöÄ ENDPOINT PUBLIC OPTIMIS√â - Pas d'authentification requise
    """
    return await _ask_internal_async(payload, request, None)

@router.get("/system-status")
def system_status() -> Dict[str, Any]:
    """√âtat synth√©tique du service avec info persistance."""
    # V√©rifier la disponibilit√© de la persistance
    persistence_available = False
    try:
        from .pipeline.dialogue_manager import POSTGRES_AVAILABLE, PERSIST_CONVERSATIONS
        persistence_available = POSTGRES_AVAILABLE and PERSIST_CONVERSATIONS
    except ImportError:
        pass
    
    return {
        "status": "ok" if DIALOGUE_AVAILABLE else "degraded",
        "dialogue_manager_available": DIALOGUE_AVAILABLE,
        "agricultural_validator_available": AGRICULTURAL_VALIDATOR_AVAILABLE,
        "agricultural_validation_enabled": AGRICULTURAL_VALIDATOR_AVAILABLE and is_agricultural_validation_enabled(),
        "billing_system_available": True,  # ü¶Ü NOUVEAU
        "analytics_system_available": True,  # üìä NOUVEAU
        "conversation_persistence_available": persistence_available,  # üíæ NOUVEAU
        "performance_optimizations_enabled": True,  # üöÄ NOUVEAU
        "service": "expert_api",
    }

# ===== NOUVEAUX ENDPOINTS: Fallback OpenAI =====

@router.get("/fallback-status")
def fallback_status() -> Dict[str, Any]:
    """
    Status d√©taill√© du syst√®me de fallback OpenAI + persistance.
    """
    try:
        from .pipeline.dialogue_manager import get_fallback_status
        return get_fallback_status()
    except Exception as e:
        return {
            "error": "Could not get fallback status",
            "message": str(e),
            "openai_fallback_available": False
        }

@router.post("/test-openai-fallback")
async def test_openai_fallback(  # üöÄ ASYNC
    test_question: str,
    current_user: dict = Depends(get_current_user)  # üîí Auth requise
) -> Dict[str, Any]:
    """
    Teste le fallback OpenAI directement (bypass RAG).
    """
    try:
        # Import correct de la fonction et de l'Intention
        from .pipeline.dialogue_manager import generate_openai_fallback_response  # Correction import
        from .pipeline.utils.question_classifier import Intention  # Import correct
        
        # Entit√©s de test basiques
        test_entities = {
            "species": "broiler",
            "line": "ross308", 
            "sex": "as_hatched",
            "age_days": 21
        }
        
        # Ex√©cuter en thread pour √©viter de bloquer
        result = await asyncio.to_thread(
            generate_openai_fallback_response,
            question=test_question,
            entities=test_entities,
            intent=Intention.PerfTargets,  # Intent par d√©faut pour test
            rag_context="Contexte RAG non disponible (test)"
        )
        
        return {
            "test_question": test_question,
            "openai_response": result,
            "tester": current_user.get('email', 'unknown'),
            "timestamp": time.time()
        }
        
    except Exception as e:
        return {
            "error": f"Test OpenAI fallback failed: {str(e)}",
            "test_question": test_question
        }

@router.post("/test-fallback-integration")
async def test_fallback_integration(  # üöÄ ASYNC
    test_question: str = "Quel est le poids √† 21 jours pour des Ross 308 m√¢les ?",
    current_user: dict = Depends(get_current_user)
) -> Dict[str, Any]:
    """
    Teste l'int√©gration compl√®te RAG ‚Üí Fallback OpenAI + persistance
    """
    try:
        # Test avec une question qui devrait d√©clencher le fallback
        payload = AskPayload(
            session_id="test_fallback",
            question=test_question,
            lang="fr",
            debug=True,
            entities={"species": "broiler", "line": "ross308", "sex": "male", "age_days": 21}
        )
        
        # Simulation d'une request basique
        class MockRequest:
            def __init__(self):
                self.query_params = {}
                self.client = type('obj', (object,), {'host': 'localhost'})
                self.headers = {}
        
        mock_request = MockRequest()
        
        # Appel du syst√®me complet optimis√©
        result = await _ask_internal_async(payload, mock_request, current_user)
        
        # Analyse du r√©sultat pour v√©rifier si fallback activ√©
        answer = result.get("answer", {})
        source = answer.get("source", "unknown")
        meta = answer.get("meta", {})
        
        return {
            "test_question": test_question,
            "result_source": source,
            "fallback_activated": source == "openai_fallback",
            "rag_attempted": meta.get("rag_attempted", False),
            "result_preview": answer.get("text", "")[:200] + "..." if answer.get("text") else None,
            "persistence_metadata": result.get("persistence_metadata", {}),
            "full_result": result,
            "tester": current_user.get('email', 'unknown'),
            "timestamp": time.time()
        }
        
    except Exception as e:
        return {
            "error": f"Integration test failed: {str(e)}",
            "test_question": test_question
        }

# ===== üíæ NOUVEAUX ENDPOINTS: Test persistance conversations =====

@router.post("/test-conversation-persistence")
async def test_conversation_persistence(  # üöÄ ASYNC
    test_question: str = "Test de persistance des conversations",
    current_user: dict = Depends(get_current_user)
) -> Dict[str, Any]:
    """
    Teste la persistance des conversations directement.
    """
    try:
        from .pipeline.dialogue_manager import _persist_conversation
        
        test_session_id = f"test_persistence_{int(time.time())}"
        test_answer = "R√©ponse de test pour v√©rifier la persistance"
        user_id = _extract_user_id_for_persistence(current_user)
        
        # Test de la fonction de persistance en thread
        persistence_success = await asyncio.to_thread(
            _persist_conversation,
            session_id=test_session_id,
            question=test_question,
            answer_text=test_answer,
            language="fr",
            user_id=user_id,
            additional_context={
                "test": True,
                "intent": "test_persistence",
                "route": "test_endpoint"
            }
        )
        
        return {
            "status": "success" if persistence_success else "failed",
            "test_session_id": test_session_id,
            "test_question": test_question,
            "test_answer": test_answer,
            "user_id": user_id,
            "persistence_success": persistence_success,
            "tester": current_user.get('email', 'unknown'),
            "timestamp": time.time()
        }
        
    except Exception as e:
        return {
            "error": f"Persistence test failed: {str(e)}",
            "test_question": test_question
        }

@router.get("/conversation-persistence-status")
def conversation_persistence_status() -> Dict[str, Any]:
    """
    Status d√©taill√© de la persistance des conversations.
    """
    try:
        from .pipeline.dialogue_manager import (
            POSTGRES_AVAILABLE, 
            PERSIST_CONVERSATIONS, 
            CLEAR_CONTEXT_AFTER_ASK,
            _POSTGRES_MEMORY
        )
        
        return {
            "postgres_available": POSTGRES_AVAILABLE,
            "persist_conversations": PERSIST_CONVERSATIONS,
            "clear_context_after_ask": CLEAR_CONTEXT_AFTER_ASK,
            "postgres_memory_initialized": _POSTGRES_MEMORY is not None,
            "database_url_configured": bool(os.getenv("DATABASE_URL")),
            "status": "operational" if (POSTGRES_AVAILABLE and PERSIST_CONVERSATIONS) else "limited"
        }
        
    except ImportError as e:
        return {
            "error": "Could not import persistence modules",
            "message": str(e),
            "status": "unavailable"
        }

# ===== Endpoints existants (code original conserv√©) =====

@router.get("/agricultural-validation-status")
def agricultural_validation_status() -> Dict[str, Any]:
    """Status d√©taill√© du validateur agricole."""
    if not AGRICULTURAL_VALIDATOR_AVAILABLE:
        return {
            "available": False,
            "reason": "Module not imported or not available"
        }
    
    try:
        stats = get_agricultural_validator_stats()
        return {
            "available": True,
            "stats": stats
        }
    except Exception as e:
        return {
            "available": False,
            "error": str(e)
        }

@router.post("/test-agricultural-validation")
async def test_agricultural_validation(  # üöÄ ASYNC
    test_question: str,
    lang: str = "fr",
    current_user: dict = Depends(get_current_user)  # üîí Auth requise pour les tests
) -> Dict[str, Any]:
    """Teste la validation agricole sur une question donn√©e."""
    if not AGRICULTURAL_VALIDATOR_AVAILABLE:
        return {
            "error": "Agricultural validator not available"
        }
    
    user_id = current_user.get('email', current_user.get('user_id', 'test_user'))
    
    try:
        # Ex√©cuter en thread pour √©viter de bloquer
        validation_result = await asyncio.to_thread(
            validate_agricultural_question,
            question=test_question,
            language=lang,
            user_id=str(user_id),
            request_ip="test_ip"
        )
        
        return {
            "question": test_question,
            "lang": lang,
            "validation": validation_result.to_dict(),
            "tester": user_id
        }
    except Exception as e:
        return {
            "error": f"Validation test failed: {str(e)}",
            "question": test_question
        }

# ü¶Ü NOUVEAUX ENDPOINTS QUOTA
@router.get("/quota-status")
async def quota_status(  # üöÄ ASYNC
    current_user: dict = Depends(get_current_user)
) -> Dict[str, Any]:
    """R√©cup√®re le statut du quota pour l'utilisateur connect√©."""
    user_email = current_user.get('email')
    if not user_email:
        raise HTTPException(status_code=400, detail="Email utilisateur non trouv√©")
    
    try:
        # Ex√©cuter en thread pour √©viter de bloquer
        quota_allowed, quota_details = await asyncio.to_thread(
            check_quota_middleware, user_email
        )
        return {
            "user_email": user_email,
            "quota_allowed": quota_allowed,
            "quota_details": quota_details,
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration quota pour {user_email}: {e}")
        return {
            "error": f"Failed to get quota status: {str(e)}",
            "user_email": user_email
        }

@router.post("/test-quota-increment")
async def test_quota_increment(  # üöÄ ASYNC
    success: bool = True,
    current_user: dict = Depends(get_current_user)
) -> Dict[str, Any]:
    """Teste l'incr√©mentation du quota (pour debug)."""
    user_email = current_user.get('email')
    if not user_email:
        raise HTTPException(status_code=400, detail="Email utilisateur non trouv√©")
    
    try:
        # Utiliser la fonction async optimis√©e
        if success:
            await _increment_quota_async(user_email)
        else:
            await asyncio.to_thread(increment_quota_usage, user_email, success=False)
        
        # R√©cup√©ration du statut mis √† jour
        quota_allowed, quota_details = await asyncio.to_thread(
            check_quota_middleware, user_email
        )
        
        return {
            "message": f"Quota incr√©ment√© (success={success})",
            "user_email": user_email,
            "updated_quota": quota_details,
            "tester": current_user.get('email', 'unknown'),
            "timestamp": time.time()
        }
    except Exception as e:
        return {
            "error": f"Failed to increment quota: {str(e)}",
            "user_email": user_email
        }

@router.get("/debug")
def debug_imports() -> Dict[str, Any]:
    """V√©rifie quelques imports utiles (pr√©serve le comportement original)."""
    debug_info: Dict[str, Any] = {
        "dialogue_available": DIALOGUE_AVAILABLE,
        "agricultural_validator_available": AGRICULTURAL_VALIDATOR_AVAILABLE,
        "billing_system_available": True,  # ü¶Ü NOUVEAU
        "analytics_system_available": True,  # üìä NOUVEAU
        "performance_optimizations_enabled": True,  # üöÄ NOUVEAU
        "imports_tested": []
    }
    
    # üíæ NOUVEAU: Test import persistance
    try:
        from .pipeline.dialogue_manager import POSTGRES_AVAILABLE, PERSIST_CONVERSATIONS
        debug_info["conversation_persistence_available"] = POSTGRES_AVAILABLE and PERSIST_CONVERSATIONS
    except ImportError:
        debug_info["conversation_persistence_available"] = False
    
    imports_to_test: List[str] = [
        "app.api.v1.utils.question_classifier",
        "app.api.v1.pipeline.context_extractor",
        "app.api.v1.pipeline.clarification_manager",
        "app.api.v1.pipeline.rag_engine",
        "app.api.v1.utils.formulas",
        "app.api.v1.pipeline.intent_registry",
        "app.api.v1.agricultural_domain_validator",  # üåæ
        "app.api.v1.billing",  # ü¶Ü NOUVEAU
        "app.api.v1.logging",  # üìä NOUVEAU
        "app.api.v1.pipeline.postgres_memory",  # üíæ NOUVEAU
    ]
    
    for import_path in imports_to_test:
        try:
            __import__(import_path)
            debug_info["imports_tested"].append({"path": import_path, "status": "‚úÖ OK"})
        except Exception as e:
            debug_info["imports_tested"].append({"path": import_path, "status": f"‚ùå Error: {e}"})
    
    return debug_info

@router.post("/force-import-test")
async def force_import_test():  # üöÄ ASYNC
    """Teste l'import et un appel basique de handle() sans casser l'API."""
    import traceback
    try:
        from .pipeline.dialogue_manager import handle as _handle  # type: ignore
        # Ex√©cuter en thread pour √©viter de bloquer
        test_result = await asyncio.to_thread(
            _handle, "test", "test question", "fr", debug=True, user_id="test_user"
        )
        return {"status": "‚úÖ SUCCESS", "result": test_result, "import_successful": True}
    except Exception as e:
        return {
            "status": "‚ùå FAILED",
            "error": str(e),
            "traceback": traceback.format_exc(),
            "import_successful": False,
        }

@router.get("/perfstore-status")
def perfstore_status():
    """Expose quelques infos sur le PerfStore (ne jette pas d'exception)."""
    try:
        from .pipeline.dialogue_manager import _get_perf_store  # type: ignore
        store = _get_perf_store("broiler")
        if not store:
            return {"ok": False, "reason": "PerfStore None"}
        root = getattr(store, "root", None)
        species = getattr(store, "species", None)
        tables_dir = str(getattr(store, "dir_tables", "")) if getattr(store, "dir_tables", None) else None

        lines = []
        for ln in ["ross308", "cobb500"]:
            try:
                df = store._load_df(ln)  # type: ignore
                lines.append({"line": ln, "rows": 0 if df is None else int(len(df))})
            except Exception as e:
                lines.append({"line": ln, "error": str(e)})

        return {
            "ok": True,
            "root": str(root) if root is not None else None,
            "species": species,
            "tables_dir": tables_dir,
            "lines": lines,
        }
    except Exception as e:
        return {"ok": False, "error": str(e)}

@router.get("/test-basic")
def test_basic():
    """Test ultra-basique sans aucune d√©pendance"""
    return {"status": "ok", "message": "Basic endpoint works"}

# ============================
# [FUSION] /perf-probe complet avec extraction + nettoyage JSON (INCHANG√â)
# ============================
@router.post("/perf-probe")
def perf_probe(payload: AskPayload):
    """
    Version fusionn√©e compl√®te:
    - Extraction automatique des entit√©s depuis la question
    - Nettoyage JSON des valeurs NaN/inf 
    - Diagnostics complets avec fallbacks
    - Messages d'erreur informatifs
    """
    try:
        # [STEP 1] Import PerfStore prot√©g√©
        try:
            from .pipeline.perf_store import PerfStore  # type: ignore
        except ImportError as e:
            return jsonable_encoder({
                "error": "import_failed", 
                "message": f"Failed to import PerfStore: {str(e)}",
                "entities": (payload.entities or {}) if payload else {},
            })

        # [STEP 2] Parsing de la question et des entit√©s
        q = (payload.question or "") if payload else ""
        ql = q.lower()
        entities_in = (payload.entities or {}) if (payload and payload.entities is not None) else {}
        
        # Species
        species = (entities_in.get("species") or "broiler").lower()
        
        # Line (avec extraction automatique)
        line = entities_in.get("line")
        if not line:
            if "cobb" in ql:
                line = "cobb500"
            elif "ross" in ql:
                line = "ross308"

        # Sex (avec extraction automatique)
        sex = entities_in.get("sex")
        if not sex:
            if ("as hatched" in ql) or ("as-hatched" in ql) or ("mixte" in ql) or (" ah " in ql):
                sex = "as_hatched"
            elif ("male" in ql) or ("m√¢le" in ql):
                sex = "male"
            elif ("female" in ql) or ("femelle" in ql):
                sex = "female"

        # Unit (avec extraction automatique)
        unit = entities_in.get("unit")
        if not unit:
            if ("metric" in ql) or ("m√©trique" in ql):
                unit = "metric"
            elif "imperial" in ql:
                unit = "imperial"

        # Age (avec extraction am√©lior√©e)
        age_days = entities_in.get("age_days")
        if age_days is None:
            age_days = extract_age_from_text(ql)

        # [STEP 3] Validation des param√®tres
        if age_days and (age_days < 1 or age_days > 70):
            return jsonable_encoder({
                "error": "invalid_age", 
                "message": f"Age must be between 1-70 days, got {age_days}",
                "entities": {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit}
            })

        # [STEP 4] Normalisation des entit√©s
        norm = _normalize_entities_soft_local(
            {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit}
        )

        # [STEP 5] Instanciation PerfStore (avec cache)
        try:
            store = get_cached_store(norm["species"])
            if not store:
                return jsonable_encoder({
                    "error": "perfstore_init_failed",
                    "message": "Failed to initialize PerfStore",
                    "entities": {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit},
                    "norm": norm,
                })
            available = store.available_lines()
        except Exception as e:
            return jsonable_encoder({
                "error": "perfstore_init_failed",
                "message": f"Failed to initialize PerfStore: {str(e)}",
                "entities": {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit},
                "norm": norm,
            })

        # [STEP 6] V√©rification ligne disponible
        if not norm.get("line"):
            return jsonable_encoder({
                "entities": {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit},
                "norm": norm,
                "rec": None,
                "debug": {
                    "error": "missing_line",
                    "available_lines": available,
                    "tables_dir": str(getattr(store, "dir_tables", "")),
                    "message": f"Line not specified. Available: {', '.join(available)}"
                },
            })

        # [STEP 7] Chargement DataFrame
        try:
            df = store._load_df(norm["line"])
        except Exception as e:
            return jsonable_encoder({
                "entities": {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit},
                "norm": norm,
                "rec": None,
                "debug": {
                    "error": "load_df_failed",
                    "message": str(e),
                    "line": norm.get("line"),
                    "available_lines": available,
                    "tables_dir": str(getattr(store, "dir_tables", "")),
                },
            })

        if df is None:
            return jsonable_encoder({
                "entities": {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit},
                "norm": norm,
                "rec": None,
                "debug": {
                    "error": "table_missing",
                    "line": norm.get("line"),
                    "available_lines": available,
                    "tables_dir": str(getattr(store, "dir_tables", "")),
                    "message": f"No data table found for line {norm.get('line')}"
                },
            })

        # [STEP 8] R√©cup√©ration des donn√©es avec nettoyage JSON
        try:
            rec = store.get(
                line=norm["line"],
                sex=norm["sex"],
                unit=norm["unit"],
                age_days=int(norm.get("age_days") or 21),
            )
            
            # Nettoyage JSON des valeurs
            rec_clean = clean_dict_for_json(rec) if rec else None
            
        except Exception as e:
            return jsonable_encoder({
                "error": "store_get_failed",
                "message": str(e),
                "entities": {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit},
                "norm": norm,
                "debug": {
                    "rows": int(len(df)),
                    "columns": [str(c) for c in df.columns],
                    "available_lines": available,
                }
            })

        # [SUCCESS] R√©sultat final avec message informatif
        success_message = "Performance data found"
        if not rec_clean:
            line_name = norm.get("line", "unknown")
            sex_name = norm.get("sex", "unknown") 
            age_val = norm.get("age_days", "unknown")
            success_message = f"No data found for {line_name}, {sex_name}, {age_val} days. Try: male/female/as_hatched, ages 1-49"

        result = {
            "success": bool(rec_clean),
            "entities": {"species": species, "line": line, "sex": sex, "age_days": age_days, "unit": unit},
            "norm": norm,
            "rec": rec_clean,
            "debug": {
                "rows": int(len(df)),
                "columns": [str(c) for c in df.columns],
                "available_lines": available,
                "tables_dir": str(getattr(store, "dir_tables", "")),
            },
            "message": success_message
        }
        
        return jsonable_encoder(result)

    except Exception as e:
        # Catch-all final avec informations de debug
        return jsonable_encoder({
            "error": "internal_error",
            "message": str(e),
            "entities": (payload.entities or {}) if payload else {},
            "debug": {"step": "unknown", "has_numpy": HAS_NUMPY}
        })