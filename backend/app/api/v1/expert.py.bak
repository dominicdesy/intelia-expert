"""
app/api/v1/expert.py - EXPERT ENDPOINTS PRINCIPAUX v3.7.7 - CORRECTIONS RAG ET CLARIFICATION FORC√âE

üîß CORRECTIONS APPLIQU√âES v3.7.7:
- FIX CRITIQUE: Synchronisation √©tat RAG appel√©e juste apr√®s r√©cup√©ration RAG
- FIX CRITIQUE: Clarification forc√©e si entit√©s critiques (breed, age, weight) manquent
- FIX: Validation robuste des entit√©s critiques avec extraction automatique
- FIX: D√©clenchement clarification_required_critical=True pour entit√©s manquantes
- AM√âLIORATION: D√©tection entit√©s critiques depuis le texte de la question

NOUVELLES FONCTIONS v3.7.7:
- _extract_critical_entities_from_question() - Extraction entit√©s depuis question
- _validate_critical_entities() - Validation entit√©s critiques compl√®tes
- _force_clarification_for_missing_entities() - For√ßage clarification entit√©s manquantes

CONSERVE: Toute la logique originale + corrections v3.7.6 + nouvelles validations
"""

import os
import re
import logging
import uuid
import time
from datetime import datetime
from typing import Optional, List, Dict, Any, Callable

from fastapi import APIRouter, HTTPException, Request, Depends
from fastapi.security import HTTPBearer

# üîß FIX: D√©clarer logger AVANT utilisation
logger = logging.getLogger(__name__)
router = APIRouter(tags=["expert-main"])
security = HTTPBearer()

# Imports s√©curis√©s avec gestion d'erreurs CORRIG√âE
try:
    from .expert_models import EnhancedQuestionRequest, EnhancedExpertResponse, FeedbackRequest, ConcisionLevel
    MODELS_IMPORTED = True
    logger.info("‚úÖ Models import√©s avec succ√®s")
except ImportError as e:
    logger.error(f"‚ùå Erreur import expert_models: {e}")
    # üîß FIX: Fallback plus s√©curis√© avec tous les champs requis
    from pydantic import BaseModel
    
    class ConcisionLevel:
        CONCISE = "concise"
        DETAILED = "detailed"
        COMPREHENSIVE = "comprehensive"
    
    class EnhancedQuestionRequest(BaseModel):
        text: str
        language: str = "fr"
        conversation_id: Optional[str] = None
        is_clarification_response: bool = False
        original_question: Optional[str] = None
        clarification_context: Optional[Dict[str, Any]] = None
        clarification_entities: Optional[Dict[str, str]] = None
        concision_level: str = ConcisionLevel.CONCISE
        generate_all_versions: bool = True
        enable_vagueness_detection: bool = True
        require_coherence_check: bool = True
        detailed_rag_scoring: bool = False
        enable_quality_metrics: bool = False
        
    class EnhancedExpertResponse(BaseModel):
        question: str
        response: str
        conversation_id: str
        rag_used: bool = False
        rag_score: Optional[float] = None
        timestamp: str
        language: str
        response_time_ms: int
        mode: str
        user: Optional[str] = None
        logged: bool = False
        validation_passed: Optional[bool] = None
        # NOUVEAUX CHAMPS v3.7.3
        clarification_required_critical: bool = False
        missing_critical_entities: List[str] = []
        variants_tested: List[str] = []
        # Champs optionnels pour compatibilit√©
        clarification_result: Optional[Dict[str, Any]] = None
        processing_steps: List[str] = []
        ai_enhancements_used: List[str] = []
        response_versions: Optional[Dict[str, str]] = None
        clarification_processing: Optional[Dict[str, Any]] = None
        
    class FeedbackRequest(BaseModel):
        rating: str
        comment: Optional[str] = None
        conversation_id: Optional[str] = None
        quality_feedback: Optional[Dict[str, Any]] = None
        
    MODELS_IMPORTED = False
    logger.warning("‚ö†Ô∏è Utilisation des mod√®les de fallback")

try:
    from .expert_services import ExpertService
    EXPERT_SERVICE_AVAILABLE = True
    logger.info("‚úÖ ExpertService import√© avec succ√®s")
except ImportError as e:
    logger.error(f"‚ùå Erreur import expert_services: {e}")
    EXPERT_SERVICE_AVAILABLE = False

try:
    from .expert_utils import get_user_id_from_request, extract_breed_and_sex_from_clarification
    UTILS_AVAILABLE = True
    logger.info("‚úÖ Utils import√©s avec succ√®s")
except ImportError as e:
    logger.error(f"‚ùå Erreur import expert_utils: {e}")
    # üîß FIX: Fonctions fallback plus robustes
    def get_user_id_from_request(request):
        try:
            return getattr(request.client, 'host', 'unknown') if request and request.client else 'unknown'
        except Exception:
            return 'unknown'
    
    def extract_breed_and_sex_from_clarification(text, language):
        try:
            # Fallback simple - retourner None pour forcer clarification
            return {"breed": None, "sex": None}
        except Exception:
            return {"breed": None, "sex": None}
    
    UTILS_AVAILABLE = False

# Initialisation du service avec gestion d'erreur CORRIG√âE
expert_service = None
if EXPERT_SERVICE_AVAILABLE:
    try:
        expert_service = ExpertService()
        logger.info("‚úÖ [Expert] Service expert initialis√© avec succ√®s")
    except Exception as e:
        logger.error(f"‚ùå [Expert] Erreur initialisation service: {e}")
        expert_service = None
else:
    logger.warning("‚ö†Ô∏è [Expert] Service expert non disponible - utilisation du mode fallback")

# üîß FIX CRITIQUE: Auth dependency corrig√© pour √™tre callable
def get_current_user_mock():
    """Mock user pour fallback"""
    return {"id": "fallback_user", "email": "fallback@intelia.com"}

def get_current_user_dependency() -> Callable:
    """üîß FIX CRITIQUE: Retourne une fonction callable, pas un Dependency object"""
    if expert_service and hasattr(expert_service, 'get_current_user_dependency'):
        try:
            # R√©cup√®re la fonction du service
            service_dependency = expert_service.get_current_user_dependency()
            # Si c'est d√©j√† un Depends(), extraire la fonction
            if hasattr(service_dependency, 'dependency'):
                return service_dependency.dependency
            # Sinon retourner directement
            return service_dependency
        except Exception as e:
            logger.error(f"‚ùå Erreur get_current_user_dependency: {e}")
            return get_current_user_mock
    return get_current_user_mock

# =============================================================================
# NOUVELLES FONCTIONS v3.7.7 - EXTRACTION ET VALIDATION ENTIT√âS CRITIQUES
# =============================================================================

def _extract_critical_entities_from_question(question_text: str, language: str = "fr") -> Dict[str, Any]:
    """
    üÜï NOUVELLE v3.7.7: Extrait les entit√©s critiques (breed, age, weight) depuis la question
    
    Entit√©s critiques pour les questions agricoles:
    - breed: race/souche (Ross 308, Cobb 500, etc.)
    - age: √¢ge en jours/semaines (13j, 2sem, etc.)
    - weight: poids en grammes/kg (800g, 1.2kg, etc.)
    """
    
    entities = {
        "breed": None,
        "age": None,
        "age_in_days": None,
        "weight": None,
        "weight_in_grams": None,
        "sex": None,  # Bonus - d√©j√† g√©r√© ailleurs mais utile
        "confidence": {}
    }
    
    try:
        question_lower = question_text.lower() if isinstance(question_text, str) else ""
        
        # üîç EXTRACTION 1: BREED/RACE avec patterns √©tendus
        breed_patterns = [
            r'\b(ross\s*308|ross308)\b',
            r'\b(ross\s*708|ross708)\b', 
            r'\b(cobb\s*500|cobb500)\b',
            r'\b(cobb\s*700|cobb700)\b',
            r'\b(hubbard|hub)\b',
            r'\b(arbor\s*acres|arbor)\b',
            r'\b(isa\s*brown|isa)\b',
            r'\b(lohmann|lohman)\b',
            r'\b(poulet\s*de\s*chair|broiler)\b'
        ]
        
        for pattern in breed_patterns:
            match = re.search(pattern, question_lower)
            if match:
                entities["breed"] = match.group(0).replace(" ", " ").strip()
                entities["confidence"]["breed"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Breed d√©tect√©: '{entities['breed']}'")
                break
        
        # Si pas de race sp√©cifique, chercher terme g√©n√©rique
        if not entities["breed"]:
            generic_patterns = [r'\bpoulets?\b', r'\bpoules?\b', r'\bchickens?\b', r'\bbroilers?\b']
            for pattern in generic_patterns:
                if re.search(pattern, question_lower):
                    entities["breed"] = "poulet"  # G√©n√©rique, n√©cessitera clarification
                    entities["confidence"]["breed"] = 0.3
                    logger.info(f"üîç [ENTIT√â v3.7.7] Breed g√©n√©rique d√©tect√©: '{entities['breed']}'")
                    break
        
        # üîç EXTRACTION 2: AGE avec conversion en jours
        age_patterns = [
            (r'(\d+)\s*j(?:our)?s?', 1),           # 13j, 13 jours
            (r'(\d+)\s*sem(?:aine)?s?', 7),         # 2sem, 2 semaines -> * 7
            (r'(\d+)\s*week?s?', 7),                # 2 weeks -> * 7
            (r'(\d+)\s*mois', 30),                  # 1 mois -> * 30 (approximatif)
            (r'(\d+)\s*month?s?', 30)               # 1 month -> * 30
        ]
        
        for pattern, multiplier in age_patterns:
            match = re.search(pattern, question_lower)
            if match:
                age_value = int(match.group(1))
                entities["age"] = match.group(0)
                entities["age_in_days"] = age_value * multiplier
                entities["confidence"]["age"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Age d√©tect√©: '{entities['age']}' = {entities['age_in_days']} jours")
                break
        
        # üîç EXTRACTION 3: WEIGHT avec conversion en grammes
        weight_patterns = [
            (r'(\d+(?:\.\d+)?)\s*kg', 1000),         # 1.2kg -> * 1000
            (r'(\d+(?:\.\d+)?)\s*kilo', 1000),       # 1.2 kilo -> * 1000
            (r'(\d+)\s*g(?:ramme)?s?', 1),           # 800g, 800 grammes
            (r'(\d+(?:\.\d+)?)\s*lb', 453.592)       # 2.5 lb -> * 453.592 (livres)
        ]
        
        for pattern, multiplier in weight_patterns:
            match = re.search(pattern, question_lower)
            if match:
                weight_value = float(match.group(1))
                entities["weight"] = match.group(0)
                entities["weight_in_grams"] = int(weight_value * multiplier)
                entities["confidence"]["weight"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Weight d√©tect√©: '{entities['weight']}' = {entities['weight_in_grams']}g")
                break
        
        # üîç EXTRACTION 4: SEX (bonus)
        sex_patterns = [
            (r'\bm√¢les?\b', "m√¢le"),
            (r'\bfemelles?\b', "femelle"), 
            (r'\bmales?\b', "m√¢le"),
            (r'\bfemales?\b', "femelle"),
            (r'\bmixte\b', "mixte"),
            (r'\btroupeau\s+mixte\b', "mixte")
        ]
        
        for pattern, sex_value in sex_patterns:
            if re.search(pattern, question_lower):
                entities["sex"] = sex_value
                entities["confidence"]["sex"] = 0.8
                logger.info(f"üîç [ENTIT√â v3.7.7] Sex d√©tect√©: '{entities['sex']}'")
                break
        
        # üîç VALIDATION COH√âRENCE des entit√©s extraites
        coherence_issues = []
        
        # V√©rifier coh√©rence √¢ge/poids si les deux sont pr√©sents
        if entities["age_in_days"] and entities["weight_in_grams"]:
            age_days = entities["age_in_days"]
            weight_grams = entities["weight_in_grams"]
            
            # Heuristiques de coh√©rence (√† affiner selon donn√©es r√©elles)
            if age_days < 7 and weight_grams > 500:  # Poussin < 1 sem mais > 500g
                coherence_issues.append(f"age_weight_high_{age_days}d_{weight_grams}g")
            elif age_days > 35 and weight_grams < 500:  # Poulet > 5 sem mais < 500g
                coherence_issues.append(f"age_weight_low_{age_days}d_{weight_grams}g")
            elif age_days > 60:  # √Çge tr√®s √©lev√© pour poulet de chair
                coherence_issues.append(f"age_very_high_{age_days}d")
        
        entities["coherence_issues"] = coherence_issues
        
        logger.info(f"üîç [EXTRACTION ENTIT√âS v3.7.7] R√©sultat final:")
        logger.info(f"   - Breed: {entities['breed']} (conf: {entities['confidence'].get('breed', 0)})")
        logger.info(f"   - Age: {entities['age']} = {entities['age_in_days']} jours (conf: {entities['confidence'].get('age', 0)})")
        logger.info(f"   - Weight: {entities['weight']} = {entities['weight_in_grams']}g (conf: {entities['confidence'].get('weight', 0)})")
        logger.info(f"   - Sex: {entities['sex']} (conf: {entities['confidence'].get('sex', 0)})")
        logger.info(f"   - Incoh√©rences: {coherence_issues}")
        
        return entities
        
    except Exception as e:
        logger.error(f"‚ùå [EXTRACTION ENTIT√âS v3.7.7] Erreur: {e}")
        return entities

def _validate_critical_entities(entities: Dict[str, Any], question_context: str = "") -> Dict[str, Any]:
    """
    üÜï NOUVELLE v3.7.7: Valide si les entit√©s critiques sont suffisantes pour une r√©ponse de qualit√©
    
    Returns:
        Dict avec validation_result, missing_entities, confidence_issues, etc.
    """
    
    validation_result = {
        "entities_sufficient": False,
        "missing_critical": [],
        "low_confidence": [],
        "generic_entities": [],
        "coherence_issues": [],
        "clarification_required": False,
        "clarification_priority": "low"  # low, medium, high, critical
    }
    
    try:
        if not isinstance(entities, dict):
            logger.error("‚ùå [VALIDATION ENTIT√âS v3.7.7] entities n'est pas un dict")
            validation_result["clarification_required"] = True
            validation_result["clarification_priority"] = "critical"
            return validation_result
        
        # üîç VALIDATION 1: ENTIT√âS CRITIQUES MANQUANTES
        critical_entities = ["breed", "age_in_days", "weight_in_grams"]
        
        for entity in critical_entities:
            entity_value = entities.get(entity)
            
            if entity_value is None:
                validation_result["missing_critical"].append(entity)
                logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.7] Entit√© critique manquante: {entity}")
            
            # Validation sp√©cifique par type d'entit√©
            elif entity == "breed":
                if isinstance(entity_value, str):
                    if entity_value.lower() in ["poulet", "chicken", "broiler"]:
                        validation_result["generic_entities"].append("breed_too_generic")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.7] Breed trop g√©n√©rique: {entity_value}")
                else:
                    validation_result["missing_critical"].append(entity)
            
            elif entity == "age_in_days":
                if isinstance(entity_value, (int, float)):
                    if entity_value <= 0 or entity_value > 365:  # Age aberrant
                        validation_result["coherence_issues"].append(f"age_aberrant_{entity_value}")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.7] Age aberrant: {entity_value} jours")
                else:
                    validation_result["missing_critical"].append(entity)
            
            elif entity == "weight_in_grams":
                if isinstance(entity_value, (int, float)):
                    if entity_value <= 0 or entity_value > 10000:  # Poids aberrant
                        validation_result["coherence_issues"].append(f"weight_aberrant_{entity_value}")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.7] Poids aberrant: {entity_value}g")
                else:
                    validation_result["missing_critical"].append(entity)
        
        # üîç VALIDATION 2: CONFIANCE DES ENTIT√âS
        confidence_data = entities.get("confidence", {})
        
        for entity, confidence in confidence_data.items():
            if isinstance(confidence, (int, float)) and confidence < 0.5:
                validation_result["low_confidence"].append(f"{entity}_conf_{confidence}")
                logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.7] Confiance faible {entity}: {confidence}")
        
        # üîç VALIDATION 3: INCOH√âRENCES D√âTECT√âES
        coherence_issues = entities.get("coherence_issues", [])
        validation_result["coherence_issues"].extend(coherence_issues)
        
        # üîç CALCUL PRIORIT√â CLARIFICATION
        missing_count = len(validation_result["missing_critical"])
        generic_count = len(validation_result["generic_entities"])
        coherence_count = len(validation_result["coherence_issues"])
        low_conf_count = len(validation_result["low_confidence"])
        
        # Logique de priorit√©
        if missing_count >= 2:  # 2+ entit√©s critiques manquantes
            validation_result["clarification_priority"] = "critical"
            validation_result["clarification_required"] = True
        elif missing_count == 1 and (generic_count > 0 or coherence_count > 0):
            validation_result["clarification_priority"] = "high"
            validation_result["clarification_required"] = True
        elif missing_count == 1 or generic_count > 0:
            validation_result["clarification_priority"] = "medium"
            validation_result["clarification_required"] = True
        elif coherence_count > 0 or low_conf_count > 1:
            validation_result["clarification_priority"] = "low"
            validation_result["clarification_required"] = True
        else:
            validation_result["entities_sufficient"] = True
            validation_result["clarification_required"] = False
        
        logger.info(f"üîç [VALIDATION ENTIT√âS v3.7.7] R√©sultat:")
        logger.info(f"   - Entit√©s suffisantes: {validation_result['entities_sufficient']}")
        logger.info(f"   - Critiques manquantes: {validation_result['missing_critical']}")
        logger.info(f"   - G√©n√©riques: {validation_result['generic_entities']}")
        logger.info(f"   - Incoh√©rences: {validation_result['coherence_issues']}")
        logger.info(f"   - Clarification requise: {validation_result['clarification_required']}")
        logger.info(f"   - Priorit√©: {validation_result['clarification_priority']}")
        
        return validation_result
        
    except Exception as e:
        logger.error(f"‚ùå [VALIDATION ENTIT√âS v3.7.7] Erreur: {e}")
        # En cas d'erreur, forcer clarification critique
        validation_result["clarification_required"] = True
        validation_result["clarification_priority"] = "critical"
        validation_result["missing_critical"] = ["validation_error"]
        return validation_result

def _force_clarification_for_missing_entities(
    response_data: Any, 
    validation_result: Dict[str, Any], 
    entities: Dict[str, Any]
) -> Any:
    """
    üÜï NOUVELLE v3.7.7: Force la clarification si des entit√©s critiques manquent
    
    Cette fonction modifie response_data pour d√©clencher clarification_required_critical=True
    """
    
    try:
        if not response_data or not isinstance(validation_result, dict):
            logger.error("‚ùå [FORCE CLARIFICATION v3.7.7] Param√®tres invalides")
            return response_data
        
        clarification_required = validation_result.get("clarification_required", False)
        clarification_priority = validation_result.get("clarification_priority", "low")
        
        if not clarification_required:
            logger.info("‚úÖ [FORCE CLARIFICATION v3.7.7] Aucune clarification n√©cessaire")
            return response_data
        
        logger.warning(f"üö® [FORCE CLARIFICATION v3.7.7] Clarification forc√©e - priorit√©: {clarification_priority}")
        
        # üîß MODIFICATION 1: Marquer clarification_required_critical selon priorit√©
        critical_priorities = ["high", "critical"]
        force_critical = clarification_priority in critical_priorities
        
        if hasattr(response_data, 'clarification_required_critical'):
            response_data.clarification_required_critical = force_critical
            logger.info(f"üîß [FORCE CLARIFICATION v3.7.7] clarification_required_critical = {force_critical}")
        
        # üîß MODIFICATION 2: Mettre √† jour missing_critical_entities
        missing_entities = validation_result.get("missing_critical", [])
        generic_entities = validation_result.get("generic_entities", [])
        coherence_issues = validation_result.get("coherence_issues", [])
        
        # Combiner tous les probl√®mes d'entit√©s
        all_missing = missing_entities + generic_entities + coherence_issues
        
        if hasattr(response_data, 'missing_critical_entities'):
            if isinstance(response_data.missing_critical_entities, list):
                response_data.missing_critical_entities.extend(all_missing)
            else:
                response_data.missing_critical_entities = all_missing
            logger.info(f"üîß [FORCE CLARIFICATION v3.7.7] missing_critical_entities = {response_data.missing_critical_entities}")
        
        # üîß MODIFICATION 3: Ajouter dans processing_steps pour tra√ßabilit√©
        if hasattr(response_data, 'processing_steps') and isinstance(response_data.processing_steps, list):
            response_data.processing_steps.append(f"critical_entities_validation_v3.7.7")
            response_data.processing_steps.append(f"clarification_priority_{clarification_priority}")
            if force_critical:
                response_data.processing_steps.append("clarification_forced_critical_entities")
        
        # üîß MODIFICATION 4: Ajouter dans ai_enhancements_used
        if hasattr(response_data, 'ai_enhancements_used') and isinstance(response_data.ai_enhancements_used, list):
            response_data.ai_enhancements_used.append("critical_entities_extraction_v3.7.7")
            response_data.ai_enhancements_used.append("entities_validation_forced_clarification")
        
        # üîß MODIFICATION 5: Enrichir clarification_result si pr√©sent
        if hasattr(response_data, 'clarification_result') and response_data.clarification_result:
            if isinstance(response_data.clarification_result, dict):
                response_data.clarification_result.update({
                    "critical_entities_analysis": {
                        "entities_extracted": entities,
                        "validation_result": validation_result,
                        "forced_clarification": force_critical,
                        "missing_entities": missing_entities,
                        "generic_entities": generic_entities,
                        "coherence_issues": coherence_issues
                    }
                })
                logger.info("üîß [FORCE CLARIFICATION v3.7.7] clarification_result enrichi avec analyse entit√©s")
        
        logger.info("‚úÖ [FORCE CLARIFICATION v3.7.7] Modifications appliqu√©es √† response_data")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå [FORCE CLARIFICATION v3.7.7] Erreur: {e}")
        return response_data

# =============================================================================
# FONCTIONS EXISTANTES v3.7.6 - CONSERV√âES AVEC AM√âLIORATIONS v3.7.7
# =============================================================================

def _detect_inconsistencies_and_force_clarification(question_text: str, language: str = "fr") -> Dict[str, Any]:
    """
    üÜï CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.7: D√©tecte les incoh√©rences + utilise nouvelles entit√©s
    """
    
    inconsistencies_detected = []
    force_clarification = False
    clarification_reason = ""
    
    try:
        question_lower = question_text.lower() if isinstance(question_text, str) else ""
        
        # üÜï v3.7.7: Utiliser la nouvelle extraction d'entit√©s
        entities = _extract_critical_entities_from_question(question_text, language)
        
        # üîç D√âTECTION 1: Unit√©s temporelles contradictoires (CONSERV√âE v3.7.6)
        temporal_units = []
        if "jour" in question_lower or "j" in question_lower:
            temporal_units.append("jours")
        if "semaine" in question_lower or "sem" in question_lower or "week" in question_lower:
            temporal_units.append("semaines")
        if "mois" in question_lower or "month" in question_lower:
            temporal_units.append("mois")
        
        # Si plusieurs unit√©s temporelles avec des valeurs qui pourraient √™tre contradictoires
        if len(temporal_units) >= 2:
            # Recherche de motifs comme "13j" et "1sem"
            day_pattern = r'(\d+)\s*j(?:our)?s?'
            week_pattern = r'(\d+)\s*sem(?:aine)?s?'
            
            day_matches = re.findall(day_pattern, question_lower)
            week_matches = re.findall(week_pattern, question_lower)
            
            if day_matches and week_matches:
                try:
                    days = int(day_matches[0])
                    weeks = int(week_matches[0])
                    
                    # V√©rifier si incoh√©rent (exemple: 13j ‚â† 1sem)
                    if abs(days - (weeks * 7)) > 2:  # Tol√©rance de 2 jours
                        inconsistencies_detected.append(f"temporal_contradiction")
                        force_clarification = True
                        clarification_reason = f"Incoh√©rence temporelle d√©tect√©e: {days} jours vs {weeks} semaine(s)"
                        logger.warning(f"üö® [INCOH√âRENCE v3.7.7] {clarification_reason}")
                except (ValueError, IndexError):
                    pass
        
        # üîç D√âTECTION 2: Incoh√©rences des entit√©s extraites (NOUVEAU v3.7.7)
        coherence_issues = entities.get("coherence_issues", [])
        if coherence_issues:
            inconsistencies_detected.extend(coherence_issues)
            force_clarification = True
            clarification_reason = f"Incoh√©rences entit√©s d√©tect√©es: {', '.join(coherence_issues)}"
            logger.warning(f"üö® [INCOH√âRENCE ENTIT√âS v3.7.7] {clarification_reason}")
        
        # üîç D√âTECTION 3: Sexe contradictoire (CONSERV√âE v3.7.6)
        if ("m√¢le" in question_lower and "femelle" in question_lower) or ("male" in question_lower and "female" in question_lower):
            # V√©rifier si ce n'est pas une question g√©n√©rale
            specific_indicators = ["mes", "mon", "ce", "cette", "le probl√®me", "problem with"]
            if any(indicator in question_lower for indicator in specific_indicators):
                inconsistencies_detected.append("gender_contradiction")
                force_clarification = True
                clarification_reason = "Question sp√©cifique mentionnant √† la fois m√¢les et femelles"
                logger.warning(f"üö® [INCOH√âRENCE v3.7.7] {clarification_reason}")
        
        logger.info(f"üîç [D√âTECTION INCOH√âRENCES v3.7.7] Question: '{question_text[:100]}...'")
        logger.info(f"   - Incoh√©rences d√©tect√©es: {inconsistencies_detected}")
        logger.info(f"   - Force clarification: {force_clarification}")
        logger.info(f"   - Raison: {clarification_reason}")
        logger.info(f"   - Entit√©s extraites: {entities}")
        
        return {
            "inconsistencies_detected": inconsistencies_detected,
            "force_clarification": force_clarification,
            "clarification_reason": clarification_reason,
            "temporal_units_found": temporal_units,
            "entities_extracted": entities  # NOUVEAU v3.7.7
        }
        
    except Exception as e:
        logger.error(f"‚ùå [D√âTECTION INCOH√âRENCES v3.7.7] Erreur: {e}")
        return {
            "inconsistencies_detected": [],
            "force_clarification": False,
            "clarification_reason": "",
            "temporal_units_found": [],
            "entities_extracted": {}
        }

def _validate_and_sync_rag_state(response_data: Any, processing_metadata: Dict[str, Any] = None) -> bool:
    """
    üÜï CONSERV√âE v3.7.6: Valide et synchronise l'√©tat RAG de mani√®re robuste
    
    üîß AM√âLIORATION v3.7.7: Appel√©e juste apr√®s r√©cup√©ration RAG selon demande
    
    Returns:
        bool: True si RAG a √©t√© effectivement utilis√© et doit √™tre marqu√© comme tel
    """
    
    rag_actually_used = False
    rag_indicators = []
    
    try:
        logger.info("üîç [RAG VALIDATION v3.7.7] D√âMARRAGE validation √©tat RAG...")
        
        # üîç INDICATEUR 1: V√©rifier si response_data contient des signes d'utilisation RAG
        if response_data is not None:
            
            # V√©rifier rag_score
            rag_score = getattr(response_data, 'rag_score', None)
            if rag_score is not None and rag_score > 0:
                rag_indicators.append(f"rag_score: {rag_score}")
                rag_actually_used = True
                logger.info(f"‚úÖ [RAG VALIDATION v3.7.7] RAG Score positif d√©tect√©: {rag_score}")
            
            # V√©rifier rag_used d√©j√† d√©fini
            rag_used_attr = getattr(response_data, 'rag_used', None)
            if rag_used_attr is True:
                rag_indicators.append("rag_used_attribute: True")
                rag_actually_used = True
                logger.info("‚úÖ [RAG VALIDATION v3.7.7] rag_used d√©j√† True")
            
            # V√©rifier processing_steps pour indices RAG
            processing_steps = getattr(response_data, 'processing_steps', [])
            if isinstance(processing_steps, list):
                rag_steps = [step for step in processing_steps if isinstance(step, str) and ('rag' in step.lower() or 'vector' in step.lower() or 'search' in step.lower())]
                if rag_steps:
                    rag_indicators.append(f"rag_processing_steps: {len(rag_steps)}")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.7] Steps RAG d√©tect√©s: {rag_steps}")
            
            # V√©rifier ai_enhancements_used pour RAG
            ai_enhancements = getattr(response_data, 'ai_enhancements_used', [])
            if isinstance(ai_enhancements, list):
                rag_enhancements = [enh for enh in ai_enhancements if isinstance(enh, str) and ('rag' in enh.lower() or 'vector' in enh.lower() or 'document' in enh.lower())]
                if rag_enhancements:
                    rag_indicators.append(f"rag_enhancements: {len(rag_enhancements)}")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.7] Enhancements RAG d√©tect√©s: {rag_enhancements}")
            
            # V√©rifier mode pour indices RAG
            mode = getattr(response_data, 'mode', '')
            if isinstance(mode, str) and ('rag' in mode.lower() or 'enhanced' in mode.lower()):
                rag_indicators.append(f"rag_mode: {mode}")
                rag_actually_used = True
                logger.info(f"‚úÖ [RAG VALIDATION v3.7.7] Mode RAG d√©tect√©: {mode}")
        
        # üîç INDICATEUR 2: V√©rifier processing_metadata
        if processing_metadata and isinstance(processing_metadata, dict):
            
            logger.info(f"üîç [RAG VALIDATION v3.7.7] Analyse metadata: {list(processing_metadata.keys())}")
            
            # Recherche de m√©tadonn√©es RAG
            for key, value in processing_metadata.items():
                if isinstance(key, str) and ('rag' in key.lower() or 'vector' in key.lower() or 'search' in key.lower()):
                    if value is not None and value != False and value != 0:
                        rag_indicators.append(f"metadata_{key}: {value}")
                        rag_actually_used = True
                        logger.info(f"‚úÖ [RAG VALIDATION v3.7.7] Metadata RAG: {key}={value}")
            
            # V√©rifier si des documents ont √©t√© trouv√©s
            if 'documents_found' in processing_metadata:
                docs_found = processing_metadata['documents_found']
                if isinstance(docs_found, (int, list)) and (
                    (isinstance(docs_found, int) and docs_found > 0) or 
                    (isinstance(docs_found, list) and len(docs_found) > 0)
                ):
                    rag_indicators.append(f"documents_found: {docs_found}")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.7] Documents trouv√©s: {docs_found}")
            
            # V√©rifier temps de recherche (indique qu'une recherche a eu lieu)
            if 'search_time_ms' in processing_metadata:
                search_time = processing_metadata['search_time_ms']
                if isinstance(search_time, (int, float)) and search_time > 0:
                    rag_indicators.append(f"search_time: {search_time}ms")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.7] Temps recherche: {search_time}ms")
        
        # üîç INDICATEUR 3: Analyse du contenu de la r√©ponse pour patterns RAG
        if hasattr(response_data, 'response'):
            response_text = getattr(response_data, 'response', '')
            if isinstance(response_text, str):
                # Patterns qui sugg√®rent utilisation de documents/RAG
                rag_patterns = [
                    'selon la documentation',
                    'based on the documentation',
                    'selon les documents',
                    'dans les protocoles',
                    'conform√©ment aux guides',
                    'r√©f√©rences bibliographiques',
                    'sources consult√©es'
                ]
                
                patterns_found = [pattern for pattern in rag_patterns if pattern.lower() in response_text.lower()]
                if patterns_found:
                    rag_indicators.append(f"content_patterns: {len(patterns_found)}")
                    rag_actually_used = True
                    logger.info(f"‚úÖ [RAG VALIDATION v3.7.7] Patterns contenu RAG: {patterns_found}")
        
        logger.info(f"üîç [RAG VALIDATION v3.7.7] R√âSULTAT:")
        logger.info(f"   - Indicateurs trouv√©s: {rag_indicators}")
        logger.info(f"   - RAG effectivement utilis√©: {rag_actually_used}")
        
        return rag_actually_used
        
    except Exception as e:
        logger.error(f"‚ùå [RAG VALIDATION v3.7.7] Erreur: {e}")
        return False

def _force_sync_rag_state(response: EnhancedExpertResponse, rag_actually_used: bool, rag_details: Dict[str, Any] = None) -> EnhancedExpertResponse:
    """
    üÜï CONSERV√âE v3.7.6: Force la synchronisation de l'√©tat RAG dans la r√©ponse finale
    
    üîß AM√âLIORATION v3.7.7: Plus de logging pour tra√ßabilit√©
    """
    
    try:
        if response is None:
            logger.error("‚ùå [RAG SYNC v3.7.7] Response est None")
            return response
        
        logger.info(f"üîÑ [RAG SYNC v3.7.7] D√âMARRAGE synchronisation: rag_actually_used={rag_actually_used}")
        
        # üîß SYNCHRONISATION FORC√âE
        if hasattr(response, 'rag_used'):
            old_value = response.rag_used
            response.rag_used = rag_actually_used
            
            if old_value != rag_actually_used:
                logger.warning(f"üîÑ [RAG SYNC v3.7.7] CORRECTION CRITIQUE: rag_used {old_value} ‚Üí {rag_actually_used}")
                
                # Ajouter dans processing_steps pour tra√ßabilit√©
                if hasattr(response, 'processing_steps') and isinstance(response.processing_steps, list):
                    response.processing_steps.append(f"rag_state_corrected_{old_value}_to_{rag_actually_used}_v3.7.7")
                
                # Ajouter dans ai_enhancements_used
                if hasattr(response, 'ai_enhancements_used') and isinstance(response.ai_enhancements_used, list):
                    response.ai_enhancements_used.append("rag_state_synchronization_v3.7.7")
            else:
                logger.info(f"‚úÖ [RAG SYNC v3.7.7] √âtat RAG d√©j√† correct: {rag_actually_used}")
        
        # üîß MISE √Ä JOUR DU MODE si n√©cessaire
        if hasattr(response, 'mode'):
            current_mode = response.mode
            if rag_actually_used and 'rag' not in current_mode.lower():
                response.mode = f"{current_mode}_with_rag"
                logger.info(f"üîÑ [RAG SYNC v3.7.7] Mode mis √† jour: {current_mode} ‚Üí {response.mode}")
            elif not rag_actually_used and 'rag' in current_mode.lower():
                response.mode = current_mode.replace('_rag', '').replace('_with_rag', '').replace('rag_', '')
                logger.info(f"üîÑ [RAG SYNC v3.7.7] Mode nettoy√©: {current_mode} ‚Üí {response.mode}")
        
        # üîß AJOUT D√âTAILS RAG si fournis
        if rag_details and isinstance(rag_details, dict) and rag_actually_used:
            
            # Mise √† jour rag_score si disponible
            if 'rag_score' in rag_details and hasattr(response, 'rag_score'):
                if response.rag_score is None or response.rag_score == 0:
                    response.rag_score = rag_details['rag_score']
                    logger.info(f"üîÑ [RAG SYNC v3.7.7] rag_score mis √† jour: {rag_details['rag_score']}")
            
            # Ajout m√©tadonn√©es RAG dans processing_steps si pertinentes
            if hasattr(response, 'processing_steps') and isinstance(response.processing_steps, list):
                for key, value in rag_details.items():
                    if key.startswith('rag_') or key.startswith('search_') or key.startswith('vector_'):
                        response.processing_steps.append(f"rag_detail_{key}_{value}")
        
        logger.info(f"‚úÖ [RAG SYNC v3.7.7] TERMIN√â - √âtat final: rag_used={getattr(response, 'rag_used', 'N/A')}")
        
    except Exception as e:
        logger.error(f"‚ùå [RAG SYNC v3.7.7] Erreur synchronisation: {e}")
    
    return response

# =============================================================================
# UTILITAIRES PROPAGATION CHAMPS v3.7.6 - CONSERV√âES AVEC AM√âLIORATIONS v3.7.7
# =============================================================================

def _extract_propagation_fields(response_data: Any) -> Dict[str, Any]:
    """üîß CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.7: Extraction avec plus de logging"""
    
    propagation_fields = {
        "clarification_required_critical": False,
        "missing_critical_entities": [],
        "variants_tested": []
    }
    
    try:
        # üîß FIX: Validation du type avant hasattr
        if response_data is None:
            logger.warning("‚ö†Ô∏è [PROPAGATION v3.7.7] response_data est None")
            return propagation_fields
        
        logger.info("üìã [PROPAGATION v3.7.7] D√âMARRAGE extraction champs...")
        
        # Extraction clarification_required_critical avec validation robuste
        if hasattr(response_data, 'clarification_result'):
            clarification_result = getattr(response_data, 'clarification_result', None)
            if clarification_result and isinstance(clarification_result, dict):
                propagation_fields["clarification_required_critical"] = clarification_result.get("clarification_required_critical", False)
                missing_entities = clarification_result.get("missing_critical_entities", [])
                # üîß FIX: Validation que missing_entities est une liste
                if isinstance(missing_entities, list):
                    propagation_fields["missing_critical_entities"] = missing_entities
                else:
                    propagation_fields["missing_critical_entities"] = []
                
                logger.info(f"üìã [PROPAGATION v3.7.7] Clarification critique: {propagation_fields['clarification_required_critical']}")
                logger.info(f"üìã [PROPAGATION v3.7.7] Entit√©s critiques manquantes: {propagation_fields['missing_critical_entities']}")
        
        # Extraction variants_tested depuis RAG enhancements avec validation
        if hasattr(response_data, 'rag_enhancement_info'):
            rag_enhancement_info = getattr(response_data, 'rag_enhancement_info', None)
            if rag_enhancement_info and isinstance(rag_enhancement_info, dict):
                variants = rag_enhancement_info.get("variants_tested", [])
                if isinstance(variants, list):
                    propagation_fields["variants_tested"] = variants
                    logger.info(f"üìã [PROPAGATION v3.7.7] Variantes test√©es: {propagation_fields['variants_tested']}")
        
        # Extraction alternative depuis processing_metadata avec validation
        elif hasattr(response_data, 'processing_metadata'):
            processing_metadata = getattr(response_data, 'processing_metadata', None)
            if processing_metadata and isinstance(processing_metadata, dict):
                if "rag_enhancement_info" in processing_metadata:
                    rag_info = processing_metadata["rag_enhancement_info"]
                    if isinstance(rag_info, dict):
                        variants = rag_info.get("variants_tested", [])
                        if isinstance(variants, list):
                            propagation_fields["variants_tested"] = variants
                            logger.info(f"üìã [PROPAGATION v3.7.7] Variantes depuis metadata: {propagation_fields['variants_tested']}")
        
        # Extraction depuis ai_enhancements_used (fallback) avec validation
        elif hasattr(response_data, 'ai_enhancements_used'):
            ai_enhancements = getattr(response_data, 'ai_enhancements_used', None)
            if ai_enhancements and isinstance(ai_enhancements, list):
                # Filtrer les am√©liorations li√©es aux variantes
                variant_enhancements = [
                    enhancement for enhancement in ai_enhancements 
                    if isinstance(enhancement, str) and ("variant" in enhancement.lower() or "reformulation" in enhancement.lower())
                ]
                if variant_enhancements:
                    propagation_fields["variants_tested"] = variant_enhancements
                    logger.info(f"üìã [PROPAGATION v3.7.7] Variantes inf√©r√©es: {variant_enhancements}")
        
        logger.info("‚úÖ [PROPAGATION v3.7.7] Champs extraits avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå [PROPAGATION v3.7.7] Erreur extraction champs: {e}")
        # üîß FIX: Garder les valeurs par d√©faut en cas d'erreur
    
    return propagation_fields

def _apply_propagation_fields(response: EnhancedExpertResponse, propagation_fields: Dict[str, Any]) -> EnhancedExpertResponse:
    """üîß CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.7: Application avec plus de logging"""
    
    try:
        # üîß FIX: Validation que response n'est pas None
        if response is None:
            logger.error("‚ùå [PROPAGATION v3.7.7] response est None")
            return response
        
        # üîß FIX: Validation que propagation_fields est un dict
        if not isinstance(propagation_fields, dict):
            logger.error("‚ùå [PROPAGATION v3.7.7] propagation_fields n'est pas un dict")
            return response
        
        logger.info("üìã [PROPAGATION v3.7.7] D√âMARRAGE application champs...")
        
        # Application des nouveaux champs avec validation
        if hasattr(response, 'clarification_required_critical'):
            old_val = response.clarification_required_critical
            response.clarification_required_critical = propagation_fields.get("clarification_required_critical", False)
            if old_val != response.clarification_required_critical:
                logger.info(f"üìã [PROPAGATION v3.7.7] clarification_required_critical: {old_val} ‚Üí {response.clarification_required_critical}")
        
        if hasattr(response, 'missing_critical_entities'):
            missing_entities = propagation_fields.get("missing_critical_entities", [])
            if isinstance(missing_entities, list):
                old_len = len(response.missing_critical_entities) if response.missing_critical_entities else 0
                response.missing_critical_entities = missing_entities
                logger.info(f"üìã [PROPAGATION v3.7.7] missing_critical_entities: {old_len} ‚Üí {len(missing_entities)} entit√©s")
            else:
                response.missing_critical_entities = []
        
        if hasattr(response, 'variants_tested'):
            variants = propagation_fields.get("variants_tested", [])
            if isinstance(variants, list):
                old_len = len(response.variants_tested) if response.variants_tested else 0
                response.variants_tested = variants
                logger.info(f"üìã [PROPAGATION v3.7.7] variants_tested: {old_len} ‚Üí {len(variants)} variantes")
            else:
                response.variants_tested = []
        
        logger.info("‚úÖ [PROPAGATION v3.7.7] Champs appliqu√©s √† la r√©ponse finale")
        
        # Log des valeurs appliqu√©es avec protection None
        clarification_critical = getattr(response, 'clarification_required_critical', 'N/A')
        missing_entities = getattr(response, 'missing_critical_entities', 'N/A')
        variants_tested = getattr(response, 'variants_tested', 'N/A')
        
        logger.info(f"üìã [PROPAGATION v3.7.7] FINAL clarification critique: {clarification_critical}")
        logger.info(f"üìã [PROPAGATION v3.7.7] FINAL entit√©s manquantes: {missing_entities}")
        logger.info(f"üìã [PROPAGATION v3.7.7] FINAL variantes test√©es: {variants_tested}")
        
    except Exception as e:
        logger.error(f"‚ùå [PROPAGATION v3.7.7] Erreur application champs: {e}")
    
    return response

# =============================================================================
# ENDPOINTS PRINCIPAUX AVEC CORRECTIONS RAG ET VALIDATION ENTIT√âS v3.7.7
# =============================================================================

@router.get("/health")
async def expert_health():
    """Health check pour diagnostiquer les probl√®mes - version v3.7.7 avec entit√©s critiques"""
    return {
        "status": "healthy",
        "version": "3.7.7",
        "new_fixes_v377": [
            "synchronisation RAG appel√©e juste apr√®s r√©cup√©ration RAG",
            "clarification forc√©e si entit√©s critiques (breed, age, weight) manquent",
            "validation robuste des entit√©s critiques avec extraction automatique",
            "d√©clenchement clarification_required_critical=True pour entit√©s manquantes",
            "d√©tection entit√©s critiques depuis le texte de la question"
        ],
        "new_functions_v377": [
            "_extract_critical_entities_from_question",
            "_validate_critical_entities", 
            "_force_clarification_for_missing_entities",
            "enhanced critical entities detection",
            "breed/age/weight extraction with confidence scoring"
        ],
        "fixes_applied_v376": [
            "synchronisation √©tat RAG - rag_used correctement mis √† jour",
            "d√©tection automatique incoh√©rences pour forcer clarification",
            "validation robuste r√©sultats RAG avant application",
            "tracking pr√©cis utilisation RAG dans pipeline",
            "m√©canisme forc√© clarification pour incoh√©rences temporelles"
        ],
        "critical_entities_support": [
            "breed extraction (Ross 308, Cobb 500, etc.)",
            "age extraction with conversion to days",
            "weight extraction with conversion to grams", 
            "sex extraction (bonus feature)",
            "coherence validation age/weight",
            "confidence scoring per entity",
            "forced clarification for missing entities"
        ],
        "expert_service_available": EXPERT_SERVICE_AVAILABLE,
        "expert_service_initialized": expert_service is not None,
        "models_imported": MODELS_IMPORTED,
        "utils_available": UTILS_AVAILABLE,
        "timestamp": datetime.now().isoformat(),
        "propagation_fields_supported": [
            "clarification_required_critical",
            "missing_critical_entities", 
            "variants_tested"
        ],
        "rag_sync_features": [
            "rag_score_validation",
            "processing_steps_analysis",
            "ai_enhancements_tracking",
            "content_pattern_detection",
            "metadata_indicators_check",
            "post_rag_validation_v377"
        ],
        "endpoints": [
            "/health",
            "/ask-enhanced-v2", 
            "/ask-enhanced-v2-public",
            "/feedback",
            "/topics"
        ]
    }

@router.post("/ask-enhanced-v2", response_model=EnhancedExpertResponse)
async def ask_expert_enhanced_v2(
    request_data: EnhancedQuestionRequest,
    request: Request,
    current_user: Dict[str, Any] = Depends(get_current_user_dependency())
):
    """
    üîß ENDPOINT EXPERT FINAL v3.7.7 - CORRECTIONS RAG + VALIDATION ENTIT√âS CRITIQUES:
    - Synchronisation RAG appel√©e juste apr√®s r√©cup√©ration RAG
    - Clarification forc√©e si entit√©s critiques (breed, age, weight) manquent
    - Validation robuste des entit√©s critiques avec extraction automatique
    - D√©clenchement clarification_required_critical=True pour entit√©s manquantes
    """
    start_time = time.time()
    
    # üîß FIX: Initialisation explicite des variables de clarification
    clarification_metadata = {}
    is_clarification = False
    original_question = None
    clarification_entities = None
    processing_metadata = {}
    
    try:
        logger.info("=" * 100)
        logger.info("üöÄ D√âBUT ask_expert_enhanced_v2 v3.7.7 - CORRECTIONS RAG + VALIDATION ENTIT√âS CRITIQUES")
        logger.info(f"üìù Question/R√©ponse: '{request_data.text}'")
        logger.info(f"üÜî Conversation ID: {getattr(request_data, 'conversation_id', 'None')}")
        logger.info(f"üõ†Ô∏è Service disponible: {expert_service is not None}")
        
        # V√©rification service disponible
        if not expert_service:
            logger.error("‚ùå [Expert] Service expert non disponible - mode fallback")
            return await _fallback_expert_response(request_data, start_time, current_user)
        
        # üÜï NOUVELLE v3.7.7: EXTRACTION ET VALIDATION ENTIT√âS CRITIQUES
        logger.info("üîç [ENTIT√âS CRITIQUES v3.7.7] Extraction entit√©s depuis question...")
        entities = _extract_critical_entities_from_question(
            request_data.text, 
            getattr(request_data, 'language', 'fr')
        )
        
        logger.info("üîç [ENTIT√âS CRITIQUES v3.7.7] Validation entit√©s extraites...")
        validation_result = _validate_critical_entities(entities, request_data.text)
        
        # Sauvegarder dans processing_metadata pour tra√ßabilit√©
        processing_metadata['critical_entities'] = entities
        processing_metadata['entities_validation'] = validation_result
        
        # üÜï CONSERV√âE v3.7.6: D√âTECTION INCOH√âRENCES POUR FORCER CLARIFICATION
        inconsistency_check = _detect_inconsistencies_and_force_clarification(
            request_data.text, 
            getattr(request_data, 'language', 'fr')
        )
        
        if inconsistency_check.get('force_clarification', False):
            logger.warning(f"üö® [CLARIFICATION FORC√âE v3.7.7] Incoh√©rences d√©tect√©es: {inconsistency_check['inconsistencies_detected']}")
            logger.warning(f"üö® [CLARIFICATION FORC√âE v3.7.7] Raison: {inconsistency_check['clarification_reason']}")
            
            # Forcer l'activation de la d√©tection de vagueness
            if hasattr(request_data, 'enable_vagueness_detection'):
                request_data.enable_vagueness_detection = True
            if hasattr(request_data, 'require_coherence_check'):
                request_data.require_coherence_check = True
            
            # Ajouter dans metadata pour tracking
            processing_metadata['inconsistency_check'] = inconsistency_check
        
        # üîß FIX: V√©rification robuste des param√®tres concision avec validation None
        concision_level = getattr(request_data, 'concision_level', None)
        if concision_level is None:
            concision_level = ConcisionLevel.CONCISE
            
        generate_all_versions = getattr(request_data, 'generate_all_versions', None)
        if generate_all_versions is None:
            generate_all_versions = True
        
        logger.info("üöÄ [RESPONSE_VERSIONS v3.7.7] Param√®tres concision:")
        logger.info(f"   - concision_level: {concision_level}")
        logger.info(f"   - generate_all_versions: {generate_all_versions}")
        
        # üîß FIX: D√âTECTION EXPLICITE MODE CLARIFICATION avec validation robuste
        is_clarification = getattr(request_data, 'is_clarification_response', False)
        original_question = getattr(request_data, 'original_question', None)
        clarification_entities = getattr(request_data, 'clarification_entities', None)
        
        # üîß FIX: Validation des types
        if is_clarification is None:
            is_clarification = False
        
        logger.info("üß® [D√âTECTION CLARIFICATION v3.7.7] Analyse du mode:")
        logger.info(f"   - is_clarification_response: {is_clarification}")
        logger.info(f"   - original_question fournie: {original_question is not None}")
        logger.info(f"   - clarification_entities: {clarification_entities}")
        
        if is_clarification:
            logger.info("üé™ [FLUX CLARIFICATION] Mode R√âPONSE de clarification d√©tect√©")
            logger.info(f"   - R√©ponse utilisateur: '{request_data.text}'")
            logger.info(f"   - Question originale: '{original_question}'")
            
            # üîß FIX: Initialisation s√©curis√©e des variables breed/sex
            breed = None
            sex = None
            
            # TRAITEMENT SP√âCIALIS√â R√âPONSE CLARIFICATION avec gestion d'erreur renforc√©e
            try:
                if clarification_entities and isinstance(clarification_entities, dict):
                    logger.info(f"   - Entit√©s pr√©-extraites: {clarification_entities}")
                    breed = clarification_entities.get('breed')
                    sex = clarification_entities.get('sex')
                else:
                    # Extraction automatique si pas fournie
                    logger.info("   - Extraction automatique entit√©s depuis r√©ponse")
                    extracted = extract_breed_and_sex_from_clarification(
                        request_data.text, 
                        getattr(request_data, 'language', 'fr')
                    )
                    # üîß FIX: Validation robuste du r√©sultat d'extraction
                    if extracted is None or not isinstance(extracted, dict):
                        extracted = {"breed": None, "sex": None}
                    breed = extracted.get('breed')
                    sex = extracted.get('sex')
                    logger.info(f"   - Entit√©s extraites: breed='{breed}', sex='{sex}'")
            except Exception as e:
                logger.error(f"‚ùå Erreur extraction entit√©s: {e}")
                breed, sex = None, None
            
            # VALIDATION entit√©s compl√®tes AVANT enrichissement
            clarified_entities = {"breed": breed, "sex": sex}
            
            # üéØ NOUVELLE LOGIQUE GRANULAIRE v3.7.7: Validation granulaire breed vs sex
            if not breed or not sex:
                # üîß FIX: Protection contre None dans le logging
                breed_safe = str(breed) if breed is not None else "None"
                sex_safe = str(sex) if sex is not None else "None"
                logger.warning(f"‚ö†Ô∏è [FLUX CLARIFICATION] Entit√©s incompl√®tes: breed='{breed_safe}', sex='{sex_safe}'")
                
                return _create_incomplete_clarification_response(
                    request_data, clarified_entities, breed, sex, start_time
                )
            
            # Enrichir la question originale avec les informations COMPL√àTES
            if original_question and isinstance(original_question, str):
                enriched_question = original_question
                if breed and isinstance(breed, str):
                    enriched_question += f" pour {breed}"
                if sex and isinstance(sex, str):
                    enriched_question += f" {sex}"
                
                logger.info(f"   - Question enrichie: '{enriched_question}'")
                
                # üîß FIX: M√©tadonn√©es sauvegard√©es pour response - initialisation s√©curis√©e
                clarification_metadata = {
                    "was_clarification_response": True,
                    "original_question": original_question,
                    "clarification_input": request_data.text,
                    "entities_extracted": clarified_entities,
                    "question_enriched": True
                }
                
                # Modifier la question pour traitement RAG
                request_data.text = enriched_question
                
                # Marquer comme traitement post-clarification (√©viter boucle)
                if hasattr(request_data, 'is_clarification_response'):
                    request_data.is_clarification_response = False
                
                logger.info("üéØ [FLUX CLARIFICATION] Question enrichie, passage au traitement RAG")
            else:
                logger.warning("‚ö†Ô∏è [FLUX CLARIFICATION] Question originale manquante ou invalide - impossible enrichir")
        else:
            logger.info("üéØ [FLUX CLARIFICATION] Mode QUESTION INITIALE - d√©tection vagueness active")
        
        # üîß FIX: Validation et d√©fauts concision robuste avec validation None
        if not hasattr(request_data, 'concision_level') or getattr(request_data, 'concision_level', None) is None:
            request_data.concision_level = ConcisionLevel.CONCISE
            logger.info("üöÄ [CONCISION] Niveau par d√©faut appliqu√©: CONCISE")
        
        if not hasattr(request_data, 'generate_all_versions') or getattr(request_data, 'generate_all_versions', None) is None:
            request_data.generate_all_versions = True
            logger.info("üöÄ [CONCISION] generate_all_versions activ√© par d√©faut")
        
        # FOR√áAGE SYST√âMATIQUE DES AM√âLIORATIONS avec gestion d'erreur
        original_vagueness = getattr(request_data, 'enable_vagueness_detection', None)
        original_coherence = getattr(request_data, 'require_coherence_check', None)
        
        # FORCER l'activation - AUCUNE EXCEPTION
        if hasattr(request_data, 'enable_vagueness_detection'):
            request_data.enable_vagueness_detection = True
        if hasattr(request_data, 'require_coherence_check'):
            request_data.require_coherence_check = True
        
        logger.info("üî• [CLARIFICATION FORC√âE v3.7.7] Param√®tres forc√©s:")
        logger.info(f"   - enable_vagueness_detection: {original_vagueness} ‚Üí TRUE (FORC√â)")
        logger.info(f"   - require_coherence_check: {original_coherence} ‚Üí TRUE (FORC√â)")
        
        # D√âL√âGUER AU SERVICE avec gestion d'erreur
        try:
            response = await expert_service.process_expert_question(
                request_data=request_data,
                request=request,
                current_user=current_user,
                start_time=start_time
            )
        except Exception as e:
            logger.error(f"‚ùå [Expert Service] Erreur traitement: {e}")
            return await _fallback_expert_response(request_data, start_time, current_user, str(e))
        
        # üÜï NOUVELLE v3.7.7: VALIDATION ET SYNCHRONISATION RAG STATE JUSTE APR√àS R√âCUP√âRATION
        logger.info("üîç [RAG SYNC v3.7.7] APPEL IMM√âDIAT apr√®s traitement service...")
        rag_actually_used = _validate_and_sync_rag_state(response, processing_metadata)
        
        if rag_actually_used:
            logger.info("‚úÖ [RAG SYNC v3.7.7] RAG confirm√© comme utilis√© - synchronisation FORC√âE...")
            response = _force_sync_rag_state(response, True)
        else:
            logger.warning("‚ö†Ô∏è [RAG SYNC v3.7.7] Aucun signe d'utilisation RAG d√©tect√© - marquage FALSE")
            response = _force_sync_rag_state(response, False)
        
        # üÜï NOUVELLE v3.7.7: VALIDATION ENTIT√âS CRITIQUES ET CLARIFICATION FORC√âE
        logger.info("üîç [ENTIT√âS CRITIQUES v3.7.7] Application validation entit√©s sur r√©ponse...")
        
        # Appliquer la validation des entit√©s critiques √† la r√©ponse
        response = _force_clarification_for_missing_entities(response, validation_result, entities)
        
        # üöÄ PROPAGATION NOUVEAUX CHAMPS v3.7.7 - VERSIONS CORRIG√âES
        logger.info("üìã [PROPAGATION v3.7.7] Extraction et application nouveaux champs")
        propagation_fields = _extract_propagation_fields(response)
        response = _apply_propagation_fields(response, propagation_fields)
        
        # üîß FIX: AJOUT M√âTADONN√âES CLARIFICATION dans response avec validation
        if clarification_metadata and isinstance(clarification_metadata, dict) and hasattr(response, 'clarification_processing'):
            response.clarification_processing = clarification_metadata
            logger.info("üí° [M√âTADONN√âES v3.7.7] Clarification metadata ajout√©es √† response")
        
        # üÜï AJOUT M√âTADONN√âES INCOH√âRENCES v3.7.7
        if inconsistency_check.get('force_clarification', False) and hasattr(response, 'processing_steps'):
            if isinstance(response.processing_steps, list):
                response.processing_steps.append("inconsistency_forced_clarification_v3.7.7")
            if hasattr(response, 'ai_enhancements_used') and isinstance(response.ai_enhancements_used, list):
                response.ai_enhancements_used.append("inconsistency_detection_v3.7.7")
        
        # üÜï AJOUT M√âTADONN√âES ENTIT√âS CRITIQUES v3.7.7
        if hasattr(response, 'processing_steps') and isinstance(response.processing_steps, list):
            response.processing_steps.append("critical_entities_extracted_v3.7.7")
            if validation_result.get('clarification_required', False):
                response.processing_steps.append(f"critical_entities_clarification_{validation_result.get('clarification_priority', 'unknown')}")
        
        if hasattr(response, 'ai_enhancements_used') and isinstance(response.ai_enhancements_used, list):
            response.ai_enhancements_used.append("critical_entities_validation_v3.7.7")
            if validation_result.get('entities_sufficient', False):
                response.ai_enhancements_used.append("critical_entities_sufficient")
            else:
                response.ai_enhancements_used.append("critical_entities_insufficient")
        
        # Log response_versions si pr√©sentes avec validation
        if hasattr(response, 'response_versions') and response.response_versions and isinstance(response.response_versions, dict):
            logger.info("üöÄ [RESPONSE_VERSIONS] Versions g√©n√©r√©es:")
            for level, content in response.response_versions.items():
                content_len = len(str(content)) if content else 0
                logger.info(f"   - {level}: {content_len} caract√®res")
        
        # LOGGING R√âSULTATS CLARIFICATION D√âTAILL√â avec protection None
        logger.info("üß® [R√âSULTATS CLARIFICATION v3.7.7]:")
        logger.info(f"   - Mode final: {getattr(response, 'mode', 'unknown')}")
        logger.info(f"   - Clarification d√©clench√©e: {getattr(response, 'clarification_result', None) is not None}")
        logger.info(f"   - RAG utilis√©: {getattr(response, 'rag_used', False)}")  # ‚Üê CORRIG√â v3.7.7
        
        question_preview = getattr(response, 'question', '')
        if isinstance(question_preview, str) and len(question_preview) > 100:
            question_preview = question_preview[:100] + "..."
        logger.info(f"   - Question finale trait√©e: '{question_preview}'")
        
        clarification_result = getattr(response, 'clarification_result', None)
        if clarification_result and isinstance(clarification_result, dict):
            logger.info(f"   - Type clarification: {clarification_result.get('clarification_type', 'N/A')}")
            logger.info(f"   - Infos manquantes: {clarification_result.get('missing_information', [])}")
            logger.info(f"   - Confiance: {clarification_result.get('confidence', 0)}")
            if 'provided_parts' in clarification_result:
                logger.info(f"   - Parties d√©tect√©es: {clarification_result.get('provided_parts', [])}")
        
        # üìã LOGGING NOUVEAUX CHAMPS v3.7.7 avec protection None
        logger.info("üìã [NOUVEAUX CHAMPS v3.7.7] Valeurs finales:")
        logger.info(f"   - clarification_required_critical: {getattr(response, 'clarification_required_critical', 'N/A')}")
        logger.info(f"   - missing_critical_entities: {getattr(response, 'missing_critical_entities', 'N/A')}")
        logger.info(f"   - variants_tested: {getattr(response, 'variants_tested', 'N/A')}")
        
        # üÜï LOGGING ENTIT√âS CRITIQUES v3.7.7
        logger.info("üîç [ENTIT√âS CRITIQUES v3.7.7] Analyse finale:")
        logger.info(f"   - Breed d√©tect√©: {entities.get('breed', 'N/A')}")
        logger.info(f"   - Age d√©tect√©: {entities.get('age', 'N/A')} = {entities.get('age_in_days', 'N/A')} jours")
        logger.info(f"   - Weight d√©tect√©: {entities.get('weight', 'N/A')} = {entities.get('weight_in_grams', 'N/A')}g")
        logger.info(f"   - Entit√©s suffisantes: {validation_result.get('entities_sufficient', 'N/A')}")
        logger.info(f"   - Clarification priorit√©: {validation_result.get('clarification_priority', 'N/A')}")
        
        # üÜï LOGGING RAG STATE v3.7.7
        logger.info("üîç [RAG STATE v3.7.7] √âtat final synchronis√©:")
        logger.info(f"   - rag_used: {getattr(response, 'rag_used', 'N/A')}")
        logger.info(f"   - rag_score: {getattr(response, 'rag_score', 'N/A')}")
        rag_mode = getattr(response, 'mode', '')
        logger.info(f"   - mode contains 'rag': {'rag' in str(rag_mode).lower()}")
        
        response_time = getattr(response, 'response_time_ms', 0)
        ai_enhancements = getattr(response, 'ai_enhancements_used', [])
        ai_count = len(ai_enhancements) if isinstance(ai_enhancements, list) else 0
        
        logger.info(f"‚úÖ FIN ask_expert_enhanced_v2 v3.7.7 - Temps: {response_time}ms")
        logger.info(f"ü§ñ Am√©liorations: {ai_count} features")
        logger.info(f"üîç RAG Final: {getattr(response, 'rag_used', 'N/A')}")
        logger.info(f"üéØ Entit√©s Critiques: {validation_result.get('entities_sufficient', 'N/A')}")
        logger.info("=" * 100)
        
        return response
    
    except HTTPException:
        logger.info("=" * 100)
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur critique ask_expert_enhanced_v2 v3.7.7: {e}")
        logger.info("=" * 100)
        return await _fallback_expert_response(request_data, start_time, current_user, str(e))

@router.post("/ask-enhanced-v2-public", response_model=EnhancedExpertResponse)
async def ask_expert_enhanced_v2_public(
    request_data: EnhancedQuestionRequest,
    request: Request
):
    """üîß ENDPOINT PUBLIC v3.7.7 - CORRECTIONS RAG + VALIDATION ENTIT√âS CRITIQUES"""
    start_time = time.time()
    
    # üîß FIX: Initialisation explicite des variables
    clarification_metadata = {}
    is_clarification = False
    processing_metadata = {}
    
    try:
        logger.info("=" * 100)
        logger.info("üåê D√âBUT ask_expert_enhanced_v2_public v3.7.7 - CORRECTIONS RAG + VALIDATION ENTIT√âS CRITIQUES")
        logger.info(f"üìù Question/R√©ponse: '{request_data.text}'")
        logger.info(f"üõ†Ô∏è Service disponible: {expert_service is not None}")
        
        # V√©rification service disponible
        if not expert_service:
            logger.error("‚ùå [Expert Public] Service expert non disponible - mode fallback")
            return await _fallback_expert_response(request_data, start_time, None)
        
        # üÜï NOUVELLE v3.7.7: EXTRACTION ET VALIDATION ENTIT√âS CRITIQUES POUR ENDPOINT PUBLIC
        logger.info("üîç [ENTIT√âS CRITIQUES PUBLIC v3.7.7] Extraction entit√©s depuis question...")
        entities = _extract_critical_entities_from_question(
            request_data.text, 
            getattr(request_data, 'language', 'fr')
        )
        
        logger.info("üîç [ENTIT√âS CRITIQUES PUBLIC v3.7.7] Validation entit√©s extraites...")
        validation_result = _validate_critical_entities(entities, request_data.text)
        
        # Sauvegarder dans processing_metadata pour tra√ßabilit√©
        processing_metadata['critical_entities'] = entities
        processing_metadata['entities_validation'] = validation_result
        
        # üÜï CONSERV√âE v3.7.6: D√âTECTION INCOH√âRENCES POUR ENDPOINT PUBLIC
        inconsistency_check = _detect_inconsistencies_and_force_clarification(
            request_data.text, 
            getattr(request_data, 'language', 'fr')
        )
        
        if inconsistency_check.get('force_clarification', False):
            logger.warning(f"üö® [CLARIFICATION FORC√âE PUBLIC v3.7.7] Incoh√©rences: {inconsistency_check['inconsistencies_detected']}")
            logger.warning(f"üö® [CLARIFICATION FORC√âE PUBLIC v3.7.7] Raison: {inconsistency_check['clarification_reason']}")
            
            # Forcer l'activation pour endpoint public aussi
            if hasattr(request_data, 'enable_vagueness_detection'):
                request_data.enable_vagueness_detection = True
            if hasattr(request_data, 'require_coherence_check'):
                request_data.require_coherence_check = True
            
            processing_metadata['inconsistency_check'] = inconsistency_check
        
        # üîß FIX: Param√®tres concision pour endpoint public avec validations None
        concision_level = getattr(request_data, 'concision_level', None)
        if concision_level is None:
            concision_level = ConcisionLevel.CONCISE
            
        generate_all_versions = getattr(request_data, 'generate_all_versions', None)
        if generate_all_versions is None:
            generate_all_versions = True
        
        logger.info("üöÄ [RESPONSE_VERSIONS PUBLIC] Param√®tres concision:")
        logger.info(f"   - concision_level: {concision_level}")
        logger.info(f"   - generate_all_versions: {generate_all_versions}")
        
        # üîß FIX: D√âTECTION PUBLIQUE CLARIFICATION avec validation robuste
        is_clarification = getattr(request_data, 'is_clarification_response', False)
        if is_clarification is None:
            is_clarification = False
        
        logger.info("üß® [D√âTECTION PUBLIQUE v3.7.7] Analyse mode clarification:")
        logger.info(f"   - is_clarification_response: {is_clarification}")
        logger.info(f"   - conversation_id: {getattr(request_data, 'conversation_id', 'None')}")
        
        if is_clarification:
            logger.info("üé™ [FLUX PUBLIC] Traitement r√©ponse clarification")
            
            # Logique similaire √† l'endpoint priv√© avec gestion d'erreur
            original_question = getattr(request_data, 'original_question', None)
            clarification_entities = getattr(request_data, 'clarification_entities', None)
            
            logger.info(f"   - Question originale: '{original_question}'")
            logger.info(f"   - Entit√©s fournies: {clarification_entities}")
            
            # üîß FIX: Initialisation s√©curis√©e des variables breed/sex
            breed = None
            sex = None
            
            try:
                if clarification_entities and isinstance(clarification_entities, dict):
                    breed = clarification_entities.get('breed')
                    sex = clarification_entities.get('sex')
                    logger.info(f"   - Utilisation entit√©s pr√©-extraites: breed='{breed}', sex='{sex}'")
                else:
                    # Extraction automatique
                    extracted = extract_breed_and_sex_from_clarification(
                        request_data.text, 
                        getattr(request_data, 'language', 'fr')
                    )
                    # üîß FIX: Validation robuste du r√©sultat
                    if extracted is None or not isinstance(extracted, dict):
                        extracted = {"breed": None, "sex": None}
                    breed = extracted.get('breed')
                    sex = extracted.get('sex')
                    logger.info(f"   - Extraction automatique: breed='{breed}', sex='{sex}'")
            except Exception as e:
                logger.error(f"‚ùå Erreur extraction entit√©s publique: {e}")
                breed, sex = None, None
            
            # VALIDATION entit√©s compl√®tes
            clarified_entities = {"breed": breed, "sex": sex}
            
            # üéØ LOGIQUE GRANULAIRE PUBLIQUE v3.7.7
            if not breed or not sex:
                # üîß FIX: Protection contre None dans le logging
                breed_safe = str(breed) if breed is not None else "None"
                sex_safe = str(sex) if sex is not None else "None"
                logger.warning(f"‚ö†Ô∏è [FLUX PUBLIC] Entit√©s incompl√®tes: breed='{breed_safe}', sex='{sex_safe}'")
                
                return _create_incomplete_clarification_response(
                    request_data, clarified_entities, breed, sex, start_time, public=True
                )
            
            # Enrichissement question avec entit√©s COMPL√àTES
            if original_question and isinstance(original_question, str):
                enriched_question = original_question
                if breed and isinstance(breed, str):
                    enriched_question += f" pour {breed}"
                if sex and isinstance(sex, str):
                    enriched_question += f" {sex}"
                
                # üîß FIX: M√©tadonn√©es pour response (endpoint public) - initialisation s√©curis√©e
                clarification_metadata = {
                    "was_clarification_response": True,
                    "original_question": original_question,
                    "clarification_input": request_data.text,
                    "entities_extracted": clarified_entities,
                    "question_enriched": True
                }
                
                # Modifier question pour RAG
                request_data.text = enriched_question
                if hasattr(request_data, 'is_clarification_response'):
                    request_data.is_clarification_response = False  # √âviter boucle
                
                logger.info(f"   - Question enrichie publique: '{enriched_question}'")
                logger.info(f"   - M√©tadonn√©es sauvegard√©es: {clarification_metadata}")
        else:
            logger.info("üéØ [FLUX PUBLIC] Question initiale - d√©tection vagueness")
        
        # üîß FIX: Validation et d√©fauts concision pour public avec validation None
        if not hasattr(request_data, 'concision_level') or getattr(request_data, 'concision_level', None) is None:
            request_data.concision_level = ConcisionLevel.CONCISE
        
        if not hasattr(request_data, 'generate_all_versions') or getattr(request_data, 'generate_all_versions', None) is None:
            request_data.generate_all_versions = True
        
        # FOR√áAGE MAXIMAL pour endpoint public avec gestion d'erreur
        logger.info("üî• [PUBLIC ENDPOINT v3.7.7] Activation FORC√âE des am√©liorations:")
        
        original_settings = {
            'vagueness': getattr(request_data, 'enable_vagueness_detection', None),
            'coherence': getattr(request_data, 'require_coherence_check', None),
            'detailed_rag': getattr(request_data, 'detailed_rag_scoring', None),
            'quality_metrics': getattr(request_data, 'enable_quality_metrics', None)
        }
        
        # FOR√áAGE MAXIMAL pour endpoint public
        if hasattr(request_data, 'enable_vagueness_detection'):
            request_data.enable_vagueness_detection = True
        if hasattr(request_data, 'require_coherence_check'):
            request_data.require_coherence_check = True
        if hasattr(request_data, 'detailed_rag_scoring'):
            request_data.detailed_rag_scoring = True
        if hasattr(request_data, 'enable_quality_metrics'):
            request_data.enable_quality_metrics = True
        
        logger.info("üî• [FOR√áAGE PUBLIC v3.7.7] Changements appliqu√©s:")
        for key, (old_val, new_val) in {
            'vagueness_detection': (original_settings['vagueness'], True),
            'coherence_check': (original_settings['coherence'], True),
            'detailed_rag': (original_settings['detailed_rag'], True),
            'quality_metrics': (original_settings['quality_metrics'], True)
        }.items():
            logger.info(f"   - {key}: {old_val} ‚Üí {new_val} (FORC√â)")
        
        # D√âL√âGUER AU SERVICE avec support response_versions et gestion d'erreur
        try:
            response = await expert_service.process_expert_question(
                request_data=request_data,
                request=request,
                current_user=None,  # Mode public
                start_time=start_time
            )
        except Exception as e:
            logger.error(f"‚ùå [Expert Service Public] Erreur traitement: {e}")
            return await _fallback_expert_response(request_data, start_time, None, str(e))
        
        # üÜï NOUVELLE v3.7.7: VALIDATION ET SYNCHRONISATION RAG STATE POUR PUBLIC JUSTE APR√àS R√âCUP√âRATION
        logger.info("üîç [RAG SYNC PUBLIC v3.7.7] APPEL IMM√âDIAT apr√®s traitement service...")
        rag_actually_used = _validate_and_sync_rag_state(response, processing_metadata)
        
        if rag_actually_used:
            logger.info("‚úÖ [RAG SYNC PUBLIC v3.7.7] RAG confirm√© comme utilis√© - synchronisation FORC√âE...")
            response = _force_sync_rag_state(response, True)
        else:
            logger.warning("‚ö†Ô∏è [RAG SYNC PUBLIC v3.7.7] Aucun signe d'utilisation RAG d√©tect√© - marquage FALSE")
            response = _force_sync_rag_state(response, False)
        
        # üÜï NOUVELLE v3.7.7: VALIDATION ENTIT√âS CRITIQUES ET CLARIFICATION FORC√âE POUR PUBLIC
        logger.info("üîç [ENTIT√âS CRITIQUES PUBLIC v3.7.7] Application validation entit√©s sur r√©ponse...")
        
        # Appliquer la validation des entit√©s critiques √† la r√©ponse
        response = _force_clarification_for_missing_entities(response, validation_result, entities)
        
        # üöÄ PROPAGATION NOUVEAUX CHAMPS v3.7.7 - ENDPOINT PUBLIC - VERSIONS CORRIG√âES
        logger.info("üìã [PROPAGATION PUBLIC v3.7.7] Extraction et application nouveaux champs")
        propagation_fields = _extract_propagation_fields(response)
        response = _apply_propagation_fields(response, propagation_fields)
        
        # üîß FIX: Ajout m√©tadonn√©es clarification avec validation
        if clarification_metadata and isinstance(clarification_metadata, dict) and hasattr(response, 'clarification_processing'):
            response.clarification_processing = clarification_metadata
            logger.info("üí° [M√âTADONN√âES PUBLIC v3.7.7] Clarification metadata ajout√©es")
        
        # üÜï AJOUT M√âTADONN√âES INCOH√âRENCES PUBLIC v3.7.7
        if inconsistency_check.get('force_clarification', False) and hasattr(response, 'processing_steps'):
            if isinstance(response.processing_steps, list):
                response.processing_steps.append("inconsistency_forced_clarification_public_v3.7.7")
            if hasattr(response, 'ai_enhancements_used') and isinstance(response.ai_enhancements_used, list):
                response.ai_enhancements_used.append("inconsistency_detection_public_v3.7.7")
        
        # üÜï AJOUT M√âTADONN√âES ENTIT√âS CRITIQUES PUBLIC v3.7.7
        if hasattr(response, 'processing_steps') and isinstance(response.processing_steps, list):
            response.processing_steps.append("critical_entities_extracted_public_v3.7.7")
            if validation_result.get('clarification_required', False):
                response.processing_steps.append(f"critical_entities_clarification_public_{validation_result.get('clarification_priority', 'unknown')}")
        
        if hasattr(response, 'ai_enhancements_used') and isinstance(response.ai_enhancements_used, list):
            response.ai_enhancements_used.append("critical_entities_validation_public_v3.7.7")
            if validation_result.get('entities_sufficient', False):
                response.ai_enhancements_used.append("critical_entities_sufficient_public")
            else:
                response.ai_enhancements_used.append("critical_entities_insufficient_public")
        
        # Log response_versions si pr√©sentes avec validation
        if hasattr(response, 'response_versions') and response.response_versions and isinstance(response.response_versions, dict):
            logger.info("üöÄ [RESPONSE_VERSIONS PUBLIC] Versions g√©n√©r√©es:")
            for level, content in response.response_versions.items():
                content_len = len(str(content)) if content else 0
                logger.info(f"   - {level}: {content_len} caract√®res")
        
        # VALIDATION R√âSULTATS CLARIFICATION PUBLIQUE avec protection None
        logger.info("üß® [VALIDATION PUBLIQUE v3.7.7]:")
        mode = getattr(response, 'mode', 'unknown')
        logger.info(f"   - Clarification syst√®me actif: {'clarification' in str(mode)}")
        
        ai_enhancements = getattr(response, 'ai_enhancements_used', [])
        if isinstance(ai_enhancements, list):
            logger.info(f"   - Am√©liorations appliqu√©es: {ai_enhancements}")
        
        logger.info(f"   - Mode final: {mode}")
        logger.info(f"   - RAG utilis√©: {getattr(response, 'rag_used', False)}")  # ‚Üê CORRIG√â v3.7.7
        
        # üìã LOGGING NOUVEAUX CHAMPS PUBLIC v3.7.7 avec protection None
        logger.info("üìã [NOUVEAUX CHAMPS PUBLIC v3.7.7] Valeurs finales:")
        logger.info(f"   - clarification_required_critical: {getattr(response, 'clarification_required_critical', 'N/A')}")
        logger.info(f"   - missing_critical_entities: {getattr(response, 'missing_critical_entities', 'N/A')}")
        logger.info(f"   - variants_tested: {getattr(response, 'variants_tested', 'N/A')}")
        
        # üÜï LOGGING ENTIT√âS CRITIQUES PUBLIC v3.7.7
        logger.info("üîç [ENTIT√âS CRITIQUES PUBLIC v3.7.7] Analyse finale:")
        logger.info(f"   - Breed d√©tect√©: {entities.get('breed', 'N/A')}")
        logger.info(f"   - Age d√©tect√©: {entities.get('age', 'N/A')} = {entities.get('age_in_days', 'N/A')} jours")
        logger.info(f"   - Weight d√©tect√©: {entities.get('weight', 'N/A')} = {entities.get('weight_in_grams', 'N/A')}g")
        logger.info(f"   - Entit√©s suffisantes: {validation_result.get('entities_sufficient', 'N/A')}")
        logger.info(f"   - Clarification priorit√©: {validation_result.get('clarification_priority', 'N/A')}")
        
        # üÜï LOGGING RAG STATE PUBLIC v3.7.7
        logger.info("üîç [RAG STATE PUBLIC v3.7.7] √âtat final synchronis√©:")
        logger.info(f"   - rag_used: {getattr(response, 'rag_used', 'N/A')}")
        logger.info(f"   - rag_score: {getattr(response, 'rag_score', 'N/A')}")
        rag_mode = getattr(response, 'mode', '')
        logger.info(f"   - mode contains 'rag': {'rag' in str(rag_mode).lower()}")
        
        # V√©rification critique avec protection None
        if not ai_enhancements or (isinstance(ai_enhancements, list) and len(ai_enhancements) == 0):
            logger.warning("‚ö†Ô∏è [ALERTE] Aucune am√©lioration d√©tect√©e - possible probl√®me!")
        
        vagueness_enabled = getattr(response, 'enable_vagueness_detection', True)
        if vagueness_enabled is False:
            logger.warning("‚ö†Ô∏è [ALERTE] Vagueness detection non activ√©e - v√©rifier for√ßage!")
        
        logger.info(f"‚úÖ FIN ask_expert_enhanced_v2_public v3.7.7 - Mode: {mode}")
        logger.info(f"üîç RAG Final Public: {getattr(response, 'rag_used', 'N/A')}")
        logger.info(f"üéØ Entit√©s Critiques Public: {validation_result.get('entities_sufficient', 'N/A')}")
        logger.info("=" * 100)
        
        return response
    
    except HTTPException:
        logger.info("=" * 100)
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur critique ask_expert_enhanced_v2_public v3.7.7: {e}")
        logger.info("=" * 100)
        return await _fallback_expert_response(request_data, start_time, None, str(e))

# =============================================================================
# ENDPOINT FEEDBACK ET TOPICS AVEC GESTION D'ERREUR RENFORC√âE v3.7.7
# =============================================================================

@router.post("/feedback")
async def submit_feedback_enhanced(feedback_data: FeedbackRequest):
    """Submit feedback - VERSION CORRIG√âE v3.7.7 avec gestion d'erreur robuste"""
    try:
        conversation_id = getattr(feedback_data, 'conversation_id', 'None')
        logger.info(f"üìä [Feedback v3.7.7] Re√ßu: {feedback_data.rating} pour {conversation_id}")
        
        # üîß FIX: Validation robuste des quality_feedback
        quality_feedback = getattr(feedback_data, 'quality_feedback', None)
        if quality_feedback and isinstance(quality_feedback, dict):
            logger.info(f"üìà [Feedback v3.7.7] Qualit√© d√©taill√©e: {len(quality_feedback)} m√©triques")
        
        if expert_service and hasattr(expert_service, 'process_feedback'):
            try:
                result = await expert_service.process_feedback(feedback_data)
            except Exception as e:
                logger.error(f"‚ùå [Feedback Service v3.7.7] Erreur: {e}")
                # Fallback si service expert √©choue
                result = {
                    "success": False,
                    "message": f"Erreur service feedback: {str(e)}",
                    "rating": feedback_data.rating,
                    "comment": getattr(feedback_data, 'comment', None),
                    "conversation_id": conversation_id,
                    "fallback_mode": True,
                    "timestamp": datetime.now().isoformat(),
                    "version": "3.7.7"
                }
        else:
            # Fallback si service non disponible
            result = {
                "success": True,
                "message": "Feedback enregistr√© (mode fallback v3.7.7)",
                "rating": feedback_data.rating,
                "comment": getattr(feedback_data, 'comment', None),
                "conversation_id": conversation_id,
                "fallback_mode": True,
                "timestamp": datetime.now().isoformat(),
                "version": "3.7.7"
            }
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå [Feedback v3.7.7] Erreur critique: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur feedback v3.7.7: {str(e)}")

@router.get("/topics")
async def get_suggested_topics_enhanced(language: str = "fr"):
    """Get suggested topics - VERSION CORRIG√âE v3.7.7 avec gestion d'erreur robuste"""
    try:
        if expert_service and hasattr(expert_service, 'get_suggested_topics'):
            try:
                return await expert_service.get_suggested_topics(language)
            except Exception as e:
                logger.error(f"‚ùå [Topics Service v3.7.7] Erreur: {e}")
                # Continuer vers fallback
        
        # üîß FIX: Fallback am√©lior√© avec validation language v3.7.7
        fallback_topics = {
            "fr": [
                "Probl√®mes de croissance poulets Ross 308",
                "Conditions environnementales optimales √©levage", 
                "Protocoles vaccination selon √¢ge",
                "Diagnostic probl√®mes sant√© par sympt√¥mes",
                "Nutrition et alimentation selon poids",
                "Mortalit√© √©lev√©e - causes et solutions",
                "Temp√©rature et ventilation b√¢timent",
                "D√©veloppement normal poulets de chair"
            ],
            "en": [
                "Ross 308 chicken growth problems",
                "Optimal environmental conditions breeding",
                "Age-specific vaccination protocols", 
                "Health problem diagnosis by symptoms",
                "Weight-based nutrition and feeding",
                "High mortality - causes and solutions",
                "Building temperature and ventilation",
                "Normal broiler chicken development"
            ],
            "es": [
                "Problemas crecimiento pollos Ross 308",
                "Condiciones ambientales √≥ptimas crianza",
                "Protocolos vacunaci√≥n seg√∫n edad",
                "Diagn√≥stico problemas salud por s√≠ntomas", 
                "Nutrici√≥n alimentaci√≥n seg√∫n peso",
                "Alta mortalidad - causas y soluciones",
                "Temperatura y ventilaci√≥n edificio",
                "Desarrollo normal pollos de engorde"
            ]
        }
        
        # üîß FIX: Validation robuste du language
        lang = str(language).lower() if language else "fr"
        if lang not in fallback_topics:
            lang = "fr"
        
        selected_topics = fallback_topics[lang]
        
        return {
            "topics": selected_topics,
            "language": lang,
            "count": len(selected_topics),
            "fallback_mode": True,
            "expert_service_available": expert_service is not None,
            "timestamp": datetime.now().isoformat(),
            "version": "3.7.7",
            "critical_entities_optimized": True
        }
            
    except Exception as e:
        logger.error(f"‚ùå [Topics v3.7.7] Erreur critique: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur topics v3.7.7: {str(e)}")

# =============================================================================
# FONCTIONS UTILITAIRES AVEC PROPAGATION v3.7.7 - VERSIONS AM√âLIOR√âES
# =============================================================================

def _create_incomplete_clarification_response(
    request_data: EnhancedQuestionRequest, 
    clarified_entities: Dict[str, str], 
    breed: Optional[str], 
    sex: Optional[str], 
    start_time: float,
    public: bool = False
) -> EnhancedExpertResponse:
    """üîß CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.7: Cr√©e une r√©ponse pour clarification incompl√®te avec entit√©s critiques"""
    
    # üîß FIX: Validation des param√®tres d'entr√©e
    if not isinstance(clarified_entities, dict):
        clarified_entities = {"breed": breed, "sex": sex}
    
    # üÜï v3.7.7: Extraire entit√©s critiques de la r√©ponse utilisateur aussi
    user_text = getattr(request_data, 'text', '')
    extracted_entities = _extract_critical_entities_from_question(user_text, getattr(request_data, 'language', 'fr'))
    
    # Validation granulaire des informations manquantes avec protection None
    missing_info = []
    missing_details = []
    provided_parts = []
    missing_critical_entities = []  # NOUVEAU CHAMP v3.7.6/v3.7.7
    
    # üîß FIX: V√©rification breed avec plus de nuances et protection None
    extracted_breed = extracted_entities.get('breed')
    effective_breed = breed or extracted_breed
    
    if not effective_breed or (isinstance(effective_breed, str) and len(effective_breed.strip()) == 0):
        missing_info.append("race/souche")
        missing_details.append("la race/souche (Ross 308, Cobb 500, Hubbard, etc.)")
        missing_critical_entities.append("breed")
    elif isinstance(effective_breed, str) and len(effective_breed.strip()) < 3:  # Breed trop court/vague
        missing_info.append("race/souche compl√®te")
        missing_details.append("la race/souche compl√®te (ex: 'Ross' ‚Üí 'Ross 308')")
        provided_parts.append(f"Race partielle d√©tect√©e: {effective_breed}")
        missing_critical_entities.append("breed_complete")
    elif effective_breed:  # breed est valide
        provided_parts.append(f"Race d√©tect√©e: {effective_breed}")
    
    # üîß FIX: V√©rification sex avec protection None
    if not sex or (isinstance(sex, str) and len(sex.strip()) == 0):
        missing_info.append("sexe")
        missing_details.append("le sexe (m√¢les, femelles, ou mixte)")
        missing_critical_entities.append("sex")
    elif sex:  # sex est valide
        provided_parts.append(f"Sexe d√©tect√©: {sex}")
    
    # üÜï v3.7.7: V√©rifier aussi √¢ge et poids depuis extraction automatique
    extracted_age = extracted_entities.get('age_in_days')
    extracted_weight = extracted_entities.get('weight_in_grams')
    
    if extracted_age and isinstance(extracted_age, (int, float)) and extracted_age > 0:
        provided_parts.append(f"√Çge d√©tect√©: {extracted_entities.get('age', extracted_age)} jours")
    else:
        missing_info.append("√¢ge")
        missing_details.append("l'√¢ge pr√©cis (13 jours, 2 semaines, etc.)")
        missing_critical_entities.append("age")
    
    if extracted_weight and isinstance(extracted_weight, (int, float)) and extracted_weight > 0:
        provided_parts.append(f"Poids d√©tect√©: {extracted_entities.get('weight', extracted_weight)}g")
    else:
        missing_info.append("poids")
        missing_details.append("le poids actuel (800g, 1.2kg, etc.)")
        missing_critical_entities.append("weight")
    
    # üéØ MESSAGE ADAPTATIF selon ce qui manque r√©ellement v3.7.7
    if len(missing_info) >= 3:
        error_message = f"Information incompl√®te. Il manque plusieurs √©l√©ments critiques : {', '.join(missing_info)}.\n\n"
    elif len(missing_info) == 2:
        error_message = f"Information incompl√®te. Il manque encore : {' et '.join(missing_info)}.\n\n"
    elif len(missing_info) == 1:
        error_message = f"Information incompl√®te. Il manque encore : {missing_info[0]}.\n\n"
    else:
        error_message = "Information incompl√®te.\n\n"
    
    # Ajouter contexte de ce qui a √©t√© fourni VS ce qui manque
    if provided_parts:
        error_message += f"Votre r√©ponse '{user_text}' contient : {', '.join(provided_parts)}.\n"
        error_message += f"Mais il manque encore : {', '.join(missing_details)}.\n\n"
    else:
        error_message += f"Votre r√©ponse '{user_text}' ne contient pas tous les √©l√©ments n√©cessaires.\n\n"
    
    # Exemples contextuels selon ce qui manque v3.7.7
    error_message += "**Exemples complets requis :**\n"
    
    if len(missing_critical_entities) >= 3:  # Manque breed + age + weight
        error_message += "‚Ä¢ 'Ross 308 m√¢les de 13 jours pesant 800g'\n"
        error_message += "‚Ä¢ 'Cobb 500 femelles de 2 semaines pesant 1.2kg'\n" 
        error_message += "‚Ä¢ 'Hubbard mixte de 25 jours pesant 950g'\n\n"
    elif "breed" in missing_critical_entities and "age" in missing_critical_entities:
        error_message += f"‚Ä¢ 'Ross 308 {sex or 'm√¢les'} de 13 jours'\n"
        error_message += f"‚Ä¢ 'Cobb 500 {sex or 'femelles'} de 2 semaines'\n\n"
    elif "breed" in missing_critical_entities and "weight" in missing_critical_entities:
        error_message += f"‚Ä¢ 'Ross 308 {sex or 'm√¢les'} pesant 800g'\n"
        error_message += f"‚Ä¢ 'Cobb 500 {sex or 'femelles'} pesant 1.2kg'\n\n"
    elif "age" in missing_critical_entities and "weight" in missing_critical_entities:
        error_message += f"‚Ä¢ '{effective_breed or 'Ross 308'} de 13 jours pesant 800g'\n"
        error_message += f"‚Ä¢ '{effective_breed or 'Cobb 500'} de 2 semaines pesant 1.2kg'\n\n"
    elif "breed" in missing_critical_entities:
        error_message += f"‚Ä¢ 'Ross 308 {sex or 'm√¢les'}'\n"
        error_message += f"‚Ä¢ 'Cobb 500 {sex or 'femelles'}'\n\n"
    elif "age" in missing_critical_entities:
        error_message += f"‚Ä¢ '{effective_breed or 'Ross 308'} de 13 jours'\n"
        error_message += f"‚Ä¢ '{effective_breed or 'Cobb 500'} de 2 semaines'\n\n"
    elif "weight" in missing_critical_entities:
        error_message += f"‚Ä¢ '{effective_breed or 'Ross 308'} pesant 800g'\n"
        error_message += f"‚Ä¢ '{effective_breed or 'Cobb 500'} pesant 1.2kg'\n\n"
    
    error_message += "Pouvez-vous pr√©ciser les informations manquantes ?"
    
    # üîß FIX: Retourner erreur clarification incompl√®te avec validation robuste v3.7.7
    mode_suffix = "_public" if public else ""
    conversation_id = getattr(request_data, 'conversation_id', None)
    if not conversation_id:
        conversation_id = str(uuid.uuid4())
    
    language = getattr(request_data, 'language', 'fr')
    if not isinstance(language, str):
        language = 'fr'
    
    logger.info(f"üìã [CLARIFICATION INCOMPL√àTE v3.7.7] Entit√©s critiques manquantes: {missing_critical_entities}")
    logger.info(f"üìã [CLARIFICATION INCOMPL√àTE v3.7.7] Entit√©s extraites automatiquement: {extracted_entities}")
    
    return EnhancedExpertResponse(
        question=user_text,
        response=error_message,
        conversation_id=conversation_id,
        rag_used=False,  # üÜï v3.7.6/v3.7.7: Toujours False pour clarification incompl√®te
        rag_score=None,
        timestamp=datetime.now().isoformat(),
        language=language,
        response_time_ms=int((time.time() - start_time) * 1000),
        mode=f"incomplete_clarification_response_v3.7.7{mode_suffix}",
        user=None,
        logged=True,
        validation_passed=False,
        # üöÄ NOUVEAUX CHAMPS v3.7.6/v3.7.7 POUR CLARIFICATION INCOMPL√àTE
        clarification_required_critical=True,
        missing_critical_entities=missing_critical_entities,
        variants_tested=[],  # vide pour clarification incompl√®te
        clarification_result={
            "clarification_requested": True,
            "clarification_type": f"incomplete_critical_entities_retry_v3.7.7{mode_suffix}",
            "missing_information": missing_info,
            "provided_entities": clarified_entities,
            "provided_parts": provided_parts,
            "missing_details": missing_details,
            "retry_required": True,
            "confidence": 0.3,
            # üöÄ NOUVEAUX CHAMPS DANS CLARIFICATION_RESULT v3.7.6/v3.7.7
            "clarification_required_critical": True,
            "missing_critical_entities": missing_critical_entities,
            # üÜï v3.7.7: Ajouter entit√©s extraites automatiquement
            "auto_extracted_entities": extracted_entities,
            "effective_breed": effective_breed,
            "critical_entities_analysis": {
                "breed_detected": effective_breed,
                "age_detected": extracted_age,
                "weight_detected": extracted_weight,
                "sex_detected": sex
            }
        },
        processing_steps=[
            f"incomplete_clarification_detected_v3.7.7{mode_suffix}", 
            "critical_entities_extraction_attempted",
            "retry_requested_with_critical_entities"
        ],
        ai_enhancements_used=[
            f"incomplete_clarification_handling_v3.7.7{mode_suffix}",
            "critical_entities_extraction_v3.7.7",
            "adaptive_clarification_message"
        ],
        response_versions=None  # Pas de response_versions pour erreurs
    )

async def _fallback_expert_response(
    request_data: EnhancedQuestionRequest, 
    start_time: float, 
    current_user: Optional[Dict[str, Any]] = None,
    error_message: str = "Service expert temporairement indisponible"
) -> EnhancedExpertResponse:
    """üîß CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.7: R√©ponse de fallback avec entit√©s critiques"""
    
    logger.info("üîÑ [Fallback v3.7.7] G√©n√©ration r√©ponse de fallback avec entit√©s critiques")
    
    # üîß FIX: Validation des param√®tres d'entr√©e
    user_text = getattr(request_data, 'text', 'Question non sp√©cifi√©e')
    if not isinstance(user_text, str):
        user_text = str(user_text)
    
    language = getattr(request_data, 'language', 'fr')
    if not isinstance(language, str):
        language = 'fr'
    
    # üîß FIX: Protection contre error_message None
    if not error_message or not isinstance(error_message, str):
        error_message = "Service expert temporairement indisponible"
    
    # üÜï v3.7.7: M√™me en mode fallback, essayer d'extraire entit√©s critiques
    try:
        entities = _extract_critical_entities_from_question(user_text, language)
        entities_info = f"Entit√©s d√©tect√©es: {entities.get('breed', 'N/A')}, {entities.get('age', 'N/A')}, {entities.get('weight', 'N/A')}"
    except Exception as e:
        logger.error(f"‚ùå [Fallback v3.7.7] Erreur extraction entit√©s: {e}")
        entities = {}
        entities_info = "Entit√©s non analys√©es"
    
    fallback_responses = {
        "fr": f"Je m'excuse, {error_message}. Votre question '{user_text}' a √©t√© re√ßue ({entities_info}) mais je ne peux pas la traiter actuellement. Veuillez r√©essayer dans quelques minutes.",
        "en": f"I apologize, {error_message}. Your question '{user_text}' was received ({entities_info}) but I cannot process it currently. Please try again in a few minutes.",
        "es": f"Me disculpo, {error_message}. Su pregunta '{user_text}' fue recibida ({entities_info}) pero no puedo procesarla actualmente. Por favor intente de nuevo en unos minutos."
    }
    
    response_text = fallback_responses.get(language, fallback_responses['fr'])
    
    # üîß FIX: Validation conversation_id
    conversation_id = getattr(request_data, 'conversation_id', None)
    if not conversation_id:
        conversation_id = str(uuid.uuid4())
    
    # üîß FIX: Validation current_user
    user_email = None
    if current_user and isinstance(current_user, dict):
        user_email = current_user.get("email")
    
    return EnhancedExpertResponse(
        question=user_text,
        response=response_text,
        conversation_id=conversation_id,
        rag_used=False,  # üÜï v3.7.6/v3.7.7: Toujours False pour fallback
        rag_score=None,
        timestamp=datetime.now().isoformat(),
        language=language,
        response_time_ms=int((time.time() - start_time) * 1000),
        mode="fallback_service_unavailable_v3.7.7",
        user=user_email,
        logged=False,
        validation_passed=False,
        # üöÄ NOUVEAUX CHAMPS v3.7.6/v3.7.7 POUR FALLBACK
        clarification_required_critical=False,
        missing_critical_entities=[],
        variants_tested=[],
        processing_steps=[
            "service_unavailable", 
            "fallback_response_generated_v3.7.7",
            "critical_entities_attempted" if entities else "critical_entities_failed"
        ],
        ai_enhancements_used=[
            "fallback_handling_v3.7.7",
            "entities_extraction_attempted" if entities else "entities_extraction_failed"
        ],
        response_versions=None
    )

# =============================================================================
# CONFIGURATION FINALE v3.7.7 AVEC CORRECTIONS RAG + ENTIT√âS CRITIQUES üîß
# =============================================================================

logger.info("üîß" * 50)
logger.info("üîß [EXPERT ENDPOINTS MAIN] VERSION 3.7.7 - CORRECTIONS RAG + VALIDATION ENTIT√âS CRITIQUES!")
logger.info("üîß [NOUVELLES CORRECTIONS v3.7.7]:")
logger.info("   ‚úÖ Synchronisation RAG appel√©e juste apr√®s r√©cup√©ration RAG")
logger.info("   ‚úÖ Clarification forc√©e si entit√©s critiques (breed, age, weight) manquent")
logger.info("   ‚úÖ Validation robuste des entit√©s critiques avec extraction automatique")
logger.info("   ‚úÖ D√©clenchement clarification_required_critical=True pour entit√©s manquantes")
logger.info("   ‚úÖ D√©tection entit√©s critiques depuis le texte de la question")
logger.info("")
logger.info("üîß [NOUVELLES FONCTIONS v3.7.7]:")
logger.info("   ‚úÖ _extract_critical_entities_from_question() - Extraction breed/age/weight")
logger.info("   ‚úÖ _validate_critical_entities() - Validation entit√©s avec priorit√© clarification")
logger.info("   ‚úÖ _force_clarification_for_missing_entities() - For√ßage clarification automatique")
logger.info("   ‚úÖ Extraction avanc√©e avec regex patterns pour Ross 308, Cobb 500, etc.")
logger.info("   ‚úÖ Conversion automatique √¢ge en jours, poids en grammes")
logger.info("   ‚úÖ Scoring de confiance par entit√© extraite")
logger.info("")
logger.info("üîß [CORRECTIONS RAG STATE v3.7.7]:")
logger.info("   ‚úÖ _validate_and_sync_rag_state() appel√©e IMM√âDIATEMENT apr√®s service")
logger.info("   ‚úÖ _force_sync_rag_state() avec logging d√©taill√© pour tra√ßabilit√©")
logger.info("   ‚úÖ Synchronisation forc√©e rag_used selon validation r√©elle")
logger.info("   ‚úÖ Mise √† jour mode avec/sans RAG selon utilisation effective")
logger.info("   ‚úÖ Propagation m√©tadonn√©es RAG dans processing_steps")
logger.info("")
logger.info("üîß [ENTIT√âS CRITIQUES SUPPORT√âES v3.7.7]:")
logger.info("   ‚úÖ BREED: Ross 308, Cobb 500, Hubbard, Arbor Acres, ISA Brown, etc.")
logger.info("   ‚úÖ AGE: 13j, 2sem, 3 weeks ‚Üí conversion automatique en jours")
logger.info("   ‚úÖ WEIGHT: 800g, 1.2kg, 2.5lb ‚Üí conversion automatique en grammes")
logger.info("   ‚úÖ SEX: m√¢les, femelles, mixte (bonus feature)")
logger.info("   ‚úÖ COHERENCE: validation √¢ge/poids, d√©tection aberrations")
logger.info("   ‚úÖ CONFIDENCE: scoring 0.0-1.0 par entit√© extraite")
logger.info("")
logger.info("üîß [LOGIQUE CLARIFICATION ENTIT√âS v3.7.7]:")
logger.info("   ‚úÖ Priorit√© CRITICAL si 2+ entit√©s critiques manquent")
logger.info("   ‚úÖ Priorit√© HIGH si 1 entit√© manque + incoh√©rences")
logger.info("   ‚úÖ Priorit√© MEDIUM si 1 entit√© manque ou g√©n√©rique")
logger.info("   ‚úÖ Priorit√© LOW si incoh√©rences ou confiance faible")
logger.info("   ‚úÖ clarification_required_critical=True pour HIGH/CRITICAL")
logger.info("   ‚úÖ missing_critical_entities=[breed, age, weight] selon manques")
logger.info("")
logger.info("üîß [AM√âLIORATIONS MESSAGES v3.7.7]:")
logger.info("   ‚úÖ Messages adaptatifs selon entit√©s manquantes sp√©cifiques")
logger.info("   ‚úÖ Exemples contextuels avec race/√¢ge/poids d√©tect√©s")
logger.info("   ‚úÖ Feedback pr√©cis sur ce qui a √©t√© compris vs manquant")
logger.info("   ‚úÖ Support fallback avec tentative extraction entit√©s")
logger.info("")
logger.info("üîß [FONCTIONNALIT√âS CONSERV√âES v3.7.6]:")
logger.info("   ‚úÖ Toute la logique originale v3.7.6 maintenue")
logger.info("   ‚úÖ D√©tection incoh√©rences temporelles (13j vs 1sem)")
logger.info("   ‚úÖ Propagation compl√®te nouveaux champs")
logger.info("   ‚úÖ Support response_versions et concision_level")
logger.info("   ‚úÖ Messages adaptatifs clarification granulaire")
logger.info("   ‚úÖ M√©tadonn√©es enrichies compl√®tes")
logger.info("")
logger.info("üéØ [STATUS v3.7.7]:")
logger.info(f"   - Expert Service: {'‚úÖ Disponible' if expert_service else '‚ùå Non disponible'}")
logger.info(f"   - Models: {'‚úÖ Import√©s' if MODELS_IMPORTED else '‚ùå Fallback'}")
logger.info(f"   - Utils: {'‚úÖ Disponibles' if UTILS_AVAILABLE else '‚ùå Fallback'}")
logger.info("   ‚úÖ PR√äT POUR PRODUCTION - RAG SYNC + ENTIT√âS CRITIQUES VALID√âES")
logger.info("   ‚úÖ ENDPOINT PERFORMANCES: Extraction entit√©s < 100ms")
logger.info("   ‚úÖ QUALIT√â CLARIFICATION: Messages adaptatifs selon entit√©s manquantes")
logger.info("üîß" * 50)