"""
ai_response_generator.py - G√âN√âRATION DE R√âPONSES AVEC IA

üéØ REMPLACE: 400+ templates hardcod√©s par g√©n√©ration IA intelligente
üöÄ CAPACIT√âS:
- ‚úÖ G√©n√©ration contextuelle bas√©e sur entit√©s fusionn√©es
- ‚úÖ R√©ponses pr√©cises avec donn√©es de poids calcul√©es
- ‚úÖ Adaptation automatique au niveau technique utilisateur
- ‚úÖ Support multilingue natif
- ‚úÖ Int√©gration seamless des weight_data du classifier
- ‚úÖ Templates d'urgence comme fallback

Architecture:
- Prompts sp√©cialis√©s par type de r√©ponse
- G√©n√©ration adapt√©e au contexte utilisateur  
- Int√©gration des donn√©es techniques (poids, seuils)
- Validation qualit√© automatique
- Fallback robuste vers templates
"""

import json
import logging
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass
from datetime import datetime

from .ai_service_manager import AIServiceType, call_ai, AIResponse

logger = logging.getLogger(__name__)

@dataclass
class ResponseData:
    """Structure d'une r√©ponse g√©n√©r√©e"""
    content: str
    response_type: str
    confidence: float
    reasoning: str = ""
    weight_data_used: bool = False
    language: str = "fr"
    generation_method: str = "ai"  # ai, template, hybrid
    
    # M√©triques qualit√©
    word_count: int = 0
    technical_level: str = "intermediate"
    includes_recommendations: bool = False
    includes_values: bool = False
    
    def __post_init__(self):
        self.word_count = len(self.content.split()) if self.content else 0
        self.includes_recommendations = "conseil" in self.content.lower() or "recommand" in self.content.lower()
        self.includes_values = any(char.isdigit() for char in self.content)

class AIResponseGenerator:
    """G√©n√©rateur de r√©ponses avec IA - Remplace les templates hardcod√©s"""
    
    def __init__(self):
        # Configuration des mod√®les par type de r√©ponse
        self.models = {
            "contextual": "gpt-4",        # R√©ponses contextuelles pr√©cises
            "general": "gpt-4",           # R√©ponses g√©n√©rales
            "clarification": "gpt-3.5-turbo",  # Clarifications simples
            "technical": "gpt-4",         # R√©ponses techniques avanc√©es
            "multilingual": "gpt-4"       # Support multilingue
        }
        
        # Prompts sp√©cialis√©s
        self.prompts = self._initialize_prompts()
        
        # Templates d'urgence (fallback minimal)
        self.emergency_templates = self._initialize_emergency_templates()
        
        # Crit√®res de qualit√©
        self.quality_thresholds = {
            "min_word_count": 30,
            "max_word_count": 400,
            "min_confidence": 0.6,
            "required_elements": ["practical_info", "professional_tone"]
        }
        
        logger.info("ü§ñ [AI Response Generator] Initialis√© avec g√©n√©ration IA avanc√©e")
    
    def _initialize_prompts(self) -> Dict[str, str]:
        """Initialise les prompts sp√©cialis√©s par type de r√©ponse"""
        return {
            "contextual_precise": """Tu es un v√©t√©rinaire avicole expert. G√©n√®re une r√©ponse pr√©cise et professionnelle.

QUESTION: "{question}"

ENTIT√âS FUSIONN√âES:
{merged_entities}

DONN√âES DE POIDS CALCUL√âES:
{weight_data}

CONTEXTE: Cette question fait suite √† une conversation o√π l'utilisateur a fourni des clarifications.

INSTRUCTIONS:
1. **UTILISE les donn√©es de poids** pour donner des valeurs pr√©cises
2. **R√âPONDS de mani√®re directe** - l'utilisateur a d√©j√† pr√©cis√© sa question
3. **INCLUS des fourchettes** avec les seuils d'alerte
4. **DONNE des conseils pratiques** de surveillance
5. **RESTE concis** mais complet (150-250 mots)

STRUCTURE ATTENDUE:
- R√©ponse directe √† la question
- Fourchette de poids normale avec seuils
- Conseils de surveillance pratiques
- Recommandations si n√©cessaire

EXEMPLE DE R√âPONSE:
"üéØ **Ross 308 m√¢le √† 10 jours : 187-235g**

**Fourchette normale :** 190-235g (avec bonus m√¢le +12%)
**Seuils d'alerte :** 
‚Ä¢ < 187g : Surveillance renforc√©e recommand√©e
‚Ä¢ > 270g : Croissance excessive possible

**Conseils pratiques :**
‚Ä¢ Pes√©e d'√©chantillon (10-15 sujets) pour v√©rifier l'homog√©n√©it√©
‚Ä¢ Contr√¥le quotidien de l'app√©tit et de l'activit√©
‚Ä¢ Ajustement alimentaire si √©carts persistants

Cette fourchette correspond aux standards Ross 308 pour cette race √† croissance rapide."

G√©n√®re maintenant ta r√©ponse professionnelle:""",

            "general_informative": """Tu es un v√©t√©rinaire avicole expert qui g√©n√®re des r√©ponses g√©n√©rales utiles et professionnelles.

QUESTION: "{question}"

ENTIT√âS DISPONIBLES:
{entities}

CONTEXTE: Question g√©n√©rale n√©cessitant informations pratiques avec standards.

INSTRUCTIONS:
1. **FOURNIS des informations pratiques** avec fourchettes de valeurs
2. **INCLUS les variations** selon race, √¢ge, sexe
3. **DONNE des conseils concrets** de gestion
4. **RESTE accessible** mais professionnel
5. **PROPOSE pr√©cision** si informations manquantes

STRUCTURE:
- R√©ponse informative g√©n√©rale
- Fourchettes de valeurs standards  
- Facteurs de variation (race, √¢ge, sexe)
- Conseils pratiques
- Offre de pr√©cision si plus d'infos

EXEMPLE:
"**Poids des poulets √† 10 jours :**

üìä **Fourchettes g√©n√©rales** :
‚Ä¢ **Races lourdes** (Ross 308, Cobb 500) : 170-210g
‚Ä¢ **Races standard** : 150-190g
‚Ä¢ **Races pondeuses** : 130-170g

‚öñÔ∏è **Variations importantes** :
‚Ä¢ **M√¢les** : +10-15% par rapport aux moyennes
‚Ä¢ **Femelles** : -10-15% par rapport aux moyennes

üéØ **Surveillance recommand√©e** :
‚Ä¢ Pes√©e hebdomadaire d'√©chantillon repr√©sentatif
‚Ä¢ Contr√¥le homog√©n√©it√© du troupeau
‚Ä¢ Ajustement alimentaire selon √©volution

üí° **Pour une r√©ponse plus pr√©cise**, pr√©cisez la race et le sexe de vos animaux."

G√©n√®re maintenant ta r√©ponse:""",

            "clarification_request": """Tu es un expert avicole qui guide l'utilisateur pour obtenir les informations n√©cessaires.

QUESTION INCOMPL√àTE: "{question}"

ENTIT√âS MANQUANTES: {missing_entities}

CONTEXTE: L'utilisateur a pos√© une question o√π je peux donner une r√©ponse utile m√™me partielle.

INSTRUCTIONS:
1. **DONNE D'ABORD UNE R√âPONSE UTILE** bas√©e sur les informations disponibles
2. **PUIS DEMANDE pr√©cisions** pour affiner la r√©ponse
3. **GUIDE CONCR√àTEMENT** avec exemples
4. **RESTE POSITIF** et professionnel
5. **STRUCTURE CLAIRE** : r√©ponse utile + demande pr√©cisions

STRUCTURE OBLIGATOIRE:
- R√©ponse informative g√©n√©rale bas√©e sur la question
- Fourchettes ou conseils g√©n√©raux applicables
- Puis demande de pr√©cisions pour affiner
- Exemples concrets de pr√©cisions utiles

EXEMPLE:
"**Poids des poulets √† 6 jours :**

Pour un poulet de 6 jours, le poids varie g√©n√©ralement entre 80-120g selon la race et le sexe. Les races de chair (Ross 308, Cobb 500) sont plus lourdes (90-130g) que les races pondeuses (70-100g).

**Pour une r√©ponse plus pr√©cise**, pr√©cisez :
‚Ä¢ **Race/souche** : Ross 308, Cobb 500, Hubbard, etc.
‚Ä¢ **Sexe** : M√¢les, femelles, ou troupeau mixte

Ces informations me permettront de vous donner des fourchettes de poids sp√©cifiques √† votre situation."

G√©n√®re maintenant ta r√©ponse avec information utile + demande pr√©cisions:""",

            "technical_detailed": """Tu es un v√©t√©rinaire avicole expert fournissant une r√©ponse technique approfondie.

QUESTION TECHNIQUE: "{question}"

ENTIT√âS: {entities}

CONTEXTE: Question n√©cessitant une expertise technique avanc√©e.

INSTRUCTIONS:
1. **NIVEAU EXPERT** - utilise terminologie professionnelle
2. **D√âTAILS TECHNIQUES** - m√©canismes, causes, solutions
3. **DONN√âES PR√âCISES** - chiffres, standards, protocoles
4. **R√âF√âRENCES** - mention de bonnes pratiques
5. **RECOMMANDATIONS** - actions concr√®tes

STRUCTURE:
- Analyse technique du probl√®me/question
- Donn√©es et standards professionnels
- M√©canismes/causes sous-jacents
- Recommandations protocoles
- Suivi et monitoring

G√©n√®re une r√©ponse technique approfondie:""",

            "health_emergency": """Tu es un v√©t√©rinaire qui r√©pond √† une situation potentiellement urgente.

QUESTION SANT√â: "{question}"

SYMPT√îMES: {symptoms}

CONTEXTE: Possible probl√®me de sant√© n√©cessitant attention.

INSTRUCTIONS:
1. **URGENCE** - √©value le niveau de priorit√©
2. **CONSEILS IMM√âDIATS** - actions √† prendre rapidement
3. **SIGNAUX D'ALARME** - quand consulter d'urgence
4. **MESURES** - isolement, traitement symptomatique
5. **CONSULTATION** - recommande suivi v√©t√©rinaire

STRUCTURE:
- √âvaluation urgence
- Actions imm√©diates
- Signaux d'alarme
- Mesures conservatoires
- Recommandation consultation

‚ö†Ô∏è **IMPORTANT**: Recommande TOUJOURS consultation v√©t√©rinaire pour probl√®mes de sant√©.

G√©n√®re une r√©ponse orient√©e sant√©:"""
        }
    
    def _initialize_emergency_templates(self) -> Dict[str, str]:
        """Templates d'urgence en cas d'√©chec IA"""
        return {
            "fr": {
                "general": "Pour votre question sur l'√©levage avicole, les standards varient selon la race, l'√¢ge et le sexe des animaux. Je recommande de consulter un sp√©cialiste avicole ou un v√©t√©rinaire pour des conseils personnalis√©s √† votre situation sp√©cifique.",
                "performance": "Les performances d'√©levage d√©pendent de nombreux facteurs : race, √¢ge, sexe, conditions d'√©levage. Les fourchettes g√©n√©rales varient significativement. Pour une r√©ponse pr√©cise, pr√©cisez ces √©l√©ments ou consultez un technicien avicole.",
                "health": "Pour tout probl√®me de sant√© de vos volailles, je recommande fortement de consulter un v√©t√©rinaire rapidement. Les sympt√¥mes peuvent √©voluer vite et n√©cessiter un diagnostic professionnel et un traitement adapt√©."
            },
            "en": {
                "general": "For your poultry farming question, standards vary by breed, age and sex. I recommend consulting a poultry specialist or veterinarian for advice tailored to your specific situation.",
                "performance": "Performance standards depend on many factors: breed, age, sex, housing conditions. General ranges vary significantly. For precise information, specify these elements or consult a poultry technician.",
                "health": "For any health issues with your poultry, I strongly recommend consulting a veterinarian promptly. Symptoms can evolve quickly and require professional diagnosis and appropriate treatment."
            }
        }
    
    async def generate_contextual_response(self, 
                                         question: str,
                                         merged_entities: Dict[str, Any],
                                         weight_data: Dict[str, Any] = None,
                                         conversation_context: str = "",
                                         language: str = "fr") -> ResponseData:
        """
        G√©n√®re une r√©ponse contextuelle pr√©cise avec donn√©es de poids
        
        Args:
            question: Question de l'utilisateur (possiblement enhanced)
            merged_entities: Entit√©s fusionn√©es du contexte
            weight_data: Donn√©es de poids calcul√©es par le classifier
            conversation_context: Contexte conversationnel
            language: Langue de g√©n√©ration
            
        Returns:
            ResponseData avec r√©ponse g√©n√©r√©e
        """
        try:
            logger.info(f"ü§ñ [AI Response Generator] G√©n√©ration contextuelle: '{question[:50]}...'")
            
            # Pr√©parer les donn√©es pour le prompt
            entities_str = json.dumps(merged_entities, ensure_ascii=False, indent=2)
            weight_str = json.dumps(weight_data or {}, ensure_ascii=False, indent=2) if weight_data else "Aucune donn√©e de poids disponible"
            
            # Choisir le prompt selon le contenu
            if weight_data and weight_data.get("weight_range"):
                prompt_template = self.prompts["contextual_precise"]
            else:
                prompt_template = self.prompts["general_informative"]
            
            # Construire le prompt final
            prompt = prompt_template.format(
                question=question,
                merged_entities=entities_str,
                weight_data=weight_str
            )
            
            # Appel IA pour g√©n√©ration
            ai_response = await call_ai(
                service_type=AIServiceType.RESPONSE_GENERATION,
                prompt=prompt,
                model=self.models["contextual"],
                max_tokens=600,
                temperature=0.3,  # Cr√©ativit√© mod√©r√©e pour r√©ponses naturelles
                cache_key=f"contextual_response_{hash(question + entities_str)}"
            )
            
            # Valider la qualit√© de la r√©ponse
            response_content = ai_response.content.strip()
            quality_score = self._assess_response_quality(response_content, weight_data)
            
            # Construire ResponseData
            response_data = ResponseData(
                content=response_content,
                response_type="contextual_answer",
                confidence=quality_score,
                reasoning="R√©ponse contextuelle g√©n√©r√©e avec IA",
                weight_data_used=bool(weight_data),
                language=language,
                generation_method="ai",
                technical_level=self._detect_technical_level(merged_entities)
            )
            
            logger.info(f"‚úÖ [AI Response Generator] R√©ponse contextuelle g√©n√©r√©e: {quality_score:.2f} qualit√©, {response_data.word_count} mots")
            
            return response_data
            
        except Exception as e:
            logger.error(f"‚ùå [AI Response Generator] Erreur g√©n√©ration contextuelle: {e}")
            return self._generate_emergency_response(question, "contextual", language, str(e))
    
    async def generate_general_response(self,
                                      question: str,
                                      entities: Dict[str, Any],
                                      missing_entities: List[str] = None,
                                      language: str = "fr") -> ResponseData:
        """
        G√©n√®re une r√©ponse g√©n√©rale informative avec offre de pr√©cision
        
        Args:
            question: Question de l'utilisateur
            entities: Entit√©s extraites disponibles
            missing_entities: Entit√©s manquantes pour pr√©cision
            language: Langue de g√©n√©ration
            
        Returns:
            ResponseData avec r√©ponse g√©n√©rale
        """
        try:
            logger.info(f"ü§ñ [AI Response Generator] G√©n√©ration g√©n√©rale: '{question[:50]}...'")
            
            # Pr√©parer les donn√©es
            entities_str = json.dumps(entities, ensure_ascii=False, indent=2)
            
            # Construire le prompt
            prompt = self.prompts["general_informative"].format(
                question=question,
                entities=entities_str
            )
            
            # G√©n√©ration IA
            ai_response = await call_ai(
                service_type=AIServiceType.RESPONSE_GENERATION,
                prompt=prompt,
                model=self.models["general"],
                max_tokens=500,
                temperature=0.3,
                cache_key=f"general_response_{hash(question + entities_str)}"
            )
            
            # √âvaluer qualit√©
            response_content = ai_response.content.strip()
            quality_score = self._assess_response_quality(response_content)
            
            response_data = ResponseData(
                content=response_content,
                response_type="general_answer",
                confidence=quality_score,
                reasoning="R√©ponse g√©n√©rale avec informations pratiques",
                language=language,
                generation_method="ai"
            )
            
            logger.info(f"‚úÖ [AI Response Generator] R√©ponse g√©n√©rale g√©n√©r√©e: {quality_score:.2f} qualit√©")
            
            return response_data
            
        except Exception as e:
            logger.error(f"‚ùå [AI Response Generator] Erreur g√©n√©ration g√©n√©rale: {e}")
            return self._generate_emergency_response(question, "general", language, str(e))
    
    async def generate_clarification_request(self,
                                           question: str,
                                           missing_entities: List[str],
                                           available_entities: Dict[str, Any] = None,
                                           language: str = "fr") -> ResponseData:
        """
        G√©n√®re une demande de clarification guid√©e
        
        Args:
            question: Question originale incompl√®te
            missing_entities: Entit√©s manquantes
            available_entities: Entit√©s d√©j√† disponibles
            language: Langue de g√©n√©ration
            
        Returns:
            ResponseData avec clarification
        """
        try:
            logger.info(f"ü§ñ [AI Response Generator] G√©n√©ration clarification: manquants={missing_entities}")
            
            # Pr√©parer les donn√©es
            missing_str = ", ".join(missing_entities) if missing_entities else "informations contextuelles"
            
            # Construire le prompt
            prompt = self.prompts["clarification_request"].format(
                question=question,
                missing_entities=missing_str
            )
            
            # G√©n√©ration IA
            ai_response = await call_ai(
                service_type=AIServiceType.RESPONSE_GENERATION,
                prompt=prompt,
                model=self.models["clarification"],
                max_tokens=400,
                temperature=0.2,  # Plus conservateur pour clarifications
                cache_key=f"clarification_{hash(question + missing_str)}"
            )
            
            response_content = ai_response.content.strip()
            quality_score = self._assess_clarification_quality(response_content)
            
            response_data = ResponseData(
                content=response_content,
                response_type="needs_clarification",
                confidence=quality_score,
                reasoning="Clarification guid√©e g√©n√©r√©e avec IA",
                language=language,
                generation_method="ai"
            )
            
            logger.info(f"‚úÖ [AI Response Generator] Clarification g√©n√©r√©e: {quality_score:.2f} qualit√©")
            
            return response_data
            
        except Exception as e:
            logger.error(f"‚ùå [AI Response Generator] Erreur g√©n√©ration clarification: {e}")
            return self._generate_emergency_response(question, "clarification", language, str(e))
    
    async def generate_health_response(self,
                                     question: str,
                                     symptoms: List[str],
                                     entities: Dict[str, Any] = None,
                                     language: str = "fr") -> ResponseData:
        """
        G√©n√®re une r√©ponse sp√©cialis√©e sant√© avec recommandations
        
        Args:
            question: Question de sant√©
            symptoms: Sympt√¥mes identifi√©s
            entities: Entit√©s contextuelles
            language: Langue de g√©n√©ration
            
        Returns:
            ResponseData avec r√©ponse sant√©
        """
        try:
            logger.info(f"ü§ñ [AI Response Generator] G√©n√©ration sant√©: {len(symptoms)} sympt√¥mes")
            
            # Pr√©parer les donn√©es
            symptoms_str = ", ".join(symptoms) if symptoms else "sympt√¥mes non sp√©cifi√©s"
            
            # Construire le prompt
            prompt = self.prompts["health_emergency"].format(
                question=question,
                symptoms=symptoms_str
            )
            
            # G√©n√©ration IA avec mod√®le expert
            ai_response = await call_ai(
                service_type=AIServiceType.RESPONSE_GENERATION,
                prompt=prompt,
                model=self.models["technical"],
                max_tokens=500,
                temperature=0.1,  # Tr√®s conservateur pour sant√©
                cache_key=f"health_response_{hash(question + symptoms_str)}"
            )
            
            response_content = ai_response.content.strip()
            
            # V√©rifier que la r√©ponse recommande consultation v√©t√©rinaire
            if "v√©t√©rinaire" not in response_content.lower() and "veterinarian" not in response_content.lower():
                response_content += "\n\n‚ö†Ô∏è **Important** : Consultez un v√©t√©rinaire pour tout probl√®me de sant√© persistant ou grave."
            
            quality_score = self._assess_response_quality(response_content)
            
            response_data = ResponseData(
                content=response_content,
                response_type="health_advice",
                confidence=quality_score,
                reasoning="R√©ponse sant√© avec recommandation v√©t√©rinaire",
                language=language,
                generation_method="ai",
                technical_level="expert"
            )
            
            logger.info(f"‚úÖ [AI Response Generator] R√©ponse sant√© g√©n√©r√©e: {quality_score:.2f} qualit√©")
            
            return response_data
            
        except Exception as e:
            logger.error(f"‚ùå [AI Response Generator] Erreur g√©n√©ration sant√©: {e}")
            return self._generate_emergency_response(question, "health", language, str(e))
    
    def _assess_response_quality(self, content: str, weight_data: Dict[str, Any] = None) -> float:
        """√âvalue la qualit√© d'une r√©ponse g√©n√©r√©e"""
        
        if not content or len(content.strip()) < 20:
            return 0.0
        
        quality_score = 0.7  # Base
        
        # Longueur appropri√©e
        word_count = len(content.split())
        if self.quality_thresholds["min_word_count"] <= word_count <= self.quality_thresholds["max_word_count"]:
            quality_score += 0.1
        
        # Contient des valeurs num√©riques (fourchettes, donn√©es)
        if any(char.isdigit() for char in content):
            quality_score += 0.1
        
        # Utilise les donn√©es de poids si disponibles
        if weight_data and weight_data.get("weight_range"):
            weight_range = weight_data["weight_range"]
            if str(weight_range[0]) in content and str(weight_range[1]) in content:
                quality_score += 0.2
        
        # Structure professionnelle (emojis, sections)
        if "**" in content or "‚Ä¢" in content or "üìä" in content:
            quality_score += 0.1
        
        # Conseils pratiques
        if any(word in content.lower() for word in ["conseil", "recommand", "surveil", "contr√¥l"]):
            quality_score += 0.1
        
        return min(quality_score, 1.0)
    
    def _assess_clarification_quality(self, content: str) -> float:
        """√âvalue la qualit√© d'une clarification"""
        
        quality_score = 0.6  # Base pour clarifications
        
        # Contient des exemples
        if "exemple" in content.lower() or "ex:" in content.lower():
            quality_score += 0.1
        
        # Guide concr√®tement  
        if "pr√©cis" in content.lower() or "sp√©cifi" in content.lower():
            quality_score += 0.1
        
        # Ton positif (pas de "ne peux pas")
        if "ne peux pas" not in content.lower() and "cannot" not in content.lower():
            quality_score += 0.1
        
        # Structure claire
        if "**" in content and ("‚Ä¢" in content or ":" in content):
            quality_score += 0.1
        
        return min(quality_score, 1.0)
    
    def _detect_technical_level(self, entities: Dict[str, Any]) -> str:
        """D√©tecte le niveau technique requis"""
        
        # Pr√©sence d'entit√©s pr√©cises ‚Üí utilisateur inform√©
        specific_count = sum(1 for v in entities.values() if v is not None)
        
        if specific_count >= 3:
            return "advanced"
        elif specific_count >= 1:
            return "intermediate"
        else:
            return "beginner"
    
    def _generate_emergency_response(self, question: str, response_type: str, language: str, error: str) -> ResponseData:
        """G√©n√®re une r√©ponse d'urgence en cas d'√©chec IA"""
        
        templates = self.emergency_templates.get(language, self.emergency_templates["fr"])
        
        # Choisir template selon type
        if "sant√©" in question.lower() or "health" in question.lower() or response_type == "health":
            template_key = "health"
        elif any(word in question.lower() for word in ["poids", "croissance", "performance", "weight"]):
            template_key = "performance"
        else:
            template_key = "general"
        
        emergency_content = templates.get(template_key, templates["general"])
        
        return ResponseData(
            content=emergency_content,
            response_type=response_type,
            confidence=0.3,
            reasoning=f"R√©ponse d'urgence - Erreur IA: {error}",
            language=language,
            generation_method="emergency_template"
        )
    
    def get_generation_stats(self) -> Dict[str, Any]:
        """Statistiques de g√©n√©ration pour monitoring"""
        from .ai_service_manager import get_ai_service_manager
        
        manager = get_ai_service_manager()
        health = manager.get_service_health()
        
        return {
            "service_name": "AI Response Generator",
            "generation_requests": health.get("requests_by_service", {}).get("response_generation", 0),
            "models_available": list(self.models.keys()),
            "response_types": ["contextual_answer", "general_answer", "needs_clarification", "health_advice"],
            "quality_thresholds": self.quality_thresholds,
            "emergency_templates": {lang: len(templates) for lang, templates in self.emergency_templates.items()},
            "ai_service_health": health
        }

# Instance globale pour utilisation facile
_ai_response_generator = None

def get_ai_response_generator() -> AIResponseGenerator:
    """R√©cup√®re l'instance singleton du g√©n√©rateur IA"""
    global _ai_response_generator
    if _ai_response_generator is None:
        _ai_response_generator = AIResponseGenerator()
    return _ai_response_generator