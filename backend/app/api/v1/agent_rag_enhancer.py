# app/api/v1/agent_rag_enhancer.py
"""
Agent RAG Enhancer - Am√©lioration des r√©ponses apr√®s RAG

üéØ FONCTIONNALIT√âS:
- Adapte les r√©ponses RAG selon le contexte utilisateur
- V√©rifie la coh√©rence entre question enrichie et r√©ponse RAG
- Ajoute des avertissements si informations manquantes
- Propose des clarifications optionnelles
- Am√©liore la lisibilit√© et la pertinence
"""

import os
import logging
import json
import re
from typing import Dict, List, Any, Optional
from datetime import datetime

# Import OpenAI s√©curis√©
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

logger = logging.getLogger(__name__)

class AgentRAGEnhancer:
    """Agent intelligent pour am√©liorer les r√©ponses RAG"""
    
    def __init__(self):
        self.openai_available = OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY')
        self.model = os.getenv('RAG_ENHANCER_MODEL', 'gpt-4o-mini')
        self.timeout = int(os.getenv('RAG_ENHANCER_TIMEOUT', '15'))
        self.max_retries = int(os.getenv('RAG_ENHANCER_RETRIES', '2'))
        
        # Statistiques
        self.stats = {
            "total_requests": 0,
            "openai_success": 0,
            "openai_failures": 0,
            "fallback_used": 0,
            "answers_enhanced": 0,
            "clarifications_generated": 0,
            "coherence_checks": 0,
            "coherence_issues_detected": 0
        }
        
        logger.info(f"üîß [AgentRAGEnhancer] Initialis√©")
        logger.info(f"   OpenAI disponible: {'‚úÖ' if self.openai_available else '‚ùå'}")
        logger.info(f"   Mod√®le: {self.model}")
    
    async def enhance_rag_answer(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        original_question: str = "",
        enriched_question: str = "",  # üÜï Question enrichie par le pr√©-RAG
        language: str = "fr"
    ) -> Dict[str, Any]:
        """
        Am√©liore une r√©ponse RAG avec le contexte utilisateur et v√©rifie la coh√©rence
        
        Args:
            rag_answer: R√©ponse brute du syst√®me RAG
            entities: Entit√©s extraites du contexte
            missing_entities: Entit√©s manquantes critiques
            conversation_context: Contexte conversationnel
            original_question: Question originale pos√©e
            enriched_question: Question enrichie par le pr√©-RAG üÜï
            language: Langue de la conversation
            
        Returns:
            {
                "enhanced_answer": "r√©ponse am√©lior√©e",
                "optional_clarifications": ["question1", "question2"],
                "warnings": ["avertissement1"],
                "confidence_impact": "low/medium/high",
                "coherence_check": "good/partial/poor",  üÜï
                "coherence_notes": "d√©tails sur la coh√©rence",  üÜï
                "method_used": "openai/fallback"
            }
        """
        
        self.stats["total_requests"] += 1
        self.stats["coherence_checks"] += 1
        
        try:
            # Tentative OpenAI si disponible
            if self.openai_available:
                result = await self._enhance_with_openai(
                    rag_answer, entities, missing_entities, conversation_context, 
                    original_question, enriched_question, language
                )
                if result["success"]:
                    self.stats["openai_success"] += 1
                    if result["enhanced_answer"] != rag_answer:
                        self.stats["answers_enhanced"] += 1
                    if result.get("optional_clarifications"):
                        self.stats["clarifications_generated"] += 1
                    if result.get("coherence_check") in ["partial", "poor"]:
                        self.stats["coherence_issues_detected"] += 1
                    return result
                else:
                    self.stats["openai_failures"] += 1
            
            # Fallback: Am√©lioration basique
            logger.info("üîÑ [AgentRAGEnhancer] Utilisation fallback basique")
            result = self._enhance_fallback(
                rag_answer, entities, missing_entities, 
                original_question, enriched_question, language
            )
            self.stats["fallback_used"] += 1
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AgentRAGEnhancer] Erreur critique: {e}")
            return {
                "enhanced_answer": rag_answer,
                "optional_clarifications": [],
                "warnings": [f"Erreur am√©lioration: {str(e)}"],
                "confidence_impact": "unknown",
                "coherence_check": "unknown",
                "coherence_notes": "Impossible de v√©rifier la coh√©rence en raison d'une erreur",
                "method_used": "error_fallback",
                "success": False
            }
    
    async def _enhance_with_openai(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        original_question: str,
        enriched_question: str,  # üÜï
        language: str
    ) -> Dict[str, Any]:
        """Am√©lioration avec OpenAI GPT"""
        
        try:
            # Pr√©parer le contexte pour GPT
            entities_summary = self._format_entities_for_gpt(entities)
            missing_summary = ", ".join(missing_entities) if missing_entities else "Aucune"
            
            # Prompt sp√©cialis√© selon la langue
            system_prompt = self._get_system_prompt(language)
            user_prompt = self._build_enhancement_prompt(
                rag_answer, entities_summary, missing_summary, conversation_context,
                original_question, enriched_question, language  # üÜï
            )
            
            # Appel OpenAI
            client = openai.AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            
            response = await client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1000,  # Augment√© pour inclure la v√©rification de coh√©rence
                timeout=self.timeout
            )
            
            answer = response.choices[0].message.content.strip()
            
            # Parser la r√©ponse JSON
            result = self._parse_gpt_response(answer, rag_answer, entities, missing_entities)
            result["success"] = True
            result["method_used"] = "openai"
            
            logger.info(f"‚úÖ [AgentRAGEnhancer] Am√©lioration OpenAI r√©ussie")
            logger.debug(f"   Clarifications g√©n√©r√©es: {len(result.get('optional_clarifications', []))}")
            logger.debug(f"   Coh√©rence: {result.get('coherence_check', 'unknown')}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AgentRAGEnhancer] Erreur OpenAI: {e}")
            return {"success": False, "error": str(e)}
    
    def _get_system_prompt(self, language: str) -> str:
        """Retourne le prompt syst√®me selon la langue"""
        
        system_prompts = {
            "fr": """Tu es un expert v√©t√©rinaire en aviculture sp√©cialis√© dans l'adaptation de r√©ponses techniques.

Ta mission:
1. V√©rifier la coh√©rence entre la question enrichie et la r√©ponse RAG
2. Adapter la r√©ponse RAG pour qu'elle soit pertinente malgr√© les informations manquantes
3. Ajouter des avertissements si l'absence de donn√©es affecte la pr√©cision
4. Proposer 1-3 questions de clarification pour am√©liorer le conseil
5. Garder un ton professionnel mais accessible
6. Prioriser la s√©curit√© des animaux

V√âRIFICATION DE COH√âRENCE:
- "good": La r√©ponse RAG correspond parfaitement √† la question enrichie
- "partial": La r√©ponse RAG est pertinente mais incompl√®te ou tangentielle
- "poor": La r√©ponse RAG ne correspond pas bien √† la question enrichie

IMPORTANT: 
- Si des informations critiques manquent, le mentionner clairement
- Si la r√©ponse RAG semble hors-sujet, l'adapter ou le signaler
- Proposer des questions de clarification utiles, pas √©videntes
- √âviter les conseils dangereux sans contexte complet
- R√©pondre UNIQUEMENT en JSON avec la structure exacte demand√©e""",
            
            "en": """You are a poultry veterinary expert specialized in adapting technical responses.

Your mission:
1. Verify coherence between enriched question and RAG response
2. Adapt the RAG response to be relevant despite missing information
3. Add warnings if missing data affects accuracy
4. Propose 1-3 clarification questions to improve advice
5. Keep professional but accessible tone
6. Prioritize animal safety

COHERENCE CHECK:
- "good": RAG response perfectly matches the enriched question
- "partial": RAG response is relevant but incomplete or tangential
- "poor": RAG response doesn't match well with the enriched question

IMPORTANT:
- If critical information is missing, mention it clearly
- If RAG response seems off-topic, adapt it or flag it
- Propose useful clarification questions, not obvious ones
- Avoid dangerous advice without complete context
- Respond ONLY in JSON with the exact requested structure""",
            
            "es": """Eres un experto veterinario en avicultura especializado en adaptar respuestas t√©cnicas.

Tu misi√≥n:
1. Verificar la coherencia entre la pregunta enriquecida y la respuesta RAG
2. Adaptar la respuesta RAG para que sea relevante a pesar de la informaci√≥n faltante
3. Agregar advertencias si los datos faltantes afectan la precisi√≥n
4. Proponer 1-3 preguntas de aclaraci√≥n para mejorar el consejo
5. Mantener tono profesional pero accesible
6. Priorizar la seguridad de los animales

VERIFICACI√ìN DE COHERENCIA:
- "good": La respuesta RAG coincide perfectamente con la pregunta enriquecida
- "partial": La respuesta RAG es relevante pero incompleta o tangencial
- "poor": La respuesta RAG no coincide bien con la pregunta enriquecida

IMPORTANTE:
- Si falta informaci√≥n cr√≠tica, mencionarlo claramente
- Si la respuesta RAG parece fuera de tema, adaptarla o se√±alarlo
- Proponer preguntas de aclaraci√≥n √∫tiles, no obvias
- Evitar consejos peligrosos sin contexto completo
- Responder SOLO en JSON con la estructura exacta solicitada"""
        }
        
        return system_prompts.get(language, system_prompts["fr"])
    
    def _build_enhancement_prompt(
        self,
        rag_answer: str,
        entities_summary: str,
        missing_summary: str,
        conversation_context: str,
        original_question: str,
        enriched_question: str,  # üÜï
        language: str
    ) -> str:
        """Construit le prompt d'am√©lioration avec v√©rification de coh√©rence"""
        
        if language == "fr":
            return f"""QUESTION ORIGINALE: "{original_question}"

QUESTION ENRICHIE (g√©n√©r√©e par le pr√©-RAG): "{enriched_question}"

R√âPONSE RAG BRUTE:
"{rag_answer}"

ENTIT√âS CONNUES:
{entities_summary}

ENTIT√âS MANQUANTES CRITIQUES: {missing_summary}

CONTEXTE CONVERSATIONNEL:
{conversation_context}

INSTRUCTIONS:
1. COH√âRENCE: Compare la question enrichie avec la r√©ponse RAG. La r√©ponse traite-t-elle bien le sujet de la question enrichie ?
2. Adapte la r√©ponse pour le contexte sp√©cifique de l'utilisateur
3. Si des informations critiques manquent, ajoute un avertissement et explique l'impact
4. Si la r√©ponse RAG ne correspond pas bien √† la question enrichie, corrige ou signale le probl√®me
5. Am√©liore la lisibilit√© et la structure de la r√©ponse
6. Propose 1-3 questions de clarification pertinentes (pas √©videntes)
7. Garde la pr√©cision technique mais rends accessible

EXEMPLE V√âRIFICATION COH√âRENCE:
Question enrichie: "√âvaluation poids poulet Ross 308, 21 jours, croissance normale ?"
R√©ponse RAG: "Les poulets doivent peser 800g √† 3 semaines"
Coh√©rence: "partial" - r√©pond au poids mais ignore la race sp√©cifique et l'√©valuation de normalit√©

R√©ponds en JSON:
{{
  "enhanced_answer": "r√©ponse adapt√©e et am√©lior√©e",
  "optional_clarifications": ["Question pr√©cise 1?", "Question pr√©cise 2?"],
  "warnings": ["Avertissement si info manquante impacte conseil"],
  "confidence_impact": "low/medium/high selon impact infos manquantes",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "explication d√©taill√©e de la coh√©rence entre question enrichie et r√©ponse RAG",
  "improvement_notes": "explications des am√©liorations apport√©es"
}}"""
        
        elif language == "en":
            return f"""ORIGINAL QUESTION: "{original_question}"

ENRICHED QUESTION (generated by pre-RAG): "{enriched_question}"

RAW RAG RESPONSE:
"{rag_answer}"

KNOWN ENTITIES:
{entities_summary}

MISSING CRITICAL ENTITIES: {missing_summary}

CONVERSATIONAL CONTEXT:
{conversation_context}

INSTRUCTIONS:
1. COHERENCE: Compare enriched question with RAG response. Does the response properly address the enriched question's topic?
2. Adapt response for user's specific context
3. If critical information missing, add warning and explain impact
4. If RAG response doesn't match well with enriched question, correct or flag the issue
5. Improve readability and structure of response
6. Propose 1-3 relevant clarification questions (not obvious ones)
7. Keep technical accuracy but make accessible

EXAMPLE COHERENCE CHECK:
Enriched question: "Ross 308 chicken weight evaluation, 21 days, normal growth?"
RAG response: "Chickens should weigh 800g at 3 weeks"
Coherence: "partial" - addresses weight but ignores specific breed and normality evaluation

Respond in JSON:
{{
  "enhanced_answer": "adapted and improved response",
  "optional_clarifications": ["Specific question 1?", "Specific question 2?"],
  "warnings": ["Warning if missing info impacts advice"],
  "confidence_impact": "low/medium/high based on missing info impact",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "detailed explanation of coherence between enriched question and RAG response",
  "improvement_notes": "explanations of improvements made"
}}"""
        
        else:  # Spanish
            return f"""PREGUNTA ORIGINAL: "{original_question}"

PREGUNTA ENRIQUECIDA (generada por pre-RAG): "{enriched_question}"

RESPUESTA RAG BRUTA:
"{rag_answer}"

ENTIDADES CONOCIDAS:
{entities_summary}

ENTIDADES CR√çTICAS FALTANTES: {missing_summary}

CONTEXTO CONVERSACIONAL:
{conversation_context}

INSTRUCCIONES:
1. COHERENCIA: Compara la pregunta enriquecida con la respuesta RAG. ¬øLa respuesta aborda adecuadamente el tema de la pregunta enriquecida?
2. Adapta la respuesta para el contexto espec√≠fico del usuario
3. Si falta informaci√≥n cr√≠tica, agrega advertencia y explica el impacto
4. Si la respuesta RAG no coincide bien con la pregunta enriquecida, corrige o se√±ala el problema
5. Mejora la legibilidad y estructura de la respuesta
6. Propone 1-3 preguntas de aclaraci√≥n relevantes (no obvias)
7. Mant√©n precisi√≥n t√©cnica pero hazla accesible

EJEMPLO VERIFICACI√ìN COHERENCIA:
Pregunta enriquecida: "Evaluaci√≥n peso pollo Ross 308, 21 d√≠as, crecimiento normal?"
Respuesta RAG: "Los pollos deben pesar 800g a las 3 semanas"
Coherencia: "partial" - aborda el peso pero ignora la raza espec√≠fica y evaluaci√≥n de normalidad

Responde en JSON:
{{
  "enhanced_answer": "respuesta adaptada y mejorada",
  "optional_clarifications": ["Pregunta espec√≠fica 1?", "Pregunta espec√≠fica 2?"],
  "warnings": ["Advertencia si info faltante impacta consejo"],
  "confidence_impact": "low/medium/high seg√∫n impacto info faltante",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "explicaci√≥n detallada de la coherencia entre pregunta enriquecida y respuesta RAG",
  "improvement_notes": "explicaciones de mejoras realizadas"
}}"""
    
    def _format_entities_for_gpt(self, entities: Dict[str, Any]) -> str:
        """Formate les entit√©s pour le prompt GPT"""
        
        formatted_parts = []
        
        # Informations de base avec niveaux de confiance
        if entities.get("breed"):
            confidence = entities.get("breed_confidence", 0.0)
            status = "‚úÖ" if confidence > 0.7 else "‚ö†Ô∏è" if confidence > 0.4 else "‚ùå"
            formatted_parts.append(f"{status} Race: {entities['breed']} (confiance: {confidence:.1f})")
        else:
            formatted_parts.append("‚ùå Race: inconnue")
        
        if entities.get("sex"):
            confidence = entities.get("sex_confidence", 0.0)
            status = "‚úÖ" if confidence > 0.7 else "‚ö†Ô∏è" if confidence > 0.4 else "‚ùå"
            formatted_parts.append(f"{status} Sexe: {entities['sex']} (confiance: {confidence:.1f})")
        else:
            formatted_parts.append("‚ùå Sexe: inconnu")
        
        if entities.get("age_days"):
            confidence = entities.get("age_confidence", 0.0)
            status = "‚úÖ" if confidence > 0.7 else "‚ö†Ô∏è" if confidence > 0.4 else "‚ùå"
            weeks = entities.get("age_weeks", entities["age_days"] / 7)
            formatted_parts.append(f"{status} √Çge: {entities['age_days']} jours ({weeks:.1f} semaines)")
        else:
            formatted_parts.append("‚ùå √Çge: inconnu")
        
        # Performance et sant√©
        if entities.get("weight_grams"):
            confidence = entities.get("weight_confidence", 0.0)
            status = "‚úÖ" if confidence > 0.6 else "‚ö†Ô∏è"
            formatted_parts.append(f"{status} Poids actuel: {entities['weight_grams']}g")
        
        if entities.get("symptoms"):
            symptoms = ", ".join(entities["symptoms"])
            formatted_parts.append(f"üö® Sympt√¥mes observ√©s: {symptoms}")
        
        if entities.get("mortality_rate") is not None:
            rate = entities["mortality_rate"]
            status = "üö®" if rate > 5 else "‚ö†Ô∏è" if rate > 2 else "‚úÖ"
            formatted_parts.append(f"{status} Mortalit√©: {rate}%")
        
        # Environnement
        if entities.get("temperature"):
            temp = entities["temperature"]
            status = "üö®" if temp < 18 or temp > 30 else "‚úÖ"
            formatted_parts.append(f"{status} Temp√©rature: {temp}¬∞C")
        
        if entities.get("housing_type"):
            formatted_parts.append(f"üè† Logement: {entities['housing_type']}")
        
        if entities.get("flock_size"):
            formatted_parts.append(f"üë• Taille troupeau: {entities['flock_size']}")
        
        return "\n".join(formatted_parts) if formatted_parts else "Aucune information contextuelle disponible"
    
    def _parse_gpt_response(
        self, 
        response: str, 
        original_answer: str, 
        entities: Dict[str, Any], 
        missing_entities: List[str]
    ) -> Dict[str, Any]:
        """Parse la r√©ponse JSON de GPT avec v√©rification de coh√©rence"""
        
        try:
            # Extraire le JSON de la r√©ponse
            json_match = None
            
            # Chercher JSON dans des blocs code
            import re
            json_patterns = [
                r'```json\s*(\{.*?\})\s*```',
                r'```\s*(\{.*?\})\s*```',
                r'(\{.*?\})'
            ]
            
            for pattern in json_patterns:
                match = re.search(pattern, response, re.DOTALL)
                if match:
                    json_match = match.group(1)
                    break
            
            if not json_match:
                raise ValueError("Pas de JSON trouv√© dans la r√©ponse")
            
            # Parser le JSON
            data = json.loads(json_match)
            
            # Valider et enrichir la r√©ponse
            enhanced_answer = data.get("enhanced_answer", original_answer)
            optional_clarifications = data.get("optional_clarifications", [])
            warnings = data.get("warnings", [])
            
            # üÜï Validation de la coh√©rence
            coherence_check = data.get("coherence_check", "unknown")
            if coherence_check not in ["good", "partial", "poor"]:
                coherence_check = "unknown"
            
            coherence_notes = data.get("coherence_notes", "")
            if not coherence_notes:
                coherence_notes = f"Coh√©rence √©valu√©e comme: {coherence_check}"
            
            # Validation des clarifications (max 3, non vides)
            if isinstance(optional_clarifications, list):
                optional_clarifications = [q.strip() for q in optional_clarifications if q and q.strip()]
                optional_clarifications = optional_clarifications[:3]
            else:
                optional_clarifications = []
            
            # Validation des avertissements
            if isinstance(warnings, list):
                warnings = [w.strip() for w in warnings if w and w.strip()]
                warnings = warnings[:2]  # Max 2 avertissements
            else:
                warnings = []
            
            # D√©terminer l'impact sur la confiance
            confidence_impact = data.get("confidence_impact", "medium")
            if confidence_impact not in ["low", "medium", "high"]:
                confidence_impact = "medium"
            
            result = {
                "enhanced_answer": enhanced_answer,
                "optional_clarifications": optional_clarifications,
                "warnings": warnings,
                "confidence_impact": confidence_impact,
                "coherence_check": coherence_check,  # üÜï
                "coherence_notes": coherence_notes,  # üÜï
                "improvement_notes": data.get("improvement_notes", "Am√©liorations appliqu√©es"),
                "method_used": "openai",
                "processing_time": datetime.now().isoformat(),
                "entities_considered": len([k for k, v in entities.items() if v is not None]),
                "missing_entities_count": len(missing_entities)
            }
            
            return result
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"‚ùå [AgentRAGEnhancer] Erreur parsing JSON: {e}")
            logger.debug(f"   R√©ponse GPT: {response}")
            
            # Fallback: chercher des am√©liorations dans le texte brut
            if len(response) > len(original_answer) and response != original_answer:
                # Extraire des clarifications potentielles du texte
                clarifications = []
                question_patterns = [r'([^.!?]*\?)', r'pourriez-vous[^.!?]*\?', r'pouvez-vous[^.!?]*\?']
                
                for pattern in question_patterns:
                    matches = re.findall(pattern, response, re.IGNORECASE)
                    for match in matches[:2]:  # Max 2
                        if len(match.strip()) > 10:
                            clarifications.append(match.strip())
                
                return {
                    "enhanced_answer": response.strip(),
                    "optional_clarifications": clarifications,
                    "warnings": ["R√©ponse g√©n√©r√©e automatiquement - v√©rifiez la pertinence"],
                    "confidence_impact": "medium",
                    "coherence_check": "unknown",
                    "coherence_notes": "Impossible de v√©rifier la coh√©rence - JSON parsing √©chou√©",
                    "improvement_notes": "JSON parsing failed, used raw GPT response",
                    "method_used": "openai_fallback"
                }
            else:
                # Fallback complet
                return self._enhance_fallback(original_answer, entities, missing_entities, "", "", "fr")
    
    def _enhance_fallback(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        original_question: str,
        enriched_question: str,  # üÜï
        language: str
    ) -> Dict[str, Any]:
        """Am√©lioration fallback sans OpenAI avec v√©rification basique de coh√©rence"""
        
        enhanced_answer = rag_answer
        warnings = []
        clarifications = []
        
        # üÜï V√©rification basique de coh√©rence
        coherence_check = "unknown"
        coherence_notes = "V√©rification automatique basique"
        
        if enriched_question and original_question:
            # V√©rification tr√®s basique par mots-cl√©s
            enriched_words = set(enriched_question.lower().split())
            answer_words = set(rag_answer.lower().split())
            
            # Mots-cl√©s importants communs
            important_words = enriched_words.intersection(answer_words)
            important_words = {w for w in important_words if len(w) > 3}  # Ignorer mots courts
            
            if len(important_words) >= 3:
                coherence_check = "good"
                coherence_notes = f"R√©ponse semble coh√©rente (mots-cl√©s communs: {', '.join(list(important_words)[:3])})"
            elif len(important_words) >= 1:
                coherence_check = "partial"
                coherence_notes = f"Coh√©rence partielle (quelques mots-cl√©s communs: {', '.join(important_words)})"
            else:
                coherence_check = "poor"
                coherence_notes = "Peu de mots-cl√©s communs entre question enrichie et r√©ponse"
        
        # Ajouter des avertissements selon les entit√©s manquantes
        if "breed" in missing_entities:
            if language == "fr":
                warnings.append("‚ö†Ô∏è Sans conna√Ætre la race exacte, cette r√©ponse est g√©n√©rale. Les performances varient selon la souche.")
                clarifications.append("Quelle est la race/souche de vos volailles ?")
            elif language == "en":
                warnings.append("‚ö†Ô∏è Without knowing the exact breed, this response is general. Performance varies by strain.")
                clarifications.append("What is the breed/strain of your poultry?")
            else:  # Spanish
                warnings.append("‚ö†Ô∏è Sin conocer la raza exacta, esta respuesta es general. El rendimiento var√≠a seg√∫n la cepa.")
                clarifications.append("¬øCu√°l es la raza/cepa de sus aves?")
        
        if "age" in missing_entities:
            if language == "fr":
                warnings.append("‚ö†Ô∏è L'√¢ge est crucial pour √©valuer la normalit√© des param√®tres.")
                clarifications.append("Quel est l'√¢ge de vos volailles (en jours ou semaines) ?")
            elif language == "en":
                warnings.append("‚ö†Ô∏è Age is crucial for evaluating parameter normality.")
                clarifications.append("What is the age of your poultry (in days or weeks)?")
            else:  # Spanish
                warnings.append("‚ö†Ô∏è La edad es crucial para evaluar la normalidad de los par√°metros.")
                clarifications.append("¬øCu√°l es la edad de sus aves (en d√≠as o semanas)?")
        
        if "sex" in missing_entities and any(word in rag_answer.lower() for word in ["poids", "weight", "peso", "croissance", "growth"]):
            if language == "fr":
                clarifications.append("S'agit-il de m√¢les, femelles, ou d'un troupeau mixte ?")
            elif language == "en":
                clarifications.append("Are these males, females, or a mixed flock?")
            else:  # Spanish
                clarifications.append("¬øSon machos, hembras, o un lote mixto?")
        
        # D√©terminer l'impact sur la confiance
        confidence_impact = "low"
        if len(missing_entities) >= 2:
            confidence_impact = "high"
        elif len(missing_entities) == 1:
            confidence_impact = "medium"
        
        # Ajouter un contexte si des entit√©s sont connues
        context_additions = []
        if entities.get("breed") and entities.get("breed_confidence", 0) > 0.6:
            context_additions.append(f"race {entities['breed']}")
        
        if entities.get("age_days") and entities.get("age_confidence", 0) > 0.6:
            context_additions.append(f"√¢ge {entities['age_days']} jours")
        
        if context_additions:
            context_text = " et ".join(context_additions)
            if language == "fr":
                enhanced_answer += f"\n\nüí° Cette r√©ponse consid√®re votre contexte : {context_text}."
            elif language == "en":
                enhanced_answer += f"\n\nüí° This response considers your context: {context_text}."
            else:  # Spanish
                enhanced_answer += f"\n\nüí° Esta respuesta considera su contexto: {context_text}."
        
        # Ajouter les avertissements √† la r√©ponse si critiques
        if warnings and confidence_impact in ["medium", "high"]:
            enhanced_answer += f"\n\n{' '.join(warnings)}"
        
        return {
            "enhanced_answer": enhanced_answer,
            "optional_clarifications": clarifications[:3],
            "warnings": warnings,
            "confidence_impact": confidence_impact,
            "coherence_check": coherence_check,  # üÜï
            "coherence_notes": coherence_notes,  # üÜï
            "improvement_notes": "Am√©lioration basique appliqu√©e",
            "method_used": "fallback"
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de l'agent"""
        
        total = self.stats["total_requests"]
        success_rate = (self.stats["openai_success"] / total * 100) if total > 0 else 0
        enhancement_rate = (self.stats["answers_enhanced"] / total * 100) if total > 0 else 0
        clarification_rate = (self.stats["clarifications_generated"] / total * 100) if total > 0 else 0
        coherence_issue_rate = (self.stats["coherence_issues_detected"] / total * 100) if total > 0 else 0
        
        return {
            "agent_type": "rag_enhancer",
            "total_requests": total,
            "openai_success_rate": f"{success_rate:.1f}%",
            "answer_enhancement_rate": f"{enhancement_rate:.1f}%",
            "clarification_generation_rate": f"{clarification_rate:.1f}%",
            "coherence_issue_detection_rate": f"{coherence_issue_rate:.1f}%",  # üÜï
            "openai_available": self.openai_available,
            "model_used": self.model,
            "detailed_stats": self.stats.copy()
        }

# Instance globale
agent_rag_enhancer = AgentRAGEnhancer()

# Fonction utilitaire pour usage externe
async def enhance_rag_answer(
    rag_answer: str,
    entities: Dict[str, Any],
    missing_entities: List[str],
    conversation_context: str,
    original_question: str = "",
    enriched_question: str = "",  # üÜï Param√®tre ajout√©
    language: str = "fr"
) -> Dict[str, Any]:
    """Fonction utilitaire pour am√©liorer une r√©ponse RAG avec v√©rification de coh√©rence"""
    return await agent_rag_enhancer.enhance_rag_answer(
        rag_answer, entities, missing_entities, conversation_context, 
        original_question, enriched_question, language
    )