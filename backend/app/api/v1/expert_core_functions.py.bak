"""
app/api/v1/expert_core_functions.py - FONCTIONS PRINCIPALES v3.7.8

üîß REFACTORISATION: Ce fichier contient toutes les fonctions de logique m√©tier
extraites de expert.py pour am√©liorer la maintenabilit√©.

FONCTIONS INCLUSES:
- Gestion contexte conversation
- Analyse domaine agricole
- Service clarification dynamique
- Extraction entit√©s critiques
- Validation entit√©s
- D√©tection incoh√©rences
- Synchronisation RAG
- Propagation champs
"""

import os
import re
import logging
import uuid
import time
from datetime import datetime
from typing import Optional, List, Dict, Any

logger = logging.getLogger(__name__)

# Import s√©curis√© du service de clarification
try:
    from .expert_clarification_service import ExpertClarificationService
    CLARIFICATION_SERVICE_AVAILABLE = True
except ImportError as e:
    logger.error(f"‚ùå Erreur import expert_clarification_service: {e}")
    CLARIFICATION_SERVICE_AVAILABLE = False
    class ExpertClarificationService:
        pass

# Initialisation service clarification
clarification_service = None
if CLARIFICATION_SERVICE_AVAILABLE:
    try:
        clarification_service = ExpertClarificationService()
        logger.info("‚úÖ [Core Functions] Service clarification initialis√© avec succ√®s")
    except Exception as e:
        logger.error(f"‚ùå [Core Functions] Erreur initialisation service: {e}")
        clarification_service = None

# =============================================================================
# üÜï NOUVELLES FONCTIONS v3.7.8 - INT√âGRATION SERVICE CLARIFICATION DYNAMIQUE
# =============================================================================

def _build_conversation_context(
    request_data: Any,
    entities: Dict[str, Any],
    processing_metadata: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    üÜï NOUVELLE v3.7.8: Construit le contexte de conversation pour le service de clarification
    """
    
    context = {
        "current_question": getattr(request_data, 'text', ''),
        "language": getattr(request_data, 'language', 'fr'),
        "conversation_id": getattr(request_data, 'conversation_id', None),
        "is_clarification_response": getattr(request_data, 'is_clarification_response', False),
        "original_question": getattr(request_data, 'original_question', None),
        "extracted_entities": entities,
        "timestamp": datetime.now().isoformat()
    }
    
    # Ajouter contexte de clarification si disponible
    clarification_context = getattr(request_data, 'clarification_context', None)
    if clarification_context and isinstance(clarification_context, dict):
        context["clarification_context"] = clarification_context
    
    # Ajouter entit√©s de clarification si disponibles
    clarification_entities = getattr(request_data, 'clarification_entities', None)
    if clarification_entities and isinstance(clarification_entities, dict):
        context["clarification_entities"] = clarification_entities
    
    # Ajouter m√©tadonn√©es de traitement si disponibles
    if processing_metadata and isinstance(processing_metadata, dict):
        context["processing_metadata"] = processing_metadata
    
    # Analyser le type de domaine agricole
    context["domain_analysis"] = _analyze_agricultural_domain(context["current_question"])
    
    logger.info(f"üîß [CONTEXT v3.7.8] Contexte conversation construit:")
    logger.info(f"   - Question: '{context['current_question'][:100]}...'")
    logger.info(f"   - Langue: {context['language']}")
    logger.info(f"   - Entit√©s: {len(entities)} d√©tect√©es")
    logger.info(f"   - Domaine: {context['domain_analysis']['primary_domain']}")
    
    return context

def _analyze_agricultural_domain(question_text: str) -> Dict[str, Any]:
    """
    üÜï NOUVELLE v3.7.8: Analyse le domaine agricole de la question pour adapter les clarifications
    """
    
    domain_analysis = {
        "primary_domain": "poultry",  # Default
        "specific_topics": [],
        "urgency_level": "normal",
        "complexity": "medium"
    }
    
    try:
        question_lower = question_text.lower() if isinstance(question_text, str) else ""
        
        # D√©tection domaine principal
        if any(term in question_lower for term in ["poulet", "chicken", "broiler", "ross", "cobb"]):
            domain_analysis["primary_domain"] = "poultry"
        elif any(term in question_lower for term in ["porc", "pig", "swine", "cochon"]):
            domain_analysis["primary_domain"] = "swine"
        elif any(term in question_lower for term in ["bovin", "cattle", "vache", "cow"]):
            domain_analysis["primary_domain"] = "cattle"
        elif any(term in question_lower for term in ["ovin", "sheep", "mouton"]):
            domain_analysis["primary_domain"] = "sheep"
        
        # D√©tection sujets sp√©cifiques
        topics_map = {
            "nutrition": ["nutrition", "alimentation", "feed", "nourriture"],
            "health": ["sant√©", "health", "maladie", "disease", "sympt√¥me"],
            "growth": ["croissance", "growth", "poids", "weight", "d√©veloppement"],
            "environment": ["temp√©rature", "temperature", "ventilation", "environnement"],
            "reproduction": ["reproduction", "breeding", "reproduction", "ponte"],
            "mortality": ["mortalit√©", "mortality", "mort", "death", "perte"]
        }
        
        for topic, keywords in topics_map.items():
            if any(keyword in question_lower for keyword in keywords):
                domain_analysis["specific_topics"].append(topic)
        
        # D√©tection niveau urgence
        urgency_keywords = ["urgent", "imm√©diat", "rapide", "critique", "grave", "emergency"]
        if any(keyword in question_lower for keyword in urgency_keywords):
            domain_analysis["urgency_level"] = "high"
        elif any(term in question_lower for term in ["pr√©ventif", "routine", "normal"]):
            domain_analysis["urgency_level"] = "low"
        
        # D√©tection complexit√©
        if len(domain_analysis["specific_topics"]) >= 3:
            domain_analysis["complexity"] = "high"
        elif len(domain_analysis["specific_topics"]) <= 1:
            domain_analysis["complexity"] = "low"
        
        logger.info(f"üîç [DOMAIN ANALYSIS v3.7.8] R√©sultat:")
        logger.info(f"   - Domaine: {domain_analysis['primary_domain']}")
        logger.info(f"   - Sujets: {domain_analysis['specific_topics']}")
        logger.info(f"   - Urgence: {domain_analysis['urgency_level']}")
        logger.info(f"   - Complexit√©: {domain_analysis['complexity']}")
        
    except Exception as e:
        logger.error(f"‚ùå [DOMAIN ANALYSIS v3.7.8] Erreur: {e}")
    
    return domain_analysis

async def _apply_dynamic_clarification_service(
    response_data: Any,
    validation_result: Dict[str, Any],
    entities: Dict[str, Any],
    conversation_context: Dict[str, Any]
) -> Any:
    """
    üÜï NOUVELLE v3.7.8: Applique le service de clarification dynamique si n√©cessaire
    
    Cette fonction est appel√©e APR√àS validation des entit√©s critiques
    et g√©n√®re des questions dynamiques si clarification_required_critical = True
    """
    
    try:
        if not response_data:
            logger.error("‚ùå [CLARIFICATION SERVICE v3.7.8] response_data est None")
            return response_data
        
        # V√©rifier si clarification critique requise
        clarification_required = getattr(response_data, 'clarification_required_critical', False)
        if not clarification_required:
            logger.info("‚úÖ [CLARIFICATION SERVICE v3.7.8] Aucune clarification critique requise")
            return response_data
        
        logger.info("üö® [CLARIFICATION SERVICE v3.7.8] Clarification critique d√©tect√©e - activation service")
        
        # V√©rifier disponibilit√© du service
        if not clarification_service:
            logger.warning("‚ö†Ô∏è [CLARIFICATION SERVICE v3.7.8] Service non disponible - mode fallback")
            return _apply_fallback_clarification(response_data, validation_result, entities)
        
        # Extraire entit√©s manquantes
        missing_entities = getattr(response_data, 'missing_critical_entities', [])
        if not missing_entities:
            missing_entities = validation_result.get('missing_critical', [])
        
        logger.info(f"üîç [CLARIFICATION SERVICE v3.7.8] Entit√©s manquantes: {missing_entities}")
        
        # √âTAPE 1: S√©lection dynamique du prompt
        logger.info("üéØ [CLARIFICATION SERVICE v3.7.8] √âTAPE 1: S√©lection prompt dynamique...")
        
        clarification_prompt = clarification_service.select_clarification_prompt(
            question=conversation_context.get('current_question', ''),
            missing_entities=missing_entities,
            conversation_context=conversation_context
        )
        
        if not clarification_prompt:
            logger.error("‚ùå [CLARIFICATION SERVICE v3.7.8] √âchec s√©lection prompt")
            return _apply_fallback_clarification(response_data, validation_result, entities)
        
        logger.info(f"‚úÖ [CLARIFICATION SERVICE v3.7.8] Prompt s√©lectionn√©: {clarification_prompt.get('prompt_type', 'unknown')}")
        
        # √âTAPE 2: G√©n√©ration questions avec GPT
        logger.info("ü§ñ [CLARIFICATION SERVICE v3.7.8] √âTAPE 2: G√©n√©ration questions GPT...")
        
        clarification_questions = await clarification_service.generate_questions_with_gpt(
            clarification_prompt=clarification_prompt,
            context=conversation_context
        )
        
        if not clarification_questions:
            logger.error("‚ùå [CLARIFICATION SERVICE v3.7.8] √âchec g√©n√©ration questions")
            return _apply_fallback_clarification(response_data, validation_result, entities)
        
        logger.info(f"‚úÖ [CLARIFICATION SERVICE v3.7.8] {len(clarification_questions)} questions g√©n√©r√©es")
        
        # √âTAPE 3: Validation questions dynamiques
        logger.info("üîç [CLARIFICATION SERVICE v3.7.8] √âTAPE 3: Validation questions...")
        
        validated_questions = clarification_service.validate_dynamic_questions(
            clarification_questions=clarification_questions,
            missing_entities=missing_entities,
            context=conversation_context
        )
        
        if not validated_questions:
            logger.error("‚ùå [CLARIFICATION SERVICE v3.7.8] √âchec validation questions")
            return _apply_fallback_clarification(response_data, validation_result, entities)
        
        logger.info(f"‚úÖ [CLARIFICATION SERVICE v3.7.8] {len(validated_questions)} questions valid√©es")
        
        # √âTAPE 4: Application √† response_data
        logger.info("üîß [CLARIFICATION SERVICE v3.7.8] √âTAPE 4: Application √† response...")
        
        # Marquer service utilis√©
        if hasattr(response_data, 'clarification_service_used'):
            response_data.clarification_service_used = True
        
        # Ajouter questions dynamiques
        if hasattr(response_data, 'dynamic_questions'):
            response_data.dynamic_questions = validated_questions
        
        # Enrichir clarification_result
        if hasattr(response_data, 'clarification_result') and response_data.clarification_result:
            if isinstance(response_data.clarification_result, dict):
                response_data.clarification_result.update({
                    "dynamic_clarification_service": {
                        "service_used": True,
                        "prompt_selected": clarification_prompt,
                        "questions_generated": len(clarification_questions),
                        "questions_validated": len(validated_questions),
                        "missing_entities": missing_entities,
                        "context_analyzed": conversation_context.get('domain_analysis', {}),
                        "timestamp": datetime.now().isoformat()
                    },
                    "dynamic_questions": validated_questions
                })
        
        # Enrichir processing_steps
        if hasattr(response_data, 'processing_steps') and isinstance(response_data.processing_steps, list):
            response_data.processing_steps.extend([
                "dynamic_clarification_service_activated_v3.7.8",
                f"prompt_selected_{clarification_prompt.get('prompt_type', 'unknown')}",
                f"questions_generated_{len(clarification_questions)}",
                f"questions_validated_{len(validated_questions)}"
            ])
        
        # Enrichir ai_enhancements_used
        if hasattr(response_data, 'ai_enhancements_used') and isinstance(response_data.ai_enhancements_used, list):
            response_data.ai_enhancements_used.extend([
                "dynamic_clarification_service_v3.7.8",
                "gpt_question_generation",
                "intelligent_prompt_selection",
                "dynamic_question_validation"
            ])
        
        # Modifier la r√©ponse pour inclure les questions dynamiques
        if hasattr(response_data, 'response') and validated_questions:
            original_response = response_data.response
            
            # Construire nouvelle r√©ponse avec questions dynamiques
            enhanced_response = original_response + "\n\n**Questions de clarification intelligentes :**\n"
            
            for i, question_data in enumerate(validated_questions, 1):
                question_text = question_data.get('question', '')
                question_type = question_data.get('type', 'general')
                
                enhanced_response += f"\n{i}. **{question_text}**"
                
                # Ajouter options si disponibles
                options = question_data.get('options', [])
                if options:
                    enhanced_response += "\n   Options sugg√©r√©es:"
                    for option in options[:3]:  # Limiter √† 3 options
                        enhanced_response += f"\n   ‚Ä¢ {option}"
                
                enhanced_response += "\n"
            
            response_data.response = enhanced_response
            
            logger.info("üîß [CLARIFICATION SERVICE v3.7.8] R√©ponse enrichie avec questions dynamiques")
        
        logger.info("‚úÖ [CLARIFICATION SERVICE v3.7.8] Service appliqu√© avec succ√®s")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå [CLARIFICATION SERVICE v3.7.8] Erreur: {e}")
        return _apply_fallback_clarification(response_data, validation_result, entities)

def _apply_fallback_clarification(
    response_data: Any,
    validation_result: Dict[str, Any],
    entities: Dict[str, Any]
) -> Any:
    """
    üÜï NOUVELLE v3.7.8: Applique une clarification fallback si le service dynamique √©choue
    """
    
    try:
        logger.info("üîÑ [FALLBACK CLARIFICATION v3.7.8] Application clarification de secours")
        
        # Marquer service non utilis√©
        if hasattr(response_data, 'clarification_service_used'):
            response_data.clarification_service_used = False
        
        # Questions fallback basiques
        missing_entities = validation_result.get('missing_critical', [])
        
        fallback_questions = []
        
        if 'breed' in missing_entities:
            fallback_questions.append({
                "question": "Quelle est la race/souche de vos animaux ?",
                "type": "breed",
                "priority": "critical",
                "options": ["Ross 308", "Cobb 500", "Hubbard", "Arbor Acres", "Autre"]
            })
        
        if 'age' in missing_entities or 'age_in_days' in missing_entities:
            fallback_questions.append({
                "question": "Quel est l'√¢ge pr√©cis de vos animaux ?",
                "type": "age",
                "priority": "critical",
                "options": ["13 jours", "2 semaines", "3 semaines", "1 mois", "Autre"]
            })
        
        if 'weight' in missing_entities or 'weight_in_grams' in missing_entities:
            fallback_questions.append({
                "question": "Quel est le poids actuel de vos animaux ?",
                "type": "weight",
                "priority": "critical",
                "options": ["800g", "1.2kg", "1.8kg", "2.5kg", "Autre"]
            })
        
        if 'sex' in missing_entities:
            fallback_questions.append({
                "question": "S'agit-il de m√¢les, femelles, ou un troupeau mixte ?",
                "type": "sex",
                "priority": "medium",
                "options": ["M√¢les", "Femelles", "Mixte"]
            })
        
        # Ajouter questions fallback
        if hasattr(response_data, 'dynamic_questions'):
            response_data.dynamic_questions = fallback_questions
        
        # Enrichir processing_steps
        if hasattr(response_data, 'processing_steps') and isinstance(response_data.processing_steps, list):
            response_data.processing_steps.append("fallback_clarification_applied_v3.7.8")
        
        # Enrichir ai_enhancements_used
        if hasattr(response_data, 'ai_enhancements_used') and isinstance(response_data.ai_enhancements_used, list):
            response_data.ai_enhancements_used.append("fallback_clarification_v3.7.8")
        
        logger.info(f"‚úÖ [FALLBACK CLARIFICATION v3.7.8] {len(fallback_questions)} questions fallback g√©n√©r√©es")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå [FALLBACK CLARIFICATION v3.7.8] Erreur: {e}")
        return response_data

# =============================================================================
# FONCTIONS EXISTANTES v3.7.7 - CONSERV√âES INT√âGRALEMENT
# =============================================================================

def _extract_critical_entities_from_question(question_text: str, language: str = "fr") -> Dict[str, Any]:
    """
    üÜï CONSERV√âE v3.7.7: Extrait les entit√©s critiques (breed, age, weight) depuis la question
    
    Entit√©s critiques pour les questions agricoles:
    - breed: race/souche (Ross 308, Cobb 500, etc.)
    - age: √¢ge en jours/semaines (13j, 2sem, etc.)
    - weight: poids en grammes/kg (800g, 1.2kg, etc.)
    """
    
    entities = {
        "breed": None,
        "age": None,
        "age_in_days": None,
        "weight": None,
        "weight_in_grams": None,
        "sex": None,  # Bonus - d√©j√† g√©r√© ailleurs mais utile
        "confidence": {}
    }
    
    try:
        question_lower = question_text.lower() if isinstance(question_text, str) else ""
        
        # üîç EXTRACTION 1: BREED/RACE avec patterns √©tendus
        breed_patterns = [
            r'\b(ross\s*308|ross308)\b',
            r'\b(ross\s*708|ross708)\b', 
            r'\b(cobb\s*500|cobb500)\b',
            r'\b(cobb\s*700|cobb700)\b',
            r'\b(hubbard|hub)\b',
            r'\b(arbor\s*acres|arbor)\b',
            r'\b(isa\s*brown|isa)\b',
            r'\b(lohmann|lohman)\b',
            r'\b(poulet\s*de\s*chair|broiler)\b'
        ]
        
        for pattern in breed_patterns:
            match = re.search(pattern, question_lower)
            if match:
                entities["breed"] = match.group(0).replace(" ", " ").strip()
                entities["confidence"]["breed"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Breed d√©tect√©: '{entities['breed']}'")
                break
        
        # Si pas de race sp√©cifique, chercher terme g√©n√©rique
        if not entities["breed"]:
            generic_patterns = [r'\bpoulets?\b', r'\bpoules?\b', r'\bchickens?\b', r'\bbroilers?\b']
            for pattern in generic_patterns:
                if re.search(pattern, question_lower):
                    entities["breed"] = "poulet"  # G√©n√©rique, n√©cessitera clarification
                    entities["confidence"]["breed"] = 0.3
                    logger.info(f"üîç [ENTIT√â v3.7.7] Breed g√©n√©rique d√©tect√©: '{entities['breed']}'")
                    break
        
        # üîç EXTRACTION 2: AGE avec conversion en jours
        age_patterns = [
            (r'(\d+)\s*j(?:our)?s?', 1),           # 13j, 13 jours
            (r'(\d+)\s*sem(?:aine)?s?', 7),         # 2sem, 2 semaines -> * 7
            (r'(\d+)\s*week?s?', 7),                # 2 weeks -> * 7
            (r'(\d+)\s*mois', 30),                  # 1 mois -> * 30 (approximatif)
            (r'(\d+)\s*month?s?', 30)               # 1 month -> * 30
        ]
        
        for pattern, multiplier in age_patterns:
            match = re.search(pattern, question_lower)
            if match:
                age_value = int(match.group(1))
                entities["age"] = match.group(0)
                entities["age_in_days"] = age_value * multiplier
                entities["confidence"]["age"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Age d√©tect√©: '{entities['age']}' = {entities['age_in_days']} jours")
                break
        
        # üîç EXTRACTION 3: WEIGHT avec conversion en grammes
        weight_patterns = [
            (r'(\d+(?:\.\d+)?)\s*kg', 1000),         # 1.2kg -> * 1000
            (r'(\d+(?:\.\d+)?)\s*kilo', 1000),       # 1.2 kilo -> * 1000
            (r'(\d+)\s*g(?:ramme)?s?', 1),           # 800g, 800 grammes
            (r'(\d+(?:\.\d+)?)\s*lb', 453.592)       # 2.5 lb -> * 453.592 (livres)
        ]
        
        for pattern, multiplier in weight_patterns:
            match = re.search(pattern, question_lower)
            if match:
                weight_value = float(match.group(1))
                entities["weight"] = match.group(0)
                entities["weight_in_grams"] = int(weight_value * multiplier)
                entities["confidence"]["weight"] = 0.9
                logger.info(f"üîç [ENTIT√â v3.7.7] Weight d√©tect√©: '{entities['weight']}' = {entities['weight_in_grams']}g")
                break
        
        # üîç EXTRACTION 4: SEX (bonus)
        sex_patterns = [
            (r'\bm√¢les?\b', "m√¢le"),
            (r'\bfemelles?\b', "femelle"), 
            (r'\bmales?\b', "m√¢le"),
            (r'\bfemales?\b', "femelle"),
            (r'\bmixte\b', "mixte"),
            (r'\btroupeau\s+mixte\b', "mixte")
        ]
        
        for pattern, sex_value in sex_patterns:
            if re.search(pattern, question_lower):
                entities["sex"] = sex_value
                entities["confidence"]["sex"] = 0.8
                logger.info(f"üîç [ENTIT√â v3.7.7] Sex d√©tect√©: '{entities['sex']}'")
                break
        
        # üîç VALIDATION COH√âRENCE des entit√©s extraites
        coherence_issues = []
        
        # V√©rifier coh√©rence √¢ge/poids si les deux sont pr√©sents
        if entities["age_in_days"] and entities["weight_in_grams"]:
            age_days = entities["age_in_days"]
            weight_grams = entities["weight_in_grams"]
            
            # Heuristiques de coh√©rence (√† affiner selon donn√©es r√©elles)
            if age_days < 7 and weight_grams > 500:  # Poussin < 1 sem mais > 500g
                coherence_issues.append(f"age_weight_high_{age_days}d_{weight_grams}g")
            elif age_days > 35 and weight_grams < 500:  # Poulet > 5 sem mais < 500g
                coherence_issues.append(f"age_weight_low_{age_days}d_{weight_grams}g")
            elif age_days > 60:  # √Çge tr√®s √©lev√© pour poulet de chair
                coherence_issues.append(f"age_very_high_{age_days}d")
        
        entities["coherence_issues"] = coherence_issues
        
        logger.info(f"üîç [EXTRACTION ENTIT√âS v3.7.8] R√©sultat final:")
        logger.info(f"   - Breed: {entities['breed']} (conf: {entities['confidence'].get('breed', 0)})")
        logger.info(f"   - Age: {entities['age']} = {entities['age_in_days']} jours (conf: {entities['confidence'].get('age', 0)})")
        logger.info(f"   - Weight: {entities['weight']} = {entities['weight_in_grams']}g (conf: {entities['confidence'].get('weight', 0)})")
        logger.info(f"   - Sex: {entities['sex']} (conf: {entities['confidence'].get('sex', 0)})")
        logger.info(f"   - Incoh√©rences: {coherence_issues}")
        
        return entities
        
    except Exception as e:
        logger.error(f"‚ùå [EXTRACTION ENTIT√âS v3.7.8] Erreur: {e}")
        return entities

def _validate_critical_entities(entities: Dict[str, Any], question_context: str = "") -> Dict[str, Any]:
    """
    üÜï CONSERV√âE v3.7.7: Valide si les entit√©s critiques sont suffisantes pour une r√©ponse de qualit√©
    
    Returns:
        Dict avec validation_result, missing_entities, confidence_issues, etc.
    """
    
    validation_result = {
        "entities_sufficient": False,
        "missing_critical": [],
        "low_confidence": [],
        "generic_entities": [],
        "coherence_issues": [],
        "clarification_required": False,
        "clarification_priority": "low"  # low, medium, high, critical
    }
    
    try:
        if not isinstance(entities, dict):
            logger.error("‚ùå [VALIDATION ENTIT√âS v3.7.8] entities n'est pas un dict")
            validation_result["clarification_required"] = True
            validation_result["clarification_priority"] = "critical"
            return validation_result
        
        # üîç VALIDATION 1: ENTIT√âS CRITIQUES MANQUANTES
        critical_entities = ["breed", "age_in_days", "weight_in_grams"]
        
        for entity in critical_entities:
            entity_value = entities.get(entity)
            
            if entity_value is None:
                validation_result["missing_critical"].append(entity)
                logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Entit√© critique manquante: {entity}")
            
            # Validation sp√©cifique par type d'entit√©
            elif entity == "breed":
                if isinstance(entity_value, str):
                    if entity_value.lower() in ["poulet", "chicken", "broiler"]:
                        validation_result["generic_entities"].append("breed_too_generic")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Breed trop g√©n√©rique: {entity_value}")
                else:
                    validation_result["missing_critical"].append(entity)
            
            elif entity == "age_in_days":
                if isinstance(entity_value, (int, float)):
                    if entity_value <= 0 or entity_value > 365:  # Age aberrant
                        validation_result["coherence_issues"].append(f"age_aberrant_{entity_value}")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Age aberrant: {entity_value} jours")
                else:
                    validation_result["missing_critical"].append(entity)
            
            elif entity == "weight_in_grams":
                if isinstance(entity_value, (int, float)):
                    if entity_value <= 0 or entity_value > 10000:  # Poids aberrant
                        validation_result["coherence_issues"].append(f"weight_aberrant_{entity_value}")
                        logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Poids aberrant: {entity_value}g")
                else:
                    validation_result["missing_critical"].append(entity)
        
        # üîç VALIDATION 2: CONFIANCE DES ENTIT√âS
        confidence_data = entities.get("confidence", {})
        
        for entity, confidence in confidence_data.items():
            if isinstance(confidence, (int, float)) and confidence < 0.5:
                validation_result["low_confidence"].append(f"{entity}_conf_{confidence}")
                logger.warning(f"‚ö†Ô∏è [VALIDATION v3.7.8] Confiance faible {entity}: {confidence}")
        
        # üîç VALIDATION 3: INCOH√âRENCES D√âTECT√âES
        coherence_issues = entities.get("coherence_issues", [])
        validation_result["coherence_issues"].extend(coherence_issues)
        
        # üîç CALCUL PRIORIT√â CLARIFICATION
        missing_count = len(validation_result["missing_critical"])
        generic_count = len(validation_result["generic_entities"])
        coherence_count = len(validation_result["coherence_issues"])
        low_conf_count = len(validation_result["low_confidence"])
        
        # Logique de priorit√©
        if missing_count >= 2:  # 2+ entit√©s critiques manquantes
            validation_result["clarification_priority"] = "critical"
            validation_result["clarification_required"] = True
        elif missing_count == 1 and (generic_count > 0 or coherence_count > 0):
            validation_result["clarification_priority"] = "high"
            validation_result["clarification_required"] = True
        elif missing_count == 1 or generic_count > 0:
            validation_result["clarification_priority"] = "medium"
            validation_result["clarification_required"] = True
        elif coherence_count > 0 or low_conf_count > 1:
            validation_result["clarification_priority"] = "low"
            validation_result["clarification_required"] = True
        else:
            validation_result["entities_sufficient"] = True
            validation_result["clarification_required"] = False
        
        logger.info(f"üîç [VALIDATION ENTIT√âS v3.7.8] R√©sultat:")
        logger.info(f"   - Entit√©s suffisantes: {validation_result['entities_sufficient']}")
        logger.info(f"   - Critiques manquantes: {validation_result['missing_critical']}")
        logger.info(f"   - G√©n√©riques: {validation_result['generic_entities']}")
        logger.info(f"   - Incoh√©rences: {validation_result['coherence_issues']}")
        logger.info(f"   - Clarification requise: {validation_result['clarification_required']}")
        logger.info(f"   - Priorit√©: {validation_result['clarification_priority']}")
        
        return validation_result
        
    except Exception as e:
        logger.error(f"‚ùå [VALIDATION ENTIT√âS v3.7.8] Erreur: {e}")
        # En cas d'erreur, forcer clarification critique
        validation_result["clarification_required"] = True
        validation_result["clarification_priority"] = "critical"
        validation_result["missing_critical"] = ["validation_error"]
        return validation_result

def _force_clarification_for_missing_entities(
    response_data: Any, 
    validation_result: Dict[str, Any], 
    entities: Dict[str, Any]
) -> Any:
    """
    üÜï CONSERV√âE v3.7.7: Force la clarification si des entit√©s critiques manquent
    
    Cette fonction modifie response_data pour d√©clencher clarification_required_critical=True
    """
    
    try:
        if not response_data or not isinstance(validation_result, dict):
            logger.error("‚ùå [FORCE CLARIFICATION v3.7.8] Param√®tres invalides")
            return response_data
        
        clarification_required = validation_result.get("clarification_required", False)
        clarification_priority = validation_result.get("clarification_priority", "low")
        
        if not clarification_required:
            logger.info("‚úÖ [FORCE CLARIFICATION v3.7.8] Aucune clarification n√©cessaire")
            return response_data
        
        logger.warning(f"üö® [FORCE CLARIFICATION v3.7.8] Clarification forc√©e - priorit√©: {clarification_priority}")
        
        # üîß MODIFICATION 1: Marquer clarification_required_critical selon priorit√©
        critical_priorities = ["high", "critical"]
        force_critical = clarification_priority in critical_priorities
        
        if hasattr(response_data, 'clarification_required_critical'):
            response_data.clarification_required_critical = force_critical
            logger.info(f"üîß [FORCE CLARIFICATION v3.7.8] clarification_required_critical = {force_critical}")
        
        # üîß MODIFICATION 2: Mettre √† jour missing_critical_entities
        missing_entities = validation_result.get("missing_critical", [])
        generic_entities = validation_result.get("generic_entities", [])
        coherence_issues = validation_result.get("coherence_issues", [])
        
        # Combiner tous les probl√®mes d'entit√©s
        all_missing = missing_entities + generic_entities + coherence_issues
        
        if hasattr(response_data, 'missing_critical_entities'):
            if isinstance(response_data.missing_critical_entities, list):
                response_data.missing_critical_entities.extend(all_missing)
            else:
                response_data.missing_critical_entities = all_missing
            logger.info(f"üîß [FORCE CLARIFICATION v3.7.8] missing_critical_entities = {response_data.missing_critical_entities}")
        
        # üîß MODIFICATION 3: Ajouter dans processing_steps pour tra√ßabilit√©
        if hasattr(response_data, 'processing_steps') and isinstance(response_data.processing_steps, list):
            response_data.processing_steps.append(f"critical_entities_validation_v3.7.8")
            response_data.processing_steps.append(f"clarification_priority_{clarification_priority}")
            if force_critical:
                response_data.processing_steps.append("clarification_forced_critical_entities")
        
        # üîß MODIFICATION 4: Ajouter dans ai_enhancements_used
        if hasattr(response_data, 'ai_enhancements_used') and isinstance(response_data.ai_enhancements_used, list):
            response_data.ai_enhancements_used.append("critical_entities_extraction_v3.7.8")
            response_data.ai_enhancements_used.append("entities_validation_forced_clarification")
        
        # üîß MODIFICATION 5: Enrichir clarification_result si pr√©sent
        if hasattr(response_data, 'clarification_result') and response_data.clarification_result:
            if isinstance(response_data.clarification_result, dict):
                response_data.clarification_result.update({
                    "critical_entities_analysis": {
                        "entities_extracted": entities,
                        "validation_result": validation_result,
                        "forced_clarification": force_critical,
                        "missing_entities": missing_entities,
                        "generic_entities": generic_entities,
                        "coherence_issues": coherence_issues,
                        "version": "3.7.8"
                    }
                })
                logger.info("üîß [FORCE CLARIFICATION v3.7.8] clarification_result enrichi avec analyse entit√©s")
        
        logger.info("‚úÖ [FORCE CLARIFICATION v3.7.8] Modifications appliqu√©es √† response_data")
        
        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå [FORCE CLARIFICATION v3.7.8] Erreur: {e}")
        return response_data

def _detect_inconsistencies_and_force_clarification(question_text: str, language: str = "fr") -> Dict[str, Any]:
    """üÜï CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.7: D√©tecte les incoh√©rences + utilise nouvelles entit√©s"""
    
    inconsistencies_detected = []
    force_clarification = False
    clarification_reason = ""
    
    try:
        question_lower = question_text.lower() if isinstance(question_text, str) else ""
        
        # üÜï v3.7.7: Utiliser la nouvelle extraction d'entit√©s
        entities = _extract_critical_entities_from_question(question_text, language)
        
        # üîç D√âTECTION 1: Unit√©s temporelles contradictoires (CONSERV√âE v3.7.6)
        temporal_units = []
        if "jour" in question_lower or "j" in question_lower:
            temporal_units.append("jours")
        if "semaine" in question_lower or "sem" in question_lower or "week" in question_lower:
            temporal_units.append("semaines")
        if "mois" in question_lower or "month" in question_lower:
            temporal_units.append("mois")
        
        # Si plusieurs unit√©s temporelles avec des valeurs qui pourraient √™tre contradictoires
        if len(temporal_units) >= 2:
            # Recherche de motifs comme "13j" et "1sem"
            day_pattern = r'(\d+)\s*j(?:our)?s?'
            week_pattern = r'(\d+)\s*sem(?:aine)?s?'
            
            day_matches = re.findall(day_pattern, question_lower)
            week_matches = re.findall(week_pattern, question_lower)
            
            if day_matches and week_matches:
                try:
                    days = int(day_matches[0])
                    weeks = int(week_matches[0])
                    
                    # V√©rifier si incoh√©rent (exemple: 13j ‚â† 1sem)
                    if abs(days - (weeks * 7)) > 2:  # Tol√©rance de 2 jours
                        inconsistencies_detected.append(f"temporal_contradiction")
                        force_clarification = True
                        clarification_reason = f"Incoh√©rence temporelle d√©tect√©e: {days} jours vs {weeks} semaine(s)"
                        logger.warning(f"üö® [INCOH√âRENCE v3.7.8] {clarification_reason}")
                except (ValueError, IndexError):
                    pass
        
        # üîç D√âTECTION 2: Incoh√©rences des entit√©s extraites (NOUVEAU v3.7.7)
        coherence_issues = entities.get("coherence_issues", [])
        if coherence_issues:
            inconsistencies_detected.extend(coherence_issues)
            force_clarification = True
            clarification_reason = f"Incoh√©rences entit√©s d√©tect√©es: {', '.join(coherence_issues)}"
            logger.warning(f"üö® [INCOH√âRENCE ENTIT√âS v3.7.8] {clarification_reason}")
        
        # üîç D√âTECTION 3: Sexe contradictoire (CONSERV√âE v3.7.6)
        if ("m√¢le" in question_lower and "femelle" in question_lower) or ("male" in question_lower and "female" in question_lower):
            # V√©rifier si ce n'est pas une question g√©n√©rale
            specific_indicators = ["mes", "mon", "ce", "cette", "le probl√®me", "problem with"]
            if any(indicator in question_lower for indicator in specific_indicators):
                inconsistencies_detected.append("gender_contradiction")
                force_clarification = True
                clarification_reason = "Question sp√©cifique mentionnant √† la fois m√¢les et femelles"
                logger.warning(f"üö® [INCOH√âRENCE v3.7.8] {clarification_reason}")
        
        logger.info(f"üîç [D√âTECTION INCOH√âRENCES v3.7.8] Question: '{question_text[:100]}...'")
        logger.info(f"   - Incoh√©rences d√©tect√©es: {inconsistencies_detected}")
        logger.info(f"   - Force clarification: {force_clarification}")
        logger.info(f"   - Raison: {clarification_reason}")
        logger.info(f"   - Entit√©s extraites: {entities}")
        
        return {
            "inconsistencies_detected": inconsistencies_detected,
            "force_clarification": force_clarification,
            "clarification_reason": clarification_reason,
            "temporal_units_found": temporal_units,
            "entities_extracted": entities  # NOUVEAU v3.7.7
        }
        
    except Exception as e:
        logger.error(f"‚ùå [D√âTECTION INCOH√âRENCES v3.7.8] Erreur: {e}")
        return {
            "inconsistencies_detected": [],
            "force_clarification": False,
            "clarification_reason": "",
            "temporal_units_found": [],
            "entities_extracted": {}
        }

# =============================================================================
# üîß NOUVELLE VERSION SIMPLIFI√âE RAG SYNC - R√âSOLUTION BOUCLES INFINIES v3.7.8
# =============================================================================

def _sync_rag_state_simple(response_data: Any, processing_metadata: Dict[str, Any] = None) -> bool:
    """
    ‚úÖ VERSION SIMPLIFI√âE v3.7.8 - Une seule correction, pas de boucles
    
    Remplace _validate_and_sync_rag_state et _force_sync_rag_state pour √©viter les boucles infinies.
    """
    try:
        logger.info("üîç [RAG Sync Simple v3.7.8] D√âMARRAGE validation √©tat RAG simplifi√©e...")
        
        if response_data is None:
            logger.error("‚ùå [RAG Sync Simple] response_data est None")
            return False
        
        # Indicateurs RAG simplifi√©s - pas de boucles complexes
        rag_indicators = [
            'rag_processing' in str(getattr(response_data, 'mode', '')).lower(),
            'rag_enhancer' in str(getattr(response_data, 'ai_enhancements_used', [])),
            len(getattr(response_data, 'processing_steps', [])) > 2,
            getattr(response_data, 'rag_score', 0) > 0
        ]
        
        # V√©rifier processing_metadata pour indicateurs suppl√©mentaires
        if processing_metadata and isinstance(processing_metadata, dict):
            # Recherche simple d'indicateurs RAG dans metadata
            for key, value in processing_metadata.items():
                if isinstance(key, str) and ('rag' in key.lower() or 'vector' in key.lower() or 'search' in key.lower()):
                    if value is not None and value != False and value != 0:
                        rag_indicators.append(True)
                        logger.info(f"‚úÖ [RAG Sync Simple] Metadata RAG: {key}={value}")
                        break
        
        should_be_true = any(rag_indicators)
        current_value = getattr(response_data, 'rag_used', False)
        
        # ‚úÖ CORRECTION UNIQUE - Pas de boucle
        if should_be_true != current_value:
            logger.info(f"üîÑ [RAG Sync Simple] Correction unique: {current_value} ‚Üí {should_be_true}")
            
            # Appliquer correction directement
            if hasattr(response_data, 'rag_used'):
                response_data.rag_used = should_be_true
            
            # Mise √† jour mode simple si n√©cessaire
            if hasattr(response_data, 'mode'):
                current_mode = getattr(response_data, 'mode', '')
                if should_be_true and 'rag' not in current_mode.lower():
                    response_data.mode = f"{current_mode}_with_rag"
                elif not should_be_true and 'rag' in current_mode.lower():
                    response_data.mode = current_mode.replace('_rag', '').replace('_with_rag', '').replace('rag_', '')
            
            # Ajouter trace simple dans processing_steps
            if hasattr(response_data, 'processing_steps') and isinstance(response_data.processing_steps, list):
                response_data.processing_steps.append(f"rag_sync_simple_correction_{current_value}_to_{should_be_true}")
            
            # Ajouter enhancement simple
            if hasattr(response_data, 'ai_enhancements_used') and isinstance(response_data.ai_enhancements_used, list):
                response_data.ai_enhancements_used.append("rag_sync_simple_v3.7.8")
            
            logger.info(f"‚úÖ [RAG Sync Simple] Correction appliqu√©e - nouvel √©tat: {should_be_true}")
            return True
        
        logger.info(f"‚úÖ [RAG Sync Simple] Aucune correction n√©cessaire - √©tat: {current_value}")
        return False
        
    except Exception as e:
        logger.error(f"‚ùå [RAG Sync Simple] Erreur: {e}")
        return False

# =============================================================================
# UTILITAIRES PROPAGATION CHAMPS - CONSERV√âS INT√âGRALEMENT
# =============================================================================

def _extract_propagation_fields(response_data: Any) -> Dict[str, Any]:
    """üîß CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.8: Extraction avec nouveaux champs clarification"""
    
    propagation_fields = {
        "clarification_required_critical": False,
        "missing_critical_entities": [],
        "variants_tested": [],
        # üÜï NOUVEAUX v3.7.8
        "dynamic_questions": None,
        "clarification_service_used": False
    }
    
    try:
        # üîß FIX: Validation du type avant hasattr
        if response_data is None:
            logger.warning("‚ö†Ô∏è [PROPAGATION v3.7.8] response_data est None")
            return propagation_fields
        
        logger.info("üìã [PROPAGATION v3.7.8] D√âMARRAGE extraction champs...")
        
        # Extraction clarification_required_critical avec validation robuste
        if hasattr(response_data, 'clarification_result'):
            clarification_result = getattr(response_data, 'clarification_result', None)
            if clarification_result and isinstance(clarification_result, dict):
                propagation_fields["clarification_required_critical"] = clarification_result.get("clarification_required_critical", False)
                missing_entities = clarification_result.get("missing_critical_entities", [])
                # üîß FIX: Validation que missing_entities est une liste
                if isinstance(missing_entities, list):
                    propagation_fields["missing_critical_entities"] = missing_entities
                else:
                    propagation_fields["missing_critical_entities"] = []
                
                # üÜï NOUVEAU v3.7.8: Extraction dynamic_questions
                dynamic_questions = clarification_result.get("dynamic_questions", None)
                if dynamic_questions and isinstance(dynamic_questions, list):
                    propagation_fields["dynamic_questions"] = dynamic_questions
                
                logger.info(f"üìã [PROPAGATION v3.7.8] Clarification critique: {propagation_fields['clarification_required_critical']}")
                logger.info(f"üìã [PROPAGATION v3.7.8] Entit√©s critiques manquantes: {propagation_fields['missing_critical_entities']}")
                logger.info(f"üìã [PROPAGATION v3.7.8] Questions dynamiques: {len(dynamic_questions) if dynamic_questions else 0}")
        
        # üÜï NOUVEAU v3.7.8: Extraction directe des nouveaux champs
        if hasattr(response_data, 'dynamic_questions'):
            dynamic_questions = getattr(response_data, 'dynamic_questions', None)
            if dynamic_questions and isinstance(dynamic_questions, list):
                propagation_fields["dynamic_questions"] = dynamic_questions
                logger.info(f"üìã [PROPAGATION v3.7.8] Questions dynamiques directes: {len(dynamic_questions)}")
        
        if hasattr(response_data, 'clarification_service_used'):
            service_used = getattr(response_data, 'clarification_service_used', False)
            propagation_fields["clarification_service_used"] = service_used
            logger.info(f"üìã [PROPAGATION v3.7.8] Service clarification utilis√©: {service_used}")
        
        # Extraction variants_tested depuis RAG enhancements avec validation
        if hasattr(response_data, 'rag_enhancement_info'):
            rag_enhancement_info = getattr(response_data, 'rag_enhancement_info', None)
            if rag_enhancement_info and isinstance(rag_enhancement_info, dict):
                variants = rag_enhancement_info.get("variants_tested", [])
                if isinstance(variants, list):
                    propagation_fields["variants_tested"] = variants
                    logger.info(f"üìã [PROPAGATION v3.7.8] Variantes test√©es: {propagation_fields['variants_tested']}")
        
        logger.info("‚úÖ [PROPAGATION v3.7.8] Champs extraits avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå [PROPAGATION v3.7.8] Erreur extraction champs: {e}")
        # üîß FIX: Garder les valeurs par d√©faut en cas d'erreur
    
    return propagation_fields

def _apply_propagation_fields(response: Any, propagation_fields: Dict[str, Any]) -> Any:
    """üîß CONSERV√âE v3.7.6 + AM√âLIORATION v3.7.8: Application avec nouveaux champs clarification"""
    
    try:
        # üîß FIX: Validation que response n'est pas None
        if response is None:
            logger.error("‚ùå [PROPAGATION v3.7.8] response est None")
            return response
        
        # üîß FIX: Validation que propagation_fields est un dict
        if not isinstance(propagation_fields, dict):
            logger.error("‚ùå [PROPAGATION v3.7.8] propagation_fields n'est pas un dict")
            return response
        
        logger.info("üìã [PROPAGATION v3.7.8] D√âMARRAGE application champs...")
        
        # Application des champs existants avec validation
        if hasattr(response, 'clarification_required_critical'):
            old_val = response.clarification_required_critical
            response.clarification_required_critical = propagation_fields.get("clarification_required_critical", False)
            if old_val != response.clarification_required_critical:
                logger.info(f"üìã [PROPAGATION v3.7.8] clarification_required_critical: {old_val} ‚Üí {response.clarification_required_critical}")
        
        if hasattr(response, 'missing_critical_entities'):
            missing_entities = propagation_fields.get("missing_critical_entities", [])
            if isinstance(missing_entities, list):
                old_len = len(response.missing_critical_entities) if response.missing_critical_entities else 0
                response.missing_critical_entities = missing_entities
                logger.info(f"üìã [PROPAGATION v3.7.8] missing_critical_entities: {old_len} ‚Üí {len(missing_entities)} entit√©s")
            else:
                response.missing_critical_entities = []
        
        if hasattr(response, 'variants_tested'):
            variants = propagation_fields.get("variants_tested", [])
            if isinstance(variants, list):
                old_len = len(response.variants_tested) if response.variants_tested else 0
                response.variants_tested = variants
                logger.info(f"üìã [PROPAGATION v3.7.8] variants_tested: {old_len} ‚Üí {len(variants)} variantes")
            else:
                response.variants_tested = []
        
        # üÜï NOUVEAUX CHAMPS v3.7.8: Application dynamic_questions et clarification_service_used
        if hasattr(response, 'dynamic_questions'):
            dynamic_questions = propagation_fields.get("dynamic_questions", None)
            if dynamic_questions and isinstance(dynamic_questions, list):
                response.dynamic_questions = dynamic_questions
                logger.info(f"üìã [PROPAGATION v3.7.8] dynamic_questions: {len(dynamic_questions)} questions appliqu√©es")
            else:
                response.dynamic_questions = None
        
        if hasattr(response, 'clarification_service_used'):
            service_used = propagation_fields.get("clarification_service_used", False)
            response.clarification_service_used = service_used
            logger.info(f"üìã [PROPAGATION v3.7.8] clarification_service_used: {service_used}")
        
        logger.info("‚úÖ [PROPAGATION v3.7.8] Champs appliqu√©s √† la r√©ponse finale")
        
    except Exception as e:
        logger.error(f"‚ùå [PROPAGATION v3.7.8] Erreur application champs: {e}")
    
    return response

# =============================================================================
# LOGGING ET INITIALISATION FINALE v3.7.8
# =============================================================================

logger.info("üöÄ" * 50)
logger.info("üöÄ [EXPERT CORE FUNCTIONS] VERSION 3.7.8 - FONCTIONS REFACTORIS√âES!")
logger.info("üöÄ [REFACTORISATION]:")
logger.info("   ‚úÖ Fonctions de logique m√©tier extraites de expert.py")
logger.info("   ‚úÖ Code conserv√© int√©gralement")
logger.info("   ‚úÖ Service clarification int√©gr√©")
logger.info("   ‚úÖ Validation entit√©s critiques")
logger.info("   ‚úÖ Synchronisation RAG simplifi√©e")
logger.info("   ‚úÖ Gestion d'erreur robuste")
logger.info("")
logger.info("üîß [FONCTIONS DISPONIBLES v3.7.8]:")
logger.info("   - _build_conversation_context")
logger.info("   - _analyze_agricultural_domain")
logger.info("   - _apply_dynamic_clarification_service")
logger.info("   - _apply_fallback_clarification")
logger.info("   - _extract_critical_entities_from_question")
logger.info("   - _validate_critical_entities")
logger.info("   - _force_clarification_for_missing_entities")
logger.info("   - _detect_inconsistencies_and_force_clarification")
logger.info("   - _sync_rag_state_simple")
logger.info("   - _extract_propagation_fields")
logger.info("   - _apply_propagation_fields")
logger.info("")
logger.info("‚úÖ [R√âSULTAT ATTENDU v3.7.8]:")
logger.info("   ‚úÖ Fonctions m√©tier s√©par√©es")
logger.info("   ‚úÖ Logique pr√©serv√©e")
logger.info("   ‚úÖ Imports s√©curis√©s")
logger.info("   ‚úÖ Gestion d'erreur robuste")
logger.info("   ‚úÖ SYNTAXE PYTHON 100% CORRECTE")
logger.info("üöÄ" * 50)