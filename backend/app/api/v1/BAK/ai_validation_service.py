"""
ai_validation_service.py - VALIDATION ET CLASSIFICATION AVEC IA

üéØ REMPLACE: Logique complexe de validation hardcod√©e par analyse IA intelligente
üöÄ CAPACIT√âS:
- ‚úÖ Classification d'intention avec IA (performance, sant√©, alimentation)
- ‚úÖ Validation de clarifications contextuelles
- ‚úÖ D√©tection intelligente des types de r√©ponse optimaux
- ‚úÖ Analyse de coh√©rence des entit√©s
- ‚úÖ Recommandations de classification avec raisonnement
- ‚úÖ Support du workflow conversationnel

Architecture:
- Classification bas√©e sur compr√©hension du langage naturel
- Validation contextuelle des clarifications utilisateur
- Analyse de coh√©rence multi-entit√©s
- Int√©gration seamless avec le smart_classifier existant
"""

import json
import logging
from typing import Dict, Any, Optional, List, Union, Tuple
from dataclasses import dataclass
from enum import Enum
from datetime import datetime

from .ai_service_manager import AIServiceType, call_ai, AIResponse

logger = logging.getLogger(__name__)

class ResponseType(Enum):
    """Types de r√©ponse recommand√©s"""
    PRECISE_ANSWER = "precise_answer"
    CONTEXTUAL_ANSWER = "contextual_answer"  
    GENERAL_ANSWER = "general_answer"
    NEEDS_CLARIFICATION = "needs_clarification"

class IntentType(Enum):
    """Types d'intention d√©tect√©s"""
    PERFORMANCE_QUERY = "performance"     # Poids, croissance, standards
    HEALTH_CONCERN = "sant√©"             # Sympt√¥mes, maladies, traitements
    FEEDING_QUESTION = "alimentation"     # Nutrition, aliments, rationing
    HOUSING_QUERY = "logement"           # Conditions, environnement
    GENERAL_INFO = "g√©n√©ral"             # Questions g√©n√©rales
    CLARIFICATION = "clarification"       # R√©ponse √† une demande de pr√©cision

@dataclass
class ValidationResult:
    """R√©sultat de validation d'une clarification"""
    is_valid_clarification: bool = False
    extracted_entities: Dict[str, Any] = None
    confidence: float = 0.0
    validation_reasoning: str = ""
    suggested_action: str = ""  # "accept", "request_more", "reject"
    
    def __post_init__(self):
        if self.extracted_entities is None:
            self.extracted_entities = {}

@dataclass
class ClassificationResult:
    """R√©sultat de classification d'intention"""
    intent_type: IntentType
    response_type: ResponseType
    confidence: float
    reasoning: str
    missing_entities: List[str] = None
    suggested_weight_calculation: bool = False
    urgency_level: str = "normal"  # normal, elevated, urgent
    
    def __post_init__(self):
        if self.missing_entities is None:
            self.missing_entities = []

class AIValidationService:
    """Service de validation et classification avec IA"""
    
    def __init__(self):
        # Configuration des mod√®les
        self.models = {
            "intent_classification": "gpt-4",     # Classification d'intention
            "entity_validation": "gpt-3.5-turbo", # Validation d'entit√©s
            "clarification_analysis": "gpt-4",    # Analyse de clarifications
            "coherence_check": "gpt-3.5-turbo"    # V√©rification de coh√©rence
        }
        
        # Prompts sp√©cialis√©s
        self.prompts = self._initialize_prompts()
        
        # R√®gles de validation (backup)
        self.validation_rules = self._initialize_validation_rules()
        
        logger.info("ü§ñ [AI Validation Service] Initialis√© avec classification IA intelligente")
    
    def _initialize_prompts(self) -> Dict[str, str]:
        """Initialise les prompts sp√©cialis√©s pour validation/classification"""
        return {
            "intent_classification": """Analyse cette question d'√©levage avicole et d√©termine l'intention et le type de r√©ponse optimal.

QUESTION: "{question}"

ENTIT√âS D√âTECT√âES:
{entities}

CONTEXTE CONVERSATIONNEL:
{context}

T√ÇCHE: D√©termine l'intention r√©elle et le type de r√©ponse le plus appropri√©.

TYPES D'INTENTION POSSIBLES:
1. **PERFORMANCE** - Questions sur poids, croissance, standards, d√©veloppement
2. **SANT√â** - Sympt√¥mes, maladies, traitements, probl√®mes sanitaires
3. **ALIMENTATION** - Nutrition, aliments, rationing, besoins nutritionnels
4. **LOGEMENT** - Conditions d'√©levage, environnement, h√©bergement
5. **G√âN√âRAL** - Questions g√©n√©rales, informations de base
6. **CLARIFICATION** - R√©ponse √† une demande de pr√©cision pr√©c√©dente

TYPES DE R√âPONSE OPTIMAUX:
- **PRECISE_ANSWER**: Assez d'informations pour r√©ponse sp√©cifique avec calculs
- **CONTEXTUAL_ANSWER**: Question de clarification qui compl√®te un contexte pr√©c√©dent  
- **GENERAL_ANSWER**: Informations g√©n√©rales utiles avec offre de pr√©cision
- **NEEDS_CLARIFICATION**: Vraiment trop vague pour √™tre utile

CRIT√àRES DE D√âCISION:
- PRECISE_ANSWER: Race sp√©cifique + √¢ge + (sexe OU contexte performance)
- CONTEXTUAL_ANSWER: Clarification courte + contexte conversationnel riche
- GENERAL_ANSWER: Un √©l√©ment manque mais question reste utile
- NEEDS_CLARIFICATION: Plusieurs √©l√©ments essentiels manquants

R√©ponds en JSON:
```json
{{
  "intent_type": "performance"|"sant√©"|"alimentation"|"logement"|"g√©n√©ral"|"clarification",
  "response_type": "precise_answer"|"contextual_answer"|"general_answer"|"needs_clarification",
  "confidence": 0.0-1.0,
  "reasoning": "explication d√©taill√©e du raisonnement",
  "missing_entities": ["liste des entit√©s manquantes"],
  "suggested_weight_calculation": true|false,
  "urgency_level": "normal"|"elevated"|"urgent",
  "key_factors": ["facteurs cl√©s de la d√©cision"]
}}
```

EXEMPLES:
- "Poids Ross 308 m√¢les 21 jours" ‚Üí PERFORMANCE + PRECISE_ANSWER
- "Ross 308 male" (apr√®s question poids) ‚Üí CLARIFICATION + CONTEXTUAL_ANSWER
- "Mes poulets sont malades" ‚Üí SANT√â + NEEDS_CLARIFICATION (symptoms manquants)
- "Poids normal √† 3 semaines" ‚Üí PERFORMANCE + GENERAL_ANSWER (race manquante)""",

            "clarification_validation": """Valide cette clarification utilisateur et extrait les entit√©s pertinentes.

CLARIFICATION UTILISATEUR: "{clarification}"

CONTEXTE PR√âC√âDENT:
{previous_context}

QUESTION ORIGINALE: "{original_question}"

T√ÇCHE: D√©termine si cette clarification est valide et suffisante.

ANALYSE REQUISE:
1. **VALIDIT√â**: La clarification apporte-t-elle des informations utiles ?
2. **COH√âRENCE**: Est-elle coh√©rente avec le contexte pr√©c√©dent ?
3. **COMPL√âTUDE**: Suffit-elle pour r√©pondre √† la question originale ?
4. **EXTRACTION**: Quelles entit√©s sp√©cifiques sont mentionn√©es ?

ENTIT√âS √Ä CHERCHER:
- Race/souche (Ross 308, Cobb 500, Hubbard, ISA Brown, etc.)
- Sexe (m√¢le, femelle, mixte, coq, poule)
- √Çge (si mentionn√©)
- Contexte additionnel (conditions, objectifs)

EXEMPLES DE VALIDIT√â:
‚úÖ VALIDE: "Ross 308 male" ‚Üí race et sexe sp√©cifi√©s
‚úÖ VALIDE: "femelles de 3 semaines" ‚Üí sexe et √¢ge pr√©cis√©s
‚ùå INVALIDE: "oui" ‚Üí aucune information
‚ùå INVALIDE: "les poulets" ‚Üí trop vague

R√©ponds en JSON:
```json
{{
  "is_valid_clarification": true|false,
  "extracted_entities": {{
    "breed_specific": "Ross 308"|null,
    "sex": "male"|"female"|"mixed"|null,
    "age_days": number|null,
    "additional_context": "description"|null
  }},
  "confidence": 0.0-1.0,
  "validation_reasoning": "explication de la validation",
  "suggested_action": "accept"|"request_more"|"reject",
  "missing_for_complete_answer": ["entit√©s encore manquantes"]
}}
```""",

            "entity_coherence_check": """V√©rifie la coh√©rence et validit√© de ces entit√©s d'√©levage avicole.

ENTIT√âS √Ä V√âRIFIER:
{entities}

QUESTION CONTEXTE: "{question}"

T√ÇCHE: V√©rifie la logique et coh√©rence des combinaisons d'entit√©s.

V√âRIFICATIONS:
1. **COH√âRENCE BIOLOGIQUE**: Combinaisons r√©alistes (race-√¢ge-poids)
2. **LOGIQUE TEMPORELLE**: √Çges coh√©rents avec stades de d√©veloppement
3. **SP√âCIFICIT√â RACIALE**: Compatibilit√© race-usage (chair vs ponte)
4. **RANGES NORMAUX**: Valeurs dans les fourchettes attendues

EXEMPLES D'INCOH√âRENCES:
‚ùå ISA Brown (pondeuses) + 21 jours + poids 1000g (trop lourd pour pondeuses)
‚ùå Ross 308 + 50 semaines (races de chair ne vivent pas si longtemps)
‚ùå √Çge 5 jours + poids 500g (croissance impossible)
‚úÖ Ross 308 + 21 jours + poids 800g + m√¢le (coh√©rent)

R√©ponds en JSON:
```json
{{
  "entities_coherent": true|false,
  "coherence_score": 0.0-1.0,
  "issues_found": ["liste des probl√®mes d√©tect√©s"],
  "corrected_entities": {{"entit√©s corrig√©es si n√©cessaire"}},
  "confidence_level": "high"|"medium"|"low",
  "validation_notes": "explication des v√©rifications"
}}
```""",

            "contextual_analysis": """Analyse cette question dans son contexte pour d√©terminer si c'est une clarification contextuelle.

QUESTION ACTUELLE: "{current_question}"

HISTORIQUE CONVERSATION:
{conversation_history}

ENTIT√âS ACTUELLES: {current_entities}

T√ÇCHE: D√©termine si cette question fait suite logiquement √† la conversation pr√©c√©dente.

INDICATEURS DE CLARIFICATION CONTEXTUELLE:
1. **QUESTION COURTE** avec entit√©s sp√©cifiques (‚â§ 5 mots)
2. **R√âF√âRENCES CONTEXTUELLES** ("pour un", "avec des", "race X")
3. **COMPL√âMENTARIT√â** avec question pr√©c√©dente
4. **PROGRESSION LOGIQUE** de la conversation

EXEMPLES:
- Question pr√©c√©dente: "Poids poulet 21 jours ?" + Actuelle: "Ross 308 male" ‚Üí CONTEXTUEL
- Question pr√©c√©dente: "Probl√®me sant√©" + Actuelle: "diarrh√©e depuis 2 jours" ‚Üí CONTEXTUEL  
- Question isol√©e: "Comment nourrir mes poules ?" ‚Üí NON CONTEXTUEL

R√©ponds en JSON:
```json
{{
  "is_contextual_clarification": true|false,
  "contextual_confidence": 0.0-1.0,
  "context_reasoning": "explication de l'analyse contextuelle",
  "merged_context": {{"contexte fusionn√© si applicable"}},
  "next_action": "process_as_contextual"|"process_as_new_question"
}}
```"""
        }
    
    def _initialize_validation_rules(self) -> Dict[str, Any]:
        """R√®gles de validation de backup (fallback)"""
        return {
            "min_clarification_length": 2,  # Minimum 2 caract√®res
            "max_clarification_length": 100,  # Maximum 100 caract√®res
            "valid_breeds": [
                "ross 308", "cobb 500", "hubbard", "arbor acres", 
                "isa brown", "lohmann brown", "hy-line", "bovans"
            ],
            "valid_sexes": ["m√¢le", "male", "femelle", "female", "mixte", "mixed"],
            "age_ranges": {
                "broilers": {"min": 1, "max": 70},  # 1-70 jours
                "layers": {"min": 1, "max": 500}     # 1-500 jours
            },
            "weight_ranges": {
                "day_1": {"min": 35, "max": 50},      # Poussin 1 jour
                "day_7": {"min": 120, "max": 220},    # 1 semaine
                "day_21": {"min": 500, "max": 1200},  # 3 semaines
                "day_35": {"min": 1200, "max": 2800}  # 5 semaines
            }
        }
    
    async def classify_intent_and_response_type(self,
                                              question: str,
                                              entities: Dict[str, Any],
                                              conversation_context: str = "",
                                              language: str = "fr") -> ClassificationResult:
        """
        Classification principale - D√©termine l'intention et le type de r√©ponse optimal
        
        Args:
            question: Question de l'utilisateur
            entities: Entit√©s extraites
            conversation_context: Contexte conversationnel
            language: Langue d√©tect√©e
            
        Returns:
            ClassificationResult avec recommandations
        """
        try:
            logger.info(f"ü§ñ [AI Validation] Classification intention: '{question[:50]}...'")
            
            # Pr√©parer les donn√©es pour le prompt
            entities_str = json.dumps(entities, ensure_ascii=False, indent=2)
            context_str = conversation_context[-1000:] if conversation_context else "Pas de contexte"
            
            # Construire le prompt
            prompt = self.prompts["intent_classification"].format(
                question=question,
                entities=entities_str,
                context=context_str
            )
            
            # Appel IA pour classification
            ai_response = await call_ai(
                service_type=AIServiceType.CLASSIFICATION,
                prompt=prompt,
                model=self.models["intent_classification"],
                max_tokens=700,
                temperature=0.1,  # Tr√®s conservateur pour classification
                cache_key=f"intent_classify_{hash(question + entities_str[:200])}"
            )
            
            # Parser le r√©sultat
            classification_data = self._parse_json_response(ai_response.content)
            
            # Convertir en objets typ√©s
            intent_type = IntentType(classification_data.get("intent_type", "g√©n√©ral"))
            response_type = ResponseType(classification_data.get("response_type", "general_answer"))
            
            # Construire le r√©sultat
            result = ClassificationResult(
                intent_type=intent_type,
                response_type=response_type,
                confidence=classification_data.get("confidence", 0.0),
                reasoning=classification_data.get("reasoning", ""),
                missing_entities=classification_data.get("missing_entities", []),
                suggested_weight_calculation=classification_data.get("suggested_weight_calculation", False),
                urgency_level=classification_data.get("urgency_level", "normal")
            )
            
            logger.info(f"‚úÖ [AI Validation] Classification termin√©e: {intent_type.value} ‚Üí {response_type.value} (conf: {result.confidence})")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AI Validation] Erreur classification: {e}")
            return self._fallback_classification(question, entities)
    
    async def validate_clarification(self,
                                   clarification: str,
                                   original_question: str,
                                   previous_context: Dict[str, Any] = None,
                                   language: str = "fr") -> ValidationResult:
        """
        Valide une clarification utilisateur
        
        Args:
            clarification: Clarification fournie par l'utilisateur
            original_question: Question originale qui n√©cessitait clarification
            previous_context: Contexte de la conversation pr√©c√©dente
            language: Langue
            
        Returns:
            ValidationResult avec analyse de la clarification
        """
        try:
            logger.info(f"ü§ñ [AI Validation] Validation clarification: '{clarification}'")
            
            # Pr√©parer le contexte
            context_str = json.dumps(previous_context or {}, ensure_ascii=False, indent=2)
            
            # Construire le prompt
            prompt = self.prompts["clarification_validation"].format(
                clarification=clarification,
                previous_context=context_str,
                original_question=original_question
            )
            
            # Appel IA pour validation
            ai_response = await call_ai(
                service_type=AIServiceType.VALIDATION,
                prompt=prompt,
                model=self.models["clarification_analysis"],
                max_tokens=500,
                temperature=0.05,  # Tr√®s pr√©cis pour validation
                cache_key=f"clarification_validate_{hash(clarification + original_question)}"
            )
            
            # Parser le r√©sultat
            validation_data = self._parse_json_response(ai_response.content)
            
            # Construire le r√©sultat
            result = ValidationResult(
                is_valid_clarification=validation_data.get("is_valid_clarification", False),
                extracted_entities=validation_data.get("extracted_entities", {}),
                confidence=validation_data.get("confidence", 0.0),
                validation_reasoning=validation_data.get("validation_reasoning", ""),
                suggested_action=validation_data.get("suggested_action", "request_more")
            )
            
            logger.info(f"‚úÖ [AI Validation] Validation termin√©e: valide={result.is_valid_clarification}, action={result.suggested_action}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AI Validation] Erreur validation clarification: {e}")
            return self._fallback_clarification_validation(clarification)
    
    async def check_entity_coherence(self,
                                   entities: Dict[str, Any],
                                   question_context: str = "") -> Tuple[bool, float, List[str]]:
        """
        V√©rifie la coh√©rence des entit√©s extraites
        
        Args:
            entities: Entit√©s √† v√©rifier
            question_context: Contexte de la question
            
        Returns:
            Tuple (is_coherent, confidence_score, issues_found)
        """
        try:
            logger.info(f"ü§ñ [AI Validation] V√©rification coh√©rence: {len(entities)} entit√©s")
            
            # Pr√©parer les donn√©es
            entities_str = json.dumps(entities, ensure_ascii=False, indent=2)
            
            # Construire le prompt
            prompt = self.prompts["entity_coherence_check"].format(
                entities=entities_str,
                question=question_context
            )
            
            # Appel IA pour v√©rification
            ai_response = await call_ai(
                service_type=AIServiceType.VALIDATION,
                prompt=prompt,
                model=self.models["coherence_check"],
                max_tokens=400,
                temperature=0.05,
                cache_key=f"coherence_check_{hash(entities_str)}"
            )
            
            # Parser le r√©sultat
            coherence_data = self._parse_json_response(ai_response.content)
            
            is_coherent = coherence_data.get("entities_coherent", True)
            confidence = coherence_data.get("coherence_score", 0.5)
            issues = coherence_data.get("issues_found", [])
            
            logger.info(f"‚úÖ [AI Validation] Coh√©rence v√©rifi√©e: coh√©rent={is_coherent}, score={confidence}")
            
            return is_coherent, confidence, issues
            
        except Exception as e:
            logger.error(f"‚ùå [AI Validation] Erreur v√©rification coh√©rence: {e}")
            return True, 0.5, []  # Assume coherent if check fails
    
    async def analyze_contextual_clarification(self,
                                             current_question: str,
                                             conversation_history: str,
                                             current_entities: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyse si la question actuelle est une clarification contextuelle
        
        Args:
            current_question: Question actuelle
            conversation_history: Historique de conversation
            current_entities: Entit√©s de la question actuelle
            
        Returns:
            Dict avec analyse contextuelle
        """
        try:
            logger.info(f"ü§ñ [AI Validation] Analyse contextuelle: '{current_question[:30]}...'")
            
            # Pr√©parer les donn√©es
            entities_str = json.dumps(current_entities, ensure_ascii=False)
            
            # Construire le prompt
            prompt = self.prompts["contextual_analysis"].format(
                current_question=current_question,
                conversation_history=conversation_history[-1500:],  # Limiter pour tokens
                current_entities=entities_str
            )
            
            # Appel IA pour analyse
            ai_response = await call_ai(
                service_type=AIServiceType.VALIDATION,
                prompt=prompt,
                model=self.models["clarification_analysis"],
                max_tokens=500,
                temperature=0.1,
                cache_key=f"contextual_analysis_{hash(current_question + conversation_history[-500:])}"
            )
            
            # Parser et retourner
            analysis_data = self._parse_json_response(ai_response.content)
            
            logger.info(f"‚úÖ [AI Validation] Analyse contextuelle termin√©e: contextuel={analysis_data.get('is_contextual_clarification', False)}")
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"‚ùå [AI Validation] Erreur analyse contextuelle: {e}")
            return {
                "is_contextual_clarification": False,
                "contextual_confidence": 0.0,
                "context_reasoning": f"Erreur: {e}",
                "next_action": "process_as_new_question"
            }
    
    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """Parse une r√©ponse JSON avec gestion d'erreurs robuste"""
        
        try:
            # Nettoyer le contenu
            content = content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            return json.loads(content)
            
        except json.JSONDecodeError as e:
            logger.warning(f"‚ö†Ô∏è [AI Validation] Erreur parsing JSON: {e}")
            return {}
        except Exception as e:
            logger.error(f"‚ùå [AI Validation] Erreur parsing: {e}")
            return {}
    
    def _fallback_classification(self, question: str, entities: Dict[str, Any]) -> ClassificationResult:
        """Classification de fallback avec r√®gles simples"""
        
        logger.info("üîß [AI Validation] Fallback classification avec r√®gles")
        
        question_lower = question.lower()
        
        # D√©tecter l'intention avec mots-cl√©s
        if any(word in question_lower for word in ["poids", "croissance", "performance", "weight"]):
            intent = IntentType.PERFORMANCE_QUERY
        elif any(word in question_lower for word in ["malade", "sympt√¥me", "sant√©", "probl√®me"]):
            intent = IntentType.HEALTH_CONCERN
        elif any(word in question_lower for word in ["alimentation", "nourrir", "aliment"]):
            intent = IntentType.FEEDING_QUESTION
        else:
            intent = IntentType.GENERAL_INFO
        
        # D√©tecter le type de r√©ponse
        has_breed = bool(entities.get("breed_specific"))
        has_age = bool(entities.get("age_days"))
        has_sex = bool(entities.get("sex"))
        
        if has_breed and has_age and has_sex:
            response_type = ResponseType.PRECISE_ANSWER
            confidence = 0.8
        elif has_breed and (has_age or has_sex):
            response_type = ResponseType.GENERAL_ANSWER
            confidence = 0.7
        elif len(question.split()) <= 3 and (has_breed or has_sex):
            response_type = ResponseType.CONTEXTUAL_ANSWER
            confidence = 0.6
        else:
            response_type = ResponseType.NEEDS_CLARIFICATION
            confidence = 0.5
        
        return ClassificationResult(
            intent_type=intent,
            response_type=response_type,
            confidence=confidence,
            reasoning="Classification fallback avec r√®gles simples"
        )
    
    def _fallback_clarification_validation(self, clarification: str) -> ValidationResult:
        """Validation de clarification de fallback"""
        
        logger.info("üîß [AI Validation] Fallback validation clarification")
        
        clarification_lower = clarification.lower().strip()
        
        # V√©rifications basiques
        if len(clarification_lower) < 2:
            return ValidationResult(
                is_valid_clarification=False,
                confidence=0.1,
                validation_reasoning="Clarification trop courte",
                suggested_action="request_more"
            )
        
        # Recherche d'entit√©s simples
        extracted = {}
        
        # Races
        for breed in self.validation_rules["valid_breeds"]:
            if breed in clarification_lower:
                extracted["breed_specific"] = breed.title()
                break
        
        # Sexes
        for sex in self.validation_rules["valid_sexes"]:
            if sex in clarification_lower:
                extracted["sex"] = "male" if sex in ["m√¢le", "male"] else "female" if sex in ["femelle", "female"] else "mixed"
                break
        
        is_valid = len(extracted) > 0
        confidence = 0.6 if is_valid else 0.3
        
        return ValidationResult(
            is_valid_clarification=is_valid,
            extracted_entities=extracted,
            confidence=confidence,
            validation_reasoning="Validation fallback avec patterns simples",
            suggested_action="accept" if is_valid else "request_more"
        )
    
    def get_validation_stats(self) -> Dict[str, Any]:
        """Statistiques de validation pour monitoring"""
        from .ai_service_manager import get_ai_service_manager
        
        manager = get_ai_service_manager()
        health = manager.get_service_health()
        
        return {
            "service_name": "AI Validation Service",
            "validation_requests": health.get("requests_by_service", {}).get("validation", 0),
            "classification_requests": health.get("requests_by_service", {}).get("classification", 0),
            "models_available": list(self.models.keys()),
            "intent_types": [t.value for t in IntentType],
            "response_types": [t.value for t in ResponseType],
            "validation_rules": {k: len(v) if isinstance(v, (list, dict)) else v for k, v in self.validation_rules.items()},
            "ai_service_health": health
        }

# Instance globale pour utilisation facile
_ai_validation_service = None

def get_ai_validation_service() -> AIValidationService:
    """R√©cup√®re l'instance singleton du service de validation IA"""
    global _ai_validation_service
    if _ai_validation_service is None:
        _ai_validation_service = AIValidationService()
    return _ai_validation_service