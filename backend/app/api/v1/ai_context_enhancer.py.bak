f"""
ai_context_enhancer.py - ENHANCEMENT CONTEXTUEL AVEC IA

üéØ REMPLACE: 200+ lignes de patterns pronominaux rigides par compr√©hension IA
üöÄ CAPACIT√âS:
- ‚úÖ Analyse conversationnelle intelligente
- ‚úÖ R√©solution des r√©f√©rences contextuelles ("leur poids", "ces poulets")
- ‚úÖ Enhancement pour recherche documentaire (RAG)
- ‚úÖ D√©tection des clarifications implicites
- ‚úÖ Fusion contextuelle automatique
- ‚úÖ Support multilingue natif

Architecture:
- Analyse IA du contexte conversationnel
- Enhancement automatique des questions pour RAG
- Fusion intelligente des entit√©s contextuelles
- Optimisation des requ√™tes de recherche
"""

import json
import logging
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass
from datetime import datetime

from .ai_service_manager import AIServiceType, call_ai, AIResponse

logger = logging.getLogger(__name__)

@dataclass
class ContextAnalysis:
    """R√©sultat de l'analyse contextuelle"""
    references_detected: bool = False
    enhanced_question: str = ""
    context_entities: Dict[str, Any] = None
    missing_context: List[str] = None
    confidence: float = 0.0
    reasoning: str = ""
    
    def __post_init__(self):
        if self.context_entities is None:
            self.context_entities = {}
        if self.missing_context is None:
            self.missing_context = []

@dataclass  
class EnhancedContext:
    """Contexte enrichi pour la recherche et g√©n√©ration"""
    original_question: str
    enhanced_question: str
    merged_entities: Dict[str, Any]
    rag_optimized_query: str
    context_summary: str
    enhancement_confidence: float
    ai_reasoning: str

class AIContextEnhancer:
    """Enhancer contextuel avec IA - Remplace les patterns pronominaux"""
    
    def __init__(self):
        # Configuration des mod√®les
        self.models = {
            "context_analysis": "gpt-4",      # Analyse contextuelle complexe
            "question_enhancement": "gpt-4",   # Enhancement de questions
            "entity_fusion": "gpt-3.5-turbo", # Fusion d'entit√©s
            "rag_optimization": "gpt-4"        # Optimisation pour RAG
        }
        
        # Prompts sp√©cialis√©s
        self.prompts = self._initialize_prompts()
        
        logger.info("ü§ñ [AI Context Enhancer] Initialis√© avec analyse IA contextuelle")
    
    def _initialize_prompts(self) -> Dict[str, str]:
        """Initialise les prompts sp√©cialis√©s pour l'enhancement contextuel"""
        return {
            "context_analysis": """Analyse cette question dans son contexte conversationnel pour d√©tecter les r√©f√©rences implicites.

QUESTION ACTUELLE: "{current_question}"

CONTEXTE CONVERSATIONNEL:
{conversation_context}

T√ÇCHE: D√©termine si la question fait r√©f√©rence √† des √©l√©ments du contexte pr√©c√©dent.

Recherche:
1. **PRONOMS/R√âF√âRENCES**: "leur", "son", "ces", "ils", "elles", etc.
2. **R√âF√âRENCES IMPLICITES**: "√† cet √¢ge", "pour cette race", "dans ce cas"
3. **CONTEXTE MANQUANT**: √©l√©ments n√©cessaires non explicites

R√©ponds en JSON:
```json
{{
  "references_detected": true|false,
  "reference_types": ["pronoms", "implicite", "contextuel"],
  "referenced_entities": {{
    "breed": "race r√©f√©renc√©e du contexte",
    "age": "√¢ge r√©f√©renc√© du contexte", 
    "sex": "sexe r√©f√©renc√© du contexte",
    "previous_topic": "sujet pr√©c√©dent"
  }},
  "missing_context": ["√©l√©ments manquants pour comprendre"],
  "confidence": 0.0-1.0,
  "analysis_reasoning": "explication de l'analyse"
}}
```

EXEMPLES:
- "Leur poids √† 21 jours ?" ‚Üí r√©f√©rences √† une race mentionn√©e pr√©c√©demment
- "Et pour les femelles ?" ‚Üí r√©f√©rence au sexe oppos√© d'une discussion pr√©c√©dente
- "√Ä cet √¢ge, c'est normal ?" ‚Üí r√©f√©rence √† un √¢ge mentionn√© pr√©c√©demment""",

            "question_enhancement": """Enrichis cette question en rendant explicites toutes les r√©f√©rences contextuelles.

QUESTION ORIGINALE: "{original_question}"

CONTEXTE IDENTIFI√â:
{context_entities}

R√âF√âRENCES D√âTECT√âES:
{references_detected}

T√ÇCHE: Reformule la question en rendant tout explicite et auto-suffisant.

R√àGLES:
1. Remplace les pronoms par les entit√©s concr√®tes
2. Explicite les r√©f√©rences implicites  
3. Conserve l'intention originale
4. Rends la question optimale pour recherche documentaire
5. Garde un langage naturel

EXEMPLES:
- "Leur poids normal ?" + Contexte[Ross 308, 21 jours] ‚Üí "Quel est le poids normal des poulets Ross 308 √† 21 jours ?"
- "Et les femelles ?" + Contexte[Cobb 500, m√¢les, poids] ‚Üí "Quel est le poids normal des Cobb 500 femelles ?"
- "C'est normal √† cet √¢ge ?" + Contexte[croissance, 14 jours] ‚Üí "La croissance est-elle normale pour des poulets de 14 jours ?"

R√©ponds en JSON:
```json
{{
  "enhanced_question": "question reformul√©e explicite",
  "entities_added": ["entit√©s ajout√©es du contexte"],
  "enhancement_confidence": 0.0-1.0,
  "enhancement_reasoning": "explication des modifications"
}}
```""",

# =============================================================================
# CORRECTION UNIQUE dans ai_context_enhancer.py
# Ligne ~178 : Remplacer SEULEMENT le prompt "entity_fusion"
# =============================================================================

"entity_fusion": """Fusionne intelligemment les entit√©s actuelles avec le contexte conversationnel.

ENTIT√âS ACTUELLES:
{current_entities}

CONTEXTE CONVERSATIONNEL:
{context_entities}

T√ÇCHE: Combine les entit√©s pour cr√©er une vue compl√®te et coh√©rente.

R√àGLES DE FUSION:
1. **PRIORIT√â**: Entit√©s actuelles > contexte (sauf si actuelles vides)
2. **H√âRITAGE CONDITIONNEL**: H√©rite du contexte SEULEMENT si entit√©s actuelles incompl√®tes ET question fait r√©f√©rence au contexte
3. **COH√âRENCE**: V√©rifie compatibilit√© des combinaisons
4. **COMPL√âTION CONTEXTUELLE**: Comble les manques avec le contexte

‚ö†Ô∏è R√àGLE CRITIQUE POUR QUESTIONS COURTES:
- Si la question actuelle contient d√©j√† des informations sp√©cifiques (race, √¢ge, sexe), NE PAS h√©riter d'autres entit√©s du contexte
- Exemple: "Ross 308 male" contient race + sexe ‚Üí NE PAS ajouter l'√¢ge du contexte
- Exemple: "Leur poids ?" ‚Üí question incompl√®te ‚Üí h√©riter race/√¢ge du contexte

LOGIQUE D√âTAILL√âE:
- Si breed actuel pr√©sent ‚Üí garder breed actuel, ne pas h√©riter
- Si age actuel pr√©sent ‚Üí garder age actuel, ne pas h√©riter  
- Si sex actuel pr√©sent ‚Üí garder sex actuel, ne pas h√©riter
- Si breed actuel vide ET question fait r√©f√©rence √† une race ‚Üí h√©riter breed contexte
- Si age actuel vide ET question fait r√©f√©rence √† un √¢ge ‚Üí h√©riter age contexte
- Si sex actuel vide ET question fait r√©f√©rence √† un sexe ‚Üí h√©riter sex contexte

R√©ponds en JSON:
```json
{{
  "merged_entities": {{
    "age_days": number|null,
    "breed_specific": "breed"|null,
    "sex": "male"|"female"|"mixed"|null,
    "context_type": "performance"|"sant√©"|"alimentation",
    "weight_mentioned": true|false,
    "inherited_from_context": ["liste des champs h√©rit√©s avec justification"]
  }},
  "fusion_confidence": 0.0-1.0,
  "fusion_notes": "explication d√©taill√©e de pourquoi chaque entit√© a √©t√© gard√©e ou h√©rit√©e"
}}
```"""



            "rag_optimization": """Optimise cette question pour la recherche documentaire (RAG) dans une base de connaissances avicoles.

QUESTION ENHANCED: "{enhanced_question}"
ENTIT√âS FUSIONN√âES: {merged_entities}

T√ÇCHE: Cr√©e une requ√™te optimale pour r√©cup√©rer les documents les plus pertinents.

OPTIMISATIONS:
1. **MOTS-CL√âS TECHNIQUES**: Utilise terminologie sp√©cialis√©e avicole
2. **SYNONYMES**: Inclus variations (croissance/d√©veloppement, poids/masse)
3. **SP√âCIFICIT√â**: Balance sp√©cificit√© et couverture
4. **STRUCTURE**: Organise pour matching s√©mantique optimal

EXEMPLES:
- "Poids normal Ross 308 m√¢les 21 jours" ‚Üí "poids standard poulets broilers Ross 308 m√¢les trois semaines 21 jours croissance normale"
- "Sympt√¥mes diarrh√©e poules pondeuses" ‚Üí "diarrh√©e troubles digestifs poules pondeuses sympt√¥mes sant√© intestinale"

R√©ponds en JSON:
```json
{{
  "rag_query": "requ√™te optimis√©e pour recherche",
  "key_terms": ["termes", "cl√©s", "importants"],
  "synonyms_included": ["variations", "ajout√©es"],
  "optimization_confidence": 0.0-1.0,
  "optimization_notes": "explication des optimisations"
}}
```""",

            "context_summary": """Cr√©e un r√©sum√© du contexte conversationnel pour m√©moire √† long terme.

HISTORIQUE CONVERSATION:
{conversation_history}

ENTIT√âS √âTABLIES:
{established_entities}

T√ÇCHE: R√©sume l'essentiel pour maintenir la coh√©rence conversationnelle.

R√âSUM√â DOIT INCLURE:
1. **SUJET PRINCIPAL**: Th√®me de la conversation
2. **ENTIT√âS √âTABLIES**: Race, √¢ge, sexe, contexte r√©currents
3. **PATTERN QUESTIONS**: Type de questions pos√©es
4. **CONTEXTE TECHNIQUE**: Niveau technique de l'utilisateur

R√©ponds en JSON:
```json
{{
  "conversation_topic": "sujet principal",
  "established_entities": {{
    "breed": "race √©tablie",
    "typical_age": "√¢ge typique discut√©", 
    "sex": "sexe typique",
    "context_type": "type de questions"
  }},
  "user_profile": {{
    "technical_level": "d√©butant|interm√©diaire|expert",
    "focus_areas": ["domaines d'int√©r√™t"],
    "question_patterns": ["types de questions r√©currentes"]
  }},
  "summary_confidence": 0.0-1.0
}}
```"""
        }
    
    async def analyze_conversational_context(self, 
                                           current_question: str, 
                                           conversation_history: str,
                                           language: str = "fr") -> ContextAnalysis:
        """
        Analyse le contexte conversationnel pour d√©tecter les r√©f√©rences
        
        Args:
            current_question: Question actuelle de l'utilisateur
            conversation_history: Historique de la conversation  
            language: Langue d√©tect√©e
            
        Returns:
            ContextAnalysis avec les r√©f√©rences d√©tect√©es
        """
        try:
            logger.info(f"ü§ñ [AI Context Enhancer] Analyse contextuelle: '{current_question[:50]}...'")
            
            # Pr√©parer le contexte pour analyse
            context_prompt = self.prompts["context_analysis"].format(
                current_question=current_question,
                conversation_context=conversation_history[:2000]  # Limiter pour token efficiency
            )
            
            # Analyse IA du contexte
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=context_prompt,
                model=self.models["context_analysis"],
                max_tokens=600,
                temperature=0.1,
                cache_key=f"context_analysis_{hash(current_question + conversation_history[:500])}"
            )
            
            # Parser le r√©sultat
            analysis_data = self._parse_json_response(ai_response.content)
            
            # Construire ContextAnalysis
            analysis = ContextAnalysis(
                references_detected=analysis_data.get("references_detected", False),
                context_entities=analysis_data.get("referenced_entities", {}),
                missing_context=analysis_data.get("missing_context", []),
                confidence=analysis_data.get("confidence", 0.0),
                reasoning=analysis_data.get("analysis_reasoning", "")
            )
            
            logger.info(f"‚úÖ [AI Context Enhancer] Analyse termin√©e: r√©f√©rences={analysis.references_detected}, confiance={analysis.confidence}")
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur analyse contextuelle: {e}")
            return ContextAnalysis(reasoning=f"Erreur: {e}")
    
    async def enhance_question_for_rag(self, 
                                     original_question: str,
                                     conversation_context: str = "",
                                     current_entities: Dict[str, Any] = None,
                                     language: str = "fr") -> EnhancedContext:
        """
        Point d'entr√©e principal - Enhancement complet pour RAG
        
        Args:
            original_question: Question originale
            conversation_context: Contexte conversationnel
            current_entities: Entit√©s extraites de la question actuelle
            language: Langue
            
        Returns:
            EnhancedContext avec question optimis√©e et contexte fusionn√©
        """
        try:
            logger.info(f"ü§ñ [AI Context Enhancer] Enhancement complet: '{original_question[:50]}...'")
            
            if current_entities is None:
                current_entities = {}
            
            # 1. Analyser le contexte conversationnel
            context_analysis = await self.analyze_conversational_context(
                original_question, conversation_context, language
            )
            
            # 2. Enhancer la question si r√©f√©rences d√©tect√©es
            enhanced_question = original_question
            if context_analysis.references_detected:
                enhanced_question = await self._enhance_question_with_context(
                    original_question, context_analysis.context_entities
                )
            
            # 3. Fusionner les entit√©s
            merged_entities = await self._merge_entities_with_context(
                current_entities, context_analysis.context_entities
            )
            
            # 4. Optimiser pour RAG
            rag_query = await self._optimize_for_rag(enhanced_question, merged_entities)
            
            # 5. Cr√©er le r√©sum√© contextuel
            context_summary = await self._create_context_summary(
                conversation_context, merged_entities
            )
            
            # Construire r√©sultat final
            enhanced_context = EnhancedContext(
                original_question=original_question,
                enhanced_question=enhanced_question,
                merged_entities=merged_entities,
                rag_optimized_query=rag_query,
                context_summary=context_summary,
                enhancement_confidence=context_analysis.confidence,
                ai_reasoning=context_analysis.reasoning
            )
            
            logger.info(f"‚úÖ [AI Context Enhancer] Enhancement termin√©: '{enhanced_question}'")
            
            return enhanced_context
            
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur enhancement: {e}")
            # Retour fallback
            return EnhancedContext(
                original_question=original_question,
                enhanced_question=original_question,
                merged_entities=current_entities or {},
                rag_optimized_query=original_question,
                context_summary="Erreur enhancement contextuel",
                enhancement_confidence=0.0,
                ai_reasoning=f"Erreur: {e}"
            )
    
    async def _enhance_question_with_context(self, 
                                           original_question: str, 
                                           context_entities: Dict[str, Any]) -> str:
        """Enhancement de la question avec contexte"""
        
        try:
            prompt = self.prompts["question_enhancement"].format(
                original_question=original_question,
                context_entities=json.dumps(context_entities, ensure_ascii=False),
                references_detected=True
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["question_enhancement"],
                max_tokens=400,
                temperature=0.1
            )
            
            result = self._parse_json_response(ai_response.content)
            enhanced = result.get("enhanced_question", original_question)
            
            logger.info(f"‚úÖ [Question Enhancement] '{original_question}' ‚Üí '{enhanced}'")
            return enhanced
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Question Enhancement] Erreur: {e}")
            return original_question
    
    async def _merge_entities_with_context(self, 
                                         current_entities: Dict[str, Any], 
                                         context_entities: Dict[str, Any]) -> Dict[str, Any]:
        """Fusion intelligente des entit√©s"""
        
        try:
            prompt = self.prompts["entity_fusion"].format(
                current_entities=json.dumps(current_entities, ensure_ascii=False),
                context_entities=json.dumps(context_entities, ensure_ascii=False)
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["entity_fusion"],
                max_tokens=500,
                temperature=0.05
            )
            
            result = self._parse_json_response(ai_response.content)
            merged = result.get("merged_entities", current_entities)
            
            logger.info(f"‚úÖ [Entity Fusion] Entit√©s fusionn√©es: {len(merged)} champs")
            return merged
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Entity Fusion] Erreur: {e}")
            # Fusion simple en fallback
            return {**context_entities, **current_entities}
    
    async def _optimize_for_rag(self, enhanced_question: str, merged_entities: Dict[str, Any]) -> str:
        """Optimise la question pour la recherche RAG"""
        
        try:
            prompt = self.prompts["rag_optimization"].format(
                enhanced_question=enhanced_question,
                merged_entities=json.dumps(merged_entities, ensure_ascii=False)
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["rag_optimization"],
                max_tokens=300,
                temperature=0.1
            )
            
            result = self._parse_json_response(ai_response.content)
            rag_query = result.get("rag_query", enhanced_question)
            
            logger.info(f"‚úÖ [RAG Optimization] Query optimis√©e: '{rag_query}'")
            return rag_query
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [RAG Optimization] Erreur: {e}")
            return enhanced_question
    
    async def _create_context_summary(self, conversation_history: str, entities: Dict[str, Any]) -> str:
        """Cr√©e un r√©sum√© du contexte pour m√©moire"""
        
        try:
            if not conversation_history or len(conversation_history) < 50:
                return "Conversation nouvelle - pas d'historique"
            
            prompt = self.prompts["context_summary"].format(
                conversation_history=conversation_history[-1000:],  # Derniers √©l√©ments
                established_entities=json.dumps(entities, ensure_ascii=False)
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model="gpt-3.5-turbo",  # Suffisant pour r√©sum√©
                max_tokens=300,
                temperature=0.2
            )
            
            result = self._parse_json_response(ai_response.content)
            topic = result.get("conversation_topic", "Discussion g√©n√©rale")
            
            return f"Sujet: {topic} | Entit√©s: {result.get('established_entities', {})}"
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Context Summary] Erreur: {e}")
            return "R√©sum√© contextuel indisponible"
    
    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """Parse une r√©ponse JSON de l'IA avec gestion d'erreurs"""
        
        try:
            # Nettoyer le contenu
            content = content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            return json.loads(content)
            
        except json.JSONDecodeError as e:
            logger.warning(f"‚ö†Ô∏è [AI Context Enhancer] Erreur parsing JSON: {e}")
            return {}
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur parsing: {e}")
            return {}
    
    async def enhance_for_classification(self, 
                                       question: str, 
                                       conversation_context: str = "") -> Dict[str, Any]:
        """Enhancement sp√©cialis√© pour am√©liorer la classification"""
        
        try:
            # Analyse rapide pour la classification
            enhanced_context = await self.enhance_question_for_rag(
                question, conversation_context
            )
            
            return {
                "enhanced_question": enhanced_context.enhanced_question,
                "context_confidence": enhanced_context.enhancement_confidence,
                "has_references": enhanced_context.enhanced_question != question,
                "merged_entities": enhanced_context.merged_entities,
                "classification_hints": {
                    "likely_contextual": enhanced_context.enhancement_confidence > 0.7,
                    "needs_clarification": enhanced_context.enhancement_confidence < 0.3,
                    "has_sufficient_context": len(enhanced_context.merged_entities) >= 2
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur classification enhancement: {e}")
            return {
                "enhanced_question": question,
                "context_confidence": 0.0,
                "has_references": False,
                "merged_entities": {},
                "classification_hints": {
                    "likely_contextual": False,
                    "needs_clarification": True,
                    "has_sufficient_context": False
                }
            }

# =============================================================================
# INSTANCES GLOBALES ET FACTORY FUNCTIONS
# =============================================================================

# Instance globale pour r√©utilisation
_ai_context_enhancer_instance = None

def get_ai_context_enhancer() -> AIContextEnhancer:
    """Factory function pour r√©cup√©rer l'instance singleton"""
    global _ai_context_enhancer_instance
    
    if _ai_context_enhancer_instance is None:
        _ai_context_enhancer_instance = AIContextEnhancer()
        logger.info("ü§ñ [AI Context Enhancer] Instance singleton cr√©√©e")
    
    return _ai_context_enhancer_instance

# =============================================================================
# FONCTIONS DE COMPATIBILIT√â AVEC L'ANCIEN SYST√àME  
# =============================================================================

async def enhance_question_for_rag_legacy(question: str, context: str = "") -> str:
    """
    Fonction de compatibilit√© avec l'ancien syst√®me RAG
    
    Args:
        question: Question √† enrichir
        context: Contexte conversationnel
        
    Returns:
        Question enrichie pour la recherche RAG
    """
    try:
        enhancer = get_ai_context_enhancer()
        enhanced_context = await enhancer.enhance_question_for_rag(
            original_question=question,
            conversation_context=context
        )
        return enhanced_context.rag_optimized_query
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è [Legacy RAG Enhancement] Erreur: {e}")
        return question

async def analyze_contextual_references_legacy(question: str, history: str = "") -> Dict[str, Any]:
    """
    Fonction de compatibilit√© pour l'analyse des r√©f√©rences contextuelles
    
    Args:
        question: Question √† analyser
        history: Historique conversationnel
        
    Returns:
        Dictionnaire avec les r√©f√©rences d√©tect√©es
    """
    try:
        enhancer = get_ai_context_enhancer()
        analysis = await enhancer.analyze_conversational_context(
            current_question=question,
            conversation_history=history
        )
        
        return {
            "has_references": analysis.references_detected,
            "referenced_entities": analysis.context_entities,
            "confidence": analysis.confidence,
            "missing_context": analysis.missing_context,
            "reasoning": analysis.reasoning
        }
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è [Legacy Context Analysis] Erreur: {e}")
        return {
            "has_references": False,
            "referenced_entities": {},
            "confidence": 0.0,
            "missing_context": [],
            "reasoning": f"Erreur: {e}"
        }

# =============================================================================
# TESTS ET VALIDATION
# =============================================================================

async def test_ai_context_enhancer():
    """Tests int√©gr√©s pour valider le fonctionnement"""
    
    logger.info("üß™ Tests AI Context Enhancer")
    logger.info("=" * 50)
    
    enhancer = get_ai_context_enhancer()
    
    test_cases = [
        {
            "question": "Leur poids √† 21 jours ?",
            "context": "Conversation pr√©c√©dente: Ross 308 m√¢les, probl√®mes de croissance",
            "expected_enhancement": True
        },
        {
            "question": "Quel est le poids normal des Ross 308 √† 21 jours ?",
            "context": "",
            "expected_enhancement": False
        },
        {
            "question": "Et pour les femelles ?",
            "context": "Discussion sur les m√¢les Cobb 500 de 14 jours",
            "expected_enhancement": True
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        try:
            logger.info(f"\nüß™ Test {i}: '{case['question']}'")
            
            enhanced_context = await enhancer.enhance_question_for_rag(
                original_question=case["question"],
                conversation_context=case["context"]
            )
            
            logger.info(f"   ‚úÖ Question enrichie: '{enhanced_context.enhanced_question}'")
            logger.info(f"   ‚úÖ Confiance: {enhanced_context.enhancement_confidence:.2f}")
            logger.info(f"   ‚úÖ Entit√©s fusionn√©es: {len(enhanced_context.merged_entities)}")
            
        except Exception as e:
            logger.error(f"   ‚ùå Erreur test {i}: {e}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_ai_context_enhancer())