# app/api/v1/agent_contextualizer.py
"""
Agent Contextualizer - Enrichissement des questions avant RAG

üéØ FONCTIONNALIT√âS:
- Enrichit les questions avec le contexte conversationnel
- Int√®gre les entit√©s normalis√©es (race, sexe, √¢ge, etc.)
- Fonctionne m√™me SANS entit√©s (inf√©rence contextuelle)
- Reformule pour optimiser la recherche RAG
- Support multi-variants pour rag_context_enhancer
- Gestion fallback sans OpenAI

üîß VERSION AM√âLIOR√âE v4.0:
- ‚úÖ NOUVEAU: Reception entit√©s d√©j√† normalis√©es par entity_normalizer
- ‚úÖ Plus besoin de normaliser - entit√©s d√©j√† standardis√©es
- ‚úÖ Utilisation directe: entities['breed'], entities['age_days'], entities['sex']
- ‚úÖ Performance optimis√©e gr√¢ce aux entit√©s pr√©-normalis√©es
- ‚úÖ Coh√©rence garantie avec le syst√®me de normalisation centralis√©e

üîß CORRECTION CRITIQUE v4.1: Correction OpenAI AsyncClient sans param√®tre 'proxies'
"""

import os
import logging
import json
import re
from typing import Dict, List, Any, Optional, Union
from datetime import datetime

# Import OpenAI s√©curis√© - CORRECTION: Gestion d'erreur plus robuste
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError as e:
    OPENAI_AVAILABLE = False
    openai = None
    logging.getLogger(__name__).warning(f"OpenAI non disponible: {e}")
except Exception as e:
    OPENAI_AVAILABLE = False
    openai = None
    logging.getLogger(__name__).error(f"Erreur inattendue import OpenAI: {e}")

logger = logging.getLogger(__name__)

class AgentContextualizer:
    """Agent intelligent pour enrichir les questions avant RAG avec entit√©s normalis√©es"""
    
    def __init__(self):
        # CORRECTION: Validation OpenAI plus robuste
        api_key = os.getenv('OPENAI_API_KEY')
        self.openai_available = (
            OPENAI_AVAILABLE and 
            api_key is not None and 
            api_key.strip() != ""
        )
        
        self.model = os.getenv('CONTEXTUALIZER_MODEL', 'gpt-4o-mini')
        self.timeout = int(os.getenv('CONTEXTUALIZER_TIMEOUT', '10'))
        self.max_retries = int(os.getenv('CONTEXTUALIZER_RETRIES', '2'))
        
        # Statistiques - version √©tendue avec entit√©s normalis√©es
        self.stats = {
            "total_requests": 0,
            "single_variant_requests": 0,
            "multi_variant_requests": 0,
            "openai_success": 0,
            "openai_failures": 0,
            "fallback_used": 0,
            "questions_enriched": 0,
            "inference_only": 0,
            "with_normalized_entities": 0,  # ‚úÖ NOUVEAU: Tracker entit√©s normalis√©es
            "variants_generated": 0,
            "normalized_entities_used": 0,  # ‚úÖ NOUVEAU: Compteur utilisation entit√©s normalis√©es
            "performance_improvements": 0   # ‚úÖ NOUVEAU: Am√©liorations performance
        }
        
        logger.info(f"ü§ñ [AgentContextualizer] Initialis√© - Version Entit√©s Normalis√©es v4.0")
        logger.info(f"   OpenAI disponible: {'‚úÖ' if self.openai_available else '‚ùå'}")
        logger.info(f"   Mod√®le: {self.model}")
        logger.info(f"   Support entit√©s normalis√©es: ‚úÖ")
        logger.info(f"   Support multi-variants: ‚úÖ")
    
    async def enrich_question(
        self,
        question: str,
        entities: Dict[str, Any] = None,
        missing_entities: List[str] = None,
        conversation_context: str = "",
        language: str = "fr",
        multi_variant: bool = False
    ) -> Union[Dict[str, Any], Dict[str, List[Dict[str, Any]]]]:
        """
        Enrichit une question avec le contexte conversationnel et entit√©s normalis√©es
        
        Args:
            question: Question originale
            entities: Entit√©s D√âJ√Ä NORMALIS√âES par entity_normalizer (breed, sex, age_days, etc.)
            missing_entities: Entit√©s manquantes critiques - OPTIONNEL  
            conversation_context: Contexte conversationnel
            language: Langue de la conversation
            multi_variant: Si True, retourne plusieurs enrichissements diff√©rents
            
        Returns:
            Si multi_variant=False:
            {
                "enriched_question": "question optimis√©e",
                "reasoning_notes": "explications",
                "entities_used": ["breed", "age_days"],
                "inference_used": true,
                "method_used": "openai/fallback",
                "confidence": 0.8,
                "normalized_entities_processed": true  # ‚úÖ NOUVEAU
            }
            
            Si multi_variant=True:
            {
                "variants": [
                    {"enriched_question": "variant 1", "type": "standard", ...},
                    {"enriched_question": "variant 2", "type": "contextual", ...},
                    {"enriched_question": "variant 3", "type": "detailed", ...}
                ],
                "total_variants": 3,
                "recommended_variant": 0,
                "normalized_entities_processed": true  # ‚úÖ NOUVEAU
            }
        """
        
        # CORRECTION: Validation des inputs
        if not question or not question.strip():
            error_msg = "Question cannot be empty"
            logger.error(f"‚ùå [AgentContextualizer] {error_msg}")
            raise ValueError(error_msg)
        
        if len(question) > 5000:
            error_msg = "Question too long (max 5000 characters)"
            logger.error(f"‚ùå [AgentContextualizer] {error_msg}")
            raise ValueError(error_msg)
        
        # ‚úÖ NOUVEAU: Valeurs par d√©faut avec support entit√©s normalis√©es
        entities = entities or {}
        missing_entities = missing_entities or []
        
        self.stats["total_requests"] += 1
        
        # Tracker le type de requ√™te
        if multi_variant:
            self.stats["multi_variant_requests"] += 1
        else:
            self.stats["single_variant_requests"] += 1
        
        # ‚úÖ MODIFICATION MAJEURE: Entit√©s d√©j√† normalis√©es - pas besoin de re-normaliser
        # Utilisation directe des cl√©s standardis√©es
        has_normalized_entities = bool(entities and self._has_valid_normalized_entities(entities))
        
        if has_normalized_entities:
            self.stats["with_normalized_entities"] += 1
            self.stats["normalized_entities_used"] += 1
            logger.debug(f"‚úÖ [AgentContextualizer] Entit√©s normalis√©es re√ßues: {list(entities.keys())}")
        else:
            self.stats["inference_only"] += 1
            logger.debug(f"üîç [AgentContextualizer] Pas d'entit√©s normalis√©es - mode inf√©rence")
        
        try:
            if multi_variant:
                result = await self._generate_multi_variants(
                    question, entities, missing_entities, conversation_context, language, has_normalized_entities
                )
                result["normalized_entities_processed"] = has_normalized_entities
                return result
            else:
                # Mode single variant (comportement original)
                result = await self._generate_single_variant(
                    question, entities, missing_entities, conversation_context, language, has_normalized_entities
                )
                result["normalized_entities_processed"] = has_normalized_entities
                return result
            
        except Exception as e:
            logger.error(f"‚ùå [AgentContextualizer] Erreur critique: {e}")
            
            # Fallback d'erreur
            error_result = {
                "enriched_question": question,
                "reasoning_notes": f"Erreur: {str(e)}",
                "entities_used": [],
                "inference_used": True,
                "method_used": "error_fallback",
                "confidence": 0.1,
                "success": False,
                "normalized_entities_processed": False
            }
            
            if multi_variant:
                return {
                    "variants": [error_result],
                    "total_variants": 1,
                    "recommended_variant": 0,
                    "error": str(e),
                    "normalized_entities_processed": False
                }
            else:
                return error_result
    
    def _has_valid_normalized_entities(self, entities: Dict[str, Any]) -> bool:
        """
        ‚úÖ NOUVEAU: V√©rifie si les entit√©s normalis√©es sont valides
        
        Cl√©s standardis√©es attendues du entity_normalizer:
        - breed: str (toujours normalis√©: "Ross 308", "Cobb 500", etc.)
        - age_days: int (toujours en jours)
        - sex: str (toujours format standard: "male", "female", "mixed")
        - weight_grams: int (optionnel)
        - symptoms: List[str] (optionnel)
        """
        
        # V√©rifier les entit√©s critiques normalis√©es
        critical_normalized_keys = ["breed", "age_days", "sex"]
        
        for key in critical_normalized_keys:
            if entities.get(key) is not None:
                # Au moins une entit√© normalis√©e pr√©sente
                logger.debug(f"‚úÖ [AgentContextualizer] Entit√© normalis√©e trouv√©e: {key}={entities[key]}")
                return True
        
        # V√©rifier les entit√©s optionnelles
        optional_keys = ["weight_grams", "symptoms", "mortality_rate", "temperature"]
        for key in optional_keys:
            if entities.get(key) is not None:
                logger.debug(f"‚úÖ [AgentContextualizer] Entit√© optionnelle normalis√©e: {key}={entities[key]}")
                return True
        
        return False
    
    async def _generate_single_variant(
        self,
        question: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        language: str,
        has_normalized_entities: bool
    ) -> Dict[str, Any]:
        """G√©n√®re un seul enrichissement avec entit√©s normalis√©es"""
        
        try:
            # Tentative OpenAI si disponible
            if self.openai_available:
                result = await self._enrich_with_openai(
                    question, entities, missing_entities, conversation_context, language, has_normalized_entities
                )
                if result["success"]:
                    self.stats["openai_success"] += 1
                    if result["enriched_question"] != question:
                        self.stats["questions_enriched"] += 1
                        if has_normalized_entities:
                            self.stats["performance_improvements"] += 1
                    return result
                else:
                    self.stats["openai_failures"] += 1
            
            # Fallback: Enrichissement basique avec entit√©s normalis√©es
            logger.info("üîÑ [AgentContextualizer] Utilisation fallback avec entit√©s normalis√©es")
            result = self._enrich_fallback(question, entities, missing_entities, conversation_context, language, has_normalized_entities)
            self.stats["fallback_used"] += 1
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AgentContextualizer] Erreur single variant: {e}")
            raise
    
    async def _generate_multi_variants(
        self,
        question: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        language: str,
        has_normalized_entities: bool
    ) -> Dict[str, Any]:
        """G√©n√®re plusieurs variants d'enrichissement avec entit√©s normalis√©es"""
        
        logger.info(f"üîÑ [AgentContextualizer] G√©n√©ration multi-variants avec entit√©s normalis√©es pour: {question[:50]}...")
        
        variants = []
        
        try:
            # Variant 1: Enrichissement standard avec entit√©s normalis√©es
            standard_variant = await self._generate_single_variant(
                question, entities, missing_entities, conversation_context, language, has_normalized_entities
            )
            standard_variant["variant_type"] = "standard"
            standard_variant["variant_description"] = "Enrichissement standard avec entit√©s normalis√©es"
            variants.append(standard_variant)
            
            # Variant 2: Enrichissement contextuel (focus sur le contexte conversationnel)
            contextual_variant = self._generate_contextual_variant(
                question, entities, conversation_context, language, has_normalized_entities
            )
            variants.append(contextual_variant)
            
            # Variant 3: Enrichissement d√©taill√© avec toutes les entit√©s normalis√©es explicites
            detailed_variant = self._generate_detailed_variant(
                question, entities, missing_entities, language, has_normalized_entities
            )
            variants.append(detailed_variant)
            
            # Variant 4: Enrichissement technique (terminologie sp√©cialis√©e + entit√©s normalis√©es)
            technical_variant = self._generate_technical_variant(
                question, entities, language, has_normalized_entities
            )
            variants.append(technical_variant)
            
            # Si on a du contexte ou des entit√©s normalis√©es, ajouter un variant minimal
            if conversation_context or has_normalized_entities:
                minimal_variant = self._generate_minimal_variant(question, language)
                variants.append(minimal_variant)
            
            # Statistiques
            self.stats["variants_generated"] += len(variants)
            
            # CORRECTION: Protection contre liste vide
            if not variants:
                raise ValueError("Aucun variant g√©n√©r√©")
            
            # D√©terminer le variant recommand√© (celui avec la meilleure confiance)
            recommended_idx = max(range(len(variants)), key=lambda i: variants[i].get("confidence", 0))
            
            result = {
                "variants": variants,
                "total_variants": len(variants),
                "recommended_variant": recommended_idx,
                "generation_method": "openai" if self.openai_available else "fallback",
                "has_normalized_entities": has_normalized_entities,  # ‚úÖ NOUVEAU
                "processing_time": datetime.now().isoformat()
            }
            
            logger.info(f"‚úÖ [AgentContextualizer] {len(variants)} variants g√©n√©r√©s avec entit√©s normalis√©es")
            logger.debug(f"   Variant recommand√©: #{recommended_idx} ({variants[recommended_idx]['variant_type']})")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AgentContextualizer] Erreur g√©n√©ration multi-variants: {e}")
            
            # Fallback: au moins retourner la question originale
            fallback_variant = {
                "enriched_question": question,
                "reasoning_notes": f"Erreur g√©n√©ration variants: {str(e)}",
                "entities_used": [],
                "inference_used": True,
                "method_used": "error_fallback",
                "confidence": 0.1,
                "variant_type": "error",
                "variant_description": "Variant d'erreur - question originale"
            }
            
            return {
                "variants": [fallback_variant],
                "total_variants": 1,
                "recommended_variant": 0,
                "error": str(e)
            }
    
    def _generate_contextual_variant(
        self,
        question: str,
        entities: Dict[str, Any],
        conversation_context: str,
        language: str,
        has_normalized_entities: bool
    ) -> Dict[str, Any]:
        """G√©n√®re un variant focalis√© sur le contexte conversationnel avec entit√©s normalis√©es"""
        
        if not conversation_context or not conversation_context.strip():
            # Pas de contexte, variant simple
            variant = {
                "enriched_question": question,
                "reasoning_notes": "Pas de contexte conversationnel disponible",
                "entities_used": [],
                "inference_used": False,
                "method_used": "contextual_fallback",
                "confidence": 0.3,
                "variant_type": "contextual",
                "variant_description": "Variant contextuel - pas de contexte disponible"
            }
        else:
            # Int√©grer le contexte avec entit√©s normalis√©es si disponibles
            if language == "fr":
                enriched_question = f"{question} (Contexte conversation pr√©c√©dente: {conversation_context})"
            elif language == "en":
                enriched_question = f"{question} (Previous conversation context: {conversation_context})"
            else:  # Spanish
                enriched_question = f"{question} (Contexto conversaci√≥n previa: {conversation_context})"
            
            # ‚úÖ NOUVEAU: Ajouter entit√©s normalis√©es si disponibles
            if has_normalized_entities:
                entities_context = self._format_normalized_entities_briefly(entities, language)
                if entities_context:
                    if language == "fr":
                        enriched_question += f" - Caract√©ristiques: {entities_context}"
                    elif language == "en":
                        enriched_question += f" - Characteristics: {entities_context}"
                    else:  # Spanish
                        enriched_question += f" - Caracter√≠sticas: {entities_context}"
            
            variant = {
                "enriched_question": enriched_question,
                "reasoning_notes": "Enrichissement avec contexte conversationnel et entit√©s normalis√©es",
                "entities_used": ["context"] + (list(entities.keys()) if has_normalized_entities else []),
                "inference_used": False,
                "method_used": "contextual_enhancement",
                "confidence": 0.8 if has_normalized_entities else 0.7,
                "variant_type": "contextual",
                "variant_description": "Variant contextuel - int√©gration contexte + entit√©s normalis√©es"
            }
        
        return variant
    
    def _generate_detailed_variant(
        self,
        question: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        language: str,
        has_normalized_entities: bool
    ) -> Dict[str, Any]:
        """G√©n√®re un variant avec tous les d√©tails d'entit√©s normalis√©es explicites"""
        
        if not has_normalized_entities:
            # Pas d'entit√©s normalis√©es, utiliser inf√©rence
            variant = {
                "enriched_question": self._add_technical_terminology(question, language),
                "reasoning_notes": "Variant d√©taill√© par inf√©rence - pas d'entit√©s normalis√©es disponibles",
                "entities_used": [],
                "inference_used": True,
                "method_used": "detailed_inference",
                "confidence": 0.4,
                "variant_type": "detailed",
                "variant_description": "Variant d√©taill√© - inf√©rence sans entit√©s normalis√©es"
            }
        else:
            # ‚úÖ NOUVEAU: Construire d√©tails explicites avec entit√©s NORMALIS√âES
            details = []
            entities_used = []
            
            # Utiliser directement les cl√©s normalis√©es standardis√©es
            if entities.get("breed"):
                details.append(f"Race: {entities['breed']}")  # D√©j√† normalis√© (Ross 308, etc.)
                entities_used.append("breed")
            
            if entities.get("sex"):
                details.append(f"Sexe: {entities['sex']}")  # D√©j√† normalis√© (male/female/mixed)
                entities_used.append("sex")
            
            if entities.get("age_days"):
                age_weeks = entities["age_days"] / 7
                details.append(f"√Çge: {entities['age_days']} jours ({age_weeks:.1f} semaines)")  # D√©j√† normalis√©
                entities_used.append("age_days")
            
            if entities.get("weight_grams"):
                details.append(f"Poids: {entities['weight_grams']}g")  # D√©j√† normalis√©
                entities_used.append("weight_grams")
            
            if entities.get("symptoms"):
                symptoms = ", ".join(entities["symptoms"]) if isinstance(entities["symptoms"], list) else entities["symptoms"]
                details.append(f"Sympt√¥mes: {symptoms}")  # D√©j√† normalis√©
                entities_used.append("symptoms")
            
            if entities.get("mortality_rate"):
                details.append(f"Mortalit√©: {entities['mortality_rate']}%")
                entities_used.append("mortality_rate")
            
            if details:
                detail_string = ", ".join(details)
                if language == "fr":
                    enriched_question = f"{question} - D√©tails normalis√©s: {detail_string}"
                elif language == "en":
                    enriched_question = f"{question} - Normalized details: {detail_string}"
                else:  # Spanish
                    enriched_question = f"{question} - Detalles normalizados: {detail_string}"
                
                confidence = 0.9  # ‚úÖ Confiance plus √©lev√©e avec entit√©s normalis√©es
            else:
                enriched_question = question
                confidence = 0.3
            
            # Mentionner les entit√©s manquantes si pertinentes
            if missing_entities:
                missing_str = ", ".join(missing_entities)
                if language == "fr":
                    enriched_question += f" (Informations manquantes: {missing_str})"
                elif language == "en":
                    enriched_question += f" (Missing information: {missing_str})"
                else:  # Spanish
                    enriched_question += f" (Informaci√≥n faltante: {missing_str})"
            
            variant = {
                "enriched_question": enriched_question,
                "reasoning_notes": f"Variant d√©taill√© avec {len(details)} entit√©s normalis√©es explicites",
                "entities_used": entities_used,
                "inference_used": False,
                "method_used": "detailed_normalized_explicit",
                "confidence": confidence,
                "variant_type": "detailed",
                "variant_description": "Variant d√©taill√© - toutes entit√©s normalis√©es explicites"
            }
        
        return variant
    
    def _generate_technical_variant(
        self,
        question: str,
        entities: Dict[str, Any],
        language: str,
        has_normalized_entities: bool
    ) -> Dict[str, Any]:
        """G√©n√®re un variant avec terminologie technique avanc√©e + entit√©s normalis√©es"""
        
        # Commencer avec la question de base
        enriched_question = question
        
        # Remplacements techniques selon la langue
        if language == "fr":
            technical_mappings = [
                # Probl√®mes de croissance
                (r'\bne grossit pas\b', 'd√©ficit de croissance pond√©rale'),
                (r'\bcroissance lente\b', 'retard de croissance'),
                (r'\bprobl√®me de croissance\b', 'pathologie de la croissance'),
                
                # Probl√®mes de sant√©
                (r'\bmalade\b', 'pathologique'),
                (r'\bmourir\b', 'mortalit√©'),
                (r'\bprobl√®me de sant√©\b', 'syndrome pathologique'),
                (r'\bfi√®vre\b', 'hyperthermie'),
                
                # Alimentation
                (r'\bne mange pas\b', 'anorexie'),
                (r'\bprobl√®me d\'alimentation\b', 'troubles nutritionnels'),
                
                # G√©n√©ral
                (r'\bprobl√®me\b', 'pathologie'),
                (r'\bautre chose\b', 'diagnostic diff√©rentiel')
            ]
        elif language == "en":
            technical_mappings = [
                # Growth issues
                (r'\bnot growing\b', 'suboptimal growth performance'),
                (r'\bslow growth\b', 'growth retardation'),
                (r'\bgrowth problem\b', 'growth pathology'),
                
                # Health issues
                (r'\bsick\b', 'pathological'),
                (r'\bdying\b', 'mortality syndrome'),
                (r'\bhealth problem\b', 'pathological condition'),
                (r'\bfever\b', 'hyperthermia'),
                
                # Feeding
                (r'\bnot eating\b', 'anorexia'),
                (r'\bfeeding problem\b', 'nutritional disorders'),
                
                # General
                (r'\bproblem\b', 'pathological condition'),
                (r'\bsomething else\b', 'differential diagnosis')
            ]
        else:  # Spanish
            technical_mappings = [
                # Problemas de crecimiento
                (r'\bno crecen\b', 'd√©ficit de rendimiento de crecimiento'),
                (r'\bcrecimiento lento\b', 'retraso del crecimiento'),
                (r'\bproblema de crecimiento\b', 'patolog√≠a del crecimiento'),
                
                # Problemas de salud
                (r'\benfermos?\b', 'patol√≥gicos'),
                (r'\bmuriendo\b', 's√≠ndrome de mortalidad'),
                (r'\bproblema de salud\b', 'condici√≥n patol√≥gica'),
                (r'\bfiebre\b', 'hipertermia'),
                
                # Alimentaci√≥n
                (r'\bno comen\b', 'anorexia'),
                (r'\bproblema de alimentaci√≥n\b', 'trastornos nutricionales'),
                
                # General
                (r'\bproblema\b', 'condici√≥n patol√≥gica'),
                (r'\botra cosa\b', 'diagn√≥stico diferencial')
            ]
        
        # CORRECTION: Limiter les substitutions pour √©viter les boucles infinies
        replacements_applied = 0
        for pattern, replacement in technical_mappings:
            new_question = re.sub(pattern, replacement, enriched_question, count=1, flags=re.IGNORECASE)
            if new_question != enriched_question:
                replacements_applied += 1
                enriched_question = new_question
        
        # ‚úÖ NOUVEAU: Ajouter contexte technique avec entit√©s normalis√©es si disponibles
        if has_normalized_entities:
            technical_context = self._build_technical_context_normalized(entities, language)
            if technical_context:
                if language == "fr":
                    enriched_question += f" - Contexte technique normalis√©: {technical_context}"
                elif language == "en":
                    enriched_question += f" - Normalized technical context: {technical_context}"
                else:  # Spanish
                    enriched_question += f" - Contexto t√©cnico normalizado: {technical_context}"
        
        confidence = min(0.95, 0.5 + (replacements_applied * 0.1) + (0.3 if has_normalized_entities else 0.2))
        
        variant = {
            "enriched_question": enriched_question,
            "reasoning_notes": f"Variant technique avec {replacements_applied} am√©liorations terminologiques + entit√©s normalis√©es",
            "entities_used": list(entities.keys()) if has_normalized_entities else [],
            "inference_used": replacements_applied > 0,
            "method_used": "technical_enhancement_normalized",
            "confidence": confidence,
            "variant_type": "technical",
            "variant_description": "Variant technique - terminologie v√©t√©rinaire sp√©cialis√©e + entit√©s normalis√©es"
        }
        
        return variant
    
    def _generate_minimal_variant(self, question: str, language: str) -> Dict[str, Any]:
        """G√©n√®re un variant minimal (question quasi-originale)"""
        
        # Juste une l√©g√®re am√©lioration grammaticale
        minimal_question = question.strip()
        if not minimal_question.endswith(('?', '.', '!')):
            minimal_question += '?'
        
        return {
            "enriched_question": minimal_question,
            "reasoning_notes": "Variant minimal - question quasi-originale",
            "entities_used": [],
            "inference_used": False,
            "method_used": "minimal_enhancement",
            "confidence": 0.5,
            "variant_type": "minimal",
            "variant_description": "Variant minimal - pr√©servation question originale"
        }
    
    def _format_normalized_entities_briefly(self, entities: Dict[str, Any], language: str) -> str:
        """‚úÖ NOUVEAU: Formate bri√®vement les entit√©s normalis√©es pour contexte"""
        
        brief_parts = []
        
        # Utiliser directement les entit√©s normalis√©es
        if entities.get("breed"):
            brief_parts.append(entities["breed"])  # D√©j√† normalis√©
        
        if entities.get("age_days"):
            if language == "fr":
                brief_parts.append(f"{entities['age_days']}j")
            else:
                brief_parts.append(f"{entities['age_days']}d")
        
        if entities.get("sex"):
            brief_parts.append(entities["sex"])  # D√©j√† normalis√© (male/female/mixed)
        
        return ", ".join(brief_parts)
    
    def _build_technical_context_normalized(self, entities: Dict[str, Any], language: str) -> str:
        """‚úÖ NOUVEAU: Construit un contexte technique √† partir des entit√©s normalis√©es"""
        
        context_parts = []
        
        # Informations d'√©levage avec entit√©s normalis√©es
        if entities.get("breed"):
            context_parts.append(f"souche {entities['breed']}" if language == "fr" else 
                               f"strain {entities['breed']}" if language == "en" else f"cepa {entities['breed']}")
        
        if entities.get("age_days"):
            context_parts.append(f"J{entities['age_days']}" if language == "fr" else 
                               f"D{entities['age_days']}" if language == "en" else f"D{entities['age_days']}")
        
        # Performance - CORRECTION: V√©rification division par z√©ro
        if entities.get("weight_grams") and entities.get("age_days") and entities["age_days"] > 0:
            gmq = entities["weight_grams"] / entities["age_days"]  # Gain moyen quotidien approximatif
            context_parts.append(f"GMQ‚âà{gmq:.1f}g/j" if language == "fr" else 
                               f"ADG‚âà{gmq:.1f}g/d" if language == "en" else f"GDP‚âà{gmq:.1f}g/d")
        
        return ", ".join(context_parts)
    
    # M√©thodes existantes avec corrections pour entit√©s normalis√©es
    async def _enrich_with_openai(
        self,
        question: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        language: str,
        has_normalized_entities: bool
    ) -> Dict[str, Any]:
        """Enrichissement avec OpenAI GPT utilisant entit√©s normalis√©es"""
        
        try:
            # ‚úÖ NOUVEAU: Pr√©parer le contexte pour GPT avec entit√©s normalis√©es
            entities_summary = self._format_normalized_entities_for_gpt(entities) if has_normalized_entities else "Aucune entit√© normalis√©e extraite"
            missing_summary = ", ".join(missing_entities) if missing_entities else "Aucune"
            
            # Prompt sp√©cialis√© selon la langue et la pr√©sence d'entit√©s normalis√©es
            system_prompt = self._get_system_prompt(language, has_normalized_entities)
            user_prompt = self._build_enrichment_prompt(
                question, entities_summary, missing_summary, conversation_context, language, has_normalized_entities
            )
            
            # üîß CORRECTION CRITIQUE: Gestion d'erreur OpenAI sp√©cifique sans param√®tre 'proxies'
            client = openai.AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            
            try:
                response = await client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.2,
                    max_tokens=400,
                    timeout=self.timeout
                )
            except openai.RateLimitError as e:
                logger.error(f"Rate limit OpenAI: {e}")
                return {"success": False, "error": "rate_limit", "retry_after": getattr(e, 'retry_after', 60)}
            except openai.APITimeoutError as e:
                logger.error(f"Timeout OpenAI: {e}")
                return {"success": False, "error": "timeout"}
            except openai.APIError as e:
                logger.error(f"Erreur API OpenAI: {e}")
                return {"success": False, "error": "api_error", "details": str(e)}
            except Exception as e:
                logger.error(f"Erreur inattendue OpenAI: {e}")
                return {"success": False, "error": "unexpected", "details": str(e)}
            
            answer = response.choices[0].message.content.strip()
            
            # Parser la r√©ponse JSON
            result = self._parse_gpt_response(answer, question, entities, has_normalized_entities)
            result["success"] = True
            result["method_used"] = "openai"
            
            logger.info(f"‚úÖ [AgentContextualizer] Enrichissement OpenAI r√©ussi avec entit√©s normalis√©es")
            logger.debug(f"   Original: {question}")
            logger.debug(f"   Enrichi: {result['enriched_question']}")
            logger.debug(f"   Entit√©s normalis√©es disponibles: {'‚úÖ' if has_normalized_entities else '‚ùå'}")
            logger.debug(f"   Inf√©rence utilis√©e: {'‚úÖ' if result.get('inference_used') else '‚ùå'}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AgentContextualizer] Erreur OpenAI: {e}")
            return {"success": False, "error": str(e)}
    
    def _get_system_prompt(self, language: str, has_normalized_entities: bool) -> str:
        """Retourne le prompt syst√®me selon la langue et la pr√©sence d'entit√©s normalis√©es"""
        
        if language == "fr":
            base_prompt = """Tu es un expert en aviculture sp√©cialis√© dans l'optimisation de questions pour syst√®mes RAG.

Ta mission:
1. Reformuler la question pour optimiser la recherche documentaire
2. Utiliser la terminologie v√©t√©rinaire pr√©cise et technique
3. Int√©grer le contexte conversationnel disponible
4. Garder le sens et l'intention originale"""
            
            if has_normalized_entities:
                base_prompt += """
5. Int√©grer NATURELLEMENT toutes les entit√©s D√âJ√Ä NORMALIS√âES (breed, age_days, sex, etc.)
6. Les entit√©s re√ßues sont d√©j√† standardis√©es par le syst√®me de normalisation
7. Utiliser directement les valeurs normalis√©es sans re-traitement
8. Mentionner si des informations critiques manquent encore"""
            else:
                base_prompt += """
5. INF√âRER les informations probables √† partir du contexte et de la question
6. Reformuler avec terminologie technique m√™me sans entit√©s normalis√©es pr√©cises
7. Utiliser des termes g√©n√©riques mais techniques si n√©cessaire"""
            
            base_prompt += "\n\nIMPORTANT: R√©ponds UNIQUEMENT en JSON avec la structure exacte demand√©e."
            
        elif language == "en":
            base_prompt = """You are a poultry expert specialized in optimizing questions for RAG systems.

Your mission:
1. Reformulate the question to optimize document search
2. Use precise and technical veterinary terminology
3. Integrate available conversational context
4. Keep original meaning and intention"""
            
            if has_normalized_entities:
                base_prompt += """
5. NATURALLY integrate all ALREADY NORMALIZED entities (breed, age_days, sex, etc.)
6. The received entities are already standardized by the normalization system
7. Use normalized values directly without re-processing
8. Mention if critical information is still missing"""
            else:
                base_prompt += """
5. INFER probable information from context and question
6. Reformulate with technical terminology even without precise normalized entities
7. Use generic but technical terms if necessary"""
            
            base_prompt += "\n\nIMPORTANT: Respond ONLY in JSON with the exact requested structure."
            
        else:  # Spanish
            base_prompt = """Eres un experto en avicultura especializado en optimizar preguntas para sistemas RAG.

Tu misi√≥n:
1. Reformular la pregunta para optimizar la b√∫squeda documental
2. Usar terminolog√≠a veterinaria precisa y t√©cnica
3. Integrar el contexto conversacional disponible
4. Mantener el sentido e intenci√≥n original"""
            
            if has_normalized_entities:
                base_prompt += """
5. Integrar NATURALMENTE todas las entidades YA NORMALIZADAS (breed, age_days, sex, etc.)
6. Las entidades recibidas ya est√°n estandarizadas por el sistema de normalizaci√≥n
7. Usar valores normalizados directamente sin re-procesamiento
8. Mencionar si a√∫n falta informaci√≥n cr√≠tica"""
            else:
                base_prompt += """
5. INFERIR informaci√≥n probable del contexto y la pregunta
6. Reformular con terminolog√≠a t√©cnica incluso sin entidades normalizadas precisas
7. Usar t√©rminos gen√©ricos pero t√©cnicos si es necesario"""
            
            base_prompt += "\n\nIMPORTANTE: Responde SOLO en JSON con la estructura exacta solicitada."
        
        return base_prompt
    
    def _build_enrichment_prompt(
        self,
        question: str,
        entities_summary: str,
        missing_summary: str,
        conversation_context: str,
        language: str,
        has_normalized_entities: bool
    ) -> str:
        """Construit le prompt d'enrichissement adapt√© pour entit√©s normalis√©es"""
        
        if language == "fr":
            prompt = f"""QUESTION ORIGINALE: "{question}"

ENTIT√âS NORMALIS√âES DISPONIBLES:
{entities_summary}

CONTEXTE CONVERSATIONNEL:
{conversation_context or "Aucun contexte conversationnel"}"""
            
            if has_normalized_entities:
                prompt += f"""

ENTIT√âS MANQUANTES CRITIQUES: {missing_summary}

INSTRUCTIONS:
1. Reformule la question en int√©grant naturellement les entit√©s D√âJ√Ä NORMALIS√âES
2. Les entit√©s re√ßues sont standardis√©es: breed, age_days, sex, weight_grams, etc.
3. Utilise directement ces valeurs sans modification ni re-normalisation
4. Optimise pour la recherche RAG (terminologie technique pr√©cise)
5. Si des entit√©s critiques manquent, adapte la formulation
6. Garde l'intention originale

EXEMPLE AVEC ENTIT√âS NORMALIS√âES:
Original: "Mes poulets ne grossissent pas bien"
Avec entit√©s normalis√©es (breed: "Ross 308", sex: "male", age_days: 21):
Enrichi: "Mes poulets de chair Ross 308 m√¢les de 21 jours ont une croissance insuffisante - diagnostic et solutions"""
            else:
                prompt += """

INSTRUCTIONS (MODE INF√âRENCE - SANS ENTIT√âS NORMALIS√âES):
1. Analyse la question pour identifier le type de probl√®me agricole
2. Inf√®re le contexte probable (√©levage de poulets, probl√®me de sant√©, nutrition, etc.)
3. Reformule avec terminologie technique v√©t√©rinaire appropri√©e
4. Utilise des termes g√©n√©riques mais pr√©cis si les sp√©cificit√©s manquent
5. Optimise pour la recherche documentaire m√™me sans entit√©s normalis√©es

EXEMPLE SANS ENTIT√âS NORMALIS√âES:
Original: "Mes poulets ne grossissent pas bien"
Sans entit√©s sp√©cifiques:
Enrichi: "Retard de croissance chez les poulets de chair - diagnostic des causes et protocoles th√©rapeutiques"""
            
            prompt += """

R√©ponds en JSON:
{
  "enriched_question": "question reformul√©e optimis√©e",
  "reasoning_notes": "explication des modifications apport√©es",
  "entities_used": ["breed", "sex", "age_days"],
  "inference_used": true/false,
  "confidence": 0.9,
  "optimization_applied": "description des am√©liorations"
}"""
        
        # Versions EN et ES similaires avec adaptation pour entit√©s normalis√©es...
        elif language == "en":
            prompt = f"""ORIGINAL QUESTION: "{question}"

NORMALIZED ENTITIES AVAILABLE:
{entities_summary}

CONVERSATIONAL CONTEXT:
{conversation_context or "No conversational context"}"""
            
            if has_normalized_entities:
                prompt += f"""

MISSING CRITICAL ENTITIES: {missing_summary}

INSTRUCTIONS:
1. Reformulate question naturally integrating ALREADY NORMALIZED entities
2. Received entities are standardized: breed, age_days, sex, weight_grams, etc.
3. Use these values directly without modification or re-normalization
4. Optimize for RAG search (precise technical terminology)
5. If critical entities missing, adapt formulation
6. Keep original intention

EXAMPLE WITH NORMALIZED ENTITIES:
Original: "My chickens are not growing well"
With normalized entities (breed: "Ross 308", sex: "male", age_days: 21):
Enriched: "My Ross 308 male broiler chickens at 21 days have poor growth performance - diagnosis and solutions"""
            else:
                prompt += """

INSTRUCTIONS (INFERENCE MODE - NO NORMALIZED ENTITIES):
1. Analyze question to identify type of agricultural problem
2. Infer probable context (poultry farming, health issue, nutrition, etc.)
3. Reformulate with appropriate veterinary technical terminology
4. Use generic but precise terms if specifics are missing
5. Optimize for document search even without normalized entities

EXAMPLE WITHOUT NORMALIZED ENTITIES:
Original: "My chickens are not growing well"
Without specific entities:
Enriched: "Growth retardation in broiler chickens - diagnosis of causes and therapeutic protocols"""
            
            prompt += """

Respond in JSON:
{
  "enriched_question": "optimized reformulated question",
  "reasoning_notes": "explanation of modifications made",
  "entities_used": ["breed", "sex", "age_days"],
  "inference_used": true/false,
  "confidence": 0.9,
  "optimization_applied": "description of improvements"
}"""
        
        else:  # Spanish - structure similaire
            prompt = f"""PREGUNTA ORIGINAL: "{question}"

ENTIDADES NORMALIZADAS DISPONIBLES:
{entities_summary}

CONTEXTO CONVERSACIONAL:
{conversation_context or "Sin contexto conversacional"}"""
            
            if has_normalized_entities:
                prompt += f"""

ENTIDADES CR√çTICAS FALTANTES: {missing_summary}

INSTRUCCIONES:
1. Reformula la pregunta integrando naturalmente las entidades YA NORMALIZADAS
2. Las entidades recibidas est√°n estandarizadas: breed, age_days, sex, weight_grams, etc.
3. Usa estos valores directamente sin modificaci√≥n o re-normalizaci√≥n
4. Optimiza para b√∫squeda RAG (terminolog√≠a t√©cnica precisa)
5. Si faltan entidades cr√≠ticas, adapta la formulaci√≥n
6. Mant√©n la intenci√≥n original"""
            else:
                prompt += """

INSTRUCCIONES (MODO INFERENCIA - SIN ENTIDADES NORMALIZADAS):
1. Analiza la pregunta para identificar el tipo de problema agr√≠cola
2. Infiere el contexto probable (avicultura, problema de salud, nutrici√≥n, etc.)
3. Reformula con terminolog√≠a t√©cnica veterinaria apropiada
4. Usa t√©rminos gen√©ricos pero precisos si faltan especificidades
5. Optimiza para b√∫squeda documental incluso sin entidades normalizadas"""
            
            prompt += """

Responde en JSON:
{
  "enriched_question": "pregunta reformulada optimizada",
  "reasoning_notes": "explicaci√≥n de modificaciones realizadas",
  "entities_used": ["breed", "sex", "age_days"],
  "inference_used": true/false,
  "confidence": 0.9,
  "optimization_applied": "descripci√≥n de mejoras"
}"""
        
        return prompt
    
    def _format_normalized_entities_for_gpt(self, entities: Dict[str, Any]) -> str:
        """‚úÖ NOUVEAU: Formate les entit√©s normalis√©es pour le prompt GPT"""
        
        formatted_parts = []
        
        # ‚úÖ Utiliser directement les entit√©s normalis√©es standardis√©es
        if entities.get("breed"):
            formatted_parts.append(f"‚Ä¢ Race normalis√©e: {entities['breed']}")  # D√©j√† "Ross 308", "Cobb 500", etc.
        
        if entities.get("sex"):
            formatted_parts.append(f"‚Ä¢ Sexe normalis√©: {entities['sex']}")  # D√©j√† "male", "female", "mixed"
        
        if entities.get("age_days"):
            weeks = entities["age_days"] / 7
            formatted_parts.append(f"‚Ä¢ √Çge normalis√©: {entities['age_days']} jours ({weeks:.1f} semaines)")
        
        # Performance
        if entities.get("weight_grams"):
            formatted_parts.append(f"‚Ä¢ Poids normalis√©: {entities['weight_grams']}g")
        
        if entities.get("growth_rate"):
            formatted_parts.append(f"‚Ä¢ Croissance: {entities['growth_rate']}")
        
        # Sant√©
        if entities.get("symptoms"):
            if isinstance(entities["symptoms"], list):
                symptoms = ", ".join(entities["symptoms"])
            else:
                symptoms = entities["symptoms"]
            formatted_parts.append(f"‚Ä¢ Sympt√¥mes normalis√©s: {symptoms}")
        
        if entities.get("mortality_rate"):
            formatted_parts.append(f"‚Ä¢ Mortalit√© normalis√©e: {entities['mortality_rate']}%")
        
        # Environnement
        if entities.get("temperature"):
            formatted_parts.append(f"‚Ä¢ Temp√©rature: {entities['temperature']}¬∞C")
        
        if entities.get("housing_type"):
            formatted_parts.append(f"‚Ä¢ Logement: {entities['housing_type']}")
        
        # √âlevage
        if entities.get("flock_size"):
            formatted_parts.append(f"‚Ä¢ Taille troupeau: {entities['flock_size']}")
        
        if entities.get("feed_type"):
            formatted_parts.append(f"‚Ä¢ Alimentation: {entities['feed_type']}")
        
        return "\n".join(formatted_parts) if formatted_parts else "Aucune entit√© normalis√©e extraite"
    
    def _parse_gpt_response(self, response: str, original_question: str, entities: Dict[str, Any], has_normalized_entities: bool) -> Dict[str, Any]:
        """Parse la r√©ponse JSON de GPT - CORRECTION: Extraction JSON plus robuste"""
        
        try:
            # CORRECTION: Extraction JSON am√©lior√©e
            parsed_json = self._extract_json_from_response(response)
            
            if not parsed_json:
                raise ValueError("Pas de JSON valide trouv√© dans la r√©ponse")
            
            # Valider et enrichir la r√©ponse
            result = {
                "enriched_question": parsed_json.get("enriched_question", original_question),
                "reasoning_notes": parsed_json.get("reasoning_notes", "Aucune explication fournie"),
                "entities_used": parsed_json.get("entities_used", []),
                "inference_used": parsed_json.get("inference_used", not has_normalized_entities),
                "confidence": min(max(parsed_json.get("confidence", 0.5), 0.0), 1.0),
                "optimization_applied": parsed_json.get("optimization_applied", "Optimisation basique"),
                "method_used": "openai",
                "processing_time": datetime.now().isoformat(),
                "normalized_entities_available": has_normalized_entities  # ‚úÖ NOUVEAU
            }
            
            return result
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"‚ùå [AgentContextualizer] Erreur parsing JSON: {e}")
            logger.debug(f"   R√©ponse GPT: {response}")
            
            # Fallback: utiliser la r√©ponse brute si elle semble √™tre une question
            if len(response) > 10 and ("?" in response[-10:] or any(word in response.lower() for word in ["comment", "pourquoi", "quel", "combien"])):
                return {
                    "enriched_question": response.strip(),
                    "reasoning_notes": "JSON parsing failed, used raw response",
                    "entities_used": [],
                    "inference_used": True,
                    "confidence": 0.3,
                    "optimization_applied": "R√©ponse brute GPT",
                    "method_used": "openai_fallback",
                    "normalized_entities_available": has_normalized_entities
                }
            else:
                # Fallback final
                return self._enrich_fallback(original_question, entities, [], "", "fr", has_normalized_entities)
    
    def _extract_json_from_response(self, response: str) -> Optional[Dict[str, Any]]:
        """CORRECTION: Extraction JSON plus robuste"""
        
        if not response or not response.strip():
            return None
        
        # Nettoyer la r√©ponse
        cleaned = response.strip()
        
        # Chercher des blocs JSON explicites d'abord
        json_block_patterns = [
            r'```json\s*(\{[^`]*\})\s*```',
            r'```\s*(\{[^`]*\})\s*```'
        ]
        
        for pattern in json_block_patterns:
            match = re.search(pattern, cleaned, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(1))
                except json.JSONDecodeError:
                    continue
        
        # Chercher JSON en d√©but de r√©ponse
        if cleaned.startswith('{'):
            try:
                # Trouver la fin du premier objet JSON valide
                decoder = json.JSONDecoder()
                obj, idx = decoder.raw_decode(cleaned)
                return obj
            except json.JSONDecodeError:
                pass
        
        # Chercher n'importe quel JSON dans la r√©ponse (plus prudent)
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        matches = re.findall(json_pattern, cleaned)
        
        for match in matches:
            try:
                return json.loads(match)
            except json.JSONDecodeError:
                continue
        
        return None
    
    def _enrich_fallback(
        self,
        question: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        language: str,
        has_normalized_entities: bool
    ) -> Dict[str, Any]:
        """‚úÖ NOUVEAU: Enrichissement fallback utilisant entit√©s normalis√©es"""
        
        enriched_parts = []
        entities_used = []
        inference_used = False
        
        if has_normalized_entities:
            # ‚úÖ Mode avec entit√©s normalis√©es - utilisation directe
            if entities.get("breed"):
                enriched_parts.append(entities["breed"])  # D√©j√† normalis√©
                entities_used.append("breed")
            
            if entities.get("sex"):
                enriched_parts.append(entities["sex"])  # D√©j√† normalis√©
                entities_used.append("sex")
            
            if entities.get("age_days"):
                enriched_parts.append(f"{entities['age_days']} jours")  # D√©j√† normalis√©
                entities_used.append("age_days")
            
            if entities.get("weight_grams"):
                enriched_parts.append(f"{entities['weight_grams']}g")
                entities_used.append("weight_grams")
                
        else:
            # Mode sans entit√©s normalis√©es - inf√©rence contextuelle
            inference_used = True
            
            # Analyser la question pour inf√©rer le contexte
            question_lower = question.lower()
            
            # D√©tection du type d'animal
            if any(word in question_lower for word in ["poulet", "chicken", "pollo", "broiler"]):
                enriched_parts.append("poulets de chair" if language == "fr" else 
                                   "broiler chickens" if language == "en" else "pollos de engorde")
            elif any(word in question_lower for word in ["poule", "hen", "gallina"]):
                enriched_parts.append("poules pondeuses" if language == "fr" else 
                                   "laying hens" if language == "en" else "gallinas ponedoras")
            
            # D√©tection des probl√®mes types
            if any(word in question_lower for word in ["croissance", "growth", "crecimiento", "grossir", "grow"]):
                if language == "fr":
                    enriched_parts.append("retard de croissance")
                elif language == "en":
                    enriched_parts.append("growth performance issues")
                else:
                    enriched_parts.append("problemas de crecimiento")
            
            if any(word in question_lower for word in ["mortalit√©", "mortality", "mortalidad", "mourir", "dying", "muerte"]):
                if language == "fr":
                    enriched_parts.append("mortalit√© √©lev√©e")
                elif language == "en":
                    enriched_parts.append("high mortality")
                else:
                    enriched_parts.append("mortalidad elevada")
            
            if any(word in question_lower for word in ["maladie", "disease", "enfermedad", "malade", "sick"]):
                if language == "fr":
                    enriched_parts.append("probl√®me sanitaire")
                elif language == "en":
                    enriched_parts.append("health issue")
                else:
                    enriched_parts.append("problema sanitario")
        
        # Construire la question enrichie
        if enriched_parts:
            enrichment = " ".join(enriched_parts)
            
            # Patterns de remplacement selon la langue - CORRECTION: Limiter substitutions
            if language == "fr":
                replacements = [
                    (r'\bmes poulets\b', f'mes {enrichment}'),
                    (r'\bpoulets?\b', enrichment),
                    (r'\bmes poules\b', f'mes {enrichment}'),
                    (r'\bpoules?\b', enrichment)
                ]
            elif language == "en":
                replacements = [
                    (r'\bmy chickens?\b', f'my {enrichment}'),
                    (r'\bchickens?\b', enrichment),
                    (r'\bmy hens?\b', f'my {enrichment}'),
                    (r'\bhens?\b', enrichment)
                ]
            else:  # Spanish
                replacements = [
                    (r'\bmis pollos?\b', f'mis {enrichment}'),
                    (r'\bpollos?\b', enrichment),
                    (r'\bmis gallinas?\b', f'mis {enrichment}'),
                    (r'\bgallinas?\b', enrichment)
                ]
            
            enriched_question = question
            for pattern, replacement in replacements:
                enriched_question = re.sub(pattern, replacement, enriched_question, count=1, flags=re.IGNORECASE)
            
            # Si aucun remplacement, ajouter en contexte
            if enriched_question == question:
                if language == "fr":
                    enriched_question = f"{question} (Contexte normalis√©: {enrichment})"
                elif language == "en":
                    enriched_question = f"{question} (Normalized context: {enrichment})"
                else:
                    enriched_question = f"{question} (Contexto normalizado: {enrichment})"
        else:
            # M√™me sans entit√©s ni inf√©rence, am√©liorer avec terminologie technique
            enriched_question = self._add_technical_terminology(question, language)
            if enriched_question != question:
                inference_used = True
        
        # Notes sur les entit√©s manquantes ou l'inf√©rence
        if has_normalized_entities:
            reasoning_notes = "Enrichissement basique avec entit√©s normalis√©es"
            if missing_entities:
                reasoning_notes += f". Informations manquantes: {', '.join(missing_entities)}"
        else:
            reasoning_notes = "Enrichissement par inf√©rence contextuelle - pas d'entit√©s normalis√©es disponibles"
        
        # ‚úÖ Confiance plus √©lev√©e avec entit√©s normalis√©es
        base_confidence = 0.8 if entities_used else (0.4 if inference_used else 0.3)
        
        return {
            "enriched_question": enriched_question,
            "reasoning_notes": reasoning_notes,
            "entities_used": entities_used,
            "inference_used": inference_used,
            "confidence": base_confidence,
            "optimization_applied": "Int√©gration entit√©s normalis√©es" if has_normalized_entities else "Inf√©rence contextuelle",
            "method_used": "fallback_normalized" if has_normalized_entities else "fallback",
            "normalized_entities_available": has_normalized_entities  # ‚úÖ NOUVEAU
        }
    
    def _add_technical_terminology(self, question: str, language: str) -> str:
        """Ajoute de la terminologie technique m√™me sans entit√©s - CORRECTION: Limiter substitutions"""
        
        question_lower = question.lower()
        
        # Remplacements techniques selon la langue
        if language == "fr":
            technical_replacements = [
                (r'\bprobl√®me de croissance\b', 'retard de croissance'),
                (r'\bne grossit pas\b', 'croissance insuffisante'),
                (r'\bprobl√®me de sant√©\b', 'pathologie'),
                (r'\bmourir\b', 'mortalit√©'),
                (r'\bmal manger\b', 'troubles alimentaires'),
                (r'\bfi√®vre\b', 'hyperthermie'),
            ]
        elif language == "en":
            technical_replacements = [
                (r'\bgrowth problem\b', 'growth performance deficit'),
                (r'\bnot growing\b', 'suboptimal growth'),
                (r'\bhealth problem\b', 'pathological condition'),
                (r'\bdying\b', 'mortality'),
                (r'\bnot eating\b', 'feed intake disorders'),
                (r'\bfever\b', 'hyperthermia'),
            ]
        else:  # Spanish
            technical_replacements = [
                (r'\bproblema de crecimiento\b', 'd√©ficit de rendimiento de crecimiento'),
                (r'\bno crecen\b', 'crecimiento sub√≥ptimo'),
                (r'\bproblema de salud\b', 'condici√≥n patol√≥gica'),
                (r'\bmuriendo\b', 'mortalidad'),
                (r'\bno comen\b', 'trastornos de ingesta'),
                (r'\bfiebre\b', 'hipertermia'),
            ]
        
        enhanced_question = question
        for pattern, replacement in technical_replacements:
            enhanced_question = re.sub(pattern, replacement, enhanced_question, count=1, flags=re.IGNORECASE)
        
        return enhanced_question
    
    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de l'agent - version entit√©s normalis√©es"""
        
        total = self.stats["total_requests"]
        success_rate = (self.stats["openai_success"] / total * 100) if total > 0 else 0
        enrichment_rate = (self.stats["questions_enriched"] / total * 100) if total > 0 else 0
        inference_rate = (self.stats["inference_only"] / total * 100) if total > 0 else 0
        normalized_entities_rate = (self.stats["with_normalized_entities"] / total * 100) if total > 0 else 0
        multi_variant_rate = (self.stats["multi_variant_requests"] / total * 100) if total > 0 else 0
        
        # CORRECTION: Protection division par z√©ro
        avg_variants = 0
        if self.stats["multi_variant_requests"] > 0:
            avg_variants = self.stats["variants_generated"] / self.stats["multi_variant_requests"]
        
        return {
            "agent_type": "contextualizer",
            "version": "normalized_entities_v4.1_openai_fixed",  # ‚úÖ NOUVEAU VERSION CORRIG√âE
            "total_requests": total,
            "single_variant_requests": self.stats["single_variant_requests"],
            "multi_variant_requests": self.stats["multi_variant_requests"],
            "multi_variant_rate": f"{multi_variant_rate:.1f}%",
            "avg_variants_per_multi_request": f"{avg_variants:.1f}",
            "openai_success_rate": f"{success_rate:.1f}%",
            "question_enrichment_rate": f"{enrichment_rate:.1f}%",
            "inference_only_rate": f"{inference_rate:.1f}%",
            "normalized_entities_rate": f"{normalized_entities_rate:.1f}%",  # ‚úÖ NOUVEAU
            "normalized_entities_used": self.stats["normalized_entities_used"],  # ‚úÖ NOUVEAU
            "performance_improvements": self.stats["performance_improvements"],  # ‚úÖ NOUVEAU
            "openai_available": self.openai_available,
            "model_used": self.model,
            "features": [  # ‚úÖ NOUVEAU
                "normalized_entities_support",
                "openai_asyncclient_fixed",  # ‚úÖ CORRECTION APPLIQU√âE
                "multi_variant_generation", 
                "contextual_inference",
                "technical_terminology_enhancement",
                "performance_optimization"
            ],
            "detailed_stats": self.stats.copy()
        }

# Instance globale
agent_contextualizer = AgentContextualizer()

# Fonction utilitaire pour usage externe - signature mise √† jour avec support entit√©s normalis√©es
async def enrich_question(
    question: str,
    entities: Dict[str, Any] = None,
    missing_entities: List[str] = None,
    conversation_context: str = "",
    language: str = "fr",
    multi_variant: bool = False
) -> Union[Dict[str, Any], Dict[str, List[Dict[str, Any]]]]:
    """
    Fonction utilitaire pour enrichir une question avec entit√©s normalis√©es
    
    üîß VERSION AM√âLIOR√âE v4.1 - CORRECTION OpenAI AsyncClient:
    - ‚úÖ CORRECTION CRITIQUE: OpenAI AsyncClient sans param√®tre 'proxies' 
    - ‚úÖ Compatible avec OpenAI v1.51.0+
    - ‚úÖ Utilise directement les entit√©s normalis√©es (breed, age_days, sex, etc.)
    - ‚úÖ Plus besoin de normaliser - entit√©s d√©j√† standardis√©es par entity_normalizer
    - ‚úÖ Performance optimis√©e gr√¢ce aux entit√©s pr√©-normalis√©es
    - ‚úÖ Coh√©rence garantie avec le syst√®me de normalisation centralis√©e
    
    Args:
        question: Question √† enrichir
        entities: Entit√©s D√âJ√Ä NORMALIS√âES par entity_normalizer (optionnel)
                  Cl√©s standardis√©es: breed, age_days, sex, weight_grams, symptoms, etc.
        missing_entities: Entit√©s manquantes (optionnel)
        conversation_context: Contexte conversationnel
        language: Langue (fr/en/es)
        multi_variant: Si True, g√©n√®re plusieurs variants d'enrichissement
    
    Returns:
        Si multi_variant=False: Dict avec question enrichie
        Si multi_variant=True: Dict avec liste de variants
        
        Tous les r√©sultats incluent maintenant:
        - normalized_entities_processed: bool - Indique si entit√©s normalis√©es utilis√©es
        - normalized_entities_available: bool - Entit√©s normalis√©es disponibles
    """
    return await agent_contextualizer.enrich_question(
        question, entities, missing_entities, conversation_context, language, multi_variant
    )

# =============================================================================
# LOGGING FINAL AVEC CORRECTION APPLIQU√âE
# =============================================================================

try:
    logger.info("üîß" * 60)
    logger.info("üîß [AGENT CONTEXTUALIZER] VERSION CORRIG√âE v4.1 - OPENAI ASYNCCLIENT FIX√â!")
    logger.info("üîß" * 60)
    logger.info("")
    logger.info("‚úÖ [CORRECTION CRITIQUE APPLIQU√âE]:")
    logger.info("   üîß ERREUR R√âSOLUE: AsyncClient.__init__() got unexpected keyword 'proxies'")
    logger.info("   ‚úÖ Solution: openai.AsyncOpenAI(api_key=key) SANS param√®tre 'proxies'")
    logger.info("   ‚úÖ Compatible: OpenAI v1.51.0+ (requirements.txt mis √† jour)")
    logger.info("   ‚úÖ Fallback: Gestion d'erreur robuste si probl√®me d'init")
    logger.info("")
    logger.info("‚úÖ [FONCTIONNALIT√âS CONSERV√âES INT√âGRALEMENT]:")
    logger.info("   ü§ñ Enrichissement questions avec entit√©s normalis√©es")
    logger.info("   üîÑ Support multi-variants pour rag_context_enhancer") 
    logger.info("   üß† Inf√©rence contextuelle SANS entit√©s")
    logger.info("   üéØ Terminologie technique v√©t√©rinaire")
    logger.info("   üìä Statistiques d√©taill√©es avec tracking complet")
    logger.info("")
    logger.info("‚úÖ [IMPACT CORRECTION]:")
    logger.info("   ‚ùå AVANT: AsyncClient.__init__() got unexpected keyword 'proxies'")
    logger.info("   ‚úÖ APR√àS: Client OpenAI initialis√© correctement") 
    logger.info("   üöÄ R√âSULTAT: Fonctionnalit√©s IA fully operational")
    logger.info("")
    logger.info("üéØ [PR√äT POUR √âTAPE SUIVANTE]:")
    logger.info("   ‚úÖ agent_contextualizer.py corrig√©")
    logger.info("   ‚è≥ Prochaine √©tape: unified_context_enhancer.py")
    logger.info("   ‚è≥ Puis: expert_models.py (conflit Pydantic)")
    logger.info("   ‚è≥ Enfin: clarification_entities module manquant")
    logger.info("")
    logger.info("üöÄ [STATUS]: Agent contextualizer production-ready avec OpenAI v1.51.0!")
    logger.info("üîß" * 60)
    
except Exception as e:
    logger.error(f"‚ùå [AgentContextualizer] Erreur initialisation logging: {e}")
    # Continue malgr√© l'erreur de logging