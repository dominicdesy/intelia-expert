"""
app/api/v1/expert_services.py - SERVICE PRINCIPAL EXPERT SYSTEM (VERSION CORRIG√âE + ACC√àS S√âCURIS√â WEIGHT)

üöÄ CORRECTIONS APPLIQU√âES:
1. ‚úÖ FIXE: analyze_question_for_clarification_enhanced maintenant avec await
2. ‚úÖ FIXE: Suppression des appels asyncio.run() probl√©matiques  
3. ‚úÖ FIXE: Ajout du champ contextualization_info dans EnhancedExpertResponse
4. ‚úÖ FIXE: G√©n√©ration de response_versions garantie m√™me en fallback
5. ‚úÖ NOUVEAU: Acc√®s s√©curis√© √† 'weight' avec getattr() et .get()

‚ú® R√âSULTAT: Code original conserv√© + bugs critiques corrig√©s + acc√®s s√©curis√© weight
"""

import os
import logging
import uuid
import time
import re
from datetime import datetime
from typing import Optional, Dict, Any, Tuple, List

from fastapi import HTTPException, Request

logger = logging.getLogger(__name__)


# üöÄ IMPORTS S√âCURIS√âS AVEC FALLBACKS ROBUSTES
try:
    from .clarification_entities import normalize_breed_name, infer_sex_from_breed, get_breed_type, get_supported_breeds
    CLARIFICATION_ENTITIES_AVAILABLE = True
    logger.info("üõë" * 50)
    logger.info("üõë [EXPERT SERVICE CORRIG√â COMPLET] TOUTES LES CORRECTIONS APPLIQU√âES!")
    logger.info("üõë [CORRECTIONS CRITIQUES APPLIQU√âES]:")
    logger.info("")
    logger.info("‚úÖ [1. CORRECTION await ANALYSE CLARIFICATION]:")
    logger.info("   ‚úÖ AVANT: analyze_question_for_clarification_enhanced() sans await")
    logger.info("   ‚úÖ APR√àS: await analyze_question_for_clarification_enhanced()")
    logger.info("   ‚úÖ R√âSULTAT: Clarification critique maintenant EX√âCUT√âE")
    logger.info("")
    logger.info("‚úÖ [2. CORRECTION asyncio.run() SUPPRIM√â]:")
    logger.info("   ‚úÖ AVANT: asyncio.run() dans m√©moire conversationnelle")
    logger.info("   ‚úÖ APR√àS: await natif dans environnement async")
    logger.info("   ‚úÖ R√âSULTAT: Plus d'erreur 'cannot be called from running event loop'")
    logger.info("")
    logger.info("‚úÖ [3. CORRECTION CHAMPS PYDANTIC AJOUT√âS]:")
    logger.info("   ‚úÖ AVANT: 'EnhancedExpertResponse' object has no field 'contextualization_info'")
    logger.info("   ‚úÖ APR√àS: Champs contextualization_info et enhancement_info ajout√©s")
    logger.info("   ‚úÖ R√âSULTAT: M√©tadonn√©es contextuelles transmises au frontend")
    logger.info("")
    logger.info("‚úÖ [4. CORRECTION response_versions GARANTIE]:")
    logger.info("   ‚úÖ AVANT: Backend n'a pas fourni response_versions")
    logger.info("   ‚úÖ APR√àS: ConcisionService appel√© PARTOUT (normale, fallback, erreur)")
    logger.info("   ‚úÖ R√âSULTAT: Ultra_concise/concise/standard/detailed TOUJOURS disponibles")
    logger.info("")
    logger.info("‚úÖ [5. NOUVEAU: ACC√àS S√âCURIS√â WEIGHT]:")
    logger.info("   ‚úÖ AVANT: entities.weight (risque AttributeError)")
    logger.info("   ‚úÖ APR√àS: getattr(entities, 'weight', None) et entities.get('weight')")
    logger.info("   ‚úÖ R√âSULTAT: Plus de plantage si 'weight' absent")
    logger.info("")
    logger.info("üéØ [FONCTIONNALIT√âS PR√âSERV√âES INT√âGRALEMENT]:")
    logger.info("   üõë Clarification critique bloquante ‚úÖ")
    logger.info("   üí° Clarifications optionnelles non bloquantes ‚úÖ")
    logger.info("   ü§ñ Agents toujours actifs ‚úÖ")
    logger.info("   üß† M√©moire conversationnelle intelligente ‚úÖ")
    logger.info("   üåê Support multilingue FR/EN/ES ‚úÖ")
    logger.info("   üéØ D√©tection pr√©cise types volaille ‚úÖ")
    logger.info("   üìè Versions de r√©ponse adaptatives ‚úÖ")
    logger.info("   üîí Gestion d'erreurs robuste ‚úÖ")
    logger.info("   ‚öñÔ∏è Acc√®s s√©curis√© attributs weight ‚úÖ")
    logger.info("üõë" * 50)
    logger.info("‚úÖ [Services] clarification_entities import√© avec succ√®s")
except (ImportError, ModuleNotFoundError) as e:
    logger.warning(f"‚ö†Ô∏è [Services] clarification_entities non disponible: {e}")
    
    # Fonctions fallback am√©lior√©es
    def normalize_breed_name(breed):
        if not breed or not isinstance(breed, str):
            return "", "manual"
        return breed.lower().strip(), "manual"
    
    def infer_sex_from_breed(breed):
        if not breed or not isinstance(breed, str):
            return None, False
        layer_breeds = ['isa brown', 'lohmann brown', 'hy-line', 'bovans', 'shaver', 'hissex', 'novogen']
        breed_lower = breed.lower()
        is_layer = any(layer in breed_lower for layer in layer_breeds)
        return "femelles" if is_layer else None, is_layer
    
    def get_breed_type(breed):
        if not breed or not isinstance(breed, str):
            return "unknown"
        breed_lower = breed.lower()
        layer_breeds = ['isa brown', 'lohmann brown', 'hy-line', 'bovans', 'shaver', 'hissex', 'novogen']
        if any(layer in breed_lower for layer in layer_breeds):
            return "layers"
        broiler_breeds = ['ross 308', 'cobb 500', 'hubbard', 'ross', 'cobb']
        if any(broiler in breed_lower for broiler in broiler_breeds):
            return "broilers"
        return "unknown"
    
    def get_supported_breeds():
        return ["ross 308", "cobb 500", "hubbard", "isa brown", "lohmann brown", "hy-line", "bovans", "shaver"]
    
    CLARIFICATION_ENTITIES_AVAILABLE = False


# Imports s√©curis√©s des mod√®les avec validation
try:
    from .expert_models import (
        EnhancedQuestionRequest, EnhancedExpertResponse, FeedbackRequest,
        ValidationResult, ProcessingContext, VaguenessResponse, ResponseFormat,
        ConcisionLevel, ConcisionMetrics, DynamicClarification
    )
    MODELS_AVAILABLE = True
    logger.info("‚úÖ [Services] expert_models import√© avec succ√®s")
except (ImportError, ModuleNotFoundError) as e:
    logger.warning(f"‚ö†Ô∏è [Services] expert_models non disponible: {e}")
    from pydantic import BaseModel
    
    # Mod√®les de fallback robustes
    class ValidationResult:
        def __init__(self, is_valid=True, rejection_message="", confidence=1.0):
            self.is_valid = bool(is_valid)
            self.rejection_message = str(rejection_message) if rejection_message else ""
            self.confidence = float(confidence) if confidence is not None else 1.0
    
    class ConcisionLevel:
        CONCISE = "concise"
        STANDARD = "standard"
        DETAILED = "detailed"
        ULTRA_CONCISE = "ultra_concise"
    
    # Mock pour EnhancedExpertResponse avec champ contextualization_info ajout√©
    class EnhancedExpertResponse:
        def __init__(self, **kwargs):
            for key, value in kwargs.items():
                setattr(self, key, value)
            # CORRECTION 3: Ajouter le champ manquant
            if not hasattr(self, 'contextualization_info'):
                self.contextualization_info = None
            if not hasattr(self, 'enhancement_info'):
                self.enhancement_info = None
            if not hasattr(self, 'response_versions'):
                self.response_versions = None
    
    # Mock pour autres classes
    class EnhancedQuestionRequest:
        def __init__(self, **kwargs):
            for key, value in kwargs.items():
                setattr(self, key, value)
    
    class FeedbackRequest:
        def __init__(self, **kwargs):
            for key, value in kwargs.items():
                setattr(self, key, value)
    
    MODELS_AVAILABLE = False

# Imports s√©curis√©s des utilitaires
try:
    from .expert_utils import (
        get_user_id_from_request, 
        build_enriched_question_from_clarification,
        get_enhanced_topics_by_language,
        save_conversation_auto_enhanced,
        extract_breed_and_sex_from_clarification,
        build_enriched_question_with_breed_sex,
        validate_clarification_completeness
    )
    UTILS_AVAILABLE = True
    logger.info("‚úÖ [Services] expert_utils import√© avec succ√®s")
except (ImportError, ModuleNotFoundError) as e:
    logger.warning(f"‚ö†Ô∏è [Services] expert_utils non disponible: {e}")
    
    # Fonctions fallback am√©lior√©es
    def get_user_id_from_request(request):
        try:
            if request and hasattr(request, 'client') and request.client:
                return getattr(request.client, 'host', 'unknown')
            return 'unknown'
        except Exception:
            return 'unknown'
    
    def get_enhanced_topics_by_language():
        return {
            "fr": ["Croissance poulets", "Nutrition aviaire", "Sant√© animale", "Probl√®mes ponte"],
            "en": ["Chicken growth", "Poultry nutrition", "Animal health", "Laying problems"],
            "es": ["Crecimiento pollos", "Nutrici√≥n aviar", "Salud animal", "Problemas puesta"]
        }
    
    def extract_breed_and_sex_from_clarification(text, language):
        if not text or not isinstance(text, str):
            return {"breed": None, "sex": None}
        
        text_lower = text.lower()
        entities = {}
        
        # D√©tection race avec validation
        breed_patterns = [
            r'\b(ross\s*308|cobb\s*500|hubbard|isa\s*brown|lohmann\s*brown|hy[-\s]*line|bovans|shaver)\b'
        ]
        
        for pattern in breed_patterns:
            try:
                match = re.search(pattern, text_lower, re.IGNORECASE)
                if match:
                    breed = match.group(1).strip()
                    entities['breed'] = breed
                    
                    # Auto-inf√©rence sexe pour pondeuses
                    normalized_breed, _ = normalize_breed_name(breed)
                    inferred_sex, was_inferred = infer_sex_from_breed(normalized_breed)
                    
                    if was_inferred and inferred_sex:
                        entities['sex'] = inferred_sex
                    break
            except Exception as e:
                logger.error(f"‚ùå Erreur pattern breed: {e}")
                continue
        
        # D√©tection sexe si pas d√©j√† d√©fini
        if not entities.get('sex'):
            if any(sex in text_lower for sex in ['m√¢le', 'male', 'masculin']):
                entities['sex'] = 'm√¢les'
            elif any(sex in text_lower for sex in ['femelle', 'female', 'f√©minin']):
                entities['sex'] = 'femelles'
            elif any(sex in text_lower for sex in ['mixte', 'mixed']):
                entities['sex'] = 'mixte'
        
        return entities
    
    def build_enriched_question_with_breed_sex(original_question, breed, sex, language):
        if not original_question or not isinstance(original_question, str):
            return "Question invalide"
        
        try:
            if breed and sex:
                return f"Pour des poulets {breed} {sex}: {original_question}"
            elif breed:
                return f"Pour des poulets {breed}: {original_question}"
            else:
                return original_question
        except Exception:
            return original_question
    
    def validate_clarification_completeness(text, missing_info, language):
        return {"is_complete": True, "extracted_info": {}}
    
    UTILS_AVAILABLE = False

# Imports s√©curis√©s des int√©grations
try:
    from .expert_integrations import IntegrationsManager
    INTEGRATIONS_AVAILABLE = True
    logger.info("‚úÖ [Services] expert_integrations import√© avec succ√®s")
except (ImportError, ModuleNotFoundError) as e:
    logger.warning(f"‚ö†Ô∏è [Services] expert_integrations non disponible: {e}")
    
    # Mock IntegrationsManager robuste
    class IntegrationsManager:
        def __init__(self):
            self.enhanced_clarification_available = False
            self.intelligent_memory_available = False
            self.agricultural_validator_available = False
            self.auth_available = False
            self.logging_available = False
            
            # Support clarification critique s√©curis√©
            self._clarification_functions = {
                'analyze_question_for_clarification_enhanced': self._mock_analyze_clarification
            }
        
        async def _mock_analyze_clarification(self, question, language="fr"):
            """Mock s√©curis√© pour analyse clarification critique"""
            try:
                if not question or not isinstance(question, str):
                    return {
                        "clarification_required_critical": False,
                        "clarification_required_optional": False,
                        "missing_critical_entities": [],
                        "missing_optional_entities": [],
                        "confidence": 0.5,
                        "reasoning": "Question invalide",
                        "poultry_type": "unknown"
                    }
                
                return {
                    "clarification_required_critical": False,
                    "clarification_required_optional": False,
                    "missing_critical_entities": [],
                    "missing_optional_entities": [],
                    "confidence": 0.5,
                    "reasoning": "Mock analysis",
                    "poultry_type": "unknown"
                }
            except Exception as e:
                logger.error(f"‚ùå Mock clarification error: {e}")
                return {
                    "clarification_required_critical": False,
                    "clarification_required_optional": False,
                    "missing_critical_entities": [],
                    "missing_optional_entities": [],
                    "confidence": 0.0,
                    "reasoning": f"Error: {str(e)}",
                    "poultry_type": "unknown"
                }
        
        def get_current_user_dependency(self):
            return lambda: {"id": "fallback", "email": "fallback@intelia.com"}
        
        def is_agricultural_validation_enabled(self):
            return False
        
        def validate_agricultural_question(self, **kwargs):
            return ValidationResult(is_valid=True, rejection_message="", confidence=0.5)
        
        async def update_feedback(self, conversation_id, rating):
            return False
    
    INTEGRATIONS_AVAILABLE = False

# Agents GPT avec gestion d'erreurs robuste
try:
    from .agent_contextualizer import agent_contextualizer
    from .agent_rag_enhancer import agent_rag_enhancer
    AGENTS_AVAILABLE = True
    logger.info("‚úÖ [Services] Agents GPT import√©s avec succ√®s")
except (ImportError, ModuleNotFoundError) as e:
    logger.warning(f"‚ö†Ô∏è [Services] Agents GPT non disponibles: {e}")
    
    # Mocks robustes pour les agents
    class MockAgent:
        async def enrich_question(self, *args, **kwargs):
            try:
                question = args[0] if args else kwargs.get('question', 'Question vide')
                return {
                    "enriched_question": str(question),
                    "method_used": "mock",
                    "entities_used": []
                }
            except Exception as e:
                logger.error(f"‚ùå Mock agent error: {e}")
                return {
                    "enriched_question": "Erreur agent",
                    "method_used": "error",
                    "entities_used": []
                }
        
        async def enhance_rag_answer(self, *args, **kwargs):
            try:
                answer = args[0] if args else kwargs.get('rag_answer', 'R√©ponse vide')
                return {
                    "enhanced_answer": str(answer),
                    "optional_clarifications": [],
                    "method_used": "mock"
                }
            except Exception as e:
                logger.error(f"‚ùå Mock enhancer error: {e}")
                return {
                    "enhanced_answer": "Erreur enhancement",
                    "optional_clarifications": [],
                    "method_used": "error"
                }
    
    agent_contextualizer = MockAgent()
    agent_rag_enhancer = MockAgent()
    AGENTS_AVAILABLE = False

# M√©moire conversationnelle avec gestion d'erreurs
try:
    from .conversation_memory import IntelligentConversationMemory
    CONVERSATION_MEMORY_AVAILABLE = True
    logger.info("‚úÖ [Services] M√©moire conversationnelle import√©e")
except (ImportError, ModuleNotFoundError) as e:
    logger.warning(f"‚ö†Ô∏è [Services] M√©moire conversationnelle non disponible: {e}")
    
    # Mock robuste pour m√©moire conversationnelle
    class MockConversationMemory:
        def get_conversation_context(self, conversation_id):
            try:
                if not conversation_id:
                    return None
                return None
            except Exception as e:
                logger.error(f"‚ùå Mock memory get_context error: {e}")
                return None
        
        async def add_message_to_conversation(self, *args, **kwargs):
            try:
                return True
            except Exception as e:
                logger.error(f"‚ùå Mock memory add_message error: {e}")
                return False
        
        def mark_pending_clarification(self, conversation_id, question, critical_entities):
            """Marquer clarification pendante de fa√ßon s√©curis√©e"""
            try:
                if not conversation_id or not isinstance(critical_entities, list):
                    return False
                logger.info(f"üõë [Mock Memory] Clarification critique marqu√©e: {critical_entities}")
                return True
            except Exception as e:
                logger.error(f"‚ùå Mock memory mark_pending error: {e}")
                return False
        
        def clear_pending_clarification(self, conversation_id):
            """Nettoyer clarification r√©solue de fa√ßon s√©curis√©e"""
            try:
                if not conversation_id:
                    return False
                logger.info("‚úÖ [Mock Memory] Clarification r√©solue")
                return True
            except Exception as e:
                logger.error(f"‚ùå Mock memory clear_pending error: {e}")
                return False
    
    CONVERSATION_MEMORY_AVAILABLE = False

# Imports optionnels avec fallbacks s√©curis√©s
try:
    from .api_enhancement_service import APIEnhancementService
    API_ENHANCEMENT_AVAILABLE = True
except (ImportError, ModuleNotFoundError):
    class APIEnhancementService:
        def detect_vagueness(self, question, language):
            return None
    API_ENHANCEMENT_AVAILABLE = False

try:
    from .prompt_templates import build_structured_prompt, extract_context_from_entities, validate_prompt_context, build_clarification_prompt
    PROMPT_TEMPLATES_AVAILABLE = True
except (ImportError, ModuleNotFoundError):
    def build_structured_prompt(documents, question, context):
        return f"Documents: {documents}\nQuestion: {question}\nContext: {context}"
    def extract_context_from_entities(entities):
        return entities or {}
    PROMPT_TEMPLATES_AVAILABLE = False

# CORRECTION 4: Import du service de concision
try:
    from .expert_concision_service import ConcisionService
    CONCISION_SERVICE_AVAILABLE = True
    logger.info("‚úÖ [Services] ConcisionService import√© avec succ√®s")
except (ImportError, ModuleNotFoundError) as e:
    logger.warning(f"‚ö†Ô∏è [Services] ConcisionService non disponible: {e}")
    
    # Mock ConcisionService pour garantir response_versions
    class MockConcisionService:
        def generate_all_versions(self, text, language="fr"):
            """G√©n√®re toutes les versions avec fallback robuste"""
            try:
                if not text or not isinstance(text, str):
                    text = "R√©ponse indisponible"
                
                # Versions simplifi√©es mais fonctionnelles
                words = text.split()
                
                return {
                    "ultra_concise": " ".join(words[:10]) + ("..." if len(words) > 10 else ""),
                    "concise": " ".join(words[:25]) + ("..." if len(words) > 25 else ""),
                    "standard": " ".join(words[:50]) + ("..." if len(words) > 50 else ""),
                    "detailed": text
                }
            except Exception as e:
                logger.error(f"‚ùå Mock concision error: {e}")
                return {
                    "ultra_concise": "Erreur",
                    "concise": "Erreur g√©n√©ration versions",
                    "standard": "Une erreur s'est produite",
                    "detailed": f"Erreur: {str(e)}"
                }
    
    CONCISION_SERVICE_AVAILABLE = False

# =============================================================================
# üöÄ FONCTIONS UTILITAIRES POUR ACC√àS S√âCURIS√â WEIGHT (NOUVEAU)
# =============================================================================

def safe_get_weight(entities, default=None):
    """
    ‚öñÔ∏è ACC√àS S√âCURIS√â AU POIDS - NOUVELLE FONCTION
    
    R√©cup√®re la valeur 'weight' de fa√ßon s√©curis√©e selon le type d'entities
    
    Args:
        entities: Objet ou dict contenant potentiellement 'weight'
        default: Valeur par d√©faut si 'weight' n'existe pas
    
    Returns:
        Valeur de weight ou default
    """
    try:
        if entities is None:
            return default
        
        # Si entities est un dictionnaire
        if isinstance(entities, dict):
            weight_value = entities.get('weight', default)
        # Si entities est un objet avec attributs
        elif hasattr(entities, '__dict__'):
            weight_value = getattr(entities, 'weight', default)
        else:
            weight_value = default
        
        logger.debug(f"‚öñÔ∏è [Safe Weight] R√©cup√©r√©: {weight_value} (type: {type(weight_value)})")
        return weight_value
        
    except Exception as e:
        logger.error(f"‚ùå [Safe Weight] Erreur acc√®s weight: {e}")
        return default

def safe_get_weight_unit(entities, default="g"):
    """
    ‚öñÔ∏è ACC√àS S√âCURIS√â √Ä L'UNIT√â DE POIDS - NOUVELLE FONCTION
    """
    try:
        if entities is None:
            return default
        
        if isinstance(entities, dict):
            unit_value = entities.get('weight_unit', default)
        elif hasattr(entities, '__dict__'):
            unit_value = getattr(entities, 'weight_unit', default)
        else:
            unit_value = default
        
        return unit_value
        
    except Exception as e:
        logger.error(f"‚ùå [Safe Weight Unit] Erreur: {e}")
        return default

def validate_and_normalize_weight(weight_value, unit="g"):
    """
    ‚öñÔ∏è VALIDATION ET NORMALISATION DU POIDS - NOUVELLE FONCTION
    
    Valide et normalise une valeur de poids
    
    Args:
        weight_value: Valeur √† valider (peut √™tre string, int, float, None)
        unit: Unit√© du poids
    
    Returns:
        dict avec value (float|None), unit (str), is_valid (bool)
    """
    try:
        if weight_value is None:
            return {"value": None, "unit": unit, "is_valid": False, "error": "Valeur None"}
        
        # Conversion en float si possible
        if isinstance(weight_value, str):
            try:
                # Remplacer virgule par point pour les locales fran√ßaises
                normalized_str = str(weight_value).replace(',', '.').strip()
                weight_float = float(normalized_str)
            except (ValueError, TypeError) as e:
                return {"value": None, "unit": unit, "is_valid": False, "error": f"Conversion impossible: {e}"}
        elif isinstance(weight_value, (int, float)):
            weight_float = float(weight_value)
        else:
            return {"value": None, "unit": unit, "is_valid": False, "error": f"Type non support√©: {type(weight_value)}"}
        
        # Validation des valeurs sens√©es
        if weight_float < 0:
            return {"value": weight_float, "unit": unit, "is_valid": False, "error": "Poids n√©gatif"}
        elif weight_float > 100000:  # 100kg max pour √©viter les erreurs
            return {"value": weight_float, "unit": unit, "is_valid": False, "error": "Poids trop √©lev√©"}
        
        return {"value": weight_float, "unit": unit, "is_valid": True, "error": None}
        
    except Exception as e:
        logger.error(f"‚ùå [Validate Weight] Erreur: {e}")
        return {"value": None, "unit": unit, "is_valid": False, "error": str(e)}

def extract_weight_from_text_safe(text, language="fr"):
    """
    ‚öñÔ∏è EXTRACTION S√âCURIS√âE DU POIDS DEPUIS TEXTE - NOUVELLE FONCTION
    
    Extrait mentions de poids dans un texte de fa√ßon s√©curis√©e
    """
    try:
        if not text or not isinstance(text, str):
            return {"weight": None, "unit": None, "confidence": 0.0}
        
        text_lower = text.lower()
        
        # Patterns pour d√©tecter poids + unit√©
        weight_patterns = [
            r'(\d+(?:[.,]\d+)?)\s*(g|grammes?|kg|kilogrammes?|pounds?|lbs?)',
            r'(\d+(?:[.,]\d+)?)\s*(g|kg|lb)',
            r'poids.*?(\d+(?:[.,]\d+)?)\s*(g|kg|lb)',
            r'weight.*?(\d+(?:[.,]\d+)?)\s*(g|kg|lb)',
            r'peso.*?(\d+(?:[.,]\d+)?)\s*(g|kg|lb)'
        ]
        
        for pattern in weight_patterns:
            try:
                matches = re.findall(pattern, text_lower, re.IGNORECASE)
                if matches:
                    # Prendre la premi√®re occurrence
                    weight_str, unit = matches[0]
                    
                    # Validation du poids
                    weight_result = validate_and_normalize_weight(weight_str, unit)
                    
                    if weight_result["is_valid"]:
                        return {
                            "weight": weight_result["value"],
                            "unit": weight_result["unit"],
                            "confidence": 0.8
                        }
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Extract Weight] Erreur pattern: {e}")
                continue
        
        return {"weight": None, "unit": None, "confidence": 0.0}
        
    except Exception as e:
        logger.error(f"‚ùå [Extract Weight Text] Erreur: {e}")
        return {"weight": None, "unit": None, "confidence": 0.0}

# =============================================================================
# üöÄ SYST√àME CLARIFICATION CRITIQUE VS NON CRITIQUE (VERSION CORRIG√âE)
# =============================================================================

async def analyze_question_for_clarification_enhanced(question: str, language: str = "fr") -> dict:
    """
    üõë ANALYSE CLARIFICATION CRITIQUE vs NON CRITIQUE (Version corrig√©e avec await)
    
    CORRECTION 1: Fonction maintenant async pour √™tre appel√©e avec await
    """
    
    # Validation des param√®tres d'entr√©e
    if not question or not isinstance(question, str):
        logger.warning("‚ö†Ô∏è [Critical Clarification] Question invalide")
        return {
            "clarification_required_critical": False,
            "clarification_required_optional": False,
            "missing_critical_entities": [],
            "missing_optional_entities": [],
            "confidence": 0.0,
            "reasoning": "Question invalide ou vide",
            "poultry_type": "unknown"
        }
    
    if not language or not isinstance(language, str):
        language = "fr"
    
    try:
        question_lower = question.lower().strip()
        
        # D√©tection type volaille avec gestion d'erreurs
        poultry_type = detect_poultry_type_safe(question_lower)
        
        logger.info(f"üîç [Critical Clarification] Type volaille d√©tect√©: {poultry_type}")
        
        # Analyse selon le type avec gestion d'erreurs
        if poultry_type == "layers":
            return analyze_layer_clarification_critical_safe(question_lower, language)
        elif poultry_type == "broilers":
            return analyze_broiler_clarification_critical_safe(question_lower, language)
        else:
            return analyze_general_clarification_critical_safe(question_lower, language)
            
    except Exception as e:
        logger.error(f"‚ùå [Critical Clarification] Erreur analyse: {e}")
        return {
            "clarification_required_critical": False,
            "clarification_required_optional": False,
            "missing_critical_entities": [],
            "missing_optional_entities": [],
            "confidence": 0.0,
            "reasoning": f"Erreur analyse: {str(e)}",
            "poultry_type": "unknown"
        }

def detect_poultry_type_safe(question_lower: str) -> str:
    """
    üîß D√©tection type volaille s√©curis√©e avec fallback intelligent
    """
    
    if not question_lower or not isinstance(question_lower, str):
        return "unknown"
    
    try:
        # Mots-cl√©s pondeuses
        layer_keywords = [
            "pondeuse", "pondeuses", "poule", "poules", "layer", "layers",
            "≈ìuf", "oeufs", "egg", "eggs", "ponte", "laying", "lay",
            "pondent", "pond", "production d'≈ìufs", "egg production",
            "pondoir", "nest", "nid"
        ]
        
        # Mots-cl√©s poulets de chair
        broiler_keywords = [
            "poulet", "poulets", "broiler", "broilers", "chair", "meat",
            "viande", "abattage", "slaughter", "poids", "weight", "croissance",
            "growth", "ross", "cobb", "hubbard", "fcr", "gain"
        ]
        
        # Comptage s√©curis√© des occurrences
        layer_score = 0
        broiler_score = 0
        
        for keyword in layer_keywords:
            if keyword in question_lower:
                layer_score += 1
        
        for keyword in broiler_keywords:
            if keyword in question_lower:
                broiler_score += 1
        
        logger.info(f"üîç [Safe Detection] Layer score: {layer_score}, Broiler score: {broiler_score}")
        
        # D√©cision bas√©e sur les scores
        if layer_score > broiler_score:
            logger.info("üîç [Safe Detection] Type d√©termin√© par mots-cl√©s: layers")
            return "layers"
        elif broiler_score > layer_score:
            logger.info("üîç [Safe Detection] Type d√©termin√© par mots-cl√©s: broilers")
            return "broilers"
        
        # Analyse des races si scores √©gaux
        logger.info("üîç [Safe Detection] Scores √©gaux, analyse des races...")
        
        potential_breeds = extract_breeds_from_question_safe(question_lower)
        logger.info(f"üîç [Safe Detection] Races d√©tect√©es: {potential_breeds}")
        
        if potential_breeds:
            for breed in potential_breeds:
                try:
                    normalized_breed, _ = normalize_breed_name(breed)
                    breed_type = get_breed_type(normalized_breed)
                    
                    if breed_type == "layers":
                        logger.info(f"üîç [Safe Detection] Race {breed} ‚Üí layers")
                        return "layers"
                    elif breed_type == "broilers":
                        logger.info(f"üîç [Safe Detection] Race {breed} ‚Üí broilers")
                        return "broilers"
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [Safe Detection] Erreur analyse race {breed}: {e}")
                    continue
        
        # Fallback final
        logger.info("üîç [Safe Detection] Type ind√©termin√© apr√®s analyse compl√®te")
        return "unknown"
        
    except Exception as e:
        logger.error(f"‚ùå [Safe Detection] Erreur d√©tection: {e}")
        return "unknown"

def extract_breeds_from_question_safe(question_lower: str) -> List[str]:
    """
    üîç Extrait les races mentionn√©es dans la question de fa√ßon s√©curis√©e
    """
    
    if not question_lower or not isinstance(question_lower, str):
        return []
    
    try:
        breed_patterns = [
            r'\b(ross\s*308|cobb\s*500|hubbard\s*\w*)\b',
            r'\b(ross|cobb)\s*\d{2,3}\b',
            r'\b(isa\s*brown|lohmann\s*brown|hy[-\s]*line)\b',
            r'\b(bovans|shaver|hissex|novogen|tetra|hendrix|dominant)\b',
            r'\brace[:\s]*([a-zA-Z0-9\s]{3,20})\b',
            r'\bsouche[:\s]*([a-zA-Z0-9\s]{3,20})\b',
            r'\bbreed[:\s]*([a-zA-Z0-9\s]{3,20})\b',
        ]
        
        found_breeds = []
        
        for pattern in breed_patterns:
            try:
                matches = re.findall(pattern, question_lower, re.IGNORECASE)
                if matches:
                    for match in matches:
                        try:
                            if isinstance(match, tuple):
                                breed = next((m.strip() for m in match if m and m.strip()), "")
                            else:
                                breed = str(match).strip()
                            
                            if breed and 2 <= len(breed) <= 25:
                                found_breeds.append(breed)
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è [Extract Breeds] Erreur traitement match: {e}")
                            continue
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Extract Breeds] Erreur pattern {pattern}: {e}")
                continue
        
        # D√©duplication s√©curis√©e
        unique_breeds = []
        seen = set()
        
        for breed in found_breeds:
            try:
                breed_clean = breed.lower()
                if breed_clean not in seen:
                    unique_breeds.append(breed)
                    seen.add(breed_clean)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Extract Breeds] Erreur d√©duplication: {e}")
                continue
        
        return unique_breeds
        
    except Exception as e:
        logger.error(f"‚ùå [Extract Breeds] Erreur extraction: {e}")
        return []

def analyze_layer_clarification_critical_safe(question_lower: str, language: str) -> dict:
    """
    ü•ö ANALYSE CLARIFICATION CRITIQUE PONDEUSES (Version s√©curis√©e)
    """
    
    try:
        critical_missing = []
        optional_missing = []
        confidence = 0.0
        
        # Entit√©s critiques pour pondeuses
        critical_layer_info = {
            "breed": ["isa", "brown", "lohmann", "hy-line", "race", "souche", "breed"],
            "production_stage": ["semaine", "semaines", "week", "weeks", "√¢ge", "age", "mois", "months", "d√©but", "pic", "fin"]
        }
        
        # Entit√©s non critiques
        optional_layer_info = {
            "production_rate": ["≈ìufs/jour", "eggs/day", "production", "combien", "how many"],
            "housing": ["cage", "sol", "parcours", "free range", "battery", "barn"],
            "lighting": ["lumi√®re", "√©clairage", "light", "hours", "heures"],
            "feeding": ["alimentation", "feed", "nutrition", "protein", "prot√©ine"],
            "weight": ["poids", "weight", "peso", "gramme", "kg", "g"]  # NOUVEAU: weight ajout√©
        }
        
        # V√©rifier entit√©s CRITIQUES de fa√ßon s√©curis√©e
        for info_type, keywords in critical_layer_info.items():
            try:
                if not any(keyword in question_lower for keyword in keywords if keyword):
                    critical_missing.append(info_type)
                    confidence += 0.4
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Layer Critical] Erreur v√©rification {info_type}: {e}")
        
        # V√©rifier entit√©s NON CRITIQUES de fa√ßon s√©curis√©e
        for info_type, keywords in optional_layer_info.items():
            try:
                if not any(keyword in question_lower for keyword in keywords if keyword):
                    optional_missing.append(info_type)
                    confidence += 0.1
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Layer Optional] Erreur v√©rification {info_type}: {e}")
        
        # D√©cision critique s√©curis√©e
        is_critical = len(critical_missing) >= 1
        is_optional = len(optional_missing) >= 2
        
        logger.info(f"ü•ö [Layer Critical Safe] Critique: {critical_missing}, Optionnel: {optional_missing}")
        
        return {
            "clarification_required_critical": is_critical,
            "clarification_required_optional": is_optional,
            "missing_critical_entities": critical_missing,
            "missing_optional_entities": optional_missing,
            "confidence": min(confidence, 0.9),
            "reasoning": f"Pondeuses - Entit√©s critiques manquantes: {critical_missing}",
            "poultry_type": "layers"
        }
        
    except Exception as e:
        logger.error(f"‚ùå [Layer Critical Safe] Erreur: {e}")
        return {
            "clarification_required_critical": False,
            "clarification_required_optional": False,
            "missing_critical_entities": [],
            "missing_optional_entities": [],
            "confidence": 0.0,
            "reasoning": f"Erreur analyse pondeuses: {str(e)}",
            "poultry_type": "layers"
        }

def analyze_broiler_clarification_critical_safe(question_lower: str, language: str) -> dict:
    """
    üçó ANALYSE CLARIFICATION CRITIQUE POULETS DE CHAIR (Version s√©curis√©e avec weight)
    """
    
    try:
        critical_missing = []
        optional_missing = []
        confidence = 0.0
        
        # Entit√©s critiques pour poulets de chair
        critical_broiler_info = {
            "breed": ["ross", "cobb", "hubbard", "race", "souche", "breed", "strain"],
            "age": ["jour", "jours", "day", "days", "semaine", "week", "√¢ge", "age"],
            "sex": ["m√¢le", "male", "femelle", "female", "mixte", "mixed", "sexe", "sex"]
        }
        
        # Entit√©s non critiques (weight inclus ici maintenant)
        optional_broiler_info = {
            "weight": ["poids", "weight", "peso", "gramme", "kg", "g"],  # NOUVEAU: weight s√©curis√©
            "housing": ["temp√©rature", "temperature", "ventilation", "density", "densit√©"],
            "feeding": ["alimentation", "feed", "fcr", "conversion", "nutrition"]
        }
        
        # V√©rifier entit√©s CRITIQUES de fa√ßon s√©curis√©e
        for info_type, keywords in critical_broiler_info.items():
            try:
                if not any(keyword in question_lower for keyword in keywords if keyword):
                    critical_missing.append(info_type)
                    confidence += 0.3
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Broiler Critical] Erreur v√©rification {info_type}: {e}")
        
        # V√©rifier entit√©s NON CRITIQUES de fa√ßon s√©curis√©e (incluant weight)
        for info_type, keywords in optional_broiler_info.items():
            try:
                if not any(keyword in question_lower for keyword in keywords if keyword):
                    optional_missing.append(info_type)
                    confidence += 0.1
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Broiler Optional] Erreur v√©rification {info_type}: {e}")
        
        # D√©cision critique s√©curis√©e
        is_critical = len(critical_missing) >= 2
        is_optional = len(optional_missing) >= 1
        
        logger.info(f"üçó [Broiler Critical Safe] Critique: {critical_missing}, Optionnel: {optional_missing}")
        
        return {
            "clarification_required_critical": is_critical,
            "clarification_required_optional": is_optional,
            "missing_critical_entities": critical_missing,
            "missing_optional_entities": optional_missing,
            "confidence": confidence,
            "reasoning": f"Poulets de chair - Entit√©s critiques manquantes: {critical_missing}",
            "poultry_type": "broilers"
        }
        
    except Exception as e:
        logger.error(f"‚ùå [Broiler Critical Safe] Erreur: {e}")
        return {
            "clarification_required_critical": False,
            "clarification_required_optional": False,
            "missing_critical_entities": [],
            "missing_optional_entities": [],
            "confidence": 0.0,
            "reasoning": f"Erreur analyse poulets de chair: {str(e)}",
            "poultry_type": "broilers"
        }

def analyze_general_clarification_critical_safe(question_lower: str, language: str) -> dict:
    """
    ‚ùì ANALYSE CLARIFICATION G√âN√âRALE (Version s√©curis√©e)
    """
    
    try:
        logger.info("‚ùì [General Critical Safe] Type volaille ind√©termin√© - clarification critique requise")
        
        return {
            "clarification_required_critical": True,
            "clarification_required_optional": False,
            "missing_critical_entities": ["poultry_type", "species"],
            "missing_optional_entities": ["breed", "age", "purpose", "weight"],  # NOUVEAU: weight ajout√©
            "confidence": 0.8,
            "reasoning": "Type de volaille ind√©termin√© - clarification critique n√©cessaire",
            "poultry_type": "unknown"
        }
        
    except Exception as e:
        logger.error(f"‚ùå [General Critical Safe] Erreur: {e}")
        return {
            "clarification_required_critical": False,
            "clarification_required_optional": False,
            "missing_critical_entities": [],
            "missing_optional_entities": [],
            "confidence": 0.0,
            "reasoning": f"Erreur analyse g√©n√©rale: {str(e)}",
            "poultry_type": "unknown"
        }

def generate_critical_clarification_message_safe(missing_entities: List[str], poultry_type: str, language: str) -> str:
    """
    üõë G√©n√®re le message de clarification critique de fa√ßon s√©curis√©e
    """
    
    try:
        if not missing_entities or not isinstance(missing_entities, list):
            missing_entities = ["information"]
        
        if not poultry_type or not isinstance(poultry_type, str):
            poultry_type = "unknown"
        
        if not language or not isinstance(language, str):
            language = "fr"
        
        messages = {
            "fr": {
                "layers": {
                    "breed": "Pr√©cisez la race de vos pondeuses (ISA Brown, Lohmann Brown, Hy-Line, etc.)",
                    "production_stage": "Indiquez l'√¢ge ou le stade de production de vos pondeuses",
                    "weight": "Indiquez le poids moyen de vos pondeuses",  # NOUVEAU
                    "general": "Pour vous donner une r√©ponse pr√©cise sur vos pondeuses, j'ai besoin de conna√Ætre :"
                },
                "broilers": {
                    "breed": "Pr√©cisez la race/souche de vos poulets (Ross 308, Cobb 500, Hubbard, etc.)",
                    "age": "Indiquez l'√¢ge de vos poulets (en jours ou semaines)",
                    "sex": "Pr√©cisez s'il s'agit de m√¢les, femelles, ou un troupeau mixte",
                    "weight": "Indiquez le poids moyen de vos poulets",  # NOUVEAU
                    "general": "Pour vous donner une r√©ponse pr√©cise sur vos poulets de chair, j'ai besoin de conna√Ætre :"
                },
                "unknown": {
                    "poultry_type": "Pr√©cisez le type de volailles (pondeuses, poulets de chair, etc.)",
                    "species": "Indiquez l'esp√®ce exacte de vos animaux",
                    "weight": "Indiquez le poids de vos animaux",  # NOUVEAU
                    "general": "Pour vous donner une r√©ponse pr√©cise, j'ai besoin de conna√Ætre :"
                }
            },
            "en": {
                "layers": {
                    "breed": "Specify the breed of your laying hens (ISA Brown, Lohmann Brown, Hy-Line, etc.)",
                    "production_stage": "Indicate the age or production stage of your laying hens",
                    "weight": "Indicate the average weight of your laying hens",  # NOUVEAU
                    "general": "To give you a precise answer about your laying hens, I need to know:"
                },
                "broilers": {
                    "breed": "Specify the breed/strain of your chickens (Ross 308, Cobb 500, Hubbard, etc.)",
                    "age": "Indicate the age of your chickens (in days or weeks)",
                    "sex": "Specify if they are males, females, or a mixed flock",
                    "weight": "Indicate the average weight of your chickens",  # NOUVEAU
                    "general": "To give you a precise answer about your broilers, I need to know:"
                },
                "unknown": {
                    "poultry_type": "Specify the type of poultry (laying hens, broilers, etc.)",
                    "species": "Indicate the exact species of your animals",
                    "weight": "Indicate the weight of your animals",  # NOUVEAU
                    "general": "To give you a precise answer, I need to know:"
                }
            },
            "es": {
                "layers": {
                    "breed": "Especifique la raza de sus gallinas ponedoras (ISA Brown, Lohmann Brown, Hy-Line, etc.)",
                    "production_stage": "Indique la edad o etapa de producci√≥n de sus gallinas ponedoras",
                    "weight": "Indique el peso promedio de sus gallinas ponedoras",  # NOUVEAU
                    "general": "Para darle una respuesta precisa sobre sus gallinas ponedoras, necesito saber:"
                },
                "broilers": {
                    "breed": "Especifique la raza/cepa de sus pollos (Ross 308, Cobb 500, Hubbard, etc.)",
                    "age": "Indique la edad de sus pollos (en d√≠as o semanas)",
                    "sex": "Especifique si son machos, hembras, o una bandada mixta",
                    "weight": "Indique el peso promedio de sus pollos",  # NOUVEAU
                    "general": "Para darle una respuesta precisa sobre sus pollos de engorde, necesito saber:"
                },
                "unknown": {
                    "poultry_type": "Especifique el tipo de aves (gallinas ponedoras, pollos de engorde, etc.)",
                    "species": "Indique la especie exacta de sus animales",
                    "weight": "Indique el peso de sus animales",  # NOUVEAU
                    "general": "Para darle una respuesta precisa, necesito saber:"
                }
            }
        }
        
        lang = language if language in messages else "fr"
        type_messages = messages[lang].get(poultry_type, messages[lang]["unknown"])
        
        # Construire le message de fa√ßon s√©curis√©e
        general_msg = type_messages.get("general", "Pour vous donner une r√©ponse pr√©cise, j'ai besoin de conna√Ætre :")
        specific_msgs = []
        
        for entity in missing_entities:
            if isinstance(entity, str) and entity in type_messages:
                specific_msgs.append(f"‚Ä¢ {type_messages[entity]}")
        
        if specific_msgs:
            return f"{general_msg}\n\n" + "\n".join(specific_msgs)
        else:
            return general_msg
            
    except Exception as e:
        logger.error(f"‚ùå [Generate Critical Message] Erreur: {e}")
        # Fallback s√©curis√©
        fallback_messages = {
            "fr": "Pour vous donner une r√©ponse pr√©cise, j'ai besoin de plus d'informations sur vos animaux.",
            "en": "To give you a precise answer, I need more information about your animals.",
            "es": "Para darle una respuesta precisa, necesito m√°s informaci√≥n sobre sus animales."
        }
        return fallback_messages.get(language, fallback_messages["fr"])

# =============================================================================
# üöÄ SERVICE PRINCIPAL EXPERT AVEC GESTION D'ERREURS ROBUSTE
# =============================================================================

class ExpertService:
    """Service principal pour le syst√®me expert avec gestion d'erreurs robuste"""
    
    def __init__(self):
        try:
            self.integrations = IntegrationsManager()
            self.enhancement_service = APIEnhancementService() if API_ENHANCEMENT_AVAILABLE else None
            
            # CORRECTION 4: Initialiser le service de concision
            if CONCISION_SERVICE_AVAILABLE:
                try:
                    self.concision_service = ConcisionService()
                    logger.info("‚úÖ [Expert Service] ConcisionService initialis√©")
                except Exception as e:
                    logger.error(f"‚ùå [Expert Service] Erreur init ConcisionService: {e}")
                    self.concision_service = MockConcisionService()
            else:
                self.concision_service = MockConcisionService()
                logger.warning("‚ö†Ô∏è [Expert Service] ConcisionService mock utilis√©")
            
            # Initialiser la m√©moire conversationnelle de fa√ßon s√©curis√©e
            if CONVERSATION_MEMORY_AVAILABLE:
                try:
                    self.conversation_memory = IntelligentConversationMemory()
                    logger.info("‚úÖ [Expert Service] M√©moire conversationnelle initialis√©e")
                except Exception as e:
                    logger.error(f"‚ùå [Expert Service] Erreur init m√©moire: {e}")
                    self.conversation_memory = MockConversationMemory()
            else:
                self.conversation_memory = MockConversationMemory()
                logger.warning("‚ö†Ô∏è [Expert Service] M√©moire conversationnelle mock utilis√©e")
            
            # Configuration avec validation
            self.config = {
                "enable_concise_responses": True,
                "default_concision_level": getattr(ConcisionLevel, 'CONCISE', 'concise'),
                "max_response_length": {
                    "ultra_concise": 50, 
                    "concise": 200, 
                    "standard": 500, 
                    "detailed": 1000
                },
                "fallback_mode": not all([MODELS_AVAILABLE, UTILS_AVAILABLE, INTEGRATIONS_AVAILABLE]),
                "critical_clarification_blocking": True,
                "optional_clarification_non_blocking": True,
                "agents_always_active": True,
                "agents_enabled": AGENTS_AVAILABLE,
                "conversation_memory_enabled": CONVERSATION_MEMORY_AVAILABLE,
                "concision_service_enabled": CONCISION_SERVICE_AVAILABLE or True,  # Toujours True avec mock
                "safe_weight_access": True  # NOUVEAU: Feature acc√®s s√©curis√© weight
            }
            
            logger.info("üöÄ [Expert Service] Service expert initialis√© avec gestion d'erreurs robuste")
            logger.info(f"üõë [Expert Service] Clarification critique bloquante: {self.config['critical_clarification_blocking']}")
            logger.info(f"üí° [Expert Service] Clarification optionnelle non bloquante: {self.config['optional_clarification_non_blocking']}")
            logger.info(f"üìè [Expert Service] Service concision activ√©: {self.config['concision_service_enabled']}")
            logger.info(f"‚öñÔ∏è [Expert Service] Acc√®s s√©curis√© weight: {self.config['safe_weight_access']}")
            
        except Exception as e:
            logger.error(f"‚ùå [Expert Service] Erreur critique lors de l'initialisation: {e}")
            # Configuration d'urgence
            self.integrations = IntegrationsManager()
            self.enhancement_service = None
            self.conversation_memory = MockConversationMemory()
            self.concision_service = MockConcisionService()
            self.config = {
                "enable_concise_responses": False,
                "default_concision_level": "standard",
                "max_response_length": {"standard": 500},
                "fallback_mode": True,
                "critical_clarification_blocking": False,
                "optional_clarification_non_blocking": False,
                "agents_always_active": False,
                "agents_enabled": False,
                "conversation_memory_enabled": False,
                "concision_service_enabled": True,  # Mock toujours disponible
                "safe_weight_access": True  # NOUVEAU: Toujours actif
            }
    
    def get_current_user_dependency(self):
        """Retourne la d√©pendance pour l'authentification de fa√ßon s√©curis√©e"""
        try:
            return self.integrations.get_current_user_dependency()
        except Exception as e:
            logger.error(f"‚ùå [Expert Service] Erreur get_current_user_dependency: {e}")
            return lambda: {"id": "error", "email": "error@intelia.com"}
    
    async def process_expert_question(
        self,
        request_data,
        request: Request,
        current_user: Optional[Dict[str, Any]] = None,
        start_time: float = None
    ):
        """üöÄ M√âTHODE PRINCIPALE AVEC GESTION D'ERREURS ROBUSTE"""
        
        if start_time is None:
            start_time = time.time()
        
        try:
            logger.info("üöÄ [ExpertService] Traitement avec gestion d'erreurs robuste")
            
            # Extraction s√©curis√©e des param√®tres
            question_text = self._extract_question_safe(request_data)
            language = self._extract_language_safe(request_data)
            conversation_id = self._extract_conversation_id_safe(request_data)
            
            logger.info(f"üìù [ExpertService] Question: '{question_text[:100] if question_text else 'VIDE'}...'")
            logger.info(f"üåê [ExpertService] Langue: {language}")
            logger.info(f"üÜî [ExpertService] Conversation: {conversation_id}")
            
            # Variables de traitement
            processing_steps = ["initialization", "parameter_extraction"]
            ai_enhancements_used = []
            
            # Authentification s√©curis√©e
            user_id = self._extract_user_id_safe(current_user, request_data, request)
            user_email = current_user.get("email") if current_user and isinstance(current_user, dict) else None
            
            processing_steps.append("authentication")
            
            # Validation question
            if not question_text or len(question_text.strip()) < 3:
                return self._create_error_response(
                    "Question trop courte", question_text or "Question vide", 
                    conversation_id, language, start_time
                )
            
            processing_steps.append("question_validation")
            
            # Mode fallback si n√©cessaire
            if self.config["fallback_mode"]:
                logger.info("üîÑ [ExpertService] Mode fallback activ√©")
                return await self._process_question_fallback(
                    question_text, conversation_id, language, user_email, start_time, processing_steps
                )
            
            # Pipeline principal avec gestion d'erreurs
            return await self._process_question_critical_clarification_pipeline_safe(
                request_data, request, current_user, start_time, processing_steps, ai_enhancements_used,
                question_text, language, conversation_id, user_id
            )
                
        except Exception as e:
            logger.error(f"‚ùå [ExpertService] Erreur critique: {e}")
            return self._create_error_response(
                f"Erreur interne: {str(e)}", 
                self._extract_question_safe(request_data), 
                self._extract_conversation_id_safe(request_data), 
                self._extract_language_safe(request_data), 
                start_time
            )
    
    # === M√âTHODES D'EXTRACTION S√âCURIS√âES ===
    
    def _extract_question_safe(self, request_data) -> str:
        """Extraction s√©curis√©e du texte de la question"""
        try:
            if hasattr(request_data, 'text') and request_data.text:
                return str(request_data.text)
            elif isinstance(request_data, dict) and 'text' in request_data:
                return str(request_data['text'])
            else:
                return "Question vide"
        except Exception as e:
            logger.error(f"‚ùå [Extract Question] Erreur: {e}")
            return "Question invalide"
    
    def _extract_language_safe(self, request_data) -> str:
        """Extraction s√©curis√©e de la langue"""
        try:
            if hasattr(request_data, 'language') and request_data.language:
                lang = str(request_data.language).lower()
                return lang if lang in ['fr', 'en', 'es'] else 'fr'
            elif isinstance(request_data, dict) and 'language' in request_data:
                lang = str(request_data['language']).lower()
                return lang if lang in ['fr', 'en', 'es'] else 'fr'
            else:
                return "fr"
        except Exception as e:
            logger.error(f"‚ùå [Extract Language] Erreur: {e}")
            return "fr"
    
    def _extract_conversation_id_safe(self, request_data) -> str:
        """Extraction s√©curis√©e de l'ID de conversation"""
        try:
            if hasattr(request_data, 'conversation_id') and request_data.conversation_id:
                return str(request_data.conversation_id)
            elif isinstance(request_data, dict) and 'conversation_id' in request_data:
                return str(request_data['conversation_id'])
            else:
                return str(uuid.uuid4())
        except Exception as e:
            logger.error(f"‚ùå [Extract Conversation ID] Erreur: {e}")
            return str(uuid.uuid4())
    
    def _extract_user_id_safe(self, current_user, request_data, request) -> str:
        """Extraction s√©curis√©e de l'ID utilisateur"""
        try:
            if current_user and isinstance(current_user, dict) and "id" in current_user:
                return str(current_user["id"])
            elif hasattr(request_data, 'user_id') and request_data.user_id:
                return str(request_data.user_id)
            elif UTILS_AVAILABLE:
                return get_user_id_from_request(request)
            else:
                return f"fallback_{uuid.uuid4().hex[:8]}"
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [ExpertService] Erreur extraction user_id: {e}")
            return f"error_{uuid.uuid4().hex[:8]}"
    
    # === PIPELINE PRINCIPAL S√âCURIS√â ===
    
    async def _process_question_critical_clarification_pipeline_safe(
        self, request_data, request, current_user, start_time, processing_steps, ai_enhancements_used,
        question_text, language, conversation_id, user_id
    ):
        """üõë Pipeline avec clarification critique et gestion d'erreurs robuste"""
        
        try:
            logger.info("üõë [ExpertService] Pipeline clarification critique activ√© (version s√©curis√©e)")
            processing_steps.append("critical_clarification_pipeline_activated")
            
            # Traitement clarification (si applicable)
            is_clarification = getattr(request_data, 'is_clarification_response', False)
            
            if is_clarification:
                logger.info("üé™ [ExpertService] Mode clarification d√©tect√©")
                processing_steps.append("clarification_mode_detected")
                
                try:
                    clarification_result = await self._process_clarification_enhanced_safe(request_data, processing_steps, language)
                    if clarification_result:
                        return clarification_result
                except Exception as e:
                    logger.error(f"‚ùå [Pipeline] Erreur traitement clarification: {e}")
                    # Continuer le pipeline normal
            
            # Validation agricole s√©curis√©e
            if self.integrations.agricultural_validator_available:
                try:
                    validation_result = await self._validate_agricultural_question_safe(
                        question_text, language, current_user
                    )
                    processing_steps.append("agricultural_validation")
                    
                    if not validation_result.is_valid:
                        return self._create_validation_error_response(
                            validation_result, question_text, conversation_id, language, start_time
                        )
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [ExpertService] Erreur validation agricole: {e}")
            
            # ANALYSE CLARIFICATION CRITIQUE AVANT RAG - CORRECTION 1: AWAIT AJOUT√â
            try:
                logger.info("üõë [Pipeline] Analyse clarification critique AVANT RAG")
                
                # CORRECTION 1: Ajouter await devant l'appel
                clarification_result = await self._analyze_clarification_safe(question_text, language)
                
                processing_steps.append("critical_clarification_analysis")
                ai_enhancements_used.append("critical_clarification_analysis")
                
                # V√©rifier si clarification critique requise
                if clarification_result.get("clarification_required_critical", False):
                    logger.info("üõë [Pipeline] Clarification critique requise - ARR√äT AVANT RAG")
                    processing_steps.append("critical_clarification_blocking")
                    
                    return await self._handle_critical_clarification_safe(
                        clarification_result, question_text, conversation_id, language, 
                        start_time, current_user, processing_steps, ai_enhancements_used
                    )
                    
            except Exception as e:
                logger.error(f"‚ùå [Pipeline] Erreur analyse clarification critique: {e}")
                processing_steps.append("critical_clarification_error_continue")
            
            # PIPELINE NORMAL SI PAS DE CLARIFICATION CRITIQUE
            logger.info("‚úÖ [Pipeline] Pas de clarification critique - continuation pipeline normal")
            
            return await self._process_normal_pipeline_safe(
                question_text, language, conversation_id, user_id, current_user,
                start_time, processing_steps, ai_enhancements_used, request, request_data
            )
            
        except Exception as e:
            logger.error(f"‚ùå [Pipeline Safe] Erreur critique: {e}")
            return await self._handle_pipeline_error_safe(
                e, question_text, conversation_id, language, start_time, 
                processing_steps, ai_enhancements_used
            )
    
    async def _analyze_clarification_safe(self, question_text: str, language: str) -> dict:
        """Analyse clarification de fa√ßon s√©curis√©e - CORRECTION 1: M√©thode async avec await"""
        try:
            if hasattr(self.integrations, '_clarification_functions') and \
               'analyze_question_for_clarification_enhanced' in self.integrations._clarification_functions:
                # CORRECTION 1: Ajouter await pour l'appel mock async
                return await self.integrations._clarification_functions['analyze_question_for_clarification_enhanced'](question_text, language)
            else:
                # CORRECTION 1: Ajouter await pour l'appel principal
                return await analyze_question_for_clarification_enhanced(question_text, language)
        except Exception as e:
            logger.error(f"‚ùå [Analyze Clarification Safe] Erreur: {e}")
            return {
                "clarification_required_critical": False,
                "clarification_required_optional": False,
                "missing_critical_entities": [],
                "missing_optional_entities": [],
                "confidence": 0.0,
                "reasoning": f"Erreur analyse: {str(e)}",
                "poultry_type": "unknown"
            }
    
    async def _handle_critical_clarification_safe(
        self, clarification_result, question_text, conversation_id, language, 
        start_time, current_user, processing_steps, ai_enhancements_used
    ):
        """Gestion s√©curis√©e de la clarification critique"""
        try:
            # Marquer dans la m√©moire de fa√ßon s√©curis√©e
            missing_critical_entities = clarification_result.get("missing_critical_entities", [])
            
            try:
                if self.conversation_memory:
                    self.conversation_memory.mark_pending_clarification(
                        conversation_id, question_text, missing_critical_entities
                    )
                    logger.info(f"üß† [Pipeline] Clarification critique marqu√©e en m√©moire: {missing_critical_entities}")
            except Exception as e:
                logger.error(f"‚ùå [Pipeline] Erreur marquage m√©moire: {e}")
            
            # G√©n√©rer message de clarification critique
            poultry_type = clarification_result.get("poultry_type", "unknown")
            critical_message = generate_critical_clarification_message_safe(
                missing_critical_entities, poultry_type, language
            )
            
            # Retourner la r√©ponse de clarification
            response_time_ms = int((time.time() - start_time) * 1000)
            
            return self._create_critical_clarification_response(
                question_text, critical_message, conversation_id, language, response_time_ms,
                current_user, processing_steps, ai_enhancements_used, clarification_result
            )
            
        except Exception as e:
            logger.error(f"‚ùå [Handle Critical Clarification] Erreur: {e}")
            return self._create_error_response(
                "Erreur lors de la clarification critique", question_text, 
                conversation_id, language, start_time
            )
    
    async def _process_normal_pipeline_safe(
        self, question_text, language, conversation_id, user_id, current_user,
        start_time, processing_steps, ai_enhancements_used, request, request_data
    ):
        """Pipeline normal avec gestion d'erreurs - VERSION CORRIG√âE + ACC√àS S√âCURIS√â WEIGHT"""
        try:
            # Variables par d√©faut
            question_for_rag = question_text
            final_answer = ""
            rag_score = None
            mode = "unknown"
            optional_clarifications = []
            
            # R√©cup√©ration contexte conversationnel s√©curis√©e avec ACC√àS S√âCURIS√â WEIGHT
            conversation_context = None
            entities = {}
            missing_entities = []
            formatted_context = ""
            
            if self.conversation_memory:
                try:
                    conversation_context = self.conversation_memory.get_conversation_context(conversation_id)
                    if conversation_context:
                        # CORRECTION 5: ACC√àS S√âCURIS√â aux entit√©s avec weight
                        entities_raw = getattr(conversation_context, 'consolidated_entities', {})
                        if hasattr(entities_raw, 'to_dict'):
                            entities = entities_raw.to_dict()
                        elif not isinstance(entities_raw, dict):
                            entities = {}
                        
                        # NOUVEAU: Acc√®s s√©curis√© √† weight dans les entit√©s
                        if self.config["safe_weight_access"]:
                            # R√©cup√©rer weight de fa√ßon s√©curis√©e
                            weight_value = safe_get_weight(entities)
                            weight_unit = safe_get_weight_unit(entities)
                            
                            if weight_value is not None:
                                logger.info(f"‚öñÔ∏è [Pipeline] Weight r√©cup√©r√© de fa√ßon s√©curis√©e: {weight_value} {weight_unit}")
                                # Valider et normaliser
                                weight_result = validate_and_normalize_weight(weight_value, weight_unit)
                                if weight_result["is_valid"]:
                                    # Mettre √† jour les entit√©s avec weight valid√©
                                    entities["weight"] = weight_result["value"]
                                    entities["weight_unit"] = weight_result["unit"]
                                else:
                                    logger.warning(f"‚ö†Ô∏è [Pipeline] Weight invalide ignor√©: {weight_result['error']}")
                        
                        if hasattr(conversation_context, 'get_missing_entities'):
                            missing_entities = conversation_context.get_missing_entities()
                        if hasattr(conversation_context, 'get_formatted_context'):
                            formatted_context = conversation_context.get_formatted_context()
                        
                        logger.info(f"üß† [Pipeline] Contexte r√©cup√©r√©: {len(entities)} entit√©s")
                    else:
                        logger.info("üÜï [Pipeline] Nouvelle conversation")
                except Exception as e:
                    logger.error(f"‚ùå [Pipeline] Erreur r√©cup√©ration contexte: {e}")
            
            # Agent Contextualizer s√©curis√©
            contextualization_info = {}
            
            if self.config["agents_enabled"]:
                try:
                    logger.info("ü§ñ [Pipeline] Agent Contextualizer - TOUJOURS ACTIF")
                    
                    contextualization_result = await agent_contextualizer.enrich_question(
                        question=question_text,
                        entities=entities,
                        missing_entities=missing_entities,
                        conversation_context=formatted_context,
                        language=language
                    )
                    
                    if isinstance(contextualization_result, dict):
                        question_for_rag = contextualization_result.get("enriched_question", question_text)
                        contextualization_info = contextualization_result
                        ai_enhancements_used.append(f"contextualizer_{contextualization_result.get('method_used', 'unknown')}")
                    
                    if question_for_rag != question_text:
                        logger.info("‚ú® [Pipeline] Question enrichie par agent")
                    
                except Exception as e:
                    logger.error(f"‚ùå [Pipeline] Erreur Agent Contextualizer: {e}")
                    question_for_rag = question_text
            
            # Traitement RAG s√©curis√©
            try:
                app = request.app if request else None
                process_rag = getattr(app.state, 'process_question_with_rag', None) if app else None
                
                if process_rag:
                    logger.info("üîç [Pipeline] Syst√®me RAG disponible")
                    processing_steps.append("rag_processing_with_enriched_question")
                    ai_enhancements_used.append("rag_system_enriched")
                    
                    result = await process_rag(
                        question=question_for_rag,
                        user=current_user,
                        language=language,
                        speed_mode=getattr(request_data, 'speed_mode', 'balanced')
                    )
                    
                    if isinstance(result, dict):
                        final_answer = str(result.get("response", ""))
                        rag_score = result.get("score", 0.0)
                        mode = "rag_processing_with_enriched_question"
                else:
                    logger.info("üîÑ [Pipeline] RAG non disponible - Fallback")
                    processing_steps.append("no_rag_fallback_enriched")
                    
                    fallback_data = self._generate_fallback_responses_safe(question_for_rag, language)
                    final_answer = fallback_data["response"]
                    rag_score = None
                    mode = "no_rag_fallback_enriched"
                    
            except Exception as e:
                logger.error(f"‚ùå [Pipeline] Erreur traitement RAG: {e}")
                fallback_data = self._generate_fallback_responses_safe(question_for_rag, language)
                final_answer = fallback_data["response"]
                rag_score = None
                mode = "rag_error_fallback"
            
            # Agent RAG Enhancer s√©curis√©
            enhancement_info = {}
            
            if self.config["agents_enabled"]:
                try:
                    logger.info("üîß [Pipeline] Agent RAG Enhancer")
                    
                    enhancement_result = await agent_rag_enhancer.enhance_rag_answer(
                        rag_answer=final_answer,
                        entities=entities,
                        missing_entities=missing_entities,
                        conversation_context=formatted_context,
                        original_question=question_text,
                        enriched_question=question_for_rag,
                        language=language
                    )
                    
                    if isinstance(enhancement_result, dict):
                        final_answer = enhancement_result.get("enhanced_answer", final_answer)
                        optional_clarifications.extend(enhancement_result.get("optional_clarifications", []))
                        enhancement_info = enhancement_result
                        ai_enhancements_used.append(f"rag_enhancer_{enhancement_result.get('method_used', 'unknown')}")
                    
                except Exception as e:
                    logger.error(f"‚ùå [Pipeline] Erreur Agent RAG Enhancer: {e}")
            
            # CORRECTION 4: G√©n√©ration des versions de r√©ponse GARANTIE
            response_versions = None
            try:
                if self.config["concision_service_enabled"] and final_answer:
                    logger.info("üìè [Pipeline] G√©n√©ration versions de r√©ponse")
                    response_versions = self.concision_service.generate_all_versions(final_answer, language)
                    processing_steps.append("response_versions_generated")
                    ai_enhancements_used.append("concision_service")
                    logger.info(f"‚úÖ [Pipeline] Versions g√©n√©r√©es: {list(response_versions.keys()) if response_versions else 'None'}")
            except Exception as e:
                logger.error(f"‚ùå [Pipeline] Erreur g√©n√©ration versions: {e}")
                # Fallback versions simple
                try:
                    response_versions = self.concision_service.generate_all_versions(final_answer, language)
                except Exception as e2:
                    logger.error(f"‚ùå [Pipeline] Erreur fallback versions: {e2}")
                    response_versions = None
            
            # Mise √† jour m√©moire s√©curis√©e - CORRECTION 2: Suppression asyncio.run()
            if self.conversation_memory:
                try:
                    # CORRECTION 2: Appel direct await au lieu de asyncio.run()
                    await self.conversation_memory.add_message_to_conversation(
                        conversation_id=conversation_id,
                        user_id=user_id,
                        message=question_for_rag,
                        role="user",
                        language=language
                    )
                    
                    await self.conversation_memory.add_message_to_conversation(
                        conversation_id=conversation_id,
                        user_id=user_id,
                        message=final_answer,
                        role="assistant",
                        language=language
                    )
                    
                    processing_steps.append("conversation_memory_updated")
                    
                except Exception as e:
                    logger.error(f"‚ùå [Pipeline] Erreur mise √† jour m√©moire: {e}")
                    
            # Construction r√©ponse finale s√©curis√©e
            response_time_ms = int((time.time() - start_time) * 1000)
            user_email = current_user.get("email") if current_user and isinstance(current_user, dict) else None
            
            return self._create_enhanced_response_safe(
                question_text, final_answer, conversation_id, language, response_time_ms,
                user_email, processing_steps, ai_enhancements_used, rag_score, mode,
                contextualization_info, enhancement_info, optional_clarifications,
                conversation_context, entities, missing_entities, question_for_rag, response_versions
            )

        except Exception as e:
            logger.error(f"‚ùå [Normal Pipeline] Erreur: {e}")
            return await self._handle_pipeline_error_safe(
                e, question_text, conversation_id, language, start_time, 
                processing_steps, ai_enhancements_used
            )

    # === M√âTHODES DE CR√âATION DE R√âPONSES S√âCURIS√âES ===
    
    def _create_enhanced_response_safe(
        self, question_text, final_answer, conversation_id, language, response_time_ms,
        user_email, processing_steps, ai_enhancements_used, rag_score, mode,
        contextualization_info, enhancement_info, optional_clarifications,
        conversation_context, entities, missing_entities, question_for_rag, response_versions
    ):
        """Cr√©ation s√©curis√©e de la r√©ponse enrichie - CORRECTION 3 et 4: Champs ajout√©s + weight s√©curis√©"""
        try:
            if MODELS_AVAILABLE:
                response = EnhancedExpertResponse(
                    question=str(question_text),
                    response=str(final_answer),
                    conversation_id=str(conversation_id),
                    rag_used=bool(rag_score),
                    rag_score=rag_score,
                    timestamp=datetime.now().isoformat(),
                    language=str(language),
                    response_time_ms=int(response_time_ms),
                    mode=str(mode),
                    user=str(user_email) if user_email else None,
                    logged=True,
                    validation_passed=True,
                    processing_steps=list(processing_steps) if isinstance(processing_steps, list) else [],
                    ai_enhancements_used=list(ai_enhancements_used) if isinstance(ai_enhancements_used, list) else []
                )
                
                # CORRECTION 4: Ajouter response_versions de fa√ßon garantie
                try:
                    if response_versions and isinstance(response_versions, dict):
                        response.response_versions = response_versions
                        logger.info("‚úÖ [Enhanced Response] response_versions ajout√©es")
                    else:
                        # Fallback si versions non g√©n√©r√©es
                        logger.warning("‚ö†Ô∏è [Enhanced Response] G√©n√©ration fallback response_versions")
                        response.response_versions = self.concision_service.generate_all_versions(final_answer, language)
                except Exception as e:
                    logger.error(f"‚ùå [Enhanced Response] Erreur response_versions: {e}")
                    # Fallback minimal
                    response.response_versions = {
                        "ultra_concise": final_answer[:50] + "..." if len(final_answer) > 50 else final_answer,
                        "concise": final_answer[:150] + "..." if len(final_answer) > 150 else final_answer,
                        "standard": final_answer[:300] + "..." if len(final_answer) > 300 else final_answer,
                        "detailed": final_answer
                    }
                
                # CORRECTION 3: Ajouter contextualization_info et enhancement_info de fa√ßon s√©curis√©e
                try:
                    if self.config["agents_enabled"]:
                        if isinstance(contextualization_info, dict) and contextualization_info:
                            response.contextualization_info = contextualization_info
                            if question_for_rag != question_text:
                                response.enriched_question = str(question_for_rag)
                        
                        if isinstance(enhancement_info, dict) and enhancement_info:
                            response.enhancement_info = enhancement_info
                    
                    if isinstance(optional_clarifications, list) and optional_clarifications:
                        response.optional_clarifications = optional_clarifications
                        response.clarification_mode = "optional_non_blocking"
                    
                    if conversation_context:
                        try:
                            # NOUVEAU: Acc√®s s√©curis√© aux entit√©s dans conversation_context
                            entities_count = 0
                            if isinstance(entities, dict):
                                entities_count = len([k for k, v in entities.items() if v is not None])
                                
                                # NOUVEAU: Information weight dans contexte si disponible
                                weight_info = {}
                                if self.config["safe_weight_access"]:
                                    weight_value = safe_get_weight(entities)
                                    weight_unit = safe_get_weight_unit(entities)
                                    if weight_value is not None:
                                        weight_result = validate_and_normalize_weight(weight_value, weight_unit)
                                        if weight_result["is_valid"]:
                                            weight_info = {
                                                "value": weight_result["value"],
                                                "unit": weight_result["unit"],
                                                "validated": True
                                            }
                            
                            conversation_context_info = {
                                "total_exchanges": getattr(conversation_context, 'total_exchanges', 0),
                                "conversation_urgency": getattr(conversation_context, 'conversation_urgency', 'normal'),
                                "entities_count": entities_count,
                                "missing_entities": missing_entities if isinstance(missing_entities, list) else [],
                                "overall_confidence": getattr(getattr(conversation_context, 'consolidated_entities', None), 'confidence_overall', 0.5)
                            }
                            
                            # NOUVEAU: Ajouter weight_info si disponible
                            if weight_info:
                                conversation_context_info["weight_info"] = weight_info
                            
                            response.conversation_context = conversation_context_info
                            
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è [Enhanced Response] Erreur conversation_context: {e}")
                    
                    response.pipeline_version = "critical_clarification_safe_weight_secure"
                    response.pipeline_improvements = [
                        "agents_always_active",
                        "critical_clarification_blocking",
                        "optional_clarification_non_blocking", 
                        "enriched_question_to_rag",
                        "intelligent_fallback",
                        "robust_error_handling",
                        "response_versions_guaranteed",  # CORRECTION 4
                        "safe_weight_access"  # NOUVEAU
                    ]
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [Enhanced Response] Erreur ajout m√©tadonn√©es: {e}")
                
                return response
                
            else:
                # Fallback avec response_versions guaranties
                basic_response = self._create_basic_response_safe(
                    question_text, final_answer, conversation_id, 
                    language, response_time_ms, processing_steps
                )
                # CORRECTION 4: Ajouter response_versions m√™me en fallback
                try:
                    basic_response["response_versions"] = self.concision_service.generate_all_versions(final_answer, language)
                except Exception as e:
                    logger.error(f"‚ùå [Basic Response] Erreur response_versions: {e}")
                    basic_response["response_versions"] = {
                        "ultra_concise": final_answer[:50],
                        "concise": final_answer[:150],
                        "standard": final_answer[:300],
                        "detailed": final_answer
                    }
                # NOUVEAU: Ajouter flag weight s√©curis√©
                basic_response["safe_weight_access"] = self.config["safe_weight_access"]
                return basic_response
                
        except Exception as e:
            logger.error(f"‚ùå [Create Enhanced Response] Erreur: {e}")
            fallback = self._create_basic_response_safe(
                question_text, final_answer, conversation_id, 
                language, response_time_ms, processing_steps
            )
            # CORRECTION 4: Garantir response_versions m√™me en cas d'erreur
            try:
                fallback["response_versions"] = self.concision_service.generate_all_versions(final_answer, language)
            except Exception:
                fallback["response_versions"] = {"detailed": final_answer}
            # NOUVEAU: Flag weight s√©curis√© m√™me en erreur
            fallback["safe_weight_access"] = True
            return fallback