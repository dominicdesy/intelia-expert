# app/api/v1/agent_rag_enhancer.py
"""
Agent RAG Enhancer - AmÃ©lioration des rÃ©ponses aprÃ¨s RAG

ðŸŽ¯ FONCTIONNALITÃ‰S:
- Adapte les rÃ©ponses RAG selon le contexte utilisateur
- VÃ©rifie la cohÃ©rence entre question enrichie et rÃ©ponse RAG
- Ajoute des avertissements si informations manquantes
- Propose des clarifications optionnelles
- AmÃ©liore la lisibilitÃ© et la pertinence
- âœ… CORRECTION: Propagation systÃ©matique de tous les champs
- âœ… CORRECTION: Gestion des champs absents avec valeurs par dÃ©faut
- âœ… FIX: Validation dÃ©fensive et standardisation nomenclature
"""

import os
import logging
import json
import re
from typing import Dict, List, Any, Optional
from datetime import datetime

# Import OpenAI sÃ©curisÃ©
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

logger = logging.getLogger(__name__)

class AgentRAGEnhancer:
    """Agent intelligent pour amÃ©liorer les rÃ©ponses RAG"""
    
    def __init__(self):
        self.openai_available = OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY')
        self.model = os.getenv('RAG_ENHANCER_MODEL', 'gpt-4o-mini')
        self.timeout = int(os.getenv('RAG_ENHANCER_TIMEOUT', '15'))
        self.max_retries = int(os.getenv('RAG_ENHANCER_RETRIES', '2'))
        
        # Statistiques
        self.stats = {
            "total_requests": 0,
            "openai_success": 0,
            "openai_failures": 0,
            "fallback_used": 0,
            "answers_enhanced": 0,
            "clarifications_generated": 0,
            "coherence_checks": 0,
            "coherence_issues_detected": 0,
            "field_propagation_success": 0,
            "field_propagation_fallback": 0,
            "input_validation_fixes": 0  # âœ… NOUVEAU: Tracking des corrections d'input
        }
        
        logger.info(f"ðŸ”§ [AgentRAGEnhancer] InitialisÃ©")
        logger.info(f"   OpenAI disponible: {'âœ…' if self.openai_available else 'âŒ'}")
        logger.info(f"   ModÃ¨le: {self.model}")
    
    def _validate_and_sanitize_inputs(
        self,
        entities: Dict[str, Any],
        missing_entities: List[str],
        original_question: str,
        enriched_question: str,
        language: str
    ) -> tuple:
        """
        âœ… FIX: Validation dÃ©fensive des inputs pour Ã©viter les erreurs
        """
        
        validation_fixes = 0
        
        # Validation entities
        if entities is None:
            entities = {}
            validation_fixes += 1
            logger.debug("ðŸ”§ [AgentRAGEnhancer] entities Ã©tait None, initialisÃ© Ã  {}")
        elif not isinstance(entities, dict):
            entities = {}
            validation_fixes += 1
            logger.warning(f"âš ï¸ [AgentRAGEnhancer] entities n'Ã©tait pas un dict: {type(entities)}")
        
        # Validation missing_entities
        if missing_entities is None:
            missing_entities = []
            validation_fixes += 1
            logger.debug("ðŸ”§ [AgentRAGEnhancer] missing_entities Ã©tait None, initialisÃ© Ã  []")
        elif not isinstance(missing_entities, list):
            missing_entities = []
            validation_fixes += 1
            logger.warning(f"âš ï¸ [AgentRAGEnhancer] missing_entities n'Ã©tait pas une liste: {type(missing_entities)}")
        
        # Validation strings
        if not isinstance(original_question, str):
            original_question = str(original_question) if original_question is not None else ""
            validation_fixes += 1
        
        if not isinstance(enriched_question, str):
            enriched_question = str(enriched_question) if enriched_question is not None else ""
            validation_fixes += 1
        
        if not isinstance(language, str) or language not in ["fr", "en", "es"]:
            language = "fr"
            validation_fixes += 1
        
        if validation_fixes > 0:
            self.stats["input_validation_fixes"] += validation_fixes
            logger.debug(f"ðŸ”§ [AgentRAGEnhancer] {validation_fixes} corrections d'input appliquÃ©es")
        
        return entities, missing_entities, original_question, enriched_question, language
    
    async def enhance_rag_answer(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        original_question: str = "",
        enriched_question: str = "",
        language: str = "fr",
        **additional_fields  # âœ… Capture tous les champs supplÃ©mentaires
    ) -> Dict[str, Any]:
        """
        AmÃ©liore une rÃ©ponse RAG avec le contexte utilisateur et vÃ©rifie la cohÃ©rence
        
        Args:
            rag_answer: RÃ©ponse brute du systÃ¨me RAG
            entities: EntitÃ©s extraites du contexte
            missing_entities: EntitÃ©s manquantes critiques
            conversation_context: Contexte conversationnel
            original_question: Question originale posÃ©e
            enriched_question: Question enrichie par le prÃ©-RAG
            language: Langue de la conversation
            **additional_fields: Tous les champs supplÃ©mentaires Ã  propager
            
        Returns:
            Dict avec tous les champs requis garantis, mÃªme si None
        """
        
        self.stats["total_requests"] += 1
        self.stats["coherence_checks"] += 1
        
        # âœ… FIX: Validation dÃ©fensive des inputs dÃ¨s le dÃ©but
        entities, missing_entities, original_question, enriched_question, language = (
            self._validate_and_sanitize_inputs(
                entities, missing_entities, original_question, enriched_question, language
            )
        )
        
        # âœ… FIX: Validation rag_answer
        if not isinstance(rag_answer, str):
            rag_answer = str(rag_answer) if rag_answer is not None else ""
        
        if not isinstance(conversation_context, str):
            conversation_context = str(conversation_context) if conversation_context is not None else ""
        
        try:
            # âœ… CORRECTION: Initialiser le rÃ©sultat avec TOUS les champs requis
            base_result = self._initialize_complete_result(
                rag_answer, entities, missing_entities, original_question, 
                enriched_question, language, additional_fields
            )
            
            # Tentative OpenAI si disponible
            if self.openai_available:
                enhancement_result = await self._enhance_with_openai(
                    rag_answer, entities, missing_entities, conversation_context, 
                    original_question, enriched_question, language
                )
                
                if enhancement_result.get("success"):
                    # âœ… CORRECTION: Fusionner avec le rÃ©sultat de base pour garantir tous les champs
                    final_result = self._merge_results(base_result, enhancement_result)
                    self.stats["openai_success"] += 1
                    self.stats["field_propagation_success"] += 1
                    
                    # Mise Ã  jour des statistiques
                    if final_result["enhanced_answer"] != rag_answer:
                        self.stats["answers_enhanced"] += 1
                    if final_result.get("optional_clarifications"):
                        self.stats["clarifications_generated"] += 1
                    if final_result.get("coherence_check") in ["partial", "poor"]:
                        self.stats["coherence_issues_detected"] += 1
                    
                    return final_result
                else:
                    self.stats["openai_failures"] += 1
            
            # Fallback: AmÃ©lioration basique avec tous les champs
            logger.info("ðŸ”„ [AgentRAGEnhancer] Utilisation fallback basique")
            fallback_result = self._enhance_fallback(
                rag_answer, entities, missing_entities, 
                original_question, enriched_question, language
            )
            
            # âœ… CORRECTION: Fusionner avec le rÃ©sultat de base
            final_result = self._merge_results(base_result, fallback_result)
            self.stats["fallback_used"] += 1
            self.stats["field_propagation_fallback"] += 1
            
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ [AgentRAGEnhancer] Erreur critique inattendue: {e}")
            
            # âœ… CORRECTION: MÃªme en cas d'erreur, retourner un rÃ©sultat complet
            error_result = self._initialize_complete_result(
                rag_answer, entities, missing_entities, original_question, 
                enriched_question, language, additional_fields
            )
            
            error_result.update({
                "enhanced_answer": rag_answer,
                "warnings": [f"Erreur amÃ©lioration: {str(e)}"],
                "confidence_impact": "unknown",
                "coherence_check": "unknown",
                "coherence_notes": "Impossible de vÃ©rifier la cohÃ©rence en raison d'une erreur",
                "method_used": "error_fallback",
                "success": False
            })
            
            return error_result
    
    def _initialize_complete_result(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        original_question: str,
        enriched_question: str,
        language: str,
        additional_fields: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        âœ… FIX: Initialise un rÃ©sultat complet avec TOUS les champs requis
        Nomenclature standardisÃ©e sur weight_grams
        """
        
        # Champs de base toujours prÃ©sents
        base_result = {
            # Champs de rÃ©ponse principaux
            "enhanced_answer": rag_answer,
            "optional_clarifications": [],
            "warnings": [],
            "confidence_impact": "medium",
            "coherence_check": "unknown",
            "coherence_notes": "En cours d'Ã©valuation",
            "improvement_notes": "Traitement en cours",
            "method_used": "initializing",
            "success": True,
            
            # Champs d'entrÃ©e propagÃ©s
            "original_question": original_question,
            "enriched_question": enriched_question,
            "language": language,
            
            # Champs contextuels
            "entities": entities,
            "missing_entities": missing_entities,
            
            # Champs techniques
            "processing_time": datetime.now().isoformat(),
            "entities_considered": len([k for k, v in entities.items() if v is not None]),
            "missing_entities_count": len(missing_entities),
            
            # âœ… FIX: Standardisation nomenclature weight_grams
            "weight_grams": None,  # âœ… CHANGÃ‰: weight -> weight_grams
            "weight_confidence": None,
            "age_days": None,
            "age_weeks": None,
            "age_confidence": None,
            "breed": None,
            "breed_confidence": None,
            "sex": None,
            "sex_confidence": None,
            "symptoms": None,
            "mortality_rate": None,
            "temperature": None,
            "housing_type": None,
            "flock_size": None,
            
            # Champs d'Ã©valuation technique
            "context_relevance": "unknown",
            "technical_accuracy": "unknown",
            "practical_applicability": "unknown",
            
            # âœ… NOUVEAU: Champs d'extraction automatique
            "detected_weight_grams": None,  # âœ… Poids dÃ©tectÃ© dans la rÃ©ponse
            "detected_age_days": None,      # âœ… Ã‚ge dÃ©tectÃ© dans la rÃ©ponse
            "detected_breed": None,         # âœ… Race dÃ©tectÃ©e dans la rÃ©ponse
            "extraction_confidence": 0.0    # âœ… Confiance dans l'extraction
        }
        
        # âœ… CORRECTION: Propager les valeurs des entitÃ©s si disponibles
        if entities:
            # âœ… FIX: Mapping standardisÃ© weight_grams
            entity_mapping = {
                "weight_grams": "weight_grams",  # âœ… StandardisÃ©
                "weight": "weight_grams",        # âœ… CompatibilitÃ© ancienne nomenclature
                "age_days": "age_days",
                "age_weeks": "age_weeks", 
                "breed": "breed",
                "sex": "sex",
                "symptoms": "symptoms",
                "mortality_rate": "mortality_rate",
                "temperature": "temperature",
                "housing_type": "housing_type",
                "flock_size": "flock_size"
            }
            
            for entity_key, result_key in entity_mapping.items():
                if entity_key in entities and entities[entity_key] is not None:
                    base_result[result_key] = entities[entity_key]
            
            # Propager les champs de confiance
            confidence_fields = ["weight_confidence", "age_confidence", "breed_confidence", "sex_confidence"]
            for field in confidence_fields:
                if field in entities and entities[field] is not None:
                    base_result[field] = entities[field]
        
        # âœ… CORRECTION: Propager tous les champs supplÃ©mentaires fournis
        if additional_fields:
            for key, value in additional_fields.items():
                if key not in base_result:  # Ã‰viter d'Ã©craser les champs de base
                    base_result[key] = value
                elif value is not None:  # Remplacer les None par des valeurs rÃ©elles
                    base_result[key] = value
        
        # âœ… NOUVEAU: Extraction automatique de donnÃ©es implicites
        base_result.update(self._extract_implicit_data(rag_answer, entities))
        
        logger.debug(f"ðŸ”§ [AgentRAGEnhancer] RÃ©sultat initialisÃ© avec {len(base_result)} champs")
        
        return base_result
    
    def _extract_implicit_data(self, text: str, entities: Dict[str, Any]) -> Dict[str, Any]:
        """
        âœ… NOUVEAU: Extrait des donnÃ©es implicites du texte (poids, Ã¢ge, race)
        """
        
        implicit_data = {
            "detected_weight_grams": None,
            "detected_age_days": None,
            "detected_breed": None,
            "extraction_confidence": 0.0
        }
        
        extractions_count = 0
        
        try:
            # Extraction poids (grammes/kg)
            weight_patterns = [
                r'(\d+(?:\.\d+)?)\s*(?:g|gr|grammes?|grams?)\b',
                r'(\d+(?:\.\d+)?)\s*(?:kg|kilogrammes?|kilograms?)\b',
                r'poids(?:.*?)(\d+(?:\.\d+)?)\s*(?:g|kg)',
                r'weight(?:.*?)(\d+(?:\.\d+)?)\s*(?:g|kg)'
            ]
            
            for pattern in weight_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    weight = float(match.group(1))
                    # Convertir kg en grammes
                    if 'kg' in pattern.lower() or weight < 10:
                        weight *= 1000
                    implicit_data["detected_weight_grams"] = int(weight)
                    extractions_count += 1
                    break
            
            # Extraction Ã¢ge (jours/semaines)
            age_patterns = [
                r'(\d+)\s*(?:jours?|days?)\b',
                r'(\d+)\s*(?:semaines?|weeks?)\b',
                r'Ã¢ge(?:.*?)(\d+)',
                r'age(?:.*?)(\d+)'
            ]
            
            for pattern in age_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    age = int(match.group(1))
                    # Convertir semaines en jours
                    if 'semaine' in pattern.lower() or 'week' in pattern.lower():
                        age *= 7
                    implicit_data["detected_age_days"] = age
                    extractions_count += 1
                    break
            
            # Extraction race
            breed_patterns = [
                r'\b(Ross\s*\d+)\b',
                r'\b(Cobb\s*\d+)\b',
                r'\b(Hubbard)\b',
                r'\b(Arbor\s*Acres?)\b'
            ]
            
            for pattern in breed_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    implicit_data["detected_breed"] = match.group(1).strip()
                    extractions_count += 1
                    break
            
            # Calculer confiance d'extraction
            if extractions_count > 0:
                implicit_data["extraction_confidence"] = min(extractions_count / 3.0, 1.0)
                logger.debug(f"ðŸ” [AgentRAGEnhancer] {extractions_count} donnÃ©es extraites automatiquement")
        
        except Exception as e:
            logger.error(f"âŒ [AgentRAGEnhancer] Erreur extraction implicite: {e}")
        
        return implicit_data
    
    def _merge_results(self, base_result: Dict[str, Any], enhancement_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        âœ… Fusionne les rÃ©sultats en prÃ©servant tous les champs
        """
        
        # Commencer avec le rÃ©sultat de base complet
        merged = base_result.copy()
        
        # Mettre Ã  jour avec les amÃ©liorations, en prÃ©servant les valeurs non-None existantes
        for key, value in enhancement_result.items():
            if value is not None:  # Seulement Ã©craser si la nouvelle valeur n'est pas None
                merged[key] = value
            elif key not in merged:  # Ajouter les nouveaux champs mÃªme s'ils sont None
                merged[key] = value
        
        # S'assurer que certains champs critiques sont prÃ©sents
        required_fields = [
            "enhanced_answer", "optional_clarifications", "warnings", 
            "confidence_impact", "coherence_check", "coherence_notes", 
            "method_used", "success"
        ]
        
        for field in required_fields:
            if field not in merged:
                merged[field] = None
        
        return merged
    
    async def _enhance_with_openai(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        original_question: str,
        enriched_question: str,
        language: str
    ) -> Dict[str, Any]:
        """AmÃ©lioration avec OpenAI GPT"""
        
        try:
            # PrÃ©parer le contexte pour GPT
            entities_summary = self._format_entities_for_gpt(entities)
            missing_summary = ", ".join(missing_entities) if missing_entities else "Aucune"
            
            # Prompt spÃ©cialisÃ© selon la langue
            system_prompt = self._get_system_prompt(language)
            user_prompt = self._build_enhancement_prompt(
                rag_answer, entities_summary, missing_summary, conversation_context,
                original_question, enriched_question, language
            )
            
            # Appel OpenAI
            client = openai.AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            
            response = await client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1000,
                timeout=self.timeout
            )
            
            answer = response.choices[0].message.content.strip()
            
            # Parser la rÃ©ponse JSON
            result = self._parse_gpt_response(answer, rag_answer, entities, missing_entities)
            result["success"] = True
            result["method_used"] = "openai"
            
            logger.info(f"âœ… [AgentRAGEnhancer] AmÃ©lioration OpenAI rÃ©ussie")
            logger.debug(f"   Clarifications gÃ©nÃ©rÃ©es: {len(result.get('optional_clarifications', []))}")
            logger.debug(f"   CohÃ©rence: {result.get('coherence_check', 'unknown')}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ [AgentRAGEnhancer] Erreur OpenAI: {e}")
            return {"success": False, "error": str(e)}
    
    def _get_system_prompt(self, language: str) -> str:
        """Retourne le prompt systÃ¨me selon la langue"""
        
        system_prompts = {
            "fr": """Tu es un expert vÃ©tÃ©rinaire en aviculture spÃ©cialisÃ© dans l'adaptation de rÃ©ponses techniques.

Ta mission:
1. VÃ©rifier la cohÃ©rence entre la question enrichie et la rÃ©ponse RAG
2. Adapter la rÃ©ponse RAG pour qu'elle soit pertinente malgrÃ© les informations manquantes
3. Ajouter des avertissements si l'absence de donnÃ©es affecte la prÃ©cision
4. Proposer 1-3 questions de clarification pour amÃ©liorer le conseil
5. Garder un ton professionnel mais accessible
6. Prioriser la sÃ©curitÃ© des animaux

VÃ‰RIFICATION DE COHÃ‰RENCE:
- "good": La rÃ©ponse RAG correspond parfaitement Ã  la question enrichie
- "partial": La rÃ©ponse RAG est pertinente mais incomplÃ¨te ou tangentielle
- "poor": La rÃ©ponse RAG ne correspond pas bien Ã  la question enrichie

IMPORTANT: 
- Si des informations critiques manquent, le mentionner clairement
- Si la rÃ©ponse RAG semble hors-sujet, l'adapter ou le signaler
- Proposer des questions de clarification utiles, pas Ã©videntes
- Ã‰viter les conseils dangereux sans contexte complet
- RÃ©pondre UNIQUEMENT en JSON avec la structure exacte demandÃ©e""",
            
            "en": """You are a poultry veterinary expert specialized in adapting technical responses.

Your mission:
1. Verify coherence between enriched question and RAG response
2. Adapt the RAG response to be relevant despite missing information
3. Add warnings if missing data affects accuracy
4. Propose 1-3 clarification questions to improve advice
5. Keep professional but accessible tone
6. Prioritize animal safety

COHERENCE CHECK:
- "good": RAG response perfectly matches the enriched question
- "partial": RAG response is relevant but incomplete or tangential
- "poor": RAG response doesn't match well with the enriched question

IMPORTANT:
- If critical information is missing, mention it clearly
- If RAG response seems off-topic, adapt it or flag it
- Propose useful clarification questions, not obvious ones
- Avoid dangerous advice without complete context
- Respond ONLY in JSON with the exact requested structure""",
            
            "es": """Eres un experto veterinario en avicultura especializado en adaptar respuestas tÃ©cnicas.

Tu misiÃ³n:
1. Verificar la coherencia entre la pregunta enriquecida y la respuesta RAG
2. Adaptar la respuesta RAG para que sea relevante a pesar de la informaciÃ³n faltante
3. Agregar advertencias si los datos faltantes afectan la precisiÃ³n
4. Proponer 1-3 preguntas de aclaraciÃ³n para mejorar el consejo
5. Mantener tono profesional pero accesible
6. Priorizar la seguridad de los animales

VERIFICACIÃ“N DE COHERENCIA:
- "good": La respuesta RAG coincide perfectamente con la pregunta enriquecida
- "partial": La respuesta RAG es relevante pero incompleta o tangencial
- "poor": La respuesta RAG no coincide bien con la pregunta enriquecida

IMPORTANTE:
- Si falta informaciÃ³n crÃ­tica, mencionarlo claramente
- Si la respuesta RAG parece fuera de tema, adaptarla o seÃ±alarlo
- Proponer preguntas de aclaraciÃ³n Ãºtiles, no obvias
- Evitar consejos peligrosos sin contexto completo
- Responder SOLO en JSON con la estructura exacta solicitada"""
        }
        
        return system_prompts.get(language, system_prompts["fr"])
    
    def _build_enhancement_prompt(
        self,
        rag_answer: str,
        entities_summary: str,
        missing_summary: str,
        conversation_context: str,
        original_question: str,
        enriched_question: str,
        language: str
    ) -> str:
        """Construit le prompt d'amÃ©lioration avec vÃ©rification de cohÃ©rence"""
        
        if language == "fr":
            return f"""QUESTION ORIGINALE: "{original_question}"

QUESTION ENRICHIE (gÃ©nÃ©rÃ©e par le prÃ©-RAG): "{enriched_question}"

RÃ‰PONSE RAG BRUTE:
"{rag_answer}"

ENTITÃ‰S CONNUES:
{entities_summary}

ENTITÃ‰S MANQUANTES CRITIQUES: {missing_summary}

CONTEXTE CONVERSATIONNEL:
{conversation_context}

INSTRUCTIONS:
1. COHÃ‰RENCE: Compare la question enrichie avec la rÃ©ponse RAG. La rÃ©ponse traite-t-elle bien le sujet de la question enrichie ?
2. Adapte la rÃ©ponse pour le contexte spÃ©cifique de l'utilisateur
3. Si des informations critiques manquent, ajoute un avertissement et explique l'impact
4. Si la rÃ©ponse RAG ne correspond pas bien Ã  la question enrichie, corrige ou signale le problÃ¨me
5. AmÃ©liore la lisibilitÃ© et la structure de la rÃ©ponse
6. Propose 1-3 questions de clarification pertinentes (pas Ã©videntes)
7. Garde la prÃ©cision technique mais rends accessible

EXEMPLE VÃ‰RIFICATION COHÃ‰RENCE:
Question enrichie: "Ã‰valuation poids poulet Ross 308, 21 jours, croissance normale ?"
RÃ©ponse RAG: "Les poulets doivent peser 800g Ã  3 semaines"
CohÃ©rence: "partial" - rÃ©pond au poids mais ignore la race spÃ©cifique et l'Ã©valuation de normalitÃ©

RÃ©ponds en JSON:
{{
  "enhanced_answer": "rÃ©ponse adaptÃ©e et amÃ©liorÃ©e",
  "optional_clarifications": ["Question prÃ©cise 1?", "Question prÃ©cise 2?"],
  "warnings": ["Avertissement si info manquante impacte conseil"],
  "confidence_impact": "low/medium/high selon impact infos manquantes",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "explication dÃ©taillÃ©e de la cohÃ©rence entre question enrichie et rÃ©ponse RAG",
  "improvement_notes": "explications des amÃ©liorations apportÃ©es"
}}"""
        
        elif language == "en":
            return f"""ORIGINAL QUESTION: "{original_question}"

ENRICHED QUESTION (generated by pre-RAG): "{enriched_question}"

RAW RAG RESPONSE:
"{rag_answer}"

KNOWN ENTITIES:
{entities_summary}

MISSING CRITICAL ENTITIES: {missing_summary}

CONVERSATIONAL CONTEXT:
{conversation_context}

INSTRUCTIONS:
1. COHERENCE: Compare enriched question with RAG response. Does the response properly address the enriched question's topic?
2. Adapt response for user's specific context
3. If critical information missing, add warning and explain impact
4. If RAG response doesn't match well with enriched question, correct or flag the issue
5. Improve readability and structure of response
6. Propose 1-3 relevant clarification questions (not obvious ones)
7. Keep technical accuracy but make accessible

EXAMPLE COHERENCE CHECK:
Enriched question: "Ross 308 chicken weight evaluation, 21 days, normal growth?"
RAG response: "Chickens should weigh 800g at 3 weeks"
Coherence: "partial" - addresses weight but ignores specific breed and normality evaluation

Respond in JSON:
{{
  "enhanced_answer": "adapted and improved response",
  "optional_clarifications": ["Specific question 1?", "Specific question 2?"],
  "warnings": ["Warning if missing info impacts advice"],
  "confidence_impact": "low/medium/high based on missing info impact",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "detailed explanation of coherence between enriched question and RAG response",
  "improvement_notes": "explanations of improvements made"
}}"""
        
        else:  # Spanish
            return f"""PREGUNTA ORIGINAL: "{original_question}"

PREGUNTA ENRIQUECIDA (generada por pre-RAG): "{enriched_question}"

RESPUESTA RAG BRUTA:
"{rag_answer}"

ENTIDADES CONOCIDAS:
{entities_summary}

ENTIDADES CRÃTICAS FALTANTES: {missing_summary}

CONTEXTO CONVERSACIONAL:
{conversation_context}

INSTRUCCIONES:
1. COHERENCIA: Compara la pregunta enriquecida con la respuesta RAG. Â¿La respuesta aborda adecuadamente el tema de la pregunta enriquecida?
2. Adapta la respuesta para el contexto especÃ­fico del usuario
3. Si falta informaciÃ³n crÃ­tica, agrega advertencia y explica el impacto
4. Si la respuesta RAG no coincide bien con la pregunta enriquecida, corrige o seÃ±ala el problema
5. Mejora la legibilidad y estructura de la respuesta
6. Propone 1-3 preguntas de aclaraciÃ³n relevantes (no obvias)
7. MantÃ©n precisiÃ³n tÃ©cnica pero hazla accesible

EJEMPLO VERIFICACIÃ“N COHERENCIA:
Pregunta enriquecida: "EvaluaciÃ³n peso pollo Ross 308, 21 dÃ­as, crecimiento normal?"
Respuesta RAG: "Los pollos deben pesar 800g a las 3 semanas"
Coherencia: "partial" - aborda el peso pero ignora la raza especÃ­fica y evaluaciÃ³n de normalidad

Responde en JSON:
{{
  "enhanced_answer": "respuesta adaptada y mejorada",
  "optional_clarifications": ["Pregunta especÃ­fica 1?", "Pregunta especÃ­fica 2?"],
  "warnings": ["Advertencia si info faltante impacta consejo"],
  "confidence_impact": "low/medium/high segÃºn impacto info faltante",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "explicaciÃ³n detallada de la coherencia entre pregunta enriquecida y respuesta RAG",
  "improvement_notes": "explicaciones de mejoras realizadas"
}}"""
    
    def _format_entities_for_gpt(self, entities: Dict[str, Any]) -> str:
        """âœ… FIX: Formate les entitÃ©s pour le prompt GPT - nomenclature standardisÃ©e"""
        
        formatted_parts = []
        
        # Informations de base avec niveaux de confiance
        if entities.get("breed"):
            confidence = entities.get("breed_confidence", 0.0)
            status = "âœ…" if confidence > 0.7 else "âš ï¸" if confidence > 0.4 else "âŒ"
            formatted_parts.append(f"{status} Race: {entities['breed']} (confiance: {confidence:.1f})")
        else:
            formatted_parts.append("âŒ Race: inconnue")
        
        if entities.get("sex"):
            confidence = entities.get("sex_confidence", 0.0)
            status = "âœ…" if confidence > 0.7 else "âš ï¸" if confidence > 0.4 else "âŒ"
            formatted_parts.append(f"{status} Sexe: {entities['sex']} (confiance: {confidence:.1f})")
        else:
            formatted_parts.append("âŒ Sexe: inconnu")
        
        if entities.get("age_days"):
            confidence = entities.get("age_confidence", 0.0)
            status = "âœ…" if confidence > 0.7 else "âš ï¸" if confidence > 0.4 else "âŒ"
            weeks = entities.get("age_weeks", entities["age_days"] / 7)
            formatted_parts.append(f"{status} Ã‚ge: {entities['age_days']} jours ({weeks:.1f} semaines)")
        else:
            formatted_parts.append("âŒ Ã‚ge: inconnu")
        
        # âœ… FIX: Poids standardisÃ© sur weight_grams
        weight_grams = entities.get("weight_grams") or entities.get("weight")  # CompatibilitÃ©
        if weight_grams:
            confidence = entities.get("weight_confidence", 0.0)
            status = "âœ…" if confidence > 0.6 else "âš ï¸"
            formatted_parts.append(f"{status} Poids actuel: {weight_grams}g")
        else:
            formatted_parts.append("âŒ Poids: inconnu")
        
        # Performance et santÃ©
        if entities.get("symptoms"):
            symptoms = ", ".join(entities["symptoms"]) if isinstance(entities["symptoms"], list) else str(entities["symptoms"])
            formatted_parts.append(f"ðŸš¨ SymptÃ´mes observÃ©s: {symptoms}")
        
        if entities.get("mortality_rate") is not None:
            rate = entities["mortality_rate"]
            status = "ðŸš¨" if rate > 5 else "âš ï¸" if rate > 2 else "âœ…"
            formatted_parts.append(f"{status} MortalitÃ©: {rate}%")
        
        # Environnement
        if entities.get("temperature"):
            temp = entities["temperature"]
            status = "ðŸš¨" if temp < 18 or temp > 30 else "âœ…"
            formatted_parts.append(f"{status} TempÃ©rature: {temp}Â°C")
        
        if entities.get("housing_type"):
            formatted_parts.append(f"ðŸ  Logement: {entities['housing_type']}")
        
        if entities.get("flock_size"):
            formatted_parts.append(f"ðŸ‘¥ Taille troupeau: {entities['flock_size']}")
        
        return "\n".join(formatted_parts) if formatted_parts else "Aucune information contextuelle disponible"
    
    def _parse_gpt_response(
        self, 
        response: str, 
        original_answer: str, 
        entities: Dict[str, Any], 
        missing_entities: List[str]
    ) -> Dict[str, Any]:
        """Parse la rÃ©ponse JSON de GPT avec vÃ©rification de cohÃ©rence"""
        
        try:
            # Extraction JSON robuste
            json_match = None
            
            # Patterns amÃ©liorÃ©s pour extraction JSON robuste
            json_patterns = [
                r'```json\s*({.*?})\s*```',
                r'```\s*({.*?})\s*```',
                r'({(?:[^{}]|{[^{}]*})*})'
            ]
            
            for pattern in json_patterns:
                match = re.search(pattern, response, re.DOTALL | re.MULTILINE)
                if match:
                    json_match = match.group(1)
                    break
            
            if not json_match:
                raise ValueError("Pas de JSON trouvÃ© dans la rÃ©ponse")
            
            # Parser le JSON
            data = json.loads(json_match)
            
            # Valider et enrichir la rÃ©ponse
            enhanced_answer = data.get("enhanced_answer", original_answer)
            optional_clarifications = data.get("optional_clarifications", [])
            warnings = data.get("warnings", [])
            
            # Validation de la cohÃ©rence
            coherence_check = data.get("coherence_check", "unknown")
            if coherence_check not in ["good", "partial", "poor"]:
                coherence_check = "unknown"
            
            coherence_notes = data.get("coherence_notes", "")
            if not coherence_notes:
                coherence_notes = f"CohÃ©rence Ã©valuÃ©e comme: {coherence_check}"
            
            # Validation des clarifications (max 3, non vides)
            if isinstance(optional_clarifications, list):
                optional_clarifications = [q.strip() for q in optional_clarifications if q and q.strip()]
                optional_clarifications = optional_clarifications[:3]
            else:
                optional_clarifications = []
            
            # Validation des avertissements
            if isinstance(warnings, list):
                warnings = [w.strip() for w in warnings if w and w.strip()]
                warnings = warnings[:2]  # Max 2 avertissements
            else:
                warnings = []
            
            # DÃ©terminer l'impact sur la confiance
            confidence_impact = data.get("confidence_impact", "medium")
            if confidence_impact not in ["low", "medium", "high"]:
                confidence_impact = "medium"
            
            result = {
                "enhanced_answer": enhanced_answer,
                "optional_clarifications": optional_clarifications,
                "warnings": warnings,
                "confidence_impact": confidence_impact,
                "coherence_check": coherence_check,
                "coherence_notes": coherence_notes,
                "improvement_notes": data.get("improvement_notes", "AmÃ©liorations appliquÃ©es"),
                "method_used": "openai",
                "processing_time": datetime.now().isoformat(),
                "entities_considered": len([k for k, v in (entities or {}).items() if v is not None]),
                "missing_entities_count": len(missing_entities or [])
            }
            
            return result
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"âŒ [AgentRAGEnhancer] Erreur parsing JSON: {e}")
            logger.debug(f"   RÃ©ponse GPT: {response}")
            
            # Fallback: chercher des amÃ©liorations dans le texte brut
            if len(response) > len(original_answer) and response != original_answer:
                # Extraire des clarifications potentielles du texte
                clarifications = []
                question_patterns = [r'([^.!?]*\?)', r'pourriez-vous[^.!?]*\?', r'pouvez-vous[^.!?]*\?']
                
                for pattern in question_patterns:
                    matches = re.findall(pattern, response, re.IGNORECASE)
                    for match in matches[:2]:  # Max 2
                        if len(match.strip()) > 10:
                            clarifications.append(match.strip())
                
                return {
                    "enhanced_answer": response.strip(),
                    "optional_clarifications": clarifications,
                    "warnings": ["RÃ©ponse gÃ©nÃ©rÃ©e automatiquement - vÃ©rifiez la pertinence"],
                    "confidence_impact": "medium",
                    "coherence_check": "unknown",
                    "coherence_notes": "Impossible de vÃ©rifier la cohÃ©rence - JSON parsing Ã©chouÃ©",
                    "improvement_notes": "JSON parsing failed, used raw GPT response",
                    "method_used": "openai_fallback"
                }
            else:
                # Fallback complet
                return self._enhance_fallback(original_answer, entities, missing_entities, "", "", "fr")
    
    def _enhance_fallback(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        original_question: str,
        enriched_question: str,
        language: str
    ) -> Dict[str, Any]:
        """AmÃ©lioration fallback sans OpenAI avec vÃ©rification basique de cohÃ©rence"""
        
        enhanced_answer = rag_answer
        warnings = []
        clarifications = []
        
        # VÃ©rification basique de cohÃ©rence amÃ©liorÃ©e
        coherence_check = "unknown"
        coherence_notes = "VÃ©rification automatique basique"
        
        if enriched_question and original_question:
            # VÃ©rification de cohÃ©rence amÃ©liorÃ©e
            enriched_words = set(word.lower() for word in enriched_question.split() if len(word) > 2)
            answer_words = set(word.lower() for word in rag_answer.split() if len(word) > 2)
            
            # Mots de stop Ã  ignorer
            stop_words = {'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'et', 'ou', 'est', 'sont', 'the', 'and', 'or', 'is', 'are', 'a', 'an', 'of', 'to', 'in', 'for'}
            enriched_words -= stop_words
            answer_words -= stop_words
            
            # Mots-clÃ©s importants communs
            important_words = enriched_words.intersection(answer_words)
            important_words = {w for w in important_words if len(w) > 3 or w in ['Ã¢ge', 'age', 'sex', 'sexe', 'kg', 'gr']}
            
            total_important_words = len(enriched_words.union(answer_words))
            
            if total_important_words > 0:
                similarity_ratio = len(important_words) / total_important_words
                
                if similarity_ratio >= 0.3:
                    coherence_check = "good"
                    coherence_notes = f"RÃ©ponse cohÃ©rente (similaritÃ©: {similarity_ratio:.1f}, mots-clÃ©s: {', '.join(list(important_words)[:3])})"
                elif similarity_ratio >= 0.15:
                    coherence_check = "partial"
                    coherence_notes = f"CohÃ©rence partielle (similaritÃ©: {similarity_ratio:.1f}, mots-clÃ©s: {', '.join(important_words)})"
                else:
                    coherence_check = "poor"
                    coherence_notes = f"Faible cohÃ©rence (similaritÃ©: {similarity_ratio:.1f})"
            else:
                coherence_check = "poor"
                coherence_notes = "Aucun mot-clÃ© significatif en commun"
        
        # Ajouter des avertissements selon les entitÃ©s manquantes
        if "breed" in missing_entities:
            if language == "fr":
                warnings.append("âš ï¸ Sans connaÃ®tre la race exacte, cette rÃ©ponse est gÃ©nÃ©rale. Les performances varient selon la souche.")
                clarifications.append("Quelle est la race/souche de vos volailles ?")
            elif language == "en":
                warnings.append("âš ï¸ Without knowing the exact breed, this response is general. Performance varies by strain.")
                clarifications.append("What is the breed/strain of your poultry?")
            else:  # Spanish
                warnings.append("âš ï¸ Sin conocer la raza exacta, esta respuesta es general. El rendimiento varÃ­a segÃºn la cepa.")
                clarifications.append("Â¿CuÃ¡l es la raza/cepa de sus aves?")
        
        if "age" in missing_entities:
            if language == "fr":
                warnings.append("âš ï¸ L'Ã¢ge est crucial pour Ã©valuer la normalitÃ© des paramÃ¨tres.")
                clarifications.append("Quel est l'Ã¢ge de vos volailles (en jours ou semaines) ?")
            elif language == "en":
                warnings.append("âš ï¸ Age is crucial for evaluating parameter normality.")
                clarifications.append("What is the age of your poultry (in days or weeks)?")
            else:  # Spanish
                warnings.append("âš ï¸ La edad es crucial para evaluar la normalidad de los parÃ¡metros.")
                clarifications.append("Â¿CuÃ¡l es la edad de sus aves (en dÃ­as o semanas)?")
        
        if "sex" in missing_entities and any(word in rag_answer.lower() for word in ["poids", "weight", "peso", "croissance", "growth"]):
            if language == "fr":
                clarifications.append("S'agit-il de mÃ¢les, femelles, ou d'un troupeau mixte ?")
            elif language == "en":
                clarifications.append("Are these males, females, or a mixed flock?")
            else:  # Spanish
                clarifications.append("Â¿Son machos, hembras, o un lote mixto?")
        
        # DÃ©terminer l'impact sur la confiance
        confidence_impact = "low"
        if len(missing_entities) >= 2:
            confidence_impact = "high"
        elif len(missing_entities) == 1:
            confidence_impact = "medium"
        
        # Ajouter un contexte si des entitÃ©s sont connues
        context_additions = []
        if entities.get("breed") and entities.get("breed_confidence", 0) > 0.6:
            context_additions.append(f"race {entities['breed']}")
        
        if entities.get("age_days") and entities.get("age_confidence", 0) > 0.6:
            context_additions.append(f"Ã¢ge {entities['age_days']} jours")
        
        if context_additions:
            context_text = " et ".join(context_additions)
            if language == "fr":
                enhanced_answer += f"\n\nðŸ’¡ Cette rÃ©ponse considÃ¨re votre contexte : {context_text}."
            elif language == "en":
                enhanced_answer += f"\n\nðŸ’¡ This response considers your context: {context_text}."
            else:  # Spanish
                enhanced_answer += f"\n\nðŸ’¡ Esta respuesta considera su contexto: {context_text}."
        
        # Ajouter les avertissements Ã  la rÃ©ponse si critiques
        if warnings and confidence_impact in ["medium", "high"]:
            enhanced_answer += f"\n\n{' '.join(warnings)}"
        
        return {
            "enhanced_answer": enhanced_answer,
            "optional_clarifications": clarifications[:3],
            "warnings": warnings,
            "confidence_impact": confidence_impact,
            "coherence_check": coherence_check,
            "coherence_notes": coherence_notes,
            "improvement_notes": "AmÃ©lioration basique appliquÃ©e",
            "method_used": "fallback"
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """âœ… FIX: Retourne les statistiques enrichies de l'agent"""
        
        total = self.stats["total_requests"]
        success_rate = (self.stats["openai_success"] / total * 100) if total > 0 else 0
        enhancement_rate = (self.stats["answers_enhanced"] / total * 100) if total > 0 else 0
        clarification_rate = (self.stats["clarifications_generated"] / total * 100) if total > 0 else 0
        coherence_issue_rate = (self.stats["coherence_issues_detected"] / total * 100) if total > 0 else 0
        field_propagation_success_rate = (self.stats["field_propagation_success"] / total * 100) if total > 0 else 0
        input_validation_rate = (self.stats["input_validation_fixes"] / total * 100) if total > 0 else 0
        
        return {
            "agent_type": "rag_enhancer",
            "total_requests": total,
            "openai_success_rate": f"{success_rate:.1f}%",
            "answer_enhancement_rate": f"{enhancement_rate:.1f}%",
            "clarification_generation_rate": f"{clarification_rate:.1f}%",
            "coherence_issue_detection_rate": f"{coherence_issue_rate:.1f}%",
            "field_propagation_success_rate": f"{field_propagation_success_rate:.1f}%",
            "input_validation_fixes_rate": f"{input_validation_rate:.1f}%",  # âœ… NOUVEAU
            "openai_available": self.openai_available,
            "model_used": self.model,
            "detailed_stats": self.stats.copy()
        }

# Instance globale
agent_rag_enhancer = AgentRAGEnhancer()

# âœ… FIX: Fonction utilitaire avec validation dÃ©fensive
async def enhance_rag_answer(
    rag_answer: str,
    entities: Dict[str, Any] = None,  # âœ… FIX: Valeur par dÃ©faut None
    missing_entities: List[str] = None,  # âœ… FIX: Valeur par dÃ©faut None
    conversation_context: str = "",
    original_question: str = "",
    enriched_question: str = "",
    language: str = "fr",
    **additional_fields
) -> Dict[str, Any]:
    """
    âœ… FIX: Fonction utilitaire avec validation dÃ©fensive et propagation complÃ¨te
    """
    return await agent_rag_enhancer.enhance_rag_answer(
        rag_answer, 
        entities or {}, 
        missing_entities or [], 
        conversation_context, 
        original_question, 
        enriched_question, 
        language, 
        **additional_fields
    )