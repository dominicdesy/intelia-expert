# app/api/v1/agent_rag_enhancer.py
"""
Agent RAG Enhancer - Am√©lioration des r√©ponses apr√®s RAG

üéØ FONCTIONNALIT√âS:
- Adapte les r√©ponses RAG selon le contexte utilisateur
- V√©rifie la coh√©rence entre question enrichie et r√©ponse RAG
- Ajoute des avertissements si informations manquantes
- Propose des clarifications optionnelles
- Am√©liore la lisibilit√© et la pertinence
- ‚úÖ CORRECTION: Propagation syst√©matique de tous les champs
- ‚úÖ CORRECTION: Gestion des champs absents avec valeurs par d√©faut
- ‚úÖ FIX: Validation d√©fensive et standardisation nomenclature
"""

import os
import logging
import json
import re
from typing import Dict, List, Any, Optional
from datetime import datetime

# Import OpenAI s√©curis√©
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

logger = logging.getLogger(__name__)

class AgentRAGEnhancer:
    """Agent intelligent pour am√©liorer les r√©ponses RAG"""
    
    def __init__(self):
        self.openai_available = OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY')
        self.model = os.getenv('RAG_ENHANCER_MODEL', 'gpt-4o-mini')
        self.timeout = int(os.getenv('RAG_ENHANCER_TIMEOUT', '15'))
        self.max_retries = int(os.getenv('RAG_ENHANCER_RETRIES', '2'))
        
        # Statistiques
        self.stats = {
            "total_requests": 0,
            "openai_success": 0,
            "openai_failures": 0,
            "fallback_used": 0,
            "answers_enhanced": 0,
            "clarifications_generated": 0,
            "coherence_checks": 0,
            "coherence_issues_detected": 0,
            "field_propagation_success": 0,
            "field_propagation_fallback": 0,
            "input_validation_fixes": 0  # ‚úÖ NOUVEAU: Tracking des corrections d'input
        }
        
        logger.info(f"üîß [AgentRAGEnhancer] Initialis√©")
        logger.info(f"   OpenAI disponible: {'‚úÖ' if self.openai_available else '‚ùå'}")
        logger.info(f"   Mod√®le: {self.model}")
    
    def _validate_and_sanitize_inputs(
        self,
        entities: Dict[str, Any],
        missing_entities: List[str],
        original_question: str,
        enriched_question: str,
        language: str
    ) -> tuple:
        """
        ‚úÖ FIX: Validation d√©fensive des inputs pour √©viter les erreurs
        """
        
        validation_fixes = 0
        
        # Validation entities
        if entities is None:
            entities = {}
            validation_fixes += 1
            logger.debug("üîß [AgentRAGEnhancer] entities √©tait None, initialis√© √† {}")
        elif not isinstance(entities, dict):
            entities = {}
            validation_fixes += 1
            logger.warning(f"‚ö†Ô∏è [AgentRAGEnhancer] entities n'√©tait pas un dict: {type(entities)}")
        
        # Validation missing_entities
        if missing_entities is None:
            missing_entities = []
            validation_fixes += 1
            logger.debug("üîß [AgentRAGEnhancer] missing_entities √©tait None, initialis√© √† []")
        elif not isinstance(missing_entities, list):
            missing_entities = []
            validation_fixes += 1
            logger.warning(f"‚ö†Ô∏è [AgentRAGEnhancer] missing_entities n'√©tait pas une liste: {type(missing_entities)}")
        
        # Validation strings
        if not isinstance(original_question, str):
            original_question = str(original_question) if original_question is not None else ""
            validation_fixes += 1
        
        if not isinstance(enriched_question, str):
            enriched_question = str(enriched_question) if enriched_question is not None else ""
            validation_fixes += 1
        
        if not isinstance(language, str) or language not in ["fr", "en", "es"]:
            language = "fr"
            validation_fixes += 1
        
        if validation_fixes > 0:
            self.stats["input_validation_fixes"] += validation_fixes
            logger.debug(f"üîß [AgentRAGEnhancer] {validation_fixes} corrections d'input appliqu√©es")
        
        return entities, missing_entities, original_question, enriched_question, language
    
    async def enhance_rag_answer(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        original_question: str = "",
        enriched_question: str = "",
        language: str = "fr",
        **additional_fields  # ‚úÖ Capture tous les champs suppl√©mentaires
    ) -> Dict[str, Any]:
        """
        Am√©liore une r√©ponse RAG avec le contexte utilisateur et v√©rifie la coh√©rence
        
        Args:
            rag_answer: R√©ponse brute du syst√®me RAG
            entities: Entit√©s extraites du contexte
            missing_entities: Entit√©s manquantes critiques
            conversation_context: Contexte conversationnel
            original_question: Question originale pos√©e
            enriched_question: Question enrichie par le pr√©-RAG
            language: Langue de la conversation
            **additional_fields: Tous les champs suppl√©mentaires √† propager
            
        Returns:
            Dict avec tous les champs requis garantis, m√™me si None
        """
        
        self.stats["total_requests"] += 1
        self.stats["coherence_checks"] += 1
        
        # ‚úÖ FIX: Validation d√©fensive des inputs d√®s le d√©but
        entities, missing_entities, original_question, enriched_question, language = (
            self._validate_and_sanitize_inputs(
                entities, missing_entities, original_question, enriched_question, language
            )
        )
        
        # ‚úÖ FIX: Validation rag_answer
        if not isinstance(rag_answer, str):
            rag_answer = str(rag_answer) if rag_answer is not None else ""
        
        if not isinstance(conversation_context, str):
            conversation_context = str(conversation_context) if conversation_context is not None else ""
        
        try:
            # ‚úÖ CORRECTION: Initialiser le r√©sultat avec TOUS les champs requis
            base_result = self._initialize_complete_result(
                rag_answer, entities, missing_entities, original_question, 
                enriched_question, language, additional_fields
            )
            
            # Tentative OpenAI si disponible
            if self.openai_available:
                enhancement_result = await self._enhance_with_openai(
                    rag_answer, entities, missing_entities, conversation_context, 
                    original_question, enriched_question, language
                )
                
                if enhancement_result.get("success"):
                    # ‚úÖ CORRECTION: Fusionner avec le r√©sultat de base pour garantir tous les champs
                    final_result = self._merge_results(base_result, enhancement_result)
                    self.stats["openai_success"] += 1
                    self.stats["field_propagation_success"] += 1
                    
                    # Mise √† jour des statistiques
                    if final_result["enhanced_answer"] != rag_answer:
                        self.stats["answers_enhanced"] += 1
                    if final_result.get("optional_clarifications"):
                        self.stats["clarifications_generated"] += 1
                    if final_result.get("coherence_check") in ["partial", "poor"]:
                        self.stats["coherence_issues_detected"] += 1
                    
                    return final_result
                else:
                    self.stats["openai_failures"] += 1
            
            # Fallback: Am√©lioration basique avec tous les champs
            logger.info("üîÑ [AgentRAGEnhancer] Utilisation fallback basique")
            fallback_result = self._enhance_fallback(
                rag_answer, entities, missing_entities, 
                original_question, enriched_question, language
            )
            
            # ‚úÖ CORRECTION: Fusionner avec le r√©sultat de base
            final_result = self._merge_results(base_result, fallback_result)
            self.stats["fallback_used"] += 1
            self.stats["field_propagation_fallback"] += 1
            
            return final_result
            
        except Exception as e:
            logger.error(f"‚ùå [AgentRAGEnhancer] Erreur critique inattendue: {e}")
            
            # ‚úÖ CORRECTION: M√™me en cas d'erreur, retourner un r√©sultat complet
            error_result = self._initialize_complete_result(
                rag_answer, entities, missing_entities, original_question, 
                enriched_question, language, additional_fields
            )
            
            error_result.update({
                "enhanced_answer": rag_answer,
                "warnings": [f"Erreur am√©lioration: {str(e)}"],
                "confidence_impact": "unknown",
                "coherence_check": "unknown",
                "coherence_notes": "Impossible de v√©rifier la coh√©rence en raison d'une erreur",
                "method_used": "error_fallback",
                "success": False
            })
            
            return error_result
    
    def _initialize_complete_result(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        original_question: str,
        enriched_question: str,
        language: str,
        additional_fields: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ‚úÖ FIX: Initialise un r√©sultat complet avec TOUS les champs requis
        Nomenclature standardis√©e sur weight_grams
        """
        
        # Champs de base toujours pr√©sents
        base_result = {
            # Champs de r√©ponse principaux
            "enhanced_answer": rag_answer,
            "optional_clarifications": [],
            "warnings": [],
            "confidence_impact": "medium",
            "coherence_check": "unknown",
            "coherence_notes": "En cours d'√©valuation",
            "improvement_notes": "Traitement en cours",
            "method_used": "initializing",
            "success": True,
            
            # Champs d'entr√©e propag√©s
            "original_question": original_question,
            "enriched_question": enriched_question,
            "language": language,
            
            # Champs contextuels
            "entities": entities,
            "missing_entities": missing_entities,
            
            # Champs techniques
            "processing_time": datetime.now().isoformat(),
            "entities_considered": len([k for k, v in entities.items() if v is not None]),
            "missing_entities_count": len(missing_entities),
            
            # ‚úÖ FIX: Standardisation nomenclature weight_grams
            "weight_grams": None,  # ‚úÖ CHANG√â: weight -> weight_grams
            "weight_confidence": None,
            "age_days": None,
            "age_weeks": None,
            "age_confidence": None,
            "breed": None,
            "breed_confidence": None,
            "sex": None,
            "sex_confidence": None,
            "symptoms": None,
            "mortality_rate": None,
            "temperature": None,
            "housing_type": None,
            "flock_size": None,
            
            # Champs d'√©valuation technique
            "context_relevance": "unknown",
            "technical_accuracy": "unknown",
            "practical_applicability": "unknown",
            
            # ‚úÖ NOUVEAU: Champs d'extraction automatique
            "detected_weight_grams": None,  # ‚úÖ Poids d√©tect√© dans la r√©ponse
            "detected_age_days": None,      # ‚úÖ √Çge d√©tect√© dans la r√©ponse
            "detected_breed": None,         # ‚úÖ Race d√©tect√©e dans la r√©ponse
            "extraction_confidence": 0.0    # ‚úÖ Confiance dans l'extraction
        }
        
        # ‚úÖ CORRECTION: Propager les valeurs des entit√©s si disponibles
        if entities:
            # ‚úÖ FIX: Mapping standardis√© weight_grams
            entity_mapping = {
                "weight_grams": "weight_grams",  # ‚úÖ Standardis√©
                "weight": "weight_grams",        # ‚úÖ Compatibilit√© ancienne nomenclature
                "age_days": "age_days",
                "age_weeks": "age_weeks", 
                "breed": "breed",
                "sex": "sex",
                "symptoms": "symptoms",
                "mortality_rate": "mortality_rate",
                "temperature": "temperature",
                "housing_type": "housing_type",
                "flock_size": "flock_size"
            }
            
            for entity_key, result_key in entity_mapping.items():
                if entity_key in entities and entities[entity_key] is not None:
                    base_result[result_key] = entities[entity_key]
            
            # Propager les champs de confiance
            confidence_fields = ["weight_confidence", "age_confidence", "breed_confidence", "sex_confidence"]
            for field in confidence_fields:
                if field in entities and entities[field] is not None:
                    base_result[field] = entities[field]
        
        # ‚úÖ CORRECTION: Propager tous les champs suppl√©mentaires fournis
        if additional_fields:
            for key, value in additional_fields.items():
                if key not in base_result:  # √âviter d'√©craser les champs de base
                    base_result[key] = value
                elif value is not None:  # Remplacer les None par des valeurs r√©elles
                    base_result[key] = value
        
        # ‚úÖ NOUVEAU: Extraction automatique de donn√©es implicites
        base_result.update(self._extract_implicit_data(rag_answer, entities))
        
        logger.debug(f"üîß [AgentRAGEnhancer] R√©sultat initialis√© avec {len(base_result)} champs")
        
        return base_result
    
    def _extract_implicit_data(self, text: str, entities: Dict[str, Any]) -> Dict[str, Any]:
        """
        ‚úÖ NOUVEAU: Extrait des donn√©es implicites du texte (poids, √¢ge, race)
        """
        
        implicit_data = {
            "detected_weight_grams": None,
            "detected_age_days": None,
            "detected_breed": None,
            "extraction_confidence": 0.0
        }
        
        extractions_count = 0
        
        try:
            # Extraction poids (grammes/kg)
            weight_patterns = [
                r'(\d+(?:\.\d+)?)\s*(?:g|gr|grammes?|grams?)\b',
                r'(\d+(?:\.\d+)?)\s*(?:kg|kilogrammes?|kilograms?)\b',
                r'poids(?:.*?)(\d+(?:\.\d+)?)\s*(?:g|kg)',
                r'weight(?:.*?)(\d+(?:\.\d+)?)\s*(?:g|kg)'
            ]
            
            for pattern in weight_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    weight = float(match.group(1))
                    # Convertir kg en grammes
                    if 'kg' in pattern.lower() or weight < 10:
                        weight *= 1000
                    implicit_data["detected_weight_grams"] = int(weight)
                    extractions_count += 1
                    break
            
            # Extraction √¢ge (jours/semaines)
            age_patterns = [
                r'(\d+)\s*(?:jours?|days?)\b',
                r'(\d+)\s*(?:semaines?|weeks?)\b',
                r'√¢ge(?:.*?)(\d+)',
                r'age(?:.*?)(\d+)'
            ]
            
            for pattern in age_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    age = int(match.group(1))
                    # Convertir semaines en jours
                    if 'semaine' in pattern.lower() or 'week' in pattern.lower():
                        age *= 7
                    implicit_data["detected_age_days"] = age
                    extractions_count += 1
                    break
            
            # Extraction race
            breed_patterns = [
                r'\b(Ross\s*\d+)\b',
                r'\b(Cobb\s*\d+)\b',
                r'\b(Hubbard)\b',
                r'\b(Arbor\s*Acres?)\b'
            ]
            
            for pattern in breed_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    implicit_data["detected_breed"] = match.group(1).strip()
                    extractions_count += 1
                    break
            
            # Calculer confiance d'extraction
            if extractions_count > 0:
                implicit_data["extraction_confidence"] = min(extractions_count / 3.0, 1.0)
                logger.debug(f"üîç [AgentRAGEnhancer] {extractions_count} donn√©es extraites automatiquement")
        
        except Exception as e:
            logger.error(f"‚ùå [AgentRAGEnhancer] Erreur extraction implicite: {e}")
        
        return implicit_data
    
    def _merge_results(self, base_result: Dict[str, Any], enhancement_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ‚úÖ Fusionne les r√©sultats en pr√©servant tous les champs
        """
        
        # Commencer avec le r√©sultat de base complet
        merged = base_result.copy()
        
        # Mettre √† jour avec les am√©liorations, en pr√©servant les valeurs non-None existantes
        for key, value in enhancement_result.items():
            if value is not None:  # Seulement √©craser si la nouvelle valeur n'est pas None
                merged[key] = value
            elif key not in merged:  # Ajouter les nouveaux champs m√™me s'ils sont None
                merged[key] = value
        
        # S'assurer que certains champs critiques sont pr√©sents
        required_fields = [
            "enhanced_answer", "optional_clarifications", "warnings", 
            "confidence_impact", "coherence_check", "coherence_notes", 
            "method_used", "success"
        ]
        
        for field in required_fields:
            if field not in merged:
                merged[field] = None
        
        return merged
    
    async def _enhance_with_openai(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        conversation_context: str,
        original_question: str,
        enriched_question: str,
        language: str
    ) -> Dict[str, Any]:
        """Am√©lioration avec OpenAI GPT"""
        
        try:
            # Pr√©parer le contexte pour GPT
            entities_summary = self._format_entities_for_gpt(entities)
            missing_summary = ", ".join(missing_entities) if missing_entities else "Aucune"
            
            # Prompt sp√©cialis√© selon la langue
            system_prompt = self._get_system_prompt(language)
            user_prompt = self._build_enhancement_prompt(
                rag_answer, entities_summary, missing_summary, conversation_context,
                original_question, enriched_question, language
            )
            
            # Appel OpenAI
            client = openai.AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            
            response = await client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1000,
                timeout=self.timeout
            )
            
            answer = response.choices[0].message.content.strip()
            
            # Parser la r√©ponse JSON
            result = self._parse_gpt_response(answer, rag_answer, entities, missing_entities)
            result["success"] = True
            result["method_used"] = "openai"
            
            logger.info(f"‚úÖ [AgentRAGEnhancer] Am√©lioration OpenAI r√©ussie")
            logger.debug(f"   Clarifications g√©n√©r√©es: {len(result.get('optional_clarifications', []))}")
            logger.debug(f"   Coh√©rence: {result.get('coherence_check', 'unknown')}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [AgentRAGEnhancer] Erreur OpenAI: {e}")
            return {"success": False, "error": str(e)}
    
    def _get_system_prompt(self, language: str) -> str:
        """Retourne le prompt syst√®me selon la langue"""
        
        system_prompts = {
            "fr": """Tu es un expert v√©t√©rinaire en aviculture sp√©cialis√© dans l'adaptation de r√©ponses techniques.

Ta mission:
1. V√©rifier la coh√©rence entre la question enrichie et la r√©ponse RAG
2. Adapter la r√©ponse RAG pour qu'elle soit pertinente malgr√© les informations manquantes
3. Ajouter des avertissements si l'absence de donn√©es affecte la pr√©cision
4. Proposer 1-3 questions de clarification pour am√©liorer le conseil
5. Garder un ton professionnel mais accessible
6. Prioriser la s√©curit√© des animaux

V√âRIFICATION DE COH√âRENCE:
- "good": La r√©ponse RAG correspond parfaitement √† la question enrichie
- "partial": La r√©ponse RAG est pertinente mais incompl√®te ou tangentielle
- "poor": La r√©ponse RAG ne correspond pas bien √† la question enrichie

IMPORTANT: 
- Si des informations critiques manquent, le mentionner clairement
- Si la r√©ponse RAG semble hors-sujet, l'adapter ou le signaler
- Proposer des questions de clarification utiles, pas √©videntes
- √âviter les conseils dangereux sans contexte complet
- R√©pondre UNIQUEMENT en JSON avec la structure exacte demand√©e""",
            
            "en": """You are a poultry veterinary expert specialized in adapting technical responses.

Your mission:
1. Verify coherence between enriched question and RAG response
2. Adapt the RAG response to be relevant despite missing information
3. Add warnings if missing data affects accuracy
4. Propose 1-3 clarification questions to improve advice
5. Keep professional but accessible tone
6. Prioritize animal safety

COHERENCE CHECK:
- "good": RAG response perfectly matches the enriched question
- "partial": RAG response is relevant but incomplete or tangential
- "poor": RAG response doesn't match well with the enriched question

IMPORTANT:
- If critical information is missing, mention it clearly
- If RAG response seems off-topic, adapt it or flag it
- Propose useful clarification questions, not obvious ones
- Avoid dangerous advice without complete context
- Respond ONLY in JSON with the exact requested structure""",
            
            "es": """Eres un experto veterinario en avicultura especializado en adaptar respuestas t√©cnicas.

Tu misi√≥n:
1. Verificar la coherencia entre la pregunta enriquecida y la respuesta RAG
2. Adaptar la respuesta RAG para que sea relevante a pesar de la informaci√≥n faltante
3. Agregar advertencias si los datos faltantes afectan la precisi√≥n
4. Proponer 1-3 preguntas de aclaraci√≥n para mejorar el consejo
5. Mantener tono profesional pero accesible
6. Priorizar la seguridad de los animales

VERIFICACI√ìN DE COHERENCIA:
- "good": La respuesta RAG coincide perfectamente con la pregunta enriquecida
- "partial": La respuesta RAG es relevante pero incompleta o tangencial
- "poor": La respuesta RAG no coincide bien con la pregunta enriquecida

IMPORTANTE:
- Si falta informaci√≥n cr√≠tica, mencionarlo claramente
- Si la respuesta RAG parece fuera de tema, adaptarla o se√±alarlo
- Proponer preguntas de aclaraci√≥n √∫tiles, no obvias
- Evitar consejos peligrosos sin contexto completo
- Responder SOLO en JSON con la estructura exacta solicitada"""
        }
        
        return system_prompts.get(language, system_prompts["fr"])
    
    def _build_enhancement_prompt(
        self,
        rag_answer: str,
        entities_summary: str,
        missing_summary: str,
        conversation_context: str,
        original_question: str,
        enriched_question: str,
        language: str
    ) -> str:
        """Construit le prompt d'am√©lioration avec v√©rification de coh√©rence"""
        
        if language == "fr":
            return f"""QUESTION ORIGINALE: "{original_question}"

QUESTION ENRICHIE (g√©n√©r√©e par le pr√©-RAG): "{enriched_question}"

R√âPONSE RAG BRUTE:
"{rag_answer}"

ENTIT√âS CONNUES:
{entities_summary}

ENTIT√âS MANQUANTES CRITIQUES: {missing_summary}

CONTEXTE CONVERSATIONNEL:
{conversation_context}

INSTRUCTIONS:
1. COH√âRENCE: Compare la question enrichie avec la r√©ponse RAG. La r√©ponse traite-t-elle bien le sujet de la question enrichie ?
2. Adapte la r√©ponse pour le contexte sp√©cifique de l'utilisateur
3. Si des informations critiques manquent, ajoute un avertissement et explique l'impact
4. Si la r√©ponse RAG ne correspond pas bien √† la question enrichie, corrige ou signale le probl√®me
5. Am√©liore la lisibilit√© et la structure de la r√©ponse
6. Propose 1-3 questions de clarification pertinentes (pas √©videntes)
7. Garde la pr√©cision technique mais rends accessible

EXEMPLE V√âRIFICATION COH√âRENCE:
Question enrichie: "√âvaluation poids poulet Ross 308, 21 jours, croissance normale ?"
R√©ponse RAG: "Les poulets doivent peser 800g √† 3 semaines"
Coh√©rence: "partial" - r√©pond au poids mais ignore la race sp√©cifique et l'√©valuation de normalit√©

R√©ponds en JSON:
{{
  "enhanced_answer": "r√©ponse adapt√©e et am√©lior√©e",
  "optional_clarifications": ["Question pr√©cise 1?", "Question pr√©cise 2?"],
  "warnings": ["Avertissement si info manquante impacte conseil"],
  "confidence_impact": "low/medium/high selon impact infos manquantes",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "explication d√©taill√©e de la coh√©rence entre question enrichie et r√©ponse RAG",
  "improvement_notes": "explications des am√©liorations apport√©es"
}}"""
        
        elif language == "en":
            return f"""ORIGINAL QUESTION: "{original_question}"

ENRICHED QUESTION (generated by pre-RAG): "{enriched_question}"

RAW RAG RESPONSE:
"{rag_answer}"

KNOWN ENTITIES:
{entities_summary}

MISSING CRITICAL ENTITIES: {missing_summary}

CONVERSATIONAL CONTEXT:
{conversation_context}

INSTRUCTIONS:
1. COHERENCE: Compare enriched question with RAG response. Does the response properly address the enriched question's topic?
2. Adapt response for user's specific context
3. If critical information missing, add warning and explain impact
4. If RAG response doesn't match well with enriched question, correct or flag the issue
5. Improve readability and structure of response
6. Propose 1-3 relevant clarification questions (not obvious ones)
7. Keep technical accuracy but make accessible

EXAMPLE COHERENCE CHECK:
Enriched question: "Ross 308 chicken weight evaluation, 21 days, normal growth?"
RAG response: "Chickens should weigh 800g at 3 weeks"
Coherence: "partial" - addresses weight but ignores specific breed and normality evaluation

Respond in JSON:
{{
  "enhanced_answer": "adapted and improved response",
  "optional_clarifications": ["Specific question 1?", "Specific question 2?"],
  "warnings": ["Warning if missing info impacts advice"],
  "confidence_impact": "low/medium/high based on missing info impact",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "detailed explanation of coherence between enriched question and RAG response",
  "improvement_notes": "explanations of improvements made"
}}"""
        
        else:  # Spanish
            return f"""PREGUNTA ORIGINAL: "{original_question}"

PREGUNTA ENRIQUECIDA (generada por pre-RAG): "{enriched_question}"

RESPUESTA RAG BRUTA:
"{rag_answer}"

ENTIDADES CONOCIDAS:
{entities_summary}

ENTIDADES CR√çTICAS FALTANTES: {missing_summary}

CONTEXTO CONVERSACIONAL:
{conversation_context}

INSTRUCCIONES:
1. COHERENCIA: Compara la pregunta enriquecida con la respuesta RAG. ¬øLa respuesta aborda adecuadamente el tema de la pregunta enriquecida?
2. Adapta la respuesta para el contexto espec√≠fico del usuario
3. Si falta informaci√≥n cr√≠tica, agrega advertencia y explica el impacto
4. Si la respuesta RAG no coincide bien con la pregunta enriquecida, corrige o se√±ala el problema
5. Mejora la legibilidad y estructura de la respuesta
6. Propone 1-3 preguntas de aclaraci√≥n relevantes (no obvias)
7. Mant√©n precisi√≥n t√©cnica pero hazla accesible

EJEMPLO VERIFICACI√ìN COHERENCIA:
Pregunta enriquecida: "Evaluaci√≥n peso pollo Ross 308, 21 d√≠as, crecimiento normal?"
Respuesta RAG: "Los pollos deben pesar 800g a las 3 semanas"
Coherencia: "partial" - aborda el peso pero ignora la raza espec√≠fica y evaluaci√≥n de normalidad

Responde en JSON:
{{
  "enhanced_answer": "respuesta adaptada y mejorada",
  "optional_clarifications": ["Pregunta espec√≠fica 1?", "Pregunta espec√≠fica 2?"],
  "warnings": ["Advertencia si info faltante impacta consejo"],
  "confidence_impact": "low/medium/high seg√∫n impacto info faltante",
  "coherence_check": "good/partial/poor",
  "coherence_notes": "explicaci√≥n detallada de la coherencia entre pregunta enriquecida y respuesta RAG",
  "improvement_notes": "explicaciones de mejoras realizadas"
}}"""
    
    def _format_entities_for_gpt(self, entities: Dict[str, Any]) -> str:
        """‚úÖ FIX: Formate les entit√©s pour le prompt GPT - nomenclature standardis√©e"""
        
        formatted_parts = []
        
        # Informations de base avec niveaux de confiance
        if entities.get("breed"):
            confidence = entities.get("breed_confidence", 0.0)
            status = "‚úÖ" if confidence > 0.7 else "‚ö†Ô∏è" if confidence > 0.4 else "‚ùå"
            formatted_parts.append(f"{status} Race: {entities['breed']} (confiance: {confidence:.1f})")
        else:
            formatted_parts.append("‚ùå Race: inconnue")
        
        if entities.get("sex"):
            confidence = entities.get("sex_confidence", 0.0)
            status = "‚úÖ" if confidence > 0.7 else "‚ö†Ô∏è" if confidence > 0.4 else "‚ùå"
            formatted_parts.append(f"{status} Sexe: {entities['sex']} (confiance: {confidence:.1f})")
        else:
            formatted_parts.append("‚ùå Sexe: inconnu")
        
        if entities.get("age_days"):
            confidence = entities.get("age_confidence", 0.0)
            status = "‚úÖ" if confidence > 0.7 else "‚ö†Ô∏è" if confidence > 0.4 else "‚ùå"
            weeks = entities.get("age_weeks", entities["age_days"] / 7)
            formatted_parts.append(f"{status} √Çge: {entities['age_days']} jours ({weeks:.1f} semaines)")
        else:
            formatted_parts.append("‚ùå √Çge: inconnu")
        
        # ‚úÖ FIX: Poids standardis√© sur weight_grams
        weight_grams = entities.get("weight_grams") or entities.get("weight")  # Compatibilit√©
        if weight_grams:
            confidence = entities.get("weight_confidence", 0.0)
            status = "‚úÖ" if confidence > 0.6 else "‚ö†Ô∏è"
            formatted_parts.append(f"{status} Poids actuel: {weight_grams}g")
        else:
            formatted_parts.append("‚ùå Poids: inconnu")
        
        # Performance et sant√©
        if entities.get("symptoms"):
            symptoms = ", ".join(entities["symptoms"]) if isinstance(entities["symptoms"], list) else str(entities["symptoms"])
            formatted_parts.append(f"üö® Sympt√¥mes observ√©s: {symptoms}")
        
        if entities.get("mortality_rate") is not None:
            rate = entities["mortality_rate"]
            status = "üö®" if rate > 5 else "‚ö†Ô∏è" if rate > 2 else "‚úÖ"
            formatted_parts.append(f"{status} Mortalit√©: {rate}%")
        
        # Environnement
        if entities.get("temperature"):
            temp = entities["temperature"]
            status = "üö®" if temp < 18 or temp > 30 else "‚úÖ"
            formatted_parts.append(f"{status} Temp√©rature: {temp}¬∞C")
        
        if entities.get("housing_type"):
            formatted_parts.append(f"üè† Logement: {entities['housing_type']}")
        
        if entities.get("flock_size"):
            formatted_parts.append(f"üë• Taille troupeau: {entities['flock_size']}")
        
        return "\n".join(formatted_parts) if formatted_parts else "Aucune information contextuelle disponible"
    
    def _parse_gpt_response(
        self, 
        response: str, 
        original_answer: str, 
        entities: Dict[str, Any], 
        missing_entities: List[str]
    ) -> Dict[str, Any]:
        """Parse la r√©ponse JSON de GPT avec v√©rification de coh√©rence"""
        
        try:
            # Extraction JSON robuste
            json_match = None
            
            # Patterns am√©lior√©s pour extraction JSON robuste
            json_patterns = [
                r'```json\s*({.*?})\s*```',
                r'```\s*({.*?})\s*```',
                r'({(?:[^{}]|{[^{}]*})*})'
            ]
            
            for pattern in json_patterns:
                match = re.search(pattern, response, re.DOTALL | re.MULTILINE)
                if match:
                    json_match = match.group(1)
                    break
            
            if not json_match:
                raise ValueError("Pas de JSON trouv√© dans la r√©ponse")
            
            # Parser le JSON
            data = json.loads(json_match)
            
            # Valider et enrichir la r√©ponse
            enhanced_answer = data.get("enhanced_answer", original_answer)
            optional_clarifications = data.get("optional_clarifications", [])
            warnings = data.get("warnings", [])
            
            # Validation de la coh√©rence
            coherence_check = data.get("coherence_check", "unknown")
            if coherence_check not in ["good", "partial", "poor"]:
                coherence_check = "unknown"
            
            coherence_notes = data.get("coherence_notes", "")
            if not coherence_notes:
                coherence_notes = f"Coh√©rence √©valu√©e comme: {coherence_check}"
            
            # Validation des clarifications (max 3, non vides)
            if isinstance(optional_clarifications, list):
                optional_clarifications = [q.strip() for q in optional_clarifications if q and q.strip()]
                optional_clarifications = optional_clarifications[:3]
            else:
                optional_clarifications = []
            
            # Validation des avertissements
            if isinstance(warnings, list):
                warnings = [w.strip() for w in warnings if w and w.strip()]
                warnings = warnings[:2]  # Max 2 avertissements
            else:
                warnings = []
            
            # D√©terminer l'impact sur la confiance
            confidence_impact = data.get("confidence_impact", "medium")
            if confidence_impact not in ["low", "medium", "high"]:
                confidence_impact = "medium"
            
            result = {
                "enhanced_answer": enhanced_answer,
                "optional_clarifications": optional_clarifications,
                "warnings": warnings,
                "confidence_impact": confidence_impact,
                "coherence_check": coherence_check,
                "coherence_notes": coherence_notes,
                "improvement_notes": data.get("improvement_notes", "Am√©liorations appliqu√©es"),
                "method_used": "openai",
                "processing_time": datetime.now().isoformat(),
                "entities_considered": len([k for k, v in (entities or {}).items() if v is not None]),
                "missing_entities_count": len(missing_entities or [])
            }
            
            return result
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"‚ùå [AgentRAGEnhancer] Erreur parsing JSON: {e}")
            logger.debug(f"   R√©ponse GPT: {response}")
            
            # Fallback: chercher des am√©liorations dans le texte brut
            if len(response) > len(original_answer) and response != original_answer:
                # Extraire des clarifications potentielles du texte
                clarifications = []
                question_patterns = [r'([^.!?]*\?)', r'pourriez-vous[^.!?]*\?', r'pouvez-vous[^.!?]*\?']
                
                for pattern in question_patterns:
                    matches = re.findall(pattern, response, re.IGNORECASE)
                    for match in matches[:2]:  # Max 2
                        if len(match.strip()) > 10:
                            clarifications.append(match.strip())
                
                return {
                    "enhanced_answer": response.strip(),
                    "optional_clarifications": clarifications,
                    "warnings": ["R√©ponse g√©n√©r√©e automatiquement - v√©rifiez la pertinence"],
                    "confidence_impact": "medium",
                    "coherence_check": "unknown",
                    "coherence_notes": "Impossible de v√©rifier la coh√©rence - JSON parsing √©chou√©",
                    "improvement_notes": "JSON parsing failed, used raw GPT response",
                    "method_used": "openai_fallback"
                }
            else:
                # Fallback complet
                return self._enhance_fallback(original_answer, entities, missing_entities, "", "", "fr")
    
    def _enhance_fallback(
        self,
        rag_answer: str,
        entities: Dict[str, Any],
        missing_entities: List[str],
        original_question: str,
        enriched_question: str,
        language: str
    ) -> Dict[str, Any]:
        """Am√©lioration fallback sans OpenAI avec v√©rification basique de coh√©rence"""
        
        enhanced_answer = rag_answer
        warnings = []
        clarifications = []
        
        # V√©rification basique de coh√©rence am√©lior√©e
        coherence_check = "unknown"
        coherence_notes = "V√©rification automatique basique"
        
        if enriched_question and original_question:
            # V√©rification de coh√©rence am√©lior√©e
            enriched_words = set(word.lower() for word in enriched_question.split() if len(word) > 2)
            answer_words = set(word.lower() for word in rag_answer.split() if len(word) > 2)
            
            # Mots de stop √† ignorer
            stop_words = {'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'et', 'ou', 'est', 'sont', 'the', 'and', 'or', 'is', 'are', 'a', 'an', 'of', 'to', 'in', 'for'}
            enriched_words -= stop_words
            answer_words -= stop_words
            
            # Mots-cl√©s importants communs
            important_words = enriched_words.intersection(answer_words)
            important_words = {w for w in important_words if len(w) > 3 or w in ['√¢ge', 'age', 'sex', 'sexe', 'kg', 'gr']}
            
            total_important_words = len(enriched_words.union(answer_words))
            
            if total_important_words > 0:
                similarity_ratio = len(important_words) / total_important_words
                
                if similarity_ratio >= 0.3:
                    coherence_check = "good"
                    coherence_notes = f"R√©ponse coh√©rente (similarit√©: {similarity_ratio:.1f}, mots-cl√©s: {', '.join(list(important_words)[:3])})"
                elif similarity_ratio >= 0.15:
                    coherence_check = "partial"
                    coherence_notes = f"Coh√©rence partielle (similarit√©: {similarity_ratio:.1f}, mots-cl√©s: {', '.join(important_words)})"
                else:
                    coherence_check = "poor"
                    coherence_notes = f"Faible coh√©rence (similarit√©: {similarity_ratio:.1f})"
            else:
                coherence_check = "poor"
                coherence_notes = "Aucun mot-cl√© significatif en commun"
        
        # Ajouter des avertissements selon les entit√©s manquantes
        if "breed" in missing_entities:
            if language == "fr":
                warnings.append("‚ö†Ô∏è Sans conna√Ætre la race exacte, cette r√©ponse est g√©n√©rale. Les performances varient selon la souche.")
                clarifications.append("Quelle est la race/souche de vos volailles ?")
            elif language == "en":
                warnings.append("‚ö†Ô∏è Without knowing the exact breed, this response is general. Performance varies by strain.")
                clarifications.append("What is the breed/strain of your poultry?")
            else:  # Spanish
                warnings.append("‚ö†Ô∏è Sin conocer la raza exacta, esta respuesta es general. El rendimiento var√≠a seg√∫n la cepa.")
                clarifications.append("¬øCu√°l es la raza/cepa de sus aves?")
        
        if "age" in missing_entities:
            if language == "fr":
                warnings.append("‚ö†Ô∏è L'√¢ge est crucial pour √©valuer la normalit√© des param√®tres.")
                clarifications.append("Quel est l'√¢ge de vos volailles (en jours ou semaines) ?")
            elif language == "en":
                warnings.append("‚ö†Ô∏è Age is crucial for evaluating parameter normality.")
                clarifications.append("What is the age of your poultry (in days or weeks)?")
            else:  # Spanish
                warnings.append("‚ö†Ô∏è La edad es crucial para evaluar la normalidad de los par√°metros.")
                clarifications.append("¬øCu√°l es la edad de sus aves (en d√≠as o semanas)?")
        
        if "sex" in missing_entities and any(word in rag_answer.lower() for word in ["poids", "weight", "peso", "croissance", "growth"]):
            if language == "fr":
                clarifications.append("S'agit-il de m√¢les, femelles, ou d'un troupeau mixte ?")
            elif language == "en":
                clarifications.append("Are these males, females, or a mixed flock?")
            else:  # Spanish
                clarifications.append("¬øSon machos, hembras, o un lote mixto?")
        
        # D√©terminer l'impact sur la confiance
        confidence_impact = "low"
        if len(missing_entities) >= 2:
            confidence_impact = "high"
        elif len(missing_entities) == 1:
            confidence_impact = "medium"
        
        # Ajouter un contexte si des entit√©s sont connues
        context_additions = []
        if entities.get("breed") and entities.get("breed_confidence", 0) > 0.6:
            context_additions.append(f"race {entities['breed']}")
        
        if entities.get("age_days") and entities.get("age_confidence", 0) > 0.6:
            context_additions.append(f"√¢ge {entities['age_days']} jours")
        
        if context_additions:
            context_text = " et ".join(context_additions)
            if language == "fr":
                enhanced_answer += f"\n\nüí° Cette r√©ponse consid√®re votre contexte : {context_text}."
            elif language == "en":
                enhanced_answer += f"\n\nüí° This response considers your context: {context_text}."
            else:  # Spanish
                enhanced_answer += f"\n\nüí° Esta respuesta considera su contexto: {context_text}."
        
        # Ajouter les avertissements √† la r√©ponse si critiques
        if warnings and confidence_impact in ["medium", "high"]:
            enhanced_answer += f"\n\n{' '.join(warnings)}"
        
        return {
            "enhanced_answer": enhanced_answer,
            "optional_clarifications": clarifications[:3],
            "warnings": warnings,
            "confidence_impact": confidence_impact,
            "coherence_check": coherence_check,
            "coherence_notes": coherence_notes,
            "improvement_notes": "Am√©lioration basique appliqu√©e",
            "method_used": "fallback"
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """‚úÖ FIX: Retourne les statistiques enrichies de l'agent"""
        
        total = self.stats["total_requests"]
        success_rate = (self.stats["openai_success"] / total * 100) if total > 0 else 0
        enhancement_rate = (self.stats["answers_enhanced"] / total * 100) if total > 0 else 0
        clarification_rate = (self.stats["clarifications_generated"] / total * 100) if total > 0 else 0
        coherence_issue_rate = (self.stats["coherence_issues_detected"] / total * 100) if total > 0 else 0
        field_propagation_success_rate = (self.stats["field_propagation_success"] / total * 100) if total > 0 else 0
        input_validation_rate = (self.stats["input_validation_fixes"] / total * 100) if total > 0 else 0
        
        return {
            "agent_type": "rag_enhancer",
            "total_requests": total,
            "openai_success_rate": f"{success_rate:.1f}%",
            "answer_enhancement_rate": f"{enhancement_rate:.1f}%",
            "clarification_generation_rate": f"{clarification_rate:.1f}%",
            "coherence_issue_detection_rate": f"{coherence_issue_rate:.1f}%",
            "field_propagation_success_rate": f"{field_propagation_success_rate:.1f}%",
            "input_validation_fixes_rate": f"{input_validation_rate:.1f}%",  # ‚úÖ NOUVEAU
            "openai_available": self.openai_available,
            "model_used": self.model,
            "detailed_stats": self.stats.copy()
        }

# Instance globale
agent_rag_enhancer = AgentRAGEnhancer()

# ‚úÖ FIX: Fonction utilitaire avec validation d√©fensive
async def enhance_rag_answer(
    rag_answer: str,
    entities: Dict[str, Any] = None,  # ‚úÖ FIX: Valeur par d√©faut None
    missing_entities: List[str] = None,  # ‚úÖ FIX: Valeur par d√©faut None
    conversation_context: str = "",
    original_question: str = "",
    enriched_question: str = "",
    language: str = "fr",
    **additional_fields
) -> Dict[str, Any]:
    """
    ‚úÖ FIX: Fonction utilitaire avec validation d√©fensive et propagation compl√®te
    """
    return await agent_rag_enhancer.enhance_rag_answer(
        rag_answer, 
        entities or {}, 
        missing_entities or [], 
        conversation_context, 
        original_question, 
        enriched_question, 
        language, 
        **additional_fields
    )