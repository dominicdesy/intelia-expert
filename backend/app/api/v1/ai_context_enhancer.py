"""
ai_context_enhancer.py - ENHANCEMENT CONTEXTUEL AVEC IA

üéØ REMPLACE: 200+ lignes de patterns pronominaux rigides par compr√©hension IA
üöÄ CAPACIT√âS:
- ‚úÖ Analyse conversationnelle intelligente
- ‚úÖ R√©solution des r√©f√©rences contextuelles ("leur poids", "ces poulets")
- ‚úÖ Enhancement pour recherche documentaire (RAG)
- ‚úÖ D√©tection des clarifications implicites
- ‚úÖ Fusion contextuelle automatique
- ‚úÖ Support multilingue natif

Architecture:
- Analyse IA du contexte conversationnel
- Enhancement automatique des questions pour RAG
- Fusion intelligente des entit√©s contextuelles
- Optimisation des requ√™tes de recherche
"""

import json
import logging
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass
from datetime import datetime

from .ai_service_manager import AIServiceType, call_ai, AIResponse

logger = logging.getLogger(__name__)

@dataclass
class ContextAnalysis:
    """R√©sultat de l'analyse contextuelle"""
    references_detected: bool = False
    enhanced_question: str = ""
    context_entities: Dict[str, Any] = None
    missing_context: List[str] = None
    confidence: float = 0.0
    reasoning: str = ""
    
    def __post_init__(self):
        if self.context_entities is None:
            self.context_entities = {}
        if self.missing_context is None:
            self.missing_context = []

@dataclass  
class EnhancedContext:
    """Contexte enrichi pour la recherche et g√©n√©ration"""
    original_question: str
    enhanced_question: str
    merged_entities: Dict[str, Any]
    rag_optimized_query: str
    context_summary: str
    enhancement_confidence: float
    ai_reasoning: str

class AIContextEnhancer:
    """Enhancer contextuel avec IA - Remplace les patterns pronominaux"""
    
    def __init__(self):
        # Configuration des mod√®les
        self.models = {
            "context_analysis": "gpt-4",      # Analyse contextuelle complexe
            "question_enhancement": "gpt-4",   # Enhancement de questions
            "entity_fusion": "gpt-3.5-turbo", # Fusion d'entit√©s
            "rag_optimization": "gpt-4"        # Optimisation pour RAG
        }
        
        # Prompts sp√©cialis√©s
        self.prompts = self._initialize_prompts()
        
        logger.info("ü§ñ [AI Context Enhancer] Initialis√© avec analyse IA contextuelle")
    
    def _initialize_prompts(self) -> Dict[str, str]:
        """Initialise les prompts sp√©cialis√©s pour l'enhancement contextuel"""
        return {
            "context_analysis": """Analyse cette question dans son contexte conversationnel pour d√©tecter les r√©f√©rences implicites.

QUESTION ACTUELLE: "{current_question}"

CONTEXTE CONVERSATIONNEL:
{conversation_context}

T√ÇCHE: D√©termine si la question fait r√©f√©rence √† des √©l√©ments du contexte pr√©c√©dent.

Recherche:
1. **PRONOMS/R√âF√âRENCES**: "leur", "son", "ces", "ils", "elles", etc.
2. **R√âF√âRENCES IMPLICITES**: "√† cet √¢ge", "pour cette race", "dans ce cas"
3. **CONTEXTE MANQUANT**: √©l√©ments n√©cessaires non explicites

R√©ponds en JSON:
```json
{{
  "references_detected": true|false,
  "reference_types": ["pronoms", "implicite", "contextuel"],
  "referenced_entities": {{
    "breed": "race r√©f√©renc√©e du contexte",
    "age": "√¢ge r√©f√©renc√© du contexte", 
    "sex": "sexe r√©f√©renc√© du contexte",
    "previous_topic": "sujet pr√©c√©dent"
  }},
  "missing_context": ["√©l√©ments manquants pour comprendre"],
  "confidence": 0.0-1.0,
  "analysis_reasoning": "explication de l'analyse"
}}
```

EXEMPLES:
- "Leur poids √† 21 jours ?" ‚Üí r√©f√©rences √† une race mentionn√©e pr√©c√©demment
- "Et pour les femelles ?" ‚Üí r√©f√©rence au sexe oppos√© d'une discussion pr√©c√©dente
- "√Ä cet √¢ge, c'est normal ?" ‚Üí r√©f√©rence √† un √¢ge mentionn√© pr√©c√©demment""",

            "question_enhancement": """Enrichis cette question en rendant explicites toutes les r√©f√©rences contextuelles.

QUESTION ORIGINALE: "{original_question}"

CONTEXTE IDENTIFI√â:
{context_entities}

R√âF√âRENCES D√âTECT√âES:
{references_detected}

T√ÇCHE: Reformule la question en rendant tout explicite et auto-suffisant.

R√àGLES:
1. Remplace les pronoms par les entit√©s concr√®tes
2. Explicite les r√©f√©rences implicites  
3. Conserve l'intention originale
4. Rends la question optimale pour recherche documentaire
5. Garde un langage naturel

EXEMPLES:
- "Leur poids normal ?" + Contexte[Ross 308, 21 jours] ‚Üí "Quel est le poids normal des poulets Ross 308 √† 21 jours ?"
- "Et les femelles ?" + Contexte[Cobb 500, m√¢les, poids] ‚Üí "Quel est le poids normal des Cobb 500 femelles ?"
- "C'est normal √† cet √¢ge ?" + Contexte[croissance, 14 jours] ‚Üí "La croissance est-elle normale pour des poulets de 14 jours ?"

R√©ponds en JSON:
```json
{{
  "enhanced_question": "question reformul√©e explicite",
  "entities_added": ["entit√©s ajout√©es du contexte"],
  "enhancement_confidence": 0.0-1.0,
  "enhancement_reasoning": "explication des modifications"
}}
```""",

            "entity_fusion": """Fusionne intelligemment les entit√©s actuelles avec le contexte conversationnel.

ENTIT√âS ACTUELLES:
{current_entities}

CONTEXTE CONVERSATIONNEL:
{context_entities}

T√ÇCHE: Combine les entit√©s pour cr√©er une vue compl√®te et coh√©rente.

R√àGLES DE FUSION:
1. **PRIORIT√â**: Entit√©s actuelles > contexte (sauf si actuelles vides)
2. **H√âRITAGE**: H√©rite du contexte si entit√©s actuelles incompl√®tes
3. **COH√âRENCE**: V√©rifie compatibilit√© des combinaisons
4. **COMPL√âTION**: Comble les manques avec le contexte

LOGIQUE:
- Si breed actuel vide et breed contexte pr√©sent ‚Üí h√©rite
- Si age actuel vide et age contexte pr√©sent ‚Üí h√©rite  
- Si sex actuel vide et sex contexte pr√©sent ‚Üí h√©rite
- Si context_type actuel vague et contexte pr√©cis ‚Üí h√©rite

R√©ponds en JSON:
```json
{{
  "merged_entities": {{
    "age_days": number|null,
    "breed_specific": "breed"|null,
    "sex": "male"|"female"|"mixed"|null,
    "context_type": "performance"|"sant√©"|"alimentation",
    "weight_mentioned": true|false,
    "inherited_from_context": ["liste des champs h√©rit√©s"]
  }},
  "fusion_confidence": 0.0-1.0,
  "fusion_notes": "explication de la fusion"
}}
```""",

            "rag_optimization": """Optimise cette question pour la recherche documentaire (RAG) dans une base de connaissances avicoles.

QUESTION ENHANCED: "{enhanced_question}"
ENTIT√âS FUSIONN√âES: {merged_entities}

T√ÇCHE: Cr√©e une requ√™te optimale pour r√©cup√©rer les documents les plus pertinents.

OPTIMISATIONS:
1. **MOTS-CL√âS TECHNIQUES**: Utilise terminologie sp√©cialis√©e avicole
2. **SYNONYMES**: Inclus variations (croissance/d√©veloppement, poids/masse)
3. **SP√âCIFICIT√â**: Balance sp√©cificit√© et couverture
4. **STRUCTURE**: Organise pour matching s√©mantique optimal

EXEMPLES:
- "Poids normal Ross 308 m√¢les 21 jours" ‚Üí "poids standard poulets broilers Ross 308 m√¢les trois semaines 21 jours croissance normale"
- "Sympt√¥mes diarrh√©e poules pondeuses" ‚Üí "diarrh√©e troubles digestifs poules pondeuses sympt√¥mes sant√© intestinale"

R√©ponds en JSON:
```json
{{
  "rag_query": "requ√™te optimis√©e pour recherche",
  "key_terms": ["termes", "cl√©s", "importants"],
  "synonyms_included": ["variations", "ajout√©es"],
  "optimization_confidence": 0.0-1.0,
  "optimization_notes": "explication des optimisations"
}}
```""",

            "context_summary": """Cr√©e un r√©sum√© du contexte conversationnel pour m√©moire √† long terme.

HISTORIQUE CONVERSATION:
{conversation_history}

ENTIT√âS √âTABLIES:
{established_entities}

T√ÇCHE: R√©sume l'essentiel pour maintenir la coh√©rence conversationnelle.

R√âSUM√â DOIT INCLURE:
1. **SUJET PRINCIPAL**: Th√®me de la conversation
2. **ENTIT√âS √âTABLIES**: Race, √¢ge, sexe, contexte r√©currents
3. **PATTERN QUESTIONS**: Type de questions pos√©es
4. **CONTEXTE TECHNIQUE**: Niveau technique de l'utilisateur

R√©ponds en JSON:
```json
{{
  "conversation_topic": "sujet principal",
  "established_entities": {{
    "breed": "race √©tablie",
    "typical_age": "√¢ge typique discut√©", 
    "sex": "sexe typique",
    "context_type": "type de questions"
  }},
  "user_profile": {{
    "technical_level": "d√©butant|interm√©diaire|expert",
    "focus_areas": ["domaines d'int√©r√™t"],
    "question_patterns": ["types de questions r√©currentes"]
  }},
  "summary_confidence": 0.0-1.0
}}
```"""
        }
    
    async def analyze_conversational_context(self, 
                                           current_question: str, 
                                           conversation_history: str,
                                           language: str = "fr") -> ContextAnalysis:
        """
        Analyse le contexte conversationnel pour d√©tecter les r√©f√©rences
        
        Args:
            current_question: Question actuelle de l'utilisateur
            conversation_history: Historique de la conversation  
            language: Langue d√©tect√©e
            
        Returns:
            ContextAnalysis avec les r√©f√©rences d√©tect√©es
        """
        try:
            logger.info(f"ü§ñ [AI Context Enhancer] Analyse contextuelle: '{current_question[:50]}...'")
            
            # Pr√©parer le contexte pour analyse
            context_prompt = self.prompts["context_analysis"].format(
                current_question=current_question,
                conversation_context=conversation_history[:2000]  # Limiter pour token efficiency
            )
            
            # Analyse IA du contexte
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=context_prompt,
                model=self.models["context_analysis"],
                max_tokens=600,
                temperature=0.1,
                cache_key=f"context_analysis_{hash(current_question + conversation_history[:500])}"
            )
            
            # Parser le r√©sultat
            analysis_data = self._parse_json_response(ai_response.content)
            
            # Construire ContextAnalysis
            analysis = ContextAnalysis(
                references_detected=analysis_data.get("references_detected", False),
                context_entities=analysis_data.get("referenced_entities", {}),
                missing_context=analysis_data.get("missing_context", []),
                confidence=analysis_data.get("confidence", 0.0),
                reasoning=analysis_data.get("analysis_reasoning", "")
            )
            
            logger.info(f"‚úÖ [AI Context Enhancer] Analyse termin√©e: r√©f√©rences={analysis.references_detected}, confiance={analysis.confidence}")
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur analyse contextuelle: {e}")
            return ContextAnalysis(reasoning=f"Erreur: {e}")
    
    async def enhance_question_for_rag(self, 
                                     original_question: str,
                                     conversation_context: str = "",
                                     current_entities: Dict[str, Any] = None,
                                     language: str = "fr") -> EnhancedContext:
        """
        Point d'entr√©e principal - Enhancement complet pour RAG
        
        Args:
            original_question: Question originale
            conversation_context: Contexte conversationnel
            current_entities: Entit√©s extraites de la question actuelle
            language: Langue
            
        Returns:
            EnhancedContext avec question optimis√©e et contexte fusionn√©
        """
        try:
            logger.info(f"ü§ñ [AI Context Enhancer] Enhancement complet: '{original_question[:50]}...'")
            
            if current_entities is None:
                current_entities = {}
            
            # 1. Analyser le contexte conversationnel
            context_analysis = await self.analyze_conversational_context(
                original_question, conversation_context, language
            )
            
            # 2. Enhancer la question si r√©f√©rences d√©tect√©es
            enhanced_question = original_question
            if context_analysis.references_detected:
                enhanced_question = await self._enhance_question_with_context(
                    original_question, context_analysis.context_entities
                )
            
            # 3. Fusionner les entit√©s
            merged_entities = await self._merge_entities_with_context(
                current_entities, context_analysis.context_entities
            )
            
            # 4. Optimiser pour RAG
            rag_query = await self._optimize_for_rag(enhanced_question, merged_entities)
            
            # 5. Cr√©er le r√©sum√© contextuel
            context_summary = await self._create_context_summary(
                conversation_context, merged_entities
            )
            
            # Construire r√©sultat final
            enhanced_context = EnhancedContext(
                original_question=original_question,
                enhanced_question=enhanced_question,
                merged_entities=merged_entities,
                rag_optimized_query=rag_query,
                context_summary=context_summary,
                enhancement_confidence=context_analysis.confidence,
                ai_reasoning=context_analysis.reasoning
            )
            
            logger.info(f"‚úÖ [AI Context Enhancer] Enhancement termin√©: '{enhanced_question}'")
            
            return enhanced_context
            
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur enhancement: {e}")
            # Retour fallback
            return EnhancedContext(
                original_question=original_question,
                enhanced_question=original_question,
                merged_entities=current_entities or {},
                rag_optimized_query=original_question,
                context_summary="Erreur enhancement contextuel",
                enhancement_confidence=0.0,
                ai_reasoning=f"Erreur: {e}"
            )
    
    async def _enhance_question_with_context(self, 
                                           original_question: str, 
                                           context_entities: Dict[str, Any]) -> str:
        """Enhancement de la question avec contexte"""
        
        try:
            prompt = self.prompts["question_enhancement"].format(
                original_question=original_question,
                context_entities=json.dumps(context_entities, ensure_ascii=False),
                references_detected=True
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["question_enhancement"],
                max_tokens=400,
                temperature=0.1
            )
            
            result = self._parse_json_response(ai_response.content)
            enhanced = result.get("enhanced_question", original_question)
            
            logger.info(f"‚úÖ [Question Enhancement] '{original_question}' ‚Üí '{enhanced}'")
            return enhanced
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Question Enhancement] Erreur: {e}")
            return original_question
    
    async def _merge_entities_with_context(self, 
                                         current_entities: Dict[str, Any], 
                                         context_entities: Dict[str, Any]) -> Dict[str, Any]:
        """Fusion intelligente des entit√©s"""
        
        try:
            prompt = self.prompts["entity_fusion"].format(
                current_entities=json.dumps(current_entities, ensure_ascii=False),
                context_entities=json.dumps(context_entities, ensure_ascii=False)
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["entity_fusion"],
                max_tokens=500,
                temperature=0.05
            )
            
            result = self._parse_json_response(ai_response.content)
            merged = result.get("merged_entities", current_entities)
            
            logger.info(f"‚úÖ [Entity Fusion] Entit√©s fusionn√©es: {len(merged)} champs")
            return merged
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Entity Fusion] Erreur: {e}")
            # Fusion simple en fallback
            return {**context_entities, **current_entities}
    
    async def _optimize_for_rag(self, enhanced_question: str, merged_entities: Dict[str, Any]) -> str:
        """Optimise la question pour la recherche RAG"""
        
        try:
            prompt = self.prompts["rag_optimization"].format(
                enhanced_question=enhanced_question,
                merged_entities=json.dumps(merged_entities, ensure_ascii=False)
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["rag_optimization"],
                max_tokens=300,
                temperature=0.1
            )
            
            result = self._parse_json_response(ai_response.content)
            rag_query = result.get("rag_query", enhanced_question)
            
            logger.info(f"‚úÖ [RAG Optimization] Query optimis√©e: '{rag_query}'")
            return rag_query
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [RAG Optimization] Erreur: {e}")
            return enhanced_question
    
    async def _create_context_summary(self, conversation_history: str, entities: Dict[str, Any]) -> str:
        """Cr√©e un r√©sum√© du contexte pour m√©moire"""
        
        try:
            if not conversation_history or len(conversation_history) < 50:
                return "Conversation nouvelle - pas d'historique"
            
            prompt = self.prompts["context_summary"].format(
                conversation_history=conversation_history[-1000:],  # Derniers √©l√©ments
                established_entities=json.dumps(entities, ensure_ascii=False)
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model="gpt-3.5-turbo",  # Suffisant pour r√©sum√©
                max_tokens=300,
                temperature=0.2
            )
            
            result = self._parse_json_response(ai_response.content)
            topic = result.get("conversation_topic", "Discussion g√©n√©rale")
            
            return f"Sujet: {topic} | Entit√©s: {result.get('established_entities', {})}"
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Context Summary] Erreur: {e}")
            return "R√©sum√© contextuel indisponible"
    
    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """Parse une r√©ponse JSON de l'IA avec gestion d'erreurs"""
        
        try:
            # Nettoyer le contenu
            content = content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            return json.loads(content)
            
        except json.JSONDecodeError as e:
            logger.warning(f"‚ö†Ô∏è [AI Context Enhancer] Erreur parsing JSON: {e}")
            return {}
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur parsing: {e}")
            return {}
    
    async def enhance_for_classification(self, 
                                       question: str, 
                                       conversation_context: str = "") -> Dict[str, Any]:
        """Enhancement sp√©cialis√© pour am√©liorer la classification"""
        
        try:
            # Analyse rapide pour la classification
            enhanced_context = await self.enhance_question_for_rag(
                question, conversation_context
            )
            
            return {
                "enhanced_question": enhanced_context.enhanced_question,
                "context_confidence": enhanced_context.enhancement_confidence,
                "has_references": enhanced_context.enhanced_question != question,
                "merged_entities": enhanced_context.merged_entities,
                "classification_hints": {
                    "likely_contextual": enhanced_context.enhancement_confidence > 0.7,
                    "needs_clarification": enhanced_context.enhancement_confidence < 0.3,
                    "has_sufficient_context": len(enhanced_context.merged_entities) >= 2
                }
            }
            
        