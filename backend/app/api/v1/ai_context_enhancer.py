"""
ai_context_enhancer.py - ENHANCEMENT CONTEXTUEL AVEC IA - VERSION CORRIG√âE

üéØ CORRECTIONS APPLIQU√âES:
- ‚úÖ FUSION STRICTE: Emp√™che l'h√©ritage non justifi√© d'entit√©s contextuelles
- ‚úÖ D√âTECTION AUTONOME: Identifie les questions sans r√©f√©rences contextuelles
- ‚úÖ VALIDATION POST-FUSION: V√©rifie la coh√©rence des fusions
- ‚úÖ OPTIMISATION PERFORMANCE: Bypass intelligent pour questions simples
- ‚úÖ GESTION D'ERREURS ROBUSTE: Fallbacks conservateurs
- ‚úÖ LOGGING D√âTAILL√â: Tra√ßabilit√© compl√®te des d√©cisions

üöÄ PRINCIPE CORRIG√â: "Ross 308 male" ne doit PAS h√©riter l'√¢ge du contexte pr√©c√©dent
üîß LOGIQUE: Fusion uniquement sur r√©f√©rences contextuelles explicites
‚ú® PERFORMANCE: Bypass automatique pour questions autonomes
üí° ROBUSTESSE: Validation syst√©matique des r√©sultats IA

Architecture:
- Analyse contextuelle stricte avec pr√©-filtrage
- Fusion d'entit√©s avec r√®gles de priorit√© claires
- Optimisation RAG avec validation
- Fallbacks conservateurs sur toutes les √©tapes
"""

import json
import logging
import re
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass
from datetime import datetime

from .ai_service_manager import AIServiceType, call_ai, AIResponse

logger = logging.getLogger(__name__)

@dataclass
class ContextAnalysis:
    """R√©sultat de l'analyse contextuelle"""
    references_detected: bool = False
    enhanced_question: str = ""
    context_entities: Dict[str, Any] = None
    missing_context: List[str] = None
    confidence: float = 0.0
    reasoning: str = ""
    is_standalone: bool = False  # ‚úÖ NOUVEAU: Flag pour questions autonomes
    
    def __post_init__(self):
        if self.context_entities is None:
            self.context_entities = {}
        if self.missing_context is None:
            self.missing_context = []

@dataclass  
class EnhancedContext:
    """Contexte enrichi pour la recherche et g√©n√©ration"""
    original_question: str
    enhanced_question: str
    merged_entities: Dict[str, Any]
    rag_optimized_query: str
    context_summary: str
    enhancement_confidence: float
    ai_reasoning: str
    fusion_applied: bool = False  # ‚úÖ NOUVEAU: Indique si fusion contextuelle appliqu√©e
    inheritance_log: List[str] = None  # ‚úÖ NOUVEAU: Log des h√©ritages appliqu√©s
    
    def __post_init__(self):
        if self.inheritance_log is None:
            self.inheritance_log = []

class AIContextEnhancer:
    """Enhancer contextuel avec IA - Version corrig√©e avec fusion stricte"""
    
    def __init__(self):
        # Configuration des mod√®les
        self.models = {
            "context_analysis": "gpt-4o-mini",     # ‚úÖ OPTIMIS√â: gpt-4 ‚Üí gpt-4o-mini pour performance
            "question_enhancement": "gpt-4o-mini", # ‚úÖ OPTIMIS√â: Performance/co√ªt
            "entity_fusion": "gpt-4o-mini",        # ‚úÖ OPTIMIS√â: Suffisant pour fusion
            "rag_optimization": "gpt-4o-mini"      # ‚úÖ OPTIMIS√â: Performance
        }
        
        # ‚úÖ NOUVEAU: Configuration des timeouts par service
        self.timeouts = {
            "context_analysis": 8,     # 8s pour analyse contextuelle
            "question_enhancement": 6, # 6s pour enhancement
            "entity_fusion": 5,        # 5s pour fusion
            "rag_optimization": 4      # 4s pour optimisation RAG
        }
        
        # ‚úÖ NOUVEAU: Patterns pour d√©tection automatique
        self.standalone_patterns = [
            r"^(Ross|Cobb|Hubbard)\s*\d+\s+(male|female|m√¢le|femelle|mixte?)$",  # "Ross 308 male"
            r"^(Ross|Cobb|Hubbard)\s*\d+$",  # "Ross 308"
            r"^\w+\s+(poulet|chicken|broiler|poule)\s+(de\s+)?\d+\s+(jour|day|semaine|week)",  # "poulet de 21 jours"
            r"^(Quel|What)\s+(est|is)\s+le\s+poids",  # Questions compl√®tes de poids
        ]
        
        # ‚úÖ NOUVEAU: Mots-cl√©s contextuels pour d√©tection r√©f√©rences
        self.contextual_indicators = {
            "pronouns": ["leur", "son", "sa", "ses", "ces", "cette", "cet", "ils", "elles"],
            "references": ["aussi", "√©galement", "comme", "suite", "pr√©c√©demment", "d√©j√†", "encore"],
            "temporal": ["maintenant", "√† pr√©sent", "√† cet √¢ge", "dans ce cas", "pour eux"],
            "implicit": ["et pour", "qu'en est-il", "et alors", "et si", "m√™me chose"]
        }
        
        # Prompts sp√©cialis√©s
        self.prompts = self._initialize_prompts()
        
        # ‚úÖ NOUVEAU: Statistiques pour monitoring
        self.stats = {
            "total_enhancements": 0,
            "standalone_bypassed": 0,
            "context_fusions": 0,
            "inheritance_applied": 0,
            "inheritance_rejected": 0,
            "errors": 0
        }
        
        logger.info("ü§ñ [AI Context Enhancer] Initialis√© avec fusion stricte et d√©tection autonome")
    
    def _initialize_prompts(self) -> Dict[str, str]:
        """Initialise les prompts sp√©cialis√©s - VERSION CORRIG√âE"""
        return {
            "context_analysis": """Analyse cette question dans son contexte conversationnel pour d√©tecter les r√©f√©rences implicites EXPLICITES.

QUESTION ACTUELLE: "{current_question}"

CONTEXTE CONVERSATIONNEL:
{conversation_context}

‚ö†Ô∏è R√àGLES STRICTES DE D√âTECTION:
1. **R√âF√âRENCES EXPLICITES SEULEMENT**: Cherche des pronoms, r√©f√©rences temporelles, ou liens directs
2. **PAS D'INF√âRENCE**: Ne pas d√©duire de r√©f√©rences qui n'existent pas
3. **AUTONOMIE D'ABORD**: Si la question est compl√®te et autonome, pas de r√©f√©rences

üîç RECHERCHE SP√âCIFIQUE:
- **PRONOMS**: "leur", "son", "ces", "ils", "elles"
- **R√âF√âRENCES TEMPORELLES**: "√† cet √¢ge", "comme pr√©c√©demment", "maintenant"
- **R√âF√âRENCES IMPLICITES**: "et pour", "aussi", "√©galement", "m√™me chose"
- **CONTINUATIONS**: "et alors", "qu'en est-il de", "et si"

‚ùå NE PAS D√âTECTER COMME R√âF√âRENCE:
- Questions compl√®tes avec race/√¢ge/sexe explicites: "Ross 308 male", "poulet 21 jours"
- Questions techniques autonomes: "Quel est le poids normal..."
- Informations factuelles: "Hubbard femelle", "Cobb 500"

‚úÖ D√âTECTER COMME R√âF√âRENCE:
- "Leur poids ?" ‚Üí r√©f√©rence √† une race/groupe mentionn√©
- "Et les femelles ?" ‚Üí r√©f√©rence au sexe oppos√©
- "√Ä cet √¢ge ?" ‚Üí r√©f√©rence √† un √¢ge mentionn√©
- "M√™me chose pour..." ‚Üí r√©f√©rence √† une situation pr√©c√©dente

R√©ponds en JSON:
```json
{{
  "references_detected": true|false,
  "reference_types": ["pronoms"|"implicite"|"temporel"|"continuation"],
  "specific_references": {{
    "pronouns_found": ["pronoms d√©tect√©s"],
    "temporal_references": ["r√©f√©rences temporelles"],
    "implicit_references": ["r√©f√©rences implicites"]
  }},
  "referenced_entities": {{
    "breed": "race r√©f√©renc√©e du contexte"|null,
    "age": "√¢ge r√©f√©renc√© du contexte"|null,
    "sex": "sexe r√©f√©renc√© du contexte"|null,
    "previous_topic": "sujet pr√©c√©dent"|null
  }},
  "is_standalone_question": true|false,
  "confidence": 0.0-1.0,
  "analysis_reasoning": "explication D√âTAILL√âE de la pr√©sence/absence de r√©f√©rences"
}}
```""",

            "question_enhancement": """Enrichis cette question UNIQUEMENT si des r√©f√©rences contextuelles explicites ont √©t√© d√©tect√©es.

QUESTION ORIGINALE: "{original_question}"

CONTEXTE IDENTIFI√â:
{context_entities}

R√âF√âRENCES D√âTECT√âES: {references_detected}

‚ö†Ô∏è R√àGLES STRICTES D'ENHANCEMENT:
1. **SEULEMENT SI R√âF√âRENCES**: N'enrichis QUE si references_detected = true
2. **REMPLACEMENT EXPLICITE**: Remplace les pronoms/r√©f√©rences par les entit√©s concr√®tes
3. **CONSERVATION INTENTION**: Conserve exactement l'intention originale
4. **PAS DE SURINTERPR√âTATION**: Si pas de r√©f√©rences claires, retourne la question originale

‚úÖ EXEMPLES VALIDES:
- "Leur poids ?" + Contexte[Ross 308] ‚Üí "Quel est le poids des Ross 308 ?"
- "Et les femelles ?" + Contexte[Cobb 500, m√¢les] ‚Üí "Et les Cobb 500 femelles ?"
- "√Ä cet √¢ge ?" + Contexte[21 jours] ‚Üí "√Ä 21 jours ?"

‚ùå EXEMPLES INVALIDES (PAS D'ENHANCEMENT):
- "Ross 308 male" ‚Üí PAS de r√©f√©rences ‚Üí retourner tel quel
- "Poulet 21 jours" ‚Üí Question autonome ‚Üí retourner tel quel

R√©ponds en JSON:
```json
{{
  "enhanced_question": "question reformul√©e OU originale si pas de r√©f√©rences",
  "enhancement_applied": true|false,
  "entities_added": ["entit√©s ajout√©es du contexte"],
  "enhancement_confidence": 0.0-1.0,
  "enhancement_reasoning": "explication des modifications ou pourquoi pas de modifications"
}}
```""",

            "entity_fusion": """Fusionne les entit√©s UNIQUEMENT si la question actuelle contient des r√©f√©rences contextuelles explicites.

ENTIT√âS ACTUELLES (QUESTION ACTUELLE):
{current_entities}

ENTIT√âS CONTEXTUELLES (CONVERSATION PR√âC√âDENTE):
{context_entities}

R√âF√âRENCES D√âTECT√âES: {references_detected}

‚ö†Ô∏è R√àGLES DE FUSION ULTRA-STRICTES:
1. **PAS DE FUSION SI PAS DE R√âF√âRENCES**: Si references_detected = false, retourner entit√©s actuelles inchang√©es
2. **PRIORIT√â ABSOLUE AUX ENTIT√âS ACTUELLES**: Toujours garder les entit√©s de la question actuelle
3. **H√âRITAGE CONDITIONNEL**: H√©riter du contexte SEULEMENT si:
   - L'entit√© actuelle est null/vide ET
   - Il y a une r√©f√©rence contextuelle explicite ET  
   - L'h√©ritage est logiquement coh√©rent

‚õî INTERDICTIONS ABSOLUES:
- ‚ùå "Ross 308 male" + Contexte[age: 11] ‚Üí N'ajouter AUCUN √¢ge
- ‚ùå "Poulet 21 jours" + Contexte[breed: Cobb] ‚Üí N'ajouter AUCUNE race
- ‚ùå Question autonome ‚Üí AUCUNE fusion contextuelle

‚úÖ CAS VALIDES POUR H√âRITAGE:
- "Leur poids ?" + Contexte[Ross 308, 21j] ‚Üí H√©rite race ET √¢ge (r√©f√©rence "leur")
- "Et les femelles ?" + Contexte[Cobb 500] ‚Üí H√©rite race (r√©f√©rence explicite sexe oppos√©)
- "√Ä cet √¢ge ?" + Contexte[age: 14] ‚Üí H√©rite √¢ge (r√©f√©rence temporelle explicite)

LOGIQUE DE D√âCISION:
```
SI references_detected == false:
    RETOURNER entit√©s_actuelles inchang√©es
SINON:
    POUR chaque entit√©:
        SI entit√©_actuelle pr√©sente:
            GARDER entit√©_actuelle
        SINON SI entit√©_actuelle vide ET r√©f√©rence_contextuelle_explicite:
            H√âRITER du contexte
        SINON:
            LAISSER null
```

R√©ponds en JSON:
```json
{{
  "fusion_decision": "no_fusion"|"inheritance_applied"|"entities_preserved",
  "merged_entities": {{
    "age_days": number|null,
    "breed_specific": "breed"|null,
    "sex": "male"|"female"|"mixed"|null,
    "context_type": "performance"|"sant√©"|"alimentation",
    "weight_mentioned": true|false
  }},
  "inherited_from_context": ["liste des entit√©s h√©rit√©es avec justification"],
  "fusion_confidence": 0.0-1.0,
  "fusion_reasoning": "explication D√âTAILL√âE de chaque d√©cision de fusion/non-fusion"
}}
```""",

            "rag_optimization": """Optimise cette question pour la recherche documentaire RAG dans une base avicole.

QUESTION ENHANCED: "{enhanced_question}"
ENTIT√âS FUSIONN√âES: {merged_entities}

T√ÇCHE: Cr√©e une requ√™te de recherche optimis√©e en conservant la pr√©cision.

OPTIMISATIONS STANDARD:
1. **TERMINOLOGIE TECHNIQUE**: Utilise les termes sp√©cialis√©s avicoles
2. **SYNONYMES PERTINENTS**: Ajoute variations courantes
3. **√âQUILIBRE**: Balance sp√©cificit√© et couverture de recherche
4. **STRUCTURE S√âMANTIQUE**: Organise pour matching optimal

‚ö° OPTIMISATION PERFORMANCE:
- Limiter √† 20-30 mots maximum
- Privil√©gier les termes les plus discriminants
- √âviter les mots vides ("le", "la", "des", "pour")

EXEMPLES:
- "Poids Ross 308 m√¢les 21 jours" ‚Üí "poids standard broilers Ross 308 m√¢les trois semaines 21 jours croissance"
- "Diarrh√©e poules pondeuses" ‚Üí "diarrh√©e troubles digestifs poules pondeuses sant√© intestinale sympt√¥mes"
- "Alimentation Cobb 500 d√©marrage" ‚Üí "alimentation nutrition Cobb 500 d√©marrage starter feed premi√®re semaine"

R√©ponds en JSON:
```json
{{
  "rag_query": "requ√™te optimis√©e concise",
  "key_terms": ["termes", "cl√©s", "essentiels"],
  "synonyms_added": ["synonymes", "ajout√©s"],
  "optimization_confidence": 0.0-1.0,
  "optimization_notes": "explication concise des optimisations"
}}
```""",

            "context_summary": """Cr√©e un r√©sum√© concis du contexte conversationnel.

HISTORIQUE CONVERSATION:
{conversation_history}

ENTIT√âS √âTABLIES:
{established_entities}

T√ÇCHE: R√©sume l'essentiel en maximum 100 mots.

√âL√âMENTS √Ä INCLURE:
1. **SUJET PRINCIPAL**: Th√®me dominant de la conversation
2. **ENTIT√âS R√âCURRENTES**: Race, √¢ge, sexe mentionn√©s fr√©quemment
3. **TYPE DE QUESTIONS**: Pattern des demandes utilisateur
4. **NIVEAU TECHNIQUE**: Expertise apparente de l'utilisateur

R√©ponds en JSON:
```json
{{
  "conversation_topic": "sujet principal en 1-2 mots",
  "dominant_entities": {{
    "breed": "race principale discut√©e"|null,
    "typical_age": "√¢ge typique"|null,
    "sex": "sexe typique"|null,
    "context_type": "type de questions dominant"
  }},
  "user_profile": {{
    "technical_level": "d√©butant"|"interm√©diaire"|"expert",
    "focus_areas": ["domaines principaux"]
  }},
  "summary_confidence": 0.0-1.0
}}
```"""
        }
    
    def _is_standalone_question(self, question: str) -> bool:
        """‚úÖ NOUVEAU: D√©tecte si une question est autonome (sans r√©f√©rences contextuelles)"""
        
        question_stripped = question.strip()
        
        # 1. V√©rification par patterns de questions autonomes
        for pattern in self.standalone_patterns:
            if re.match(pattern, question_stripped, re.IGNORECASE):
                logger.debug(f"üéØ [Standalone Detection] Pattern match: '{question_stripped}'")
                return True
        
        # 2. V√©rification absence de mots contextuels
        question_lower = question_stripped.lower()
        
        # Recherche de tous les indicateurs contextuels
        contextual_found = []
        for category, words in self.contextual_indicators.items():
            for word in words:
                if word in question_lower:
                    contextual_found.append(f"{category}:{word}")
        
        # Si aucun mot contextuel trouv√©, probablement autonome
        is_standalone = len(contextual_found) == 0
        
        # 3. V√©rification longueur et complexit√©
        word_count = len(question_stripped.split())
        if word_count >= 6:  # Questions longues souvent autonomes
            is_standalone = is_standalone or True
        
        logger.debug(f"üîç [Standalone Detection] '{question_stripped}': contextual={contextual_found}, standalone={is_standalone}")
        
        return is_standalone
    
    async def analyze_conversational_context(self, 
                                           current_question: str, 
                                           conversation_history: str,
                                           language: str = "fr") -> ContextAnalysis:
        """
        ‚úÖ CORRIG√â: Analyse contextuelle avec pr√©-filtrage strict
        """
        try:
            self.stats["total_enhancements"] += 1
            
            logger.info(f"ü§ñ [AI Context Enhancer] Analyse contextuelle: '{current_question[:50]}...'")
            
            # ‚úÖ NOUVEAU: Pr√©-filtrage pour questions autonomes
            if self._is_standalone_question(current_question):
                self.stats["standalone_bypassed"] += 1
                logger.info("üöÄ [Context Enhancer] Question autonome d√©tect√©e - bypass analyse contextuelle")
                return ContextAnalysis(
                    references_detected=False,
                    enhanced_question=current_question,
                    confidence=0.95,
                    reasoning="Question autonome sans r√©f√©rences contextuelles - analyse bypassed",
                    is_standalone=True
                )
            
            # ‚úÖ NOUVEAU: V√©rification contexte minimal requis
            if not conversation_history or len(conversation_history.strip()) < 20:
                logger.info("üì≠ [Context Enhancer] Contexte conversationnel insuffisant")
                return ContextAnalysis(
                    references_detected=False,
                    enhanced_question=current_question,
                    confidence=0.8,
                    reasoning="Contexte conversationnel insuffisant pour d√©tecter des r√©f√©rences"
                )
            
            # Analyse IA du contexte
            context_prompt = self.prompts["context_analysis"].format(
                current_question=current_question,
                conversation_context=conversation_history[-1500:]  # ‚úÖ OPTIMIS√â: 2000 ‚Üí 1500 pour performance
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=context_prompt,
                model=self.models["context_analysis"],
                max_tokens=500,  # ‚úÖ OPTIMIS√â: 600 ‚Üí 500
                temperature=0.0,  # ‚úÖ OPTIMIS√â: 0.1 ‚Üí 0.0 pour maximum pr√©cision
                timeout=self.timeouts["context_analysis"]
            )
            
            # Parser le r√©sultat avec validation
            analysis_data = self._parse_json_response(ai_response.content, "context_analysis")
            
            # ‚úÖ NOUVEAU: Validation de coh√©rence
            references_detected = analysis_data.get("references_detected", False)
            is_standalone = analysis_data.get("is_standalone_question", False)
            
            # Coh√©rence logique
            if references_detected and is_standalone:
                logger.warning("‚ö†Ô∏è [Context Analysis] Incoh√©rence d√©tect√©e - question autonome avec r√©f√©rences")
                references_detected = False  # Privil√©gier autonome
            
            # Construire ContextAnalysis
            analysis = ContextAnalysis(
                references_detected=references_detected,
                enhanced_question=current_question,  # Sera enrichie plus tard si n√©cessaire
                context_entities=analysis_data.get("referenced_entities", {}),
                missing_context=analysis_data.get("missing_context", []),
                confidence=analysis_data.get("confidence", 0.0),
                reasoning=analysis_data.get("analysis_reasoning", ""),
                is_standalone=is_standalone
            )
            
            logger.info(f"‚úÖ [AI Context Enhancer] Analyse termin√©e: r√©f√©rences={analysis.references_detected}, autonome={analysis.is_standalone}, confiance={analysis.confidence:.2f}")
            
            return analysis
            
        except Exception as e:
            self.stats["errors"] += 1
            logger.error(f"‚ùå [AI Context Enhancer] Erreur analyse contextuelle: {e}")
            # Fallback conservateur
            return ContextAnalysis(
                references_detected=False,
                enhanced_question=current_question,
                confidence=0.0,
                reasoning=f"Erreur analyse: {e}"
            )
    
    async def enhance_question_for_rag(self, 
                                     original_question: str,
                                     conversation_context: str = "",
                                     current_entities: Dict[str, Any] = None,
                                     language: str = "fr") -> EnhancedContext:
        """
        ‚úÖ CORRIG√â: Point d'entr√©e principal avec logique de fusion stricte
        """
        try:
            logger.info(f"ü§ñ [AI Context Enhancer] Enhancement complet: '{original_question[:50]}...'")
            
            if current_entities is None:
                current_entities = {}
            
            # 1. Analyser le contexte conversationnel avec pr√©-filtrage
            context_analysis = await self.analyze_conversational_context(
                original_question, conversation_context, language
            )
            
            # 2. Initialisation avec valeurs par d√©faut (pas de fusion)
            enhanced_question = original_question
            merged_entities = current_entities.copy()
            fusion_applied = False
            inheritance_log = []
            
            # 3. Enhancement ET fusion SEULEMENT si r√©f√©rences d√©tect√©es
            if context_analysis.references_detected and not context_analysis.is_standalone:
                
                # Enhancement de la question
                try:
                    enhanced_question = await self._enhance_question_with_context(
                        original_question, context_analysis.context_entities, True
                    )
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [Question Enhancement] Erreur: {e} - question originale conserv√©e")
                    enhanced_question = original_question
                
                # Fusion des entit√©s avec validation stricte
                try:
                    fusion_result = await self._merge_entities_with_context_strict(
                        current_entities, 
                        context_analysis.context_entities, 
                        context_analysis.references_detected
                    )
                    merged_entities = fusion_result["merged_entities"]
                    fusion_applied = fusion_result["fusion_applied"]
                    inheritance_log = fusion_result["inheritance_log"]
                    
                    if fusion_applied:
                        self.stats["context_fusions"] += 1
                        self.stats["inheritance_applied"] += len(inheritance_log)
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [Entity Fusion] Erreur: {e} - entit√©s actuelles conserv√©es")
                    merged_entities = current_entities.copy()
            
            else:
                logger.info(f"üö´ [Enhancement] Pas de r√©f√©rences contextuelles - pas de fusion appliqu√©e")
            
            # 4. Optimiser pour RAG
            rag_query = original_question  # D√©faut s√ªr
            try:
                rag_query = await self._optimize_for_rag(enhanced_question, merged_entities)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [RAG Optimization] Erreur: {e} - question originale utilis√©e")
            
            # 5. Cr√©er le r√©sum√© contextuel
            context_summary = "Pas de contexte conversationnel"
            try:
                context_summary = await self._create_context_summary(
                    conversation_context, merged_entities
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [Context Summary] Erreur: {e}")
            
            # 6. Construire r√©sultat final avec logs d√©taill√©s
            enhanced_context = EnhancedContext(
                original_question=original_question,
                enhanced_question=enhanced_question,
                merged_entities=merged_entities,
                rag_optimized_query=rag_query,
                context_summary=context_summary,
                enhancement_confidence=context_analysis.confidence,
                ai_reasoning=context_analysis.reasoning,
                fusion_applied=fusion_applied,
                inheritance_log=inheritance_log
            )
            
            # Logging d√©taill√© pour debugging
            logger.info(f"‚úÖ [AI Context Enhancer] Enhancement termin√©:")
            logger.info(f"   üìù Question enrichie: '{enhanced_question}'")
            logger.info(f"   üîó Fusion appliqu√©e: {fusion_applied}")
            logger.info(f"   üìä Entit√©s finales: {len(merged_entities)} champs")
            if inheritance_log:
                logger.info(f"   üè∑Ô∏è H√©ritages: {inheritance_log}")
            
            return enhanced_context
            
        except Exception as e:
            self.stats["errors"] += 1
            logger.error(f"‚ùå [AI Context Enhancer] Erreur enhancement: {e}")
            
            # Fallback ultra-conservateur
            return EnhancedContext(
                original_question=original_question,
                enhanced_question=original_question,
                merged_entities=current_entities or {},
                rag_optimized_query=original_question,
                context_summary="Erreur enhancement contextuel",
                enhancement_confidence=0.0,
                ai_reasoning=f"Erreur: {e}",
                fusion_applied=False,
                inheritance_log=[]
            )
    
    async def _enhance_question_with_context(self, 
                                           original_question: str, 
                                           context_entities: Dict[str, Any],
                                           references_detected: bool) -> str:
        """‚úÖ CORRIG√â: Enhancement conditionnel de la question"""
        
        try:
            # Si pas de r√©f√©rences, pas d'enhancement
            if not references_detected:
                logger.debug("üö´ [Question Enhancement] Pas de r√©f√©rences - pas d'enhancement")
                return original_question
            
            prompt = self.prompts["question_enhancement"].format(
                original_question=original_question,
                context_entities=json.dumps(context_entities, ensure_ascii=False),
                references_detected=references_detected
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["question_enhancement"],
                max_tokens=300,  # ‚úÖ OPTIMIS√â: 400 ‚Üí 300
                temperature=0.0,  # ‚úÖ OPTIMIS√â: 0.1 ‚Üí 0.0
                timeout=self.timeouts["question_enhancement"]
            )
            
            result = self._parse_json_response(ai_response.content, "question_enhancement")
            enhancement_applied = result.get("enhancement_applied", False)
            enhanced = result.get("enhanced_question", original_question)
            
            # Validation: ne pas accepter d'enhancement si pas justifi√©
            if not enhancement_applied:
                enhanced = original_question
                logger.debug("üö´ [Question Enhancement] IA indique pas d'enhancement n√©cessaire")
            
            logger.info(f"‚úÖ [Question Enhancement] '{original_question}' ‚Üí '{enhanced}' (applied: {enhancement_applied})")
            return enhanced
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Question Enhancement] Erreur: {e}")
            return original_question
    
    async def _merge_entities_with_context_strict(self, 
                                                current_entities: Dict[str, Any], 
                                                context_entities: Dict[str, Any],
                                                references_detected: bool) -> Dict[str, Any]:
        """‚úÖ NOUVEAU: Fusion stricte avec validation et logging d√©taill√©"""
        
        try:
            # Si pas de r√©f√©rences d√©tect√©es, pas de fusion
            if not references_detected:
                logger.info("üö´ [Entity Fusion] Pas de r√©f√©rences contextuelles - pas de fusion")
                return {
                    "merged_entities": current_entities.copy(),
                    "fusion_applied": False,
                    "inheritance_log": []
                }
            
            prompt = self.prompts["entity_fusion"].format(
                current_entities=json.dumps(current_entities, ensure_ascii=False),
                context_entities=json.dumps(context_entities, ensure_ascii=False),
                references_detected=references_detected
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["entity_fusion"],
                max_tokens=400,  # ‚úÖ OPTIMIS√â: 500 ‚Üí 400
                temperature=0.0,  # ‚úÖ OPTIMIS√â: Maximum pr√©cision
                timeout=self.timeouts["entity_fusion"]
            )
            
            result = self._parse_json_response(ai_response.content, "entity_fusion")
            
            # Extraction des r√©sultats
            fusion_decision = result.get("fusion_decision", "no_fusion")
            merged_entities = result.get("merged_entities", current_entities)
            inherited_list = result.get("inherited_from_context", [])
            fusion_reasoning = result.get("fusion_reasoning", "")
            
            # ‚úÖ NOUVEAU: Validation post-fusion stricte
            validated_result = self._validate_entity_fusion_strict(
                original_current=current_entities,
                merged_result=merged_entities,
                inherited_list=inherited_list,
                fusion_reasoning=fusion_reasoning,
                references_detected=references_detected
            )
            
            fusion_applied = validated_result["validation_passed"]
            final_entities = validated_result["final_entities"]
            inheritance_log = validated_result["inheritance_log"]
            
            # Statistiques
            if fusion_applied:
                logger.info(f"‚úÖ [Entity Fusion] Fusion appliqu√©e avec {len(inheritance_log)} h√©ritages")
            else:
                self.stats["inheritance_rejected"] += len(inherited_list)
                logger.info(f"üö´ [Entity Fusion] Fusion rejet√©e par validation stricte")
            
            return {
                "merged_entities": final_entities,
                "fusion_applied": fusion_applied,
                "inheritance_log": inheritance_log
            }
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Entity Fusion] Erreur: {e}")
            # Fallback ultra-conservateur
            return {
                "merged_entities": current_entities.copy(),
                "fusion_applied": False,
                "inheritance_log": []
            }
    
    def _validate_entity_fusion_strict(self, 
                                     original_current: Dict[str, Any],
                                     merged_result: Dict[str, Any],
                                     inherited_list: List[str],
                                     fusion_reasoning: str,
                                     references_detected: bool) -> Dict[str, Any]:
        """‚úÖ NOUVEAU: Validation ultra-stricte de la fusion d'entit√©s"""
        
        # Si pas de r√©f√©rences, refuse toute fusion
        if not references_detected:
            return {
                "validation_passed": False,
                "final_entities": original_current.copy(),
                "inheritance_log": [],
                "rejection_reason": "Pas de r√©f√©rences contextuelles d√©tect√©es"
            }
        
        validated_entities = original_current.copy()
        valid_inheritances = []
        rejected_inheritances = []
        
        # Valider chaque entit√© potentiellement h√©rit√©e
        for inheritance_claim in inherited_list:
            if ":" in inheritance_claim:
                entity_key = inheritance_claim.split(":")[0].strip()
            else:
                entity_key = inheritance_claim.strip()
            
            # V√©rifier si l'h√©ritage est justifi√©
            is_valid = self._is_inheritance_justified_strict(
                entity_key, 
                merged_result.get(entity_key), 
                fusion_reasoning,
                original_current
            )
            
            if is_valid:
                validated_entities[entity_key] = merged_result.get(entity_key)
                valid_inheritances.append(f"{entity_key}: {merged_result.get(entity_key)}")
                logger.debug(f"‚úÖ [Inheritance Validation] Accept√©: {entity_key}")
            else:
                # Conserver la valeur originale (ou null)
                validated_entities[entity_key] = original_current.get(entity_key)
                rejected_inheritances.append(f"{entity_key}: rejet√©")
                logger.debug(f"‚ùå [Inheritance Validation] Rejet√©: {entity_key}")
        
        validation_passed = len(valid_inheritances) > 0
        
        # Log d√©taill√© des d√©cisions
        if valid_inheritances:
            logger.info(f"‚úÖ [Fusion Validation] H√©ritages accept√©s: {valid_inheritances}")
        if rejected_inheritances:
            logger.info(f"‚ùå [Fusion Validation] H√©ritages rejet√©s: {rejected_inheritances}")
        
        return {
            "validation_passed": validation_passed,
            "final_entities": validated_entities,
            "inheritance_log": valid_inheritances,
            "rejection_reason": f"Validations: {len(valid_inheritances)}/{len(inherited_list)}"
        }
    
    def _is_inheritance_justified_strict(self, 
                                       entity_key: str, 
                                       inherited_value: Any, 
                                       reasoning: str,
                                       original_entities: Dict[str, Any]) -> bool:
        """‚úÖ NOUVEAU: Validation ultra-stricte de justification d'h√©ritage"""
        
        # L'entit√© originale doit √™tre vide pour justifier l'h√©ritage
        original_value = original_entities.get(entity_key)
        if original_value is not None and original_value != "":
            logger.debug(f"‚ùå [Inheritance Check] {entity_key}: entit√© originale pr√©sente, pas d'h√©ritage")
            return False
        
        # La valeur h√©rit√©e doit √™tre valide
        if inherited_value is None or inherited_value == "":
            logger.debug(f"‚ùå [Inheritance Check] {entity_key}: valeur h√©rit√©e invalide")
            return False
        
        # Le raisonnement doit contenir des justifications contextuelles explicites
        reasoning_lower = reasoning.lower()
        
        # Indicateurs sp√©cifiques par type d'entit√©
        justification_patterns = {
            "age": ["√¢ge", "temporel", "√† cet √¢ge", "m√™me √¢ge", "age", "temporal"],
            "age_days": ["√¢ge", "temporel", "jours", "√† cet √¢ge", "days", "temporal"],
            "breed": ["race", "breed", "leur", "ces animaux", "cette race", "m√™me race"],
            "breed_specific": ["race", "breed", "leur", "ces animaux", "cette race", "souche"],
            "sex": ["sexe", "m√¢le", "femelle", "leur", "sex", "male", "female", "oppos√©"],
        }
        
        patterns = justification_patterns.get(entity_key, ["r√©f√©rence", "contextuel", "leur", "ces"])
        
        # V√©rifier pr√©sence de justifications
        justifications_found = [pattern for pattern in patterns if pattern in reasoning_lower]
        
        # Au moins une justification requise
        is_justified = len(justifications_found) > 0
        
        logger.debug(f"üîç [Inheritance Check] {entity_key}={inherited_value}: justifications={justifications_found}, valide={is_justified}")
        
        return is_justified
    
    async def _optimize_for_rag(self, enhanced_question: str, merged_entities: Dict[str, Any]) -> str:
        """‚úÖ OPTIMIS√â: Optimisation RAG avec performance am√©lior√©e"""
        
        try:
            prompt = self.prompts["rag_optimization"].format(
                enhanced_question=enhanced_question,
                merged_entities=json.dumps(merged_entities, ensure_ascii=False, indent=None)  # ‚úÖ OPTIMIS√â: Pas d'indentation
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model=self.models["rag_optimization"],
                max_tokens=200,  # ‚úÖ OPTIMIS√â: 300 ‚Üí 200
                temperature=0.1,
                timeout=self.timeouts["rag_optimization"]
            )
            
            result = self._parse_json_response(ai_response.content, "rag_optimization")
            rag_query = result.get("rag_query", enhanced_question)
            
            # ‚úÖ NOUVEAU: Validation longueur
            if len(rag_query.split()) > 25:  # Limite pour performance
                rag_query = " ".join(rag_query.split()[:25]) + "..."
                logger.debug("‚úÇÔ∏è [RAG Optimization] Query tronqu√©e pour performance")
            
            logger.info(f"‚úÖ [RAG Optimization] Query optimis√©e: '{rag_query}'")
            return rag_query
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [RAG Optimization] Erreur: {e}")
            return enhanced_question
    
    async def _create_context_summary(self, conversation_history: str, entities: Dict[str, Any]) -> str:
        """‚úÖ OPTIMIS√â: R√©sum√© contextuel avec bypass intelligent"""
        
        try:
            # ‚úÖ NOUVEAU: Bypass si contexte minimal
            if not conversation_history or len(conversation_history.strip()) < 30:
                return "Nouvelle conversation - pas d'historique √©tabli"
            
            # Limiter la taille pour performance
            history_limited = conversation_history[-800:]  # ‚úÖ OPTIMIS√â: 1000 ‚Üí 800
            
            prompt = self.prompts["context_summary"].format(
                conversation_history=history_limited,
                established_entities=json.dumps(entities, ensure_ascii=False, indent=None)
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.CONTEXT_ENHANCEMENT,
                prompt=prompt,
                model="gpt-3.5-turbo",  # ‚úÖ OPTIMIS√â: Suffisant pour r√©sum√©
                max_tokens=150,  # ‚úÖ OPTIMIS√â: 300 ‚Üí 150
                temperature=0.2,
                timeout=5  # ‚úÖ OPTIMIS√â: Timeout court
            )
            
            result = self._parse_json_response(ai_response.content, "context_summary")
            topic = result.get("conversation_topic", "Discussion g√©n√©rale")
            dominant_entities = result.get("dominant_entities", {})
            
            # Format concis
            summary_parts = [f"Sujet: {topic}"]
            if dominant_entities.get("breed"):
                summary_parts.append(f"Race: {dominant_entities['breed']}")
            if dominant_entities.get("typical_age"):
                summary_parts.append(f"√Çge: {dominant_entities['typical_age']}")
            
            summary = " | ".join(summary_parts)
            return summary
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [Context Summary] Erreur: {e}")
            return "R√©sum√© contextuel indisponible"
    
    def _parse_json_response(self, content: str, operation: str = "unknown") -> Dict[str, Any]:
        """‚úÖ AM√âLIOR√â: Parse JSON avec gestion d'erreurs et fallbacks par op√©ration"""
        
        try:
            # Nettoyer le contenu
            content = content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            return json.loads(content)
            
        except json.JSONDecodeError as e:
            logger.warning(f"‚ö†Ô∏è [AI Context Enhancer] Erreur parsing JSON ({operation}): {e}")
            
            # Fallbacks sp√©cifiques par op√©ration
            fallback_responses = {
                "context_analysis": {
                    "references_detected": False,
                    "is_standalone_question": True,
                    "confidence": 0.0,
                    "analysis_reasoning": "Erreur parsing - fallback conservateur"
                },
                "question_enhancement": {
                    "enhanced_question": "",  # Sera remplac√© par question originale
                    "enhancement_applied": False,
                    "enhancement_confidence": 0.0
                },
                "entity_fusion": {
                    "fusion_decision": "no_fusion",
                    "merged_entities": {},  # Sera remplac√© par entit√©s actuelles
                    "inherited_from_context": [],
                    "fusion_confidence": 0.0
                },
                "rag_optimization": {
                    "rag_query": "",  # Sera remplac√© par question originale
                    "optimization_confidence": 0.0
                },
                "context_summary": {
                    "conversation_topic": "Erreur parsing",
                    "summary_confidence": 0.0
                }
            }
            
            return fallback_responses.get(operation, {})
            
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur parsing ({operation}): {e}")
            return {}
    
    async def enhance_for_classification(self, 
                                       question: str, 
                                       conversation_context: str = "") -> Dict[str, Any]:
        """‚úÖ OPTIMIS√â: Enhancement sp√©cialis√© pour classification"""
        
        try:
            # Analyse rapide pour la classification
            enhanced_context = await self.enhance_question_for_rag(
                question, conversation_context
            )
            
            return {
                "enhanced_question": enhanced_context.enhanced_question,
                "context_confidence": enhanced_context.enhancement_confidence,
                "has_references": enhanced_context.enhanced_question != question,
                "merged_entities": enhanced_context.merged_entities,
                "fusion_applied": enhanced_context.fusion_applied,
                "classification_hints": {
                    "likely_contextual": enhanced_context.enhancement_confidence > 0.7,
                    "needs_clarification": enhanced_context.enhancement_confidence < 0.3 and not enhanced_context.fusion_applied,
                    "has_sufficient_context": len(enhanced_context.merged_entities) >= 2,
                    "is_standalone": enhanced_context.enhancement_confidence == 0.0
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå [AI Context Enhancer] Erreur classification enhancement: {e}")
            return {
                "enhanced_question": question,
                "context_confidence": 0.0,
                "has_references": False,
                "merged_entities": {},
                "fusion_applied": False,
                "classification_hints": {
                    "likely_contextual": False,
                    "needs_clarification": True,
                    "has_sufficient_context": False,
                    "is_standalone": True
                }
            }
    
    def get_enhancement_stats(self) -> Dict[str, Any]:
        """‚úÖ NOUVEAU: Statistiques de performance pour monitoring"""
        
        total = self.stats["total_enhancements"]
        bypass_rate = (self.stats["standalone_bypassed"] / total * 100) if total > 0 else 0
        fusion_rate = (self.stats["context_fusions"] / total * 100) if total > 0 else 0
        
        return {
            **self.stats,
            "bypass_rate_percent": round(bypass_rate, 1),
            "fusion_rate_percent": round(fusion_rate, 1),
            "error_rate_percent": round((self.stats["errors"] / total * 100) if total > 0 else 0, 1)
        }

# =============================================================================
# INSTANCES GLOBALES ET FACTORY FUNCTIONS
# =============================================================================

# Instance globale pour r√©utilisation
_ai_context_enhancer_instance = None

def get_ai_context_enhancer() -> AIContextEnhancer:
    """Factory function pour r√©cup√©rer l'instance singleton"""
    global _ai_context_enhancer_instance
    
    if _ai_context_enhancer_instance is None:
        _ai_context_enhancer_instance = AIContextEnhancer()
        logger.info("ü§ñ [AI Context Enhancer] Instance singleton cr√©√©e")
    
    return _ai_context_enhancer_instance

# =============================================================================
# FONCTIONS DE COMPATIBILIT√â AVEC L'ANCIEN SYST√àME  
# =============================================================================

async def enhance_question_for_rag_legacy(question: str, context: str = "") -> str:
    """
    ‚úÖ MAINTENU: Fonction de compatibilit√© avec l'ancien syst√®me RAG
    """
    try:
        enhancer = get_ai_context_enhancer()
        enhanced_context = await enhancer.enhance_question_for_rag(
            original_question=question,
            conversation_context=context
        )
        return enhanced_context.rag_optimized_query
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è [Legacy RAG Enhancement] Erreur: {e}")
        return question

async def analyze_contextual_references_legacy(question: str, history: str = "") -> Dict[str, Any]:
    """
    ‚úÖ MAINTENU: Fonction de compatibilit√© pour l'analyse des r√©f√©rences contextuelles
    """
    try:
        enhancer = get_ai_context_enhancer()
        analysis = await enhancer.analyze_conversational_context(
            current_question=question,
            conversation_history=history
        )
        
        return {
            "has_references": analysis.references_detected,
            "referenced_entities": analysis.context_entities,
            "confidence": analysis.confidence,
            "missing_context": analysis.missing_context,
            "reasoning": analysis.reasoning,
            "is_standalone": analysis.is_standalone  # ‚úÖ NOUVEAU
        }
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è [Legacy Context Analysis] Erreur: {e}")
        return {
            "has_references": False,
            "referenced_entities": {},
            "confidence": 0.0,
            "missing_context": [],
            "reasoning": f"Erreur: {e}",
            "is_standalone": True
        }

# =============================================================================
# TESTS ET VALIDATION
# =============================================================================

async def test_ai_context_enhancer():
    """‚úÖ AM√âLIOR√â: Tests int√©gr√©s pour valider le fonctionnement"""
    
    logger.info("üß™ Tests AI Context Enhancer - Version Corrig√©e")
    logger.info("=" * 60)
    
    enhancer = get_ai_context_enhancer()
    
    test_cases = [
        {
            "name": "Question autonome - pas de fusion",
            "question": "Ross 308 male",
            "context": "Conversation pr√©c√©dente: poulet 11 jours, poids",
            "expected_fusion": False,
            "expected_standalone": True
        },
        {
            "name": "Question avec r√©f√©rences - fusion attendue",
            "question": "Leur poids √† 21 jours ?",
            "context": "Conversation pr√©c√©dente: Ross 308 m√¢les, probl√®mes de croissance",
            "expected_fusion": True,
            "expected_standalone": False
        },
        {
            "name": "Question compl√®te - pas de fusion",
            "question": "Quel est le poids normal des Cobb 500 √† 14 jours ?",
            "context": "Discussion pr√©c√©dente sur Ross 308",
            "expected_fusion": False,
            "expected_standalone": True
        },
        {
            "name": "R√©f√©rence explicite - fusion attendue",
            "question": "Et pour les femelles ?",
            "context": "Discussion sur les m√¢les Cobb 500 de 14 jours",
            "expected_fusion": True,
            "expected_standalone": False
        }
    ]
    
    results = []
    
    for i, case in enumerate(test_cases, 1):
        try:
            logger.info(f"\nüß™ Test {i}: {case['name']}")
            logger.info(f"   üìù Question: '{case['question']}'")
            
            enhanced_context = await enhancer.enhance_question_for_rag(
                original_question=case["question"],
                conversation_context=case["context"]
            )
            
            # V√©rifications
            fusion_applied = enhanced_context.fusion_applied
            is_standalone = case["question"] == enhanced_context.enhanced_question and not fusion_applied
            
            # R√©sultats
            fusion_correct = fusion_applied == case["expected_fusion"]
            standalone_correct = is_standalone == case["expected_standalone"]
            
            result = {
                "test": case["name"],
                "fusion_applied": fusion_applied,
                "fusion_correct": fusion_correct,
                "standalone_detected": is_standalone,
                "standalone_correct": standalone_correct,
                "success": fusion_correct and standalone_correct
            }
            
            results.append(result)
            
            # Logs d√©taill√©s
            logger.info(f"   ‚úÖ Question enrichie: '{enhanced_context.enhanced_question}'")
            logger.info(f"   ‚úÖ Fusion appliqu√©e: {fusion_applied} (attendu: {case['expected_fusion']}) {'‚úÖ' if fusion_correct else '‚ùå'}")
            logger.info(f"   ‚úÖ Autonome d√©tect√©: {is_standalone} (attendu: {case['expected_standalone']}) {'‚úÖ' if standalone_correct else '‚ùå'}")
            logger.info(f"   ‚úÖ Confiance: {enhanced_context.enhancement_confidence:.2f}")
            logger.info(f"   ‚úÖ Entit√©s finales: {len(enhanced_context.merged_entities)} champs")
            if enhanced_context.inheritance_log:
                logger.info(f"   üè∑Ô∏è H√©ritages: {enhanced_context.inheritance_log}")
            
            logger.info(f"   {'‚úÖ SUCC√àS' if result['success'] else '‚ùå √âCHEC'}")
            
        except Exception as e:
            logger.error(f"   ‚ùå Erreur test {i}: {e}")
            results.append({"test": case["name"], "success": False, "error": str(e)})
    
    # R√©sum√© des tests
    logger.info(f"\nüìä R√©sum√© des tests:")
    successful = sum(1 for r in results if r.get("success", False))
    total = len(results)
    
    logger.info(f"   ‚úÖ R√©ussis: {successful}/{total}")
    
    if successful == total:
        logger.info("   üéâ TOUS LES TESTS R√âUSSIS - Corrections valid√©es!")
    else:
        logger.warning("   ‚ö†Ô∏è Certains tests ont √©chou√© - R√©vision n√©cessaire")
    
    # Statistiques de performance
    stats = enhancer.get_enhancement_stats()
    logger.info(f"\nüìà Statistiques performance:")
    for key, value in stats.items():
        logger.info(f"   {key}: {value}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_ai_context_enhancer())