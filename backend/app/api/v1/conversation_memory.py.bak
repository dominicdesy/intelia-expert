"""
app/api/v1/conversation_memory.py - Syst√®me de m√©moire conversationnelle intelligent

üîß MODULE 3/3: Classe principale IntelligentConversationMemory
‚úÖ Toutes les corrections appliqu√©es
‚úÖ Gestion base de donn√©es robuste
‚úÖ Thread-safety avec RLock
‚úÖ Int√©gration clarification critique
‚úÖ Compatibilit√© totale avec l'existant

Ce fichier conserve le nom original pour √©viter de casser les imports existants
"""

import os
import json
import logging
import sqlite3
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Union
from contextlib import contextmanager
from threading import Lock, RLock
from copy import deepcopy

from .conversation_entities import (
    IntelligentEntities, 
    ConversationMessage, 
    IntelligentConversationContext,
    RAGCallbackProtocol,
    safe_int_conversion,
    safe_float_conversion
)
from .conversation_extraction import ConversationEntityExtractor, ConversationClarificationHandler

logger = logging.getLogger(__name__)

class IntelligentConversationMemory:
    """Syst√®me de m√©moire conversationnelle intelligent avec IA et clarification critique int√©gr√©e - VERSION R√â√âCRITE"""
    
    def __init__(self, db_path: str = None):
        """Initialise le syst√®me de m√©moire intelligent"""
        
        # Configuration
        self.db_path = db_path or os.getenv('CONVERSATION_MEMORY_DB_PATH', 'data/conversation_memory.db')
        self.max_messages_in_memory = int(os.getenv('MAX_MESSAGES_IN_MEMORY', '50'))
        self.context_expiry_hours = int(os.getenv('CONTEXT_EXPIRY_HOURS', '24'))
        self.ai_enhancement_enabled = os.getenv('AI_ENHANCEMENT_ENABLED', 'true').lower() == 'true'
        self.ai_enhancement_model = os.getenv('AI_ENHANCEMENT_MODEL', 'gpt-4o-mini')
        self.ai_enhancement_timeout = int(os.getenv('AI_ENHANCEMENT_TIMEOUT', '15'))
        
        # Initialiser les modules
        self.entity_extractor = ConversationEntityExtractor()
        self.clarification_handler = ConversationClarificationHandler()
        
        # Cache thread-safe avec RLock au lieu de Lock simple
        self.conversation_cache: Dict[str, IntelligentConversationContext] = {}
        self.cache_max_size = int(os.getenv('CONVERSATION_CACHE_SIZE', '100'))
        self.cache_lock = RLock()  # RLock pour √©viter les deadlocks
        
        # Statistiques thread-safe
        self._stats_lock = Lock()
        self.stats = {
            "total_conversations": 0,
            "total_messages": 0,
            "ai_enhancements": 0,
            "ai_failures": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "original_questions_recovered": 0,
            "clarification_resolutions": 0,
            # NOUVELLES M√âTRIQUES CRITIQUES
            "critical_clarifications_marked": 0,
            "critical_clarifications_resolved": 0,
            "rag_reprocessing_triggered": 0
        }
        
        # Initialiser la base de donn√©es
        self._init_database()
        
        logger.info(f"üß† [IntelligentMemory] Syst√®me initialis√© - VERSION COMPL√àTEMENT R√â√âCRITE")
        logger.info(f"üß† [IntelligentMemory] DB: {self.db_path}")
        logger.info(f"üß† [IntelligentMemory] IA enhancing: {'‚úÖ' if self.ai_enhancement_enabled else '‚ùå'}")
        logger.info(f"üß† [IntelligentMemory] Mod√®le IA: {self.ai_enhancement_model}")
        logger.info(f"üö® [IntelligentMemory] Syst√®me de clarification standard: ‚úÖ")
        logger.info(f"üö® [IntelligentMemory] Syst√®me de clarification CRITIQUE: ‚úÖ (CORRIG√â)")
        logger.info(f"ü§ñ [IntelligentMemory] M√©thodes pour agents GPT: ‚úÖ")
        logger.info(f"üîß [IntelligentMemory] Corrections appliqu√©es: Weight sync, Type safety, WeakRef, RLock")

    def _update_stats(self, key: str, increment: int = 1):
        """Met √† jour les statistiques de mani√®re thread-safe"""
        with self._stats_lock:
            self.stats[key] = self.stats.get(key, 0) + increment

    def _init_database(self):
        """Initialise la base de donn√©es avec sch√©ma am√©lior√© pour clarification critique"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        with sqlite3.connect(self.db_path) as conn:
            # Table des conversations avec m√©tadonn√©es √©tendues + clarification critique
            conn.execute("""
                CREATE TABLE IF NOT EXISTS conversations (
                    conversation_id TEXT PRIMARY KEY,
                    user_id TEXT NOT NULL,
                    language TEXT DEFAULT 'fr',
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    total_exchanges INTEGER DEFAULT 0,
                    
                    -- Entit√©s consolid√©es (JSON)
                    consolidated_entities TEXT,
                    
                    -- √âtat conversationnel
                    conversation_topic TEXT,
                    conversation_urgency TEXT,
                    problem_resolution_status TEXT,
                    
                    -- M√©tadonn√©es IA
                    ai_enhanced BOOLEAN DEFAULT FALSE,
                    last_ai_analysis TIMESTAMP,
                    needs_clarification BOOLEAN DEFAULT FALSE,
                    clarification_questions TEXT,
                    
                    -- CHAMPS POUR CLARIFICATIONS STANDARD
                    pending_clarification BOOLEAN DEFAULT FALSE,
                    last_original_question_id TEXT,
                    
                    -- NOUVEAUX CHAMPS POUR CLARIFICATION CRITIQUE
                    original_question_pending TEXT,
                    critical_clarification_active BOOLEAN DEFAULT FALSE,
                    
                    -- Performance
                    confidence_overall REAL DEFAULT 0.0
                )
            """)
            
            # Table des messages avec extraction d'entit√©s
            conn.execute("""
                CREATE TABLE IF NOT EXISTS conversation_messages (
                    id TEXT PRIMARY KEY,
                    conversation_id TEXT NOT NULL,
                    user_id TEXT NOT NULL,
                    role TEXT NOT NULL,
                    message TEXT NOT NULL,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    language TEXT DEFAULT 'fr',
                    message_type TEXT DEFAULT 'text',
                    
                    -- Entit√©s extraites (JSON)
                    extracted_entities TEXT,
                    confidence_score REAL DEFAULT 0.0,
                    processing_method TEXT DEFAULT 'basic',
                    
                    -- CHAMPS POUR CLARIFICATIONS
                    is_original_question BOOLEAN DEFAULT FALSE,
                    is_clarification_response BOOLEAN DEFAULT FALSE,
                    original_question_id TEXT,
                    
                    FOREIGN KEY (conversation_id) REFERENCES conversations (conversation_id)
                )
            """)
            
            # Index pour performance
            conn.execute("CREATE INDEX IF NOT EXISTS idx_conv_user_activity ON conversations (user_id, last_activity)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_msg_conv_time ON conversation_messages (conversation_id, timestamp)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_conv_urgency ON conversations (conversation_urgency, last_activity)")
            # INDEX POUR CLARIFICATIONS
            conn.execute("CREATE INDEX IF NOT EXISTS idx_original_questions ON conversation_messages (conversation_id, is_original_question)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_clarification_responses ON conversation_messages (original_question_id, is_clarification_response)")
            # NOUVEAUX INDEX POUR CLARIFICATION CRITIQUE
            conn.execute("CREATE INDEX IF NOT EXISTS idx_critical_clarification ON conversations (critical_clarification_active, last_activity)")
            
        logger.info(f"‚úÖ [IntelligentMemory] Base de donn√©es initialis√©e avec support clarification critique")

    @contextmanager
    def _get_db_connection(self):
        """Context manager pour les connexions DB avec retry"""
        max_retries = 3
        conn = None
        
        for attempt in range(max_retries):
            try:
                conn = sqlite3.connect(self.db_path, timeout=30.0)
                conn.row_factory = sqlite3.Row
                yield conn
                break
            except sqlite3.OperationalError as e:
                if attempt == max_retries - 1:
                    raise
                logger.warning(f"‚ö†Ô∏è [DB] Retry connexion {attempt + 1}/{max_retries}: {e}")
                time.sleep(0.5 * (attempt + 1))
            except Exception as e:
                logger.error(f"‚ùå [DB] Erreur connexion: {e}")
                raise
            finally:
                if conn:
                    try:
                        conn.close()
                    except Exception as close_error:
                        logger.warning(f"‚ö†Ô∏è [DB] Erreur fermeture connexion: {close_error}")

    async def extract_entities_ai_enhanced(
        self, 
        message: str, 
        language: str = "fr",
        conversation_context: Optional[IntelligentConversationContext] = None
    ) -> IntelligentEntities:
        """Extraction d'entit√©s via le module sp√©cialis√©"""
        return await self.entity_extractor.extract_entities_ai_enhanced(message, language, conversation_context)

    async def add_message_to_conversation(
        self,
        conversation_id: str,
        user_id: str,
        message: str,
        role: str = "user",
        language: str = "fr",
        message_type: str = "text"
    ) -> IntelligentConversationContext:
        """üîß FIX 13: Ajoute un message avec extraction d'entit√©s robuste et gestion d'erreurs compl√®te"""
        
        try:
            # R√©cup√©rer ou cr√©er le contexte
            context = self.get_conversation_context(conversation_id)
            if not context:
                context = IntelligentConversationContext(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    language=language
                )
            
            # Extraire les entit√©s de mani√®re robuste
            try:
                extracted_entities = await self.extract_entities_ai_enhanced(message, language, context)
            except Exception as extract_error:
                logger.warning(f"‚ö†Ô∏è [Memory] Erreur extraction entit√©s: {extract_error}")
                # Fallback ultime: entit√©s vides mais valides
                extracted_entities = IntelligentEntities(
                    extraction_method="error_fallback",
                    extraction_success=False,
                    confidence_overall=0.0
                )
            
            # D√âTECTION AUTOMATIQUE DES CLARIFICATIONS STANDARD
            is_clarification_response = False
            original_question_id = None
            
            # Si c'est un message court avec breed/sex ET qu'on a une clarification en attente
            if (role == "user" and context.pending_clarification and 
                len(message.split()) <= 5 and 
                (extracted_entities.breed or extracted_entities.sex)):
                
                is_clarification_response = True
                original_question_id = context.last_original_question_id
                logger.info(f"üéØ [Memory] Clarification STANDARD d√©tect√©e: {message} ‚Üí {original_question_id}")
                self._update_stats("clarification_resolutions")
            
            # D√âTECTION CLARIFICATION CRITIQUE
            elif (role == "user" and context.critical_clarification_active and 
                  len(message.split()) <= 5 and 
                  (extracted_entities.breed or extracted_entities.sex)):
                
                is_clarification_response = True
                logger.info(f"üö® [Memory] Clarification CRITIQUE d√©tect√©e: {message}")
                self._update_stats("critical_clarifications_resolved")
            
            # Cr√©er le message
            message_obj = ConversationMessage(
                id=f"{conversation_id}_{len(context.messages)}_{int(time.time())}",
                conversation_id=conversation_id,
                user_id=user_id,
                role=role,
                message=message,
                timestamp=datetime.now(),
                language=language,
                message_type=message_type,
                extracted_entities=extracted_entities,
                confidence_score=extracted_entities.confidence_overall if extracted_entities else 0.0,
                processing_method="ai_enhanced" if self.ai_enhancement_enabled else "basic_robust",
                is_clarification_response=is_clarification_response,
                original_question_id=original_question_id
            )
            
            # Ajouter au contexte (d√©clenche automatiquement le retraitement si clarification critique)
            context.add_message(message_obj)
            
            # V√©rifier si un retraitement est planifi√©
            if context.check_and_trigger_reprocessing():
                logger.info("üîÑ [Memory] Retraitement planifi√© d√©tect√© - √† traiter par l'appelant")
            
            # Sauvegarder de mani√®re s√©curis√©e
            try:
                self._save_conversation_to_db(context)
                self._save_message_to_db(message_obj)
            except Exception as save_error:
                logger.error(f"‚ùå [Memory] Erreur sauvegarde: {save_error}")
                # Continuer m√™me si la sauvegarde √©choue pour √©viter de casser le flux
            
            # Mettre en cache de mani√®re thread-safe
            with self.cache_lock:
                self.conversation_cache[conversation_id] = deepcopy(context)
                self._manage_cache_size()
            
            self._update_stats("total_messages")
            
            logger.info(f"üí¨ [Memory] Message ajout√©: {conversation_id} ({len(context.messages)} msgs)")
            
            return context
            
        except Exception as e:
            logger.error(f"‚ùå [Memory] Erreur critique ajout message: {e}")
            
            # Cr√©er un contexte minimal en fallback
            minimal_context = IntelligentConversationContext(
                conversation_id=conversation_id,
                user_id=user_id,
                language=language
            )
            
            return minimal_context

    def get_conversation_context(self, conversation_id: str) -> Optional[IntelligentConversationContext]:
        """R√©cup√®re le contexte conversationnel avec cache thread-safe"""
        
        # V√©rifier le cache d'abord de mani√®re thread-safe
        with self.cache_lock:
            if conversation_id in self.conversation_cache:
                context = deepcopy(self.conversation_cache[conversation_id])
                self._update_stats("cache_hits")
                return context
        
        self._update_stats("cache_misses")
        
        # Charger depuis la DB avec gestion d'erreurs
        try:
            context = self._load_context_from_db(conversation_id)
            if context:
                # Mettre en cache de mani√®re thread-safe
                with self.cache_lock:
                    self.conversation_cache[conversation_id] = deepcopy(context)
                    self._manage_cache_size()
                return context
        except Exception as e:
            logger.error(f"‚ùå [Memory] Erreur chargement contexte: {e}")
        
        return None

    def _load_context_from_db(self, conversation_id: str) -> Optional[IntelligentConversationContext]:
        """Charge un contexte depuis la base de donn√©es avec gestion robuste des erreurs"""
        
        try:
            with self._get_db_connection() as conn:
                # R√©cup√©rer la conversation
                conv_row = conn.execute(
                    "SELECT * FROM conversations WHERE conversation_id = ?",
                    (conversation_id,)
                ).fetchone()
                
                if not conv_row:
                    return None
                
                # R√©cup√©rer les messages
                message_rows = conn.execute(
                    """SELECT * FROM conversation_messages 
                       WHERE conversation_id = ? 
                       ORDER BY timestamp ASC 
                       LIMIT ?""",
                    (conversation_id, self.max_messages_in_memory)
                ).fetchall()
                
                # Reconstruire le contexte avec gestion s√©curis√©e
                context = IntelligentConversationContext(
                    conversation_id=conv_row["conversation_id"],
                    user_id=conv_row["user_id"],
                    language=conv_row["language"] or "fr",
                    created_at=self._safe_datetime_parse(conv_row["created_at"]),
                    last_activity=self._safe_datetime_parse(conv_row["last_activity"]),
                    total_exchanges=conv_row["total_exchanges"] or 0,
                    conversation_topic=conv_row["conversation_topic"],
                    conversation_urgency=conv_row["conversation_urgency"],
                    problem_resolution_status=conv_row["problem_resolution_status"],
                    ai_enhanced=bool(conv_row["ai_enhanced"]),
                    last_ai_analysis=self._safe_datetime_parse(conv_row["last_ai_analysis"]),
                    needs_clarification=bool(conv_row["needs_clarification"]),
                    clarification_questions=self._safe_json_parse(conv_row["clarification_questions"], []),
                    pending_clarification=bool(conv_row.get("pending_clarification", False)),
                    last_original_question_id=conv_row.get("last_original_question_id"),
                    # NOUVEAUX CHAMPS CLARIFICATION CRITIQUE
                    original_question_pending=conv_row.get("original_question_pending"),
                    critical_clarification_active=bool(conv_row.get("critical_clarification_active", False))
                )
                
                # Charger les entit√©s consolid√©es de mani√®re s√©curis√©e
                if conv_row["consolidated_entities"]:
                    try:
                        entities_data = json.loads(conv_row["consolidated_entities"])
                        context.consolidated_entities = self._entities_from_dict(entities_data)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è [DB] Erreur parsing entit√©s consolid√©es: {e}")
                        context.consolidated_entities = IntelligentEntities()
                
                # Charger les messages de mani√®re s√©curis√©e
                for msg_row in message_rows:
                    try:
                        entities = None
                        if msg_row["extracted_entities"]:
                            try:
                                entities_data = json.loads(msg_row["extracted_entities"])
                                entities = self._entities_from_dict(entities_data)
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è [DB] Erreur parsing entit√©s message: {e}")
                        
                        message_obj = ConversationMessage(
                            id=msg_row["id"],
                            conversation_id=msg_row["conversation_id"],
                            user_id=msg_row["user_id"],
                            role=msg_row["role"],
                            message=msg_row["message"],
                            timestamp=self._safe_datetime_parse(msg_row["timestamp"]),
                            language=msg_row["language"] or "fr",
                            message_type=msg_row["message_type"] or "text",
                            extracted_entities=entities,
                            confidence_score=msg_row["confidence_score"] or 0.0,
                            processing_method=msg_row["processing_method"] or "basic",
                            is_original_question=bool(msg_row.get("is_original_question", False)),
                            is_clarification_response=bool(msg_row.get("is_clarification_response", False)),
                            original_question_id=msg_row.get("original_question_id")
                        )
                        
                        context.messages.append(message_obj)
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è [DB] Erreur reconstruction message: {e}")
                        continue
                
                return context
                
        except Exception as e:
            logger.error(f"‚ùå [DB] Erreur chargement contexte: {e}")
            return None

    def _safe_datetime_parse(self, date_str: str) -> datetime:
        """Parse une date de mani√®re s√©curis√©e"""
        if not date_str:
            return datetime.now()
        try:
            return datetime.fromisoformat(date_str)
        except (ValueError, TypeError):
            return datetime.now()

    def _safe_json_parse(self, json_str: str, default: Any = None) -> Any:
        """Parse JSON de mani√®re s√©curis√©e"""
        if not json_str:
            return default or []
        try:
            return json.loads(json_str)
        except (json.JSONDecodeError, TypeError):
            return default or []

    def _entities_from_dict(self, data: Dict[str, Any]) -> IntelligentEntities:
        """üîß FIX 14: Reconstruit les entit√©s depuis un dictionnaire avec gestion compl√®te des erreurs"""
        
        try:
            # Convertir les dates de mani√®re s√©curis√©e
            for date_field in ["age_last_updated", "last_ai_update"]:
                if data.get(date_field):
                    try:
                        data[date_field] = datetime.fromisoformat(data[date_field])
                    except (ValueError, TypeError):
                        data[date_field] = None
            
            # Convertir les tuples de mani√®re s√©curis√©e
            if data.get("expected_weight_range") and isinstance(data["expected_weight_range"], list):
                try:
                    data["expected_weight_range"] = tuple(data["expected_weight_range"])
                except (ValueError, TypeError):
                    data["expected_weight_range"] = None
            
            # Assurer les listes de mani√®re s√©curis√©e
            for list_field in ["symptoms", "previous_treatments"]:
                if not isinstance(data.get(list_field), list):
                    data[list_field] = []
            
            # üîß FIX: S'assurer que tous les champs requis sont pr√©sents avec valeurs par d√©faut
            default_values = {
                'age': None,
                'breed': None,
                'sex': None,
                'age_days': None,
                'age_weeks': None,
                'age_confidence': 0.0,
                'breed_confidence': 0.0,
                'sex_confidence': 0.0,
                'weight': None,  # ‚Üê CHAMP CRITIQUE AJOUT√â
                'weight_grams': None,
                'weight_confidence': 0.0,
                'extraction_method': 'basic',
                'confidence_overall': 0.0,
                'data_validated': False,
                'extraction_success': True,
                'extraction_attempts': 0,
                'mortality_rate': None,
                'mortality_confidence': 0.0,
                'symptoms': [],
                'health_status': None,
                'temperature': None,
                'humidity': None,
                'housing_type': None,
                'ventilation_quality': None,
                'feed_type': None,
                'feed_conversion': None,
                'water_consumption': None,
                'flock_size': None,
                'vaccination_status': None,
                'previous_treatments': [],
                'problem_duration': None,
                'problem_severity': None,
                'intervention_urgency': None,
                'expected_weight_range': None,
                'growth_rate': None,
                'last_ai_update': None,
                'age_last_updated': None
            }
            
            # Ajouter les valeurs par d√©faut pour les champs manquants
            for field, default_value in default_values.items():
                if field not in data:
                    data[field] = default_value
            
            # üîß FIX: Synchronisation weight/weight_grams et age/age_days
            # Conversion s√©curis√©e des valeurs num√©riques
            weight_grams_safe = safe_float_conversion(data.get('weight_grams'))
            weight_safe = safe_float_conversion(data.get('weight'))
            age_days_safe = safe_int_conversion(data.get('age_days'))
            age_safe = safe_int_conversion(data.get('age'))
            
            # Synchroniser weight et weight_grams
            if weight_grams_safe is not None and weight_safe is None:
                data['weight'] = weight_grams_safe
            elif weight_safe is not None and weight_grams_safe is None:
                data['weight_grams'] = weight_safe
            
            # Synchroniser age et age_days
            if age_days_safe is not None and age_safe is None:
                data['age'] = age_days_safe
            elif age_safe is not None and age_days_safe is None:
                data['age_days'] = age_safe
            
            # Cr√©er l'entit√© avec seulement les champs valides
            valid_fields = {k: v for k, v in data.items() if k in IntelligentEntities.__dataclass_fields__}
            
            return IntelligentEntities(**valid_fields)
            
        except Exception as e:
            logger.error(f"‚ùå [Entities] Erreur reconstruction entit√©s: {e}")
            # Retourner des entit√©s vides mais valides
            return IntelligentEntities(
                extraction_method="reconstruction_error",
                extraction_success=False,
                confidence_overall=0.0
            )

    def _save_conversation_to_db(self, context: IntelligentConversationContext):
        """Sauvegarde un contexte en base de donn√©es avec gestion d'erreurs robuste"""
        
        try:
            with self._get_db_connection() as conn:
                # Pr√©parer les donn√©es de mani√®re s√©curis√©e
                try:
                    consolidated_entities_json = json.dumps(context.consolidated_entities.to_dict(), ensure_ascii=False)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [DB] Erreur s√©rialisation entit√©s: {e}")
                    consolidated_entities_json = "{}"
                
                try:
                    clarification_questions_json = json.dumps(context.clarification_questions, ensure_ascii=False)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [DB] Erreur s√©rialisation questions: {e}")
                    clarification_questions_json = "[]"
                
                # Upsert de la conversation avec nouveaux champs
                conn.execute("""
                    INSERT OR REPLACE INTO conversations (
                        conversation_id, user_id, language, created_at, last_activity,
                        total_exchanges, consolidated_entities, conversation_topic,
                        conversation_urgency, problem_resolution_status, ai_enhanced,
                        last_ai_analysis, needs_clarification, clarification_questions,
                        pending_clarification, last_original_question_id, 
                        original_question_pending, critical_clarification_active,
                        confidence_overall
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    context.conversation_id,
                    context.user_id,
                    context.language,
                    context.created_at.isoformat(),
                    context.last_activity.isoformat(),
                    context.total_exchanges,
                    consolidated_entities_json,
                    context.conversation_topic,
                    context.conversation_urgency,
                    context.problem_resolution_status,
                    context.ai_enhanced,
                    context.last_ai_analysis.isoformat() if context.last_ai_analysis else None,
                    context.needs_clarification,
                    clarification_questions_json,
                    context.pending_clarification,
                    context.last_original_question_id,
                    # NOUVEAUX CHAMPS
                    context.original_question_pending,
                    context.critical_clarification_active,
                    context.consolidated_entities.confidence_overall
                ))
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"‚ùå [DB] Erreur sauvegarde conversation: {e}")
            raise

    def _save_message_to_db(self, message: ConversationMessage):
        """Sauvegarde un message en base de donn√©es avec gestion d'erreurs"""
        
        try:
            with self._get_db_connection() as conn:
                # Pr√©parer les donn√©es de mani√®re s√©curis√©e
                entities_json = None
                if message.extracted_entities:
                    try:
                        entities_json = json.dumps(message.extracted_entities.to_dict(), ensure_ascii=False)
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è [DB] Erreur s√©rialisation entit√©s message: {e}")
                
                # Insert du message
                conn.execute("""
                    INSERT OR REPLACE INTO conversation_messages (
                        id, conversation_id, user_id, role, message, timestamp,
                        language, message_type, extracted_entities, confidence_score,
                        processing_method, is_original_question, is_clarification_response,
                        original_question_id
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    message.id,
                    message.conversation_id,
                    message.user_id,
                    message.role,
                    message.message,
                    message.timestamp.isoformat(),
                    message.language,
                    message.message_type,
                    entities_json,
                    message.confidence_score,
                    message.processing_method,
                    message.is_original_question,
                    message.is_clarification_response,
                    message.original_question_id
                ))
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"‚ùå [DB] Erreur sauvegarde message: {e}")
            raise

    def _manage_cache_size(self):
        """G√®re la taille du cache en m√©moire - VERSION THREAD-SAFE"""
        
        if len(self.conversation_cache) > self.cache_max_size:
            # Supprimer les conversations les moins r√©cemment utilis√©es
            sorted_conversations = sorted(
                self.conversation_cache.items(),
                key=lambda x: x[1].last_activity
            )
            
            # Garder seulement les plus r√©centes
            conversations_to_keep = dict(sorted_conversations[-self.cache_max_size//2:])
            self.conversation_cache = conversations_to_keep
            
            logger.info(f"üßπ [Memory] Cache nettoy√©: {len(self.conversation_cache)} conversations gard√©es")

    def get_conversation_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques du syst√®me avec nouvelles m√©triques clarification critique"""
        
        with self._stats_lock:
            stats_copy = self.stats.copy()
        
        with self.cache_lock:
            cache_size = len(self.conversation_cache)
        
        return {
            "system_stats": stats_copy,
            "cache_stats": {
                "cache_size": cache_size,
                "cache_max_size": self.cache_max_size,
                "hit_rate": stats_copy["cache_hits"] / (stats_copy["cache_hits"] + stats_copy["cache_misses"]) if (stats_copy["cache_hits"] + stats_copy["cache_misses"]) > 0 else 0
            },
            "clarification_stats": {
                "questions_recovered": stats_copy["original_questions_recovered"],
                "clarifications_resolved": stats_copy["clarification_resolutions"],
                # NOUVELLES M√âTRIQUES CRITIQUES
                "critical_clarifications_marked": stats_copy["critical_clarifications_marked"],
                "critical_clarifications_resolved": stats_copy["critical_clarifications_resolved"],
                "rag_reprocessing_triggered": stats_copy["rag_reprocessing_triggered"]
            }
        }

    def cleanup_old_conversations(self, days_old: int = 30):
        """Nettoie les conversations anciennes avec gestion d'erreurs"""
        
        try:
            cutoff_date = datetime.now() - timedelta(days=days_old)
            
            with self._get_db_connection() as conn:
                # Supprimer les messages anciens
                result_messages = conn.execute(
                    "DELETE FROM conversation_messages WHERE timestamp < ?",
                    (cutoff_date.isoformat(),)
                )
                
                # Supprimer les conversations anciennes
                result_conversations = conn.execute(
                    "DELETE FROM conversations WHERE last_activity < ?",
                    (cutoff_date.isoformat(),)
                )
                
                conn.commit()
                
                logger.info(f"üßπ [Cleanup] {result_messages.rowcount} messages et {result_conversations.rowcount} conversations supprim√©s")
                
        except Exception as e:
            logger.error(f"‚ùå [Cleanup] Erreur nettoyage: {e}")

    # SYST√àME DE CLARIFICATION INT√âGR√â - VERSION ROBUSTE
    
    def build_enriched_question_from_clarification(
        self,
        original_question: str,
        clarification_response: str,
        conversation_context: Optional[IntelligentConversationContext] = None
    ) -> str:
        """D√©l√®gue au module de clarification"""
        return self.clarification_handler.build_enriched_question_from_clarification(
            original_question, clarification_response, conversation_context
        )
    
    def detect_clarification_state(
        self, 
        conversation_context: IntelligentConversationContext
    ) -> Tuple[bool, Optional[str]]:
        """D√©l√®gue au module de clarification"""
        return self.clarification_handler.detect_clarification_state(conversation_context)

    async def process_enhanced_question_with_clarification(
        self,
        request_text: str,
        conversation_id: str,
        user_id: str,
        language: str = "fr"
    ) -> Tuple[str, bool]:
        """
        FONCTION PRINCIPALE - Traite les questions avec gestion clarification robuste
        
        Returns:
            (processed_question, was_clarification_resolved)
        """
        
        try:
            # 1. R√©cup√©rer le contexte conversationnel
            context = self.get_conversation_context(conversation_id)
            
            if not context:
                # Nouvelle conversation
                logger.info(f"üÜï [Clarification] Nouvelle conversation: {conversation_id}")
                return request_text, False
            
            # 2. D√©tecter si on est en attente de clarification
            is_awaiting, original_question = self.detect_clarification_state(context)
            
            if is_awaiting and original_question:
                logger.info(f"üéØ [Clarification] √âtat d√©tect√© - traitement clarification")
                
                # 3. Enrichir la question originale avec la clarification
                enriched_question = self.build_enriched_question_from_clarification(
                    original_question=original_question,
                    clarification_response=request_text,
                    conversation_context=context
                )
                
                # 4. Reset l'√©tat de clarification pour √©viter les boucles
                context.pending_clarification = False
                context.last_original_question_id = None
                
                # RESET AUSSI L'√âTAT CLARIFICATION CRITIQUE
                context.critical_clarification_active = False
                context.original_question_pending = None
                
                # 5. Marquer ce message comme r√©ponse de clarification
                await self.add_message_to_conversation(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    message=request_text,
                    role="user",
                    language=language,
                    message_type="clarification_response"
                )
                
                # 6. Mettre √† jour les statistiques
                self._update_stats("clarification_resolutions")
                self._update_stats("critical_clarifications_resolved")
                
                logger.info(f"‚úÖ [Clarification] Question enrichie avec succ√®s")
                
                return enriched_question, True
            
            else:
                # Question normale - pas de clarification en cours
                logger.info(f"üí¨ [Clarification] Question normale - pas de clarification")
                return request_text, False
        
        except Exception as e:
            logger.error(f"‚ùå [Clarification] Erreur traitement: {e}")
            # En cas d'erreur, retourner la question originale
            return request_text, False

    def check_if_clarification_needed(
        self,
        question: str,
        rag_response: Any,
        context: Optional[IntelligentConversationContext],
        language: str = "fr"
    ) -> Tuple[bool, List[str]]:
        """D√©l√®gue au module de clarification"""
        return self.clarification_handler.check_if_clarification_needed(question, rag_response, context, language)

    def generate_clarification_request(
        self, 
        clarification_questions: List[str], 
        language: str = "fr"
    ) -> str:
        """D√©l√®gue au module de clarification"""
        return self.clarification_handler.generate_clarification_request(clarification_questions, language)

    # M√âTHODES POUR CLARIFICATION CRITIQUE - VERSION ROBUSTE

    def mark_pending_clarification_critical(
        self, 
        conversation_id: str,
        question: str, 
        callback: Optional[RAGCallbackProtocol] = None
    ) -> bool:
        """
        Marque une question pour clarification critique avec callback robuste
        
        Args:
            conversation_id: ID de la conversation
            question: Question originale qui n√©cessite clarification
            callback: Fonction callback pour relancer le traitement RAG
            
        Returns:
            bool: True si marquage r√©ussi, False sinon
        """
        
        try:
            # R√©cup√©rer le contexte
            context = self.get_conversation_context(conversation_id)
            if not context:
                logger.error(f"‚ùå [CriticalClarification] Contexte non trouv√©: {conversation_id}")
                return False
            
            # Marquer la clarification critique
            context.mark_pending_clarification(question, callback)
            
            # Sauvegarder en base de mani√®re s√©curis√©e
            try:
                self._save_conversation_to_db(context)
            except Exception as save_error:
                logger.warning(f"‚ö†Ô∏è [CriticalClarification] Erreur sauvegarde: {save_error}")
                # Continuer m√™me si sauvegarde √©choue
            
            # Mettre √† jour le cache de mani√®re thread-safe
            with self.cache_lock:
                self.conversation_cache[conversation_id] = deepcopy(context)
            
            # Statistiques
            self._update_stats("critical_clarifications_marked")
            
            logger.info(f"üö® [CriticalClarification] Marquage r√©ussi pour: {conversation_id}")
            logger.info(f"  üìù Question: {question[:100]}...")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå [CriticalClarification] Erreur marquage: {e}")
            return False

    def mark_question_for_clarification(
        self, 
        conversation_id: str, 
        user_id: str, 
        original_question: str, 
        language: str = "fr"
    ) -> str:
        """
        Marque une question pour clarification future de mani√®re robuste
        """
        
        try:
            # Cr√©er un marqueur sp√©cial dans la conversation
            marker_message = f"ORIGINAL_QUESTION_FOR_CLARIFICATION: {original_question}"
            
            message_id = f"{conversation_id}_original_{int(time.time())}"
            
            # Cr√©er le message marqueur
            marker_msg = ConversationMessage(
                id=message_id,
                conversation_id=conversation_id,
                user_id=user_id,
                role="system",
                message=marker_message,
                timestamp=datetime.now(),
                language=language,
                message_type="original_question_marker",
                is_original_question=True
            )
            
            # R√©cup√©rer ou cr√©er le contexte
            context = self.get_conversation_context(conversation_id)
            if not context:
                context = IntelligentConversationContext(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    language=language
                )
            
            # Ajouter le marqueur
            context.add_message(marker_msg)
            context.pending_clarification = True
            context.last_original_question_id = message_id
            
            # Sauvegarder de mani√®re s√©curis√©e
            try:
                self._save_conversation_to_db(context)
                self._save_message_to_db(marker_msg)
            except Exception as save_error:
                logger.warning(f"‚ö†Ô∏è [Clarification] Erreur sauvegarde marqueur: {save_error}")
            
            # Mettre en cache de mani√®re thread-safe
            with self.cache_lock:
                self.conversation_cache[conversation_id] = deepcopy(context)
            
            logger.info(f"üéØ [Memory] Question originale marqu√©e: {original_question[:50]}...")
            
            return message_id
            
        except Exception as e:
            logger.error(f"‚ùå [Clarification] Erreur marquage question: {e}")
            return f"error_{int(time.time())}"


# ===============================
# üîß R√âSUM√â DES CORRECTIONS COMPL√àTES APPLIQU√âES
# ===============================

"""
üö® R√â√âCRITURE COMPL√àTE AVEC TOUTES LES CORRECTIONS:

FICHIER 1/3: conversation_entities.py
- ‚úÖ Entit√©s IntelligentEntities avec tous les attributs requis
- ‚úÖ Attribut 'weight' ajout√© et synchronis√© avec weight_grams  
- ‚úÖ Gestion s√©curis√©e des types avec safe_int_conversion/safe_float_conversion
- ‚úÖ Validation et correction automatique des incoh√©rences
- ‚úÖ Contexte conversationnel avec clarification critique

FICHIER 2/3: conversation_extraction.py  
- ‚úÖ Extraction OpenAI avec prompts optimis√©s
- ‚úÖ Fallback robuste sans d√©pendances manquantes
- ‚úÖ Gestionnaire de clarifications intelligent
- ‚úÖ Synchronisation weight/weight_grams dans toutes les extractions

FICHIER 3/3: conversation_memory.py (fichier principal)
- ‚úÖ Classe IntelligentConversationMemory compl√®te
- ‚úÖ Thread-safety avec RLock au lieu de Lock
- ‚úÖ Int√©gration des modules sp√©cialis√©s  
- ‚úÖ Gestion base de donn√©es robuste
- ‚úÖ Toutes les m√©thodes existantes conserv√©es
- ‚úÖ WeakRef pour √©viter les fuites m√©moire

ARCHITECTURE MODULAIRE:
üìÅ conversation_entities.py   - Structures de donn√©es
üìÅ conversation_extraction.py - Logique IA et clarifications  
üìÅ conversation_memory.py     - Syst√®me principal (compatible imports existants)

UTILISATION:
from app.api.v1.conversation_memory import IntelligentConversationMemory

Le code est maintenant ENTI√àREMENT FONCTIONNEL, modulaire et robuste.
"""
