import os
import re
import json
import logging
from typing import Dict, List, Tuple, Any
from app.api.v1.utils.entity_normalizer import EntityNormalizer
from app.api.v1.utils.validation_pipeline import validate_and_score
from app.api.v1.utils.openai_utils import safe_chat_completion

# Configuration du logging
logger = logging.getLogger(__name__)

class ContextExtractor:
    """
    Extracts structured context from a raw question.
    Uses GPT via safe_chat_completion to parse key fields into JSON,
    then falls back to regex extraction on failure.
    Returns: (context_dict, completeness_score, missing_fields)
    
    AM√âLIORATIONS APPLIQU√âES:
    - Patterns regex externalis√©s et configurables
    - Gestion d'erreurs robuste pour l'appel OpenAI
    - Validation JSON stricte avec fallback
    - Logging d√©taill√© pour debug
    - Configuration flexible via fichiers externes
    """
    
    def __init__(self, use_gpt: bool = True, patterns_config_path: str = None):
        self.normalizer = EntityNormalizer()
        self.use_gpt = use_gpt
        self.patterns = self._load_extraction_patterns(patterns_config_path)
        
        # Configuration GPT fields (externalisable aussi)
        self.gpt_fields = self._get_gpt_fields()
        
        logger.debug(f"ContextExtractor initialis√© avec {len(self.patterns)} patterns")

    def _get_gpt_fields(self) -> List[str]:
        """
        ‚úÖ AM√âLIORATION: Champs GPT configurables
        Peut √™tre √©tendu pour charger depuis la configuration
        """
        return [
            "age_jours", "production_type", "age_phase", "sex_category",
            "site_type", "housing_type", "activity", "parameter", 
            "numeric_value", "issue", "user_role", "objective", "breed"
        ]

    def _load_extraction_patterns(self, config_path: str = None) -> Dict[str, str]:
        """
        ‚úÖ AM√âLIORATION MAJEURE: Charge les patterns depuis un fichier de configuration
        
        Ordre de priorit√©:
        1. Fichier sp√©cifi√© en param√®tre
        2. Variable d'environnement EXTRACTION_PATTERNS_PATH
        3. Fichier par d√©faut extraction_patterns.json
        4. Patterns hardcod√©s en fallback
        """
        
        # D√©terminer le chemin du fichier de configuration
        if config_path:
            patterns_file = config_path
        else:
            patterns_file = os.getenv(
                'EXTRACTION_PATTERNS_PATH', 
                os.path.join(os.path.dirname(__file__), 'extraction_patterns.json')
            )
        
        # Tentative de chargement depuis fichier
        if os.path.exists(patterns_file):
            try:
                with open(patterns_file, 'r', encoding='utf-8') as f:
                    patterns_config = json.load(f)
                    
                if 'patterns' in patterns_config:
                    logger.info(f"‚úÖ Patterns charg√©s depuis: {patterns_file}")
                    return patterns_config['patterns']
                else:
                    logger.warning(f"‚ö†Ô∏è Format invalide dans {patterns_file}, cl√© 'patterns' manquante")
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur chargement patterns depuis {patterns_file}: {e}")
        else:
            logger.debug(f"üìÅ Fichier patterns non trouv√©: {patterns_file}")
        
        # Fallback vers patterns hardcod√©s
        logger.info("üîÑ Utilisation des patterns par d√©faut (hardcod√©s)")
        return self._get_default_patterns()

    def _get_default_patterns(self) -> Dict[str, str]:
        """
        ‚úÖ AM√âLIORATION: Patterns par d√©faut s√©par√©s en m√©thode
        Facilite la maintenance et les tests
        """
        return {
            "production_type": r"\b(?:broiler|layer|breeder|pullet)s?\b",
            "age_phase": r"\b(?:day|d|week|wk|wks|month|mo)s?[-\s]*old\b|\b(?:at|from|on)?\s?\b(?:day\s?\d{1,2}|week\s?\d{1,2})\b",
            "sex_category": r"\b(?:male|female|mixed flock|pullets?|cockerels?)\b",
            "site_type": r"\b(?:hatchery|barn|house|processing plant|feed mill)\b",
            "housing_type": r"\b(?:tunnel-ventilated|open-sided|enriched cage|aviary|floor|slatted floor)\b",
            "activity": r"\b(?:feeding|vaccination|beak trimming|culling|catching|lighting|ventilation|weighing|sampling)\b",
            "parameter": r"\b(?:weight|body weight|FCR|feed conversion|mortality|water intake|egg production|temperature|humidity|NH3|CO2|uniformity)\b",
            "numeric_value": r"""
                \b
                (\d+(?:[\.,]\d+)?\s*
                (?:
                    kg|g|mg|\u00b5g|mcg|lb|lbs|oz|
                    l|L|ml|mL|gal|gallon[s]?|qt[s]?|
                    \u00b0C|\u00b0F|C|F|
                    cm|mm|m|in(?:ch)?(?:es)?|ft|feet|
                    ppm|%|bpm|IU|
                    g/bird|lb/bird|oz/bird|
                    g/day|g/bird/day|lb/day|
                    birds|eggs|head[s]?|
                    cal|kcal|kcal/kg|kcal/lb
                ))
                \b
            """,
            "issue": r"\b(" + "|".join([
                "heat stress", "thermal stress", "feather pecking", "pecking", "cannibalism",
                "aggression", "fighting", "lethargy", "inactivity", "reduced mobility",
                "lameness", "leg problems", "limping", "breast blister", "keel bone damage",
                "footpad dermatitis", "footpad lesions", "slipping", "loss of balance", "paralysis", "paresis",
                "high mortality", "sudden death syndrome", "sudden death", "flip[- ]?over", "low viability",
                "low livability", "deformities", "skeletal defects",
                "wet litter", "ammonia smell", "high NH3", "high temperature", "overheating",
                "cold drafts", "low barn temperature", "poor air quality", "low airflow", "CO2 buildup",
                "underfeeding", "feed restriction", "poor FCR", "high feed conversion ratio",
                "waterline blockage", "no access to water", "nutrient deficiency", "excess salt",
                "poor formulation",
                "respiratory issues", "sneezing", "rales", "enteritis", "diarrhea", "wet droppings",
                "bacterial infection", "colibacillosis", "viral outbreak", "IBV", "NDV", "AI", "coccidiosis",
                "vaccination failure", "poor immune response",
                "low egg production", "drop in lay rate", "thin shells", "shell defects", "poor shell quality",
                "dirty eggs", "soiled eggs", "floor eggs", "eggs outside nesting area", "egg binding"
            ]) + r")\b",
            "user_role": r"\b(?:farmer|grower|veterinarian|nutritionist|technician|supervisor|consultant)\b",
            "objective": r"\b(?:optimize|improve|detect|prevent|reduce|increase|adjust|monitor)\b",
            "breed": r"\b(ross\s?\d{3}|ross|cobb\s?\d{3}|cobb|hubbard|dekalb|hy-?line|lohmann|isa\s?brown|isa)\b",
        }

    def reload_patterns(self, config_path: str = None) -> bool:
        """
        ‚úÖ NOUVELLE FONCTIONNALIT√â: Rechargement des patterns √† chaud
        Utile pour les mises √† jour sans red√©marrage
        """
        try:
            old_count = len(self.patterns)
            self.patterns = self._load_extraction_patterns(config_path)
            new_count = len(self.patterns)
            
            logger.info(f"üîÑ Patterns recharg√©s: {old_count} ‚Üí {new_count}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur rechargement patterns: {e}")
            return False

    def extract(self, question: str) -> Tuple[Dict[str, Any], float, List[str]]:
        """
        Extrait le contexte d'une question avec gestion d'erreurs robuste
        """
        if not question or not question.strip():
            logger.warning("Question vide re√ßue")
            return {}, 0.0, []
        
        question = question.strip()
        context: Dict[str, Any] = {}
        
        if self.use_gpt:
            logger.debug(f"ü§ñ Tentative d'extraction GPT pour: {question[:50]}...")
            context = self._extract_with_gpt(question)
            
            # Si GPT √©choue ou retourne peu de r√©sultats, essayer regex aussi
            if len(context) < 2:
                logger.debug("üîÑ R√©sultats GPT limit√©s, enrichissement avec regex...")
                regex_context = self._regex_extract(question)
                # Merger les r√©sultats (GPT prioritaire)
                for key, value in regex_context.items():
                    if key not in context:
                        context[key] = value
        else:
            logger.debug("üìù Extraction directe par regex (GPT d√©sactiv√©)")
            context = self._regex_extract(question)

        # Normalisation et validation (conserv√©)
        context = self.normalizer.normalize(context)
        score, missing = validate_and_score(context, question)
        
        logger.debug(f"üìä Contexte final: {len(context)} champs, score: {score:.2f}")
        
        return context, score, missing

    def _extract_with_gpt(self, question: str) -> Dict[str, Any]:
        """
        ‚úÖ AM√âLIORATION: Extraction GPT s√©par√©e avec gestion d'erreurs robuste
        """
        
        fields_str = ", ".join(self.gpt_fields)
        prompt = (
            "Vous √™tes un assistant avicole expert. √Ä partir de la question utilisateur, "
            f"extrayez les champs suivants si pr√©sents: {fields_str}. "
            "R√©pondez UNIQUEMENT au format JSON valide avec ces cl√©s si trouv√©es. "
            "Ne pas ajouter de texte avant ou apr√®s le JSON. "
            "Si un champ n'est pas pr√©sent, ne pas l'inclure dans la r√©ponse."
            f"\n\nQuestion: {question}"
        )
        
        try:
            # Tentative d'appel OpenAI avec timeout et retry
            resp = safe_chat_completion(
                model=os.getenv("OPENAI_MODEL", "gpt-4o"),
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=256
            )
            
            if not resp or not resp.choices:
                logger.warning("‚ö†Ô∏è R√©ponse OpenAI vide ou malform√©e")
                return {}
            
            content = resp.choices[0].message.content.strip()
            logger.debug(f"ü§ñ R√©ponse GPT brute: {content[:200]}...")
            
            return self._parse_json_response(content)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur extraction GPT: {type(e).__name__}: {str(e)}")
            return {}

    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """
        ‚úÖ AM√âLIORATION: Parse robuste de la r√©ponse JSON avec nettoyage
        """
        try:
            # Nettoyage du contenu
            cleaned_content = content.strip()
            
            # Supprimer les blocs de code markdown si pr√©sents
            if cleaned_content.startswith("```json"):
                cleaned_content = cleaned_content[7:]
            elif cleaned_content.startswith("```"):
                cleaned_content = cleaned_content[3:]
            
            if cleaned_content.endswith("```"):
                cleaned_content = cleaned_content[:-3]
            
            cleaned_content = cleaned_content.strip()
            
            # Tentative de parsing JSON
            extracted = json.loads(cleaned_content)
            
            if not isinstance(extracted, dict):
                logger.warning(f"‚ö†Ô∏è R√©ponse JSON n'est pas un dict: {type(extracted)}")
                return {}
            
            # Filtrer uniquement les champs valides et non vides
            valid_keys = set(self.gpt_fields)
            filtered_context = {
                k: v for k, v in extracted.items() 
                if k in valid_keys and v and str(v).strip()
            }
            
            if filtered_context:
                logger.debug(f"‚úÖ Extraction GPT r√©ussie: {len(filtered_context)} champs")
            else:
                logger.debug("‚ÑπÔ∏è Aucun champ valide dans la r√©ponse GPT")
            
            return filtered_context
                
        except json.JSONDecodeError as e:
            logger.debug(f"‚ö†Ô∏è Erreur parsing JSON: {e}")
            logger.debug(f"Contenu probl√©matique: {content[:100]}...")
            return {}
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur inattendue parsing JSON: {e}")
            return {}

    def _regex_extract(self, question: str) -> Dict[str, Any]:
        """
        ‚úÖ AM√âLIORATION: Extraction regex avec patterns configurables
        """
        ctx: Dict[str, Any] = {}
        
        for field, pattern in self.patterns.items():
            try:
                matches = re.findall(pattern, question, re.IGNORECASE | re.VERBOSE)
                if matches:
                    # Nettoyer les matches (supprimer les cha√Ænes vides)
                    clean_matches = [m for m in matches if m and str(m).strip()]
                    if clean_matches:
                        ctx[field] = clean_matches[0] if len(clean_matches) == 1 else clean_matches
                        
            except re.error as e:
                logger.error(f"‚ùå Erreur regex pour le champ '{field}': {e}")
                continue
        
        logger.debug(f"üìù Extraction regex: {len(ctx)} champs trouv√©s")
        return ctx

    def get_available_fields(self) -> Dict[str, List[str]]:
        """
        ‚úÖ NOUVELLE FONCTIONNALIT√â: Liste des champs disponibles
        Utile pour la documentation et les tests
        """
        return {
            "gpt_fields": self.gpt_fields.copy(),
            "regex_fields": list(self.patterns.keys()),
            "all_fields": list(set(self.gpt_fields) | set(self.patterns.keys()))
        }

    def validate_patterns(self) -> Dict[str, Any]:
        """
        ‚úÖ NOUVELLE FONCTIONNALIT√â: Validation des patterns regex
        D√©tecte les patterns malform√©s
        """
        results = {
            "valid": [],
            "invalid": [],
            "warnings": []
        }
        
        for field, pattern in self.patterns.items():
            try:
                # Test de compilation
                re.compile(pattern, re.IGNORECASE | re.VERBOSE)
                results["valid"].append(field)
                
                # V√©rification de patterns trop larges
                if len(pattern) < 10:
                    results["warnings"].append(f"{field}: pattern tr√®s court")
                    
            except re.error as e:
                results["invalid"].append(f"{field}: {str(e)}")
        
        return results

# ‚úÖ NOUVELLE FONCTIONNALIT√â: Fonction utilitaire pour cr√©er le fichier de configuration
def create_default_patterns_file(output_path: str = "extraction_patterns.json") -> bool:
    """
    Cr√©e un fichier de configuration par d√©faut pour les patterns
    """
    try:
        extractor = ContextExtractor()
        config = {
            "version": "1.0",
            "description": "Patterns d'extraction pour ContextExtractor",
            "patterns": extractor._get_default_patterns(),
            "gpt_fields": extractor._get_gpt_fields()
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ Fichier patterns cr√©√©: {output_path}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur cr√©ation fichier patterns: {e}")
        return False

if __name__ == "__main__":
    # Script utilitaire pour cr√©er le fichier de configuration
    create_default_patterns_file()