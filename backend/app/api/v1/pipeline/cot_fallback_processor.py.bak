# -*- coding: utf-8 -*-
"""
Processeur Chain-of-Thought et fallback OpenAI
Extrait de dialogue_manager.py pour modularit√©
VERSION CORRIG√âE: Formatage Markdown am√©lior√©
"""

import logging
import os
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

# Import conditionnel OpenAI avanc√©
try:
    from ..utils.openai_utils import (
        complete_text as openai_complete,
        complete_with_cot,
        synthesize_rag_content,
        generate_clarification_response,
        get_openai_status,
        test_cot_pipeline,
        test_synthesis_pipeline
    )
    OPENAI_FALLBACK_AVAILABLE = True
    OPENAI_COT_AVAILABLE = True
    logger.info("‚úÖ OpenAI fallback + CoT disponible pour r√©ponses avanc√©es")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è OpenAI fallback avanc√© indisponible: {e}")
    # Fallback vers fonctions basiques
    try:
        from ..utils.openai_utils import complete_text as openai_complete
        from ..utils.openai_utils import get_openai_status
        OPENAI_FALLBACK_AVAILABLE = True
        OPENAI_COT_AVAILABLE = False
        logger.info("‚úÖ OpenAI fallback basique disponible")
    except ImportError:
        OPENAI_FALLBACK_AVAILABLE = False
        OPENAI_COT_AVAILABLE = False
        def openai_complete(*args, **kwargs): return None
        def get_openai_status(): return {"status": "unavailable"}

# ---------------------------------------------------------------------------
# D√âTECTION ET ANALYSE CHAIN-OF-THOUGHT
# ---------------------------------------------------------------------------

def should_use_cot_analysis(intent, entities: Dict[str, Any], question: str) -> bool:
    """
    D√©termine si une analyse Chain-of-Thought serait b√©n√©fique
    """
    if not OPENAI_COT_AVAILABLE:
        return False
    
    # Import local pour √©viter circulaire
    from ..utils.question_classifier import Intention
    
    # Intentions complexes b√©n√©ficiant du CoT
    cot_intents = {
        Intention.HealthDiagnosis,
        Intention.MultiFactor,
        Intention.TroubleshootingMultiple,
        Intention.Economics,
        Intention.OptimizationStrategy,
        Intention.ProductionAnalysis
    }
    
    if intent in cot_intents:
        return True
    
    # D√©tection de questions complexes dans le texte
    complexity_indicators = [
        "probl√®me", "diagnostic", "analyse", "optimiser", "am√©liorer",
        "strat√©gie", "multiple", "plusieurs", "complexe", "comparer",
        "√©valuer", "recommandation", "pourquoi", "comment r√©soudre"
    ]
    
    question_lower = question.lower()
    complexity_score = sum(1 for indicator in complexity_indicators if indicator in question_lower)
    
    # Si 2+ indicateurs de complexit√© ou question tr√®s longue
    return complexity_score >= 2 or len(question) > 200

def build_agricultural_context(entities: Dict[str, Any], intent) -> str:
    """
    Construit un contexte agricole pour orienter la r√©ponse OpenAI
    """
    context_parts = []
    
    # Contexte esp√®ce
    species = entities.get("species", "").lower()
    if species == "broiler":
        context_parts.append("Contexte : Poulets de chair (broilers)")
    elif species == "layer":
        context_parts.append("Contexte : Poules pondeuses")
    else:
        context_parts.append("Contexte : √âlevage de volailles")
    
    # Contexte lign√©e si disponible
    line = entities.get("line")
    if line:
        line_map = {
            "ross308": "lign√©e Ross 308",
            "cobb500": "lign√©e Cobb 500",
            "hubbard": "lign√©e Hubbard"
        }
        line_name = line_map.get(line.lower(), f"lign√©e {line}")
        context_parts.append(f"Lign√©e : {line_name}")
    
    # Contexte √¢ge si disponible
    age_days = entities.get("age_days")
    if age_days:
        context_parts.append(f"√Çge : {age_days} jours")
    
    # Contexte sexe si disponible
    sex = entities.get("sex")
    if sex:
        sex_map = {
            "male": "m√¢les",
            "female": "femelles", 
            "as_hatched": "sexes m√©lang√©s"
        }
        sex_name = sex_map.get(sex.lower(), sex)
        context_parts.append(f"Sexe : {sex_name}")
    
    # Contexte intention
    intent_context = {
        "PerfTargets": "Focus sur les objectifs de performance (poids, croissance)",
        "HealthDiagnosis": "Focus sur la sant√© et diagnostic v√©t√©rinaire",
        "NutritionAdvice": "Focus sur l'alimentation et la nutrition",
        "HousingEnvironment": "Focus sur le logement et l'environnement d'√©levage",
        "ManagementPractices": "Focus sur les pratiques de gestion d'√©levage",
        "WaterFeedIntake": "Focus sur la consommation d'eau et d'aliment",
        "EquipmentSizing": "Focus sur le dimensionnement des √©quipements",
        "VentilationSizing": "Focus sur la ventilation et l'ambiance",
        "EnvSetpoints": "Focus sur les consignes environnementales",
        "Economics": "Focus sur les aspects √©conomiques de l'√©levage",
        "MultiFactor": "Analyse multi-factorielle complexe",
        "TroubleshootingMultiple": "R√©solution de probl√®mes multiples",
        "OptimizationStrategy": "Strat√©gie d'optimisation globale",
        "ProductionAnalysis": "Analyse de performance de production"
    }
    
    intent_name = intent.name if hasattr(intent, 'name') else str(intent)
    if intent_name in intent_context:
        context_parts.append(intent_context[intent_name])
    
    return "\n".join(context_parts)

def generate_cot_analysis(question: str, entities: Dict[str, Any], intent, 
                         rag_context: str = "", target_language: str = "fr") -> Optional[Dict[str, Any]]:
    """
    G√©n√®re une analyse Chain-of-Thought pour questions complexes
    """
    if not OPENAI_COT_AVAILABLE:
        return None
        
    try:
        # Construction du contexte avicole
        system_context = build_agricultural_context(entities, intent)
        
        # Prompt CoT sp√©cialis√© selon l'intention
        cot_prompts = {
            "HealthDiagnosis": f"""Tu es un v√©t√©rinaire avicole expert. Analyse cette situation sanitaire avec une approche m√©thodologique rigoureuse.

{system_context}

Question: {question}

Contexte disponible: {rag_context[:500] if rag_context else 'Contexte limit√©'}

<thinking>
Identifie les sympt√¥mes, signes cliniques et facteurs mentionn√©s dans la question.
</thinking>

<analysis>
Analyse les causes possibles, facteurs de risque et interconnexions.
</analysis>

<factors>
√âvalue l'impact de l'√¢ge, lign√©e, environnement et gestion sur la situation.
</factors>

<recommendations>
Propose un diagnostic diff√©rentiel et plan d'action structur√©.
</recommendations>

Diagnostic v√©t√©rinaire professionnel:""",

            "Economics": f"""Tu es un expert en √©conomie avicole. Analyse cette situation avec une approche financi√®re structur√©e.

{system_context}

Question: {question}

Contexte: {rag_context[:500] if rag_context else 'Donn√©es limit√©es'}

<economic_context>
Analyse la situation √©conomique actuelle et les facteurs de co√ªt.
</economic_context>

<cost_benefit_breakdown>
D√©compose les co√ªts et b√©n√©fices identifiables.
</cost_benefit_breakdown>

<scenario_analysis>
√âvalue diff√©rents sc√©narios et leur impact financier.
</scenario_analysis>

<optimization_levers>
Identifie les leviers d'optimisation √©conomique.
</optimization_levers>

<financial_recommendation>
Propose une strat√©gie financi√®re concr√®te et chiffr√©e.
</financial_recommendation>

Analyse √©conomique compl√®te:""",

            "default": f"""Tu es un expert avicole. Analyse cette situation avec une approche m√©thodologique.

{system_context}

Question: {question}

Contexte: {rag_context[:500] if rag_context else 'Contexte partiel'}

<thinking>
D√©compose le probl√®me et identifie les √©l√©ments cl√©s.
</thinking>

<analysis>
Analyse les facteurs impliqu√©s et leurs interactions.
</analysis>

<recommendations>
Propose des solutions concr√®tes et prioris√©es.
</recommendations>

R√©ponse experte structur√©e:"""
        }
        
        intent_name = intent.name if hasattr(intent, 'name') else str(intent)
        cot_prompt = cot_prompts.get(intent_name, cot_prompts["default"])
        
        # Adaptation linguistique du prompt si n√©cessaire
        if target_language != "fr":
            cot_prompt = cot_prompt.replace("Tu es", "You are").replace("Analyse", "Analyze")
            # Adaptation basique - le mod√®le s'adaptera au contexte
        
        # Analyse CoT avec parsing
        cot_result = complete_with_cot(
            prompt=cot_prompt,
            temperature=0.4,  # Cr√©ativit√© mod√©r√©e pour expertise
            max_tokens=800,   # Suffisant pour analyse compl√®te
            parse_cot=True
        )
        
        if cot_result:
            return {
                "text": cot_result.get("final_answer", cot_result.get("raw_response", "")),
                "source": "cot_analysis",
                "confidence": 0.85,  # Confiance √©lev√©e pour analyse structur√©e
                "sources": [],
                "meta": {
                    "cot_sections": cot_result.get("parsed_sections", {}),
                    "analysis_type": intent_name,
                    "entities_used": entities,
                    "rag_context_provided": bool(rag_context.strip()),
                    "target_language": target_language,
                    "raw_response_length": len(cot_result.get("raw_response", ""))
                }
            }
            
    except Exception as e:
        logger.error(f"‚ùå Erreur analyse CoT: {e}")
        
    return None

# ---------------------------------------------------------------------------
# FALLBACK OPENAI AM√âLIOR√â AVEC FORMATAGE CORRIG√â
# ---------------------------------------------------------------------------

def should_use_openai_fallback(rag_result: Dict[str, Any], intent) -> bool:
    """
    D√©termine si OpenAI fallback doit √™tre utilis√© apr√®s √©chec RAG
    """
    # Cas o√π le RAG n'a pas trouv√© de r√©sultats
    if rag_result.get("route") in ["rag_no_results", "rag_error", "rag_unavailable"]:
        return True
    
    # Cas o√π le RAG a trouv√© tr√®s peu de contenu pertinent
    text = rag_result.get("text", "")
    if len(text.strip()) < 50:  # R√©ponse trop courte
        return True
        
    # D√©tecter les fragments de tableaux non pertinents
    text_lower = text.lower()
    table_indicators = [
        "[tableau]", "table", "0.08", "0.10", "0.12", "0.15", "0.17", "0.20",
        "distance air", "ceiling", "width", "pressure drop", "pa (0.01",
        "post-mortem", "examination", "subdermal", "thoracic coelomic"
    ]
    table_matches = sum(1 for indicator in table_indicators if indicator in text_lower)
    
    # Si plus de 3 indicateurs de tableau d√©tect√©s, probable fragment non pertinent
    if table_matches >= 3:
        logger.info(f"üîç Fragment de tableau d√©tect√© ({table_matches} indicateurs) - activation fallback")
        return True
        
    # Cas o√π le RAG retourne un message d'erreur g√©n√©rique
    error_indicators = [
        "aucune information", "non disponible", "n'est pas disponible",
        "une erreur est survenue", "moteur rag", "base de connaissances"
    ]
    if any(indicator in text_lower for indicator in error_indicators):
        return True
        
    return False

def generate_openai_fallback_response(question: str, entities: Dict[str, Any], intent, rag_context: str = "", target_language: str = "fr") -> Optional[Dict[str, Any]]:
    """
    G√©n√®re une r√©ponse via OpenAI quand le RAG √©choue
    VERSION CORRIG√âE: Formatage Markdown forc√© et structure claire
    """
    if not OPENAI_FALLBACK_AVAILABLE:
        return None
    
    try:
        # V√©rifier si CoT serait appropri√©
        if OPENAI_COT_AVAILABLE and should_use_cot_analysis(intent, entities, question):
            logger.info("üß† Fallback avec analyse CoT pour question complexe")
            cot_result = generate_cot_analysis(
                question=question,
                entities=entities,
                intent=intent,
                rag_context=rag_context,
                target_language=target_language
            )
            
            if cot_result:
                cot_result["meta"]["fallback_reason"] = "rag_insufficient_cot_analysis"
                return cot_result
        
        # Fallback standard si CoT non disponible/appropri√©
        system_context = build_agricultural_context(entities, intent)
        
        # üîß CORRECTION: Prompt avec formatage Markdown forc√©
        if target_language == "fr":
            fallback_prompt = f"""Tu es un expert en aviculture et zootechnie. Un utilisateur pose une question sur l'√©levage de volailles.

{system_context}

Question de l'utilisateur : {question}

Contexte partiel disponible (si pertinent) : {rag_context}

INSTRUCTIONS DE FORMATAGE OBLIGATOIRES :
- Commence par un titre principal avec ## (exemple: ## Diagnostic Principal)
- Structure ta r√©ponse avec des sections claires utilisant ### pour les sous-titres
- Utilise **gras** pour les √©l√©ments importants (diagnostic, valeurs cl√©s)
- Utilise des listes √† puces avec - pour √©num√©rer les points
- S√©pare chaque section par une ligne vide
- JAMAIS de tableaux bruts ou de donn√©es mal format√©es
- JAMAIS de fragments de texte non structur√©s

STRUCTURE SUGG√âR√âE :
## Diagnostic Principal
[Description claire du diagnostic principal]

### Causes Possibles
- Cause 1 avec explication
- Cause 2 avec explication
- Cause 3 avec explication

### Recommandations
- **Imm√©diat** : Action urgente
- **Court terme** : Actions √† 2-7 jours
- **Pr√©vention** : Mesures pr√©ventives

Si tu mentionnes des valeurs, indique qu'elles sont approximatives et qu'une consultation des guides techniques sp√©cifiques est recommand√©e.

R√©ponse professionnelle BIEN FORMAT√âE EN FRAN√áAIS :"""

        else:
            # Pour toutes les autres langues (surtout anglais)
            fallback_prompt = f"""You are an expert in poultry farming and zootechnics. A user is asking a question about poultry farming.

{system_context}

User's question: {question}

Partial available context (if relevant): {rag_context}

MANDATORY FORMATTING INSTRUCTIONS:
- Start with a main title using ## (example: ## Primary Diagnosis)
- Structure your response with clear sections using ### for subtitles
- Use **bold** for important elements (diagnosis, key values)
- Use bullet points with - to enumerate items
- Separate each section with a blank line
- NEVER include raw tables or poorly formatted data
- NEVER include unstructured text fragments

SUGGESTED STRUCTURE:
## Primary Diagnosis
[Clear description of the main diagnosis]

### Possible Causes
- Cause 1 with explanation
- Cause 2 with explanation
- Cause 3 with explanation

### Recommendations
- **Immediate**: Urgent action
- **Short term**: Actions within 2-7 days
- **Prevention**: Preventive measures

If you mention values, indicate they are approximate and recommend consulting specific technical guides.

Professional WELL-FORMATTED response IN ENGLISH ONLY:"""

        # Utilisation de la fonction complete optimis√©e
        response = openai_complete(
            prompt=fallback_prompt,
            temperature=0.3,  # L√©g√®rement cr√©atif mais pr√©cis
            max_tokens=500    # Augment√© pour permettre le formatage
        )
        
        if response:
            return {
                "text": response,
                "source": "openai_fallback",
                "confidence": 0.75,  # Confiance mod√©r√©e
                "sources": [],
                "meta": {
                    "fallback_reason": "rag_insufficient",
                    "entities_used": entities,
                    "intent": intent.name if hasattr(intent, 'name') else str(intent),
                    "rag_context_provided": bool(rag_context.strip()),
                    "target_language": target_language,
                    "prompt_language": "french" if target_language == "fr" else "english",
                    "cot_attempted": False,
                    "formatting_enhanced": True  # üîß Nouveau flag
                }
            }
            
    except Exception as e:
        logger.error(f"‚ùå OpenAI fallback √©chou√©: {e}")
        
    return None

# ---------------------------------------------------------------------------
# SYNTH√àSE ET CLARIFICATION AM√âLIOR√âES
# ---------------------------------------------------------------------------

def maybe_synthesize(question: str, context_text: str) -> str:
    """
    Utilise les nouvelles fonctions de synth√®se si disponibles
    VERSION CORRIG√âE: Formatage am√©lior√©
    """
    try:
        if str(os.getenv("ENABLE_SYNTH_PROMPT", "0")).lower() not in ("1", "true", "yes", "on"):
            return context_text
        
        # Essai d'abord avec la fonction sp√©cialis√©e si disponible
        if OPENAI_FALLBACK_AVAILABLE:
            try:
                # V√©rifier si synthesize_rag_content est disponible
                if 'synthesize_rag_content' in globals():
                    return synthesize_rag_content(question, context_text, max_length=300)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec synth√®se sp√©cialis√©e, fallback standard: {e}")
        
        # üîß CORRECTION: Prompt de synth√®se avec formatage forc√©
        synthesis_prompt = f"""Tu es un expert avicole. Synth√©tise cette information de mani√®re claire et professionnelle.

R√àGLES DE FORMATAGE OBLIGATOIRES :
- Utilise ## pour le titre principal
- Utilise ### pour les sections
- Utilise **gras** pour les √©l√©ments importants
- Utilise des listes √† puces avec - pour √©num√©rer
- S√©pare les sections par des lignes vides
- NE JAMAIS mentionner les sources dans ta r√©ponse
- NE JAMAIS inclure de fragments de texte brut des PDFs
- NE JAMAIS copier-coller des tableaux mal format√©s
- Si l'info est incertaine, donne une fourchette et dis-le

Question : {question}

Informations √† synth√©tiser :
{context_text[:2000]}

R√©ponse synth√©tique BIEN FORMAT√âE :"""
        
        synthesized = openai_complete(synthesis_prompt, temperature=0.2, max_tokens=400)
        return synthesized if synthesized else context_text
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur lors de la synth√®se LLM: {e}")
        return context_text

def generate_clarification_response_advanced(intent, missing_fields: list, general_info: str = "") -> str:
    """
    Utilise generate_clarification_response si disponible, sinon fallback
    """
    try:
        if OPENAI_FALLBACK_AVAILABLE and 'generate_clarification_response' in globals():
            return generate_clarification_response(
                intent=intent.name if hasattr(intent, 'name') else str(intent),
                missing_fields=missing_fields,
                general_info=general_info
            )
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è √âchec clarification sp√©cialis√©e: {e}")
    
    # Fallback basique avec formatage
    return f"""## Informations Suppl√©mentaires Requises

Pour vous donner une r√©ponse pr√©cise, j'ai besoin de pr√©cisions sur :

{chr(10).join(f'- **{field}**' for field in missing_fields)}

Pouvez-vous me fournir ces informations pour une analyse compl√®te ?"""

# ---------------------------------------------------------------------------
# FONCTIONS DE STATUT ET TEST
# ---------------------------------------------------------------------------

def get_cot_fallback_status() -> Dict[str, Any]:
    """
    Retourne le statut du syst√®me CoT et fallback
    """
    status = {
        "openai_fallback_available": OPENAI_FALLBACK_AVAILABLE,
        "openai_cot_available": OPENAI_COT_AVAILABLE,
        "fallback_enabled": str(os.getenv("ENABLE_OPENAI_FALLBACK", "true")).lower() in ("1", "true", "yes", "on"),
        "synthesis_enabled": str(os.getenv("ENABLE_SYNTH_PROMPT", "0")).lower() in ("1", "true", "yes", "on"),
        "formatting_enhanced": True  # üîß Nouveau statut
    }
    
    if OPENAI_FALLBACK_AVAILABLE:
        try:
            openai_status = get_openai_status()
            status["openai_status"] = openai_status
        except Exception as e:
            status["openai_error"] = str(e)
    
    # Statut CoT
    if OPENAI_COT_AVAILABLE:
        status["cot_config"] = {
            "auto_detection_enabled": True,
            "supported_intents": [
                "HealthDiagnosis", "MultiFactor", "TroubleshootingMultiple", 
                "Economics", "OptimizationStrategy", "ProductionAnalysis"
            ],
            "complexity_threshold": 2
        }
    
    return status

def test_cot_fallback_pipeline() -> Dict[str, Any]:
    """
    Test complet du pipeline CoT et fallback
    """
    try:
        results = {}
        
        # Test fonction de base
        results["basic_status"] = {
            "openai_fallback": OPENAI_FALLBACK_AVAILABLE,
            "cot_available": OPENAI_COT_AVAILABLE,
            "formatting_enhanced": True
        }
        
        # Test CoT si disponible
        if OPENAI_COT_AVAILABLE:
            try:
                cot_test = test_cot_pipeline()
                results["cot_test"] = cot_test
            except Exception as e:
                results["cot_test"] = {"status": "error", "error": str(e)}
        
        # Test synth√®se si disponible
        if OPENAI_FALLBACK_AVAILABLE:
            try:
                synthesis_test = test_synthesis_pipeline()
                results["synthesis_test"] = synthesis_test
            except Exception as e:
                results["synthesis_test"] = {"status": "error", "error": str(e)}
        
        return {
            "status": "success",
            "message": "Pipeline CoT et fallback test√© avec succ√®s",
            "formatting_fix": "applied",
            "detailed_results": results
        }
        
    except Exception as e:
        return {
            "status": "error",
            "message": f"√âchec test pipeline: {str(e)}",
            "error_type": type(e).__name__
        }