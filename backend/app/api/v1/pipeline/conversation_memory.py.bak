# -*- coding: utf-8 -*-
"""
Gestion de la m√©moire conversationnelle et contexte de session
üö® VERSION S√âCURIS√âE M√âMOIRE - Cache drastiquement r√©duit pour √©viter OOM
"""

import logging
import os
import time
import re
import hashlib
import gc
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)

# Import conditionnel de la m√©moire PostgreSQL
try:
    from .postgres_memory import PostgresMemory
    MEMORY_AVAILABLE = True
    logger.info("‚úÖ PostgresMemory import√© pour la m√©moire conversationnelle")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è PostgresMemory indisponible: {e}")
    MEMORY_AVAILABLE = False
    # Fallback en m√©moire simple
    class MemoryFallback:
        def __init__(self): 
            self.store = {}
        def get(self, session_id): 
            return self.store.get(session_id, {})
        def update(self, session_id, context): 
            self.store[session_id] = context
        def clear(self, session_id): 
            self.store.pop(session_id, None)
    PostgresMemory = MemoryFallback

# üö® CORRECTION URGENTE: Cache drastiquement r√©duit pour √©viter OOM
_EXTRACTION_CACHE = {}
_CACHE_MAX_SIZE = int(os.getenv("EXTRACTION_CACHE_SIZE", "25"))  # ‚ö†Ô∏è R√âDUIT de 1000 ‚Üí 25
_CACHE_TTL_SECONDS = int(os.getenv("EXTRACTION_CACHE_TTL", "300"))  # ‚ö†Ô∏è R√âDUIT de 3600 ‚Üí 300 (5 min)

# üö® PROTECTION M√âMOIRE - D√©sactivation du cache si pas assez de RAM
CACHE_ENABLED = str(os.getenv("ENABLE_EXTRACTION_CACHE", "true")).lower() in ("1", "true", "yes")

def _memory_emergency_cleanup():
    """üö® NOUVEAU: Nettoyage d'urgence si m√©moire critique"""
    global _EXTRACTION_CACHE
    try:
        # Si plus de 50 entr√©es en cache ou cache d√©sactiv√© ‚Üí vider
        if len(_EXTRACTION_CACHE) > 50 or not CACHE_ENABLED:
            cleared_count = len(_EXTRACTION_CACHE)
            _EXTRACTION_CACHE.clear()
            gc.collect()  # Force garbage collection
            logger.warning(f"üö® [EMERGENCY] Cache extraction vid√©: {cleared_count} entr√©es - protection m√©moire")
            return True
    except Exception as e:
        logger.error(f"‚ùå Erreur nettoyage urgence: {e}")
    return False

def _get_text_hash(text: str) -> str:
    """G√©n√®re un hash pour le cache bas√© sur le texte"""
    return hashlib.md5(text.encode('utf-8')).hexdigest()[:8]  # ‚ö†Ô∏è R√âDUIT de 16 ‚Üí 8 caract√®res

def _cleanup_cache():
    """üö® VERSION S√âCURIS√âE: Nettoyage intelligent avec protection m√©moire"""
    global _EXTRACTION_CACHE
    
    # V√©rification de s√©curit√© m√©moire
    if _memory_emergency_cleanup():
        return
    
    current_time = time.time()
    
    # Supprimer les entr√©es expir√©es
    expired_keys = [
        key for key, (_, timestamp) in _EXTRACTION_CACHE.items()
        if current_time - timestamp > _CACHE_TTL_SECONDS
    ]
    
    for key in expired_keys:
        _EXTRACTION_CACHE.pop(key, None)
    
    # ‚ö†Ô∏è S√âCURIT√â RENFORC√âE: Si encore trop d'entr√©es, limiter drastiquement  
    if len(_EXTRACTION_CACHE) > _CACHE_MAX_SIZE:
        # Garder seulement les 50% les plus r√©centes
        sorted_items = sorted(
            _EXTRACTION_CACHE.items(),
            key=lambda x: x[1][1]  # Trier par timestamp
        )
        
        keep_count = max(5, int(_CACHE_MAX_SIZE * 0.5))  # Minimum 5, max 50% de la limite
        items_to_keep = sorted_items[-keep_count:]
        
        _EXTRACTION_CACHE = {key: value for key, value in items_to_keep}
        logger.warning(f"üö® [CACHE] Nettoyage s√©curis√©: {len(expired_keys)} expir√©es, gard√© seulement {keep_count} entr√©es")

def _get_cached_extraction(text: str, extraction_type: str) -> Optional[Any]:
    """üö® VERSION S√âCURIS√âE: R√©cup√®re le r√©sultat d'extraction depuis le cache"""
    # ‚ö†Ô∏è S√âCURIT√â: Si cache d√©sactiv√©, retourner None
    if not CACHE_ENABLED or not text or not text.strip():
        return None
        
    cache_key = f"{_get_text_hash(text)}:{extraction_type}"
    
    if cache_key in _EXTRACTION_CACHE:
        cached_result, timestamp = _EXTRACTION_CACHE[cache_key]
        
        # V√©rifier TTL
        if time.time() - timestamp <= _CACHE_TTL_SECONDS:
            logger.debug(f"üíæ [CACHE] Hit pour {extraction_type}: '{text[:20]}...' -> {cached_result}")
            return cached_result
        else:
            # Entr√©e expir√©e
            _EXTRACTION_CACHE.pop(cache_key, None)
    
    return None

def _cache_extraction_result(text: str, extraction_type: str, result: Any):
    """üö® VERSION S√âCURIS√âE: Sauvegarde le r√©sultat d'extraction en cache"""
    # ‚ö†Ô∏è S√âCURIT√â: Si cache d√©sactiv√© ou limite atteinte, ne pas sauvegarder
    if not CACHE_ENABLED or not text or not text.strip():
        return
        
    if len(_EXTRACTION_CACHE) >= _CACHE_MAX_SIZE:
        logger.debug(f"‚ö†Ô∏è [CACHE] Limite atteinte ({_CACHE_MAX_SIZE}), nettoyage...")
        _cleanup_cache()
        
        # Si toujours plein apr√®s nettoyage, ne pas ajouter
        if len(_EXTRACTION_CACHE) >= _CACHE_MAX_SIZE:
            logger.warning("‚ö†Ô∏è [CACHE] Cache plein apr√®s nettoyage, skip sauvegarde")
            return
        
    cache_key = f"{_get_text_hash(text)}:{extraction_type}"
    _EXTRACTION_CACHE[cache_key] = (result, time.time())
    
    logger.debug(f"üíæ [CACHE] Sauvegarde {extraction_type}: '{text[:20]}...' -> {result}")
    
    # ‚ö†Ô∏è S√âCURIT√â: Nettoyage plus fr√©quent  
    if len(_EXTRACTION_CACHE) % 10 == 0:  # Toutes les 10 entr√©es au lieu de 50
        _cleanup_cache()

# Singleton m√©moire conversationnelle
_CONVERSATION_MEMORY = None

# ---------------------------------------------------------------------------
# PATTERNS D'EXTRACTION AUTOMATIQUE - VERSION AM√âLIOR√âE (CONSERV√â)
# ---------------------------------------------------------------------------

# CORRECTION: Patterns plus robustes et ordonn√©s par priorit√©
_AGE_PATTERNS = [
    # Patterns sp√©cifiques d'abord (plus pr√©cis)
    r"\bjour\s+(\d{1,2})\b",                                     # jour 14 (priorit√© haute)
    r"\b(?:J|D)(\d{1,2})\b",                                     # J14, D14 (sans espace)
    r"\b(?:J|D)\s*(\d{1,2})\b",                                  # J 14, D 14 (avec espace)
    r"\b(?:√¢ge|age)\s*[:=]?\s*(\d{1,2})\s*(?:j|jours|d|days)\b", # √¢ge: 21 jours / age=21d
    r"\b(?:day|jour)\s+(\d{1,2})\b",                             # day 21 / jour 14
    r"\bage_days\s*[:=]\s*(\d{1,2})\b",                          # age_days=21
    # Patterns g√©n√©riques en dernier (moins pr√©cis)
    r"\b(\d{1,2})\s*(?:j|jours|d|days)\b",                       # 21 j / 21d
]

def extract_age_days_from_text(text: str) -> Optional[int]:
    """üö® VERSION S√âCURIS√âE: Extraction automatique de l'√¢ge depuis le texte avec cache limit√©"""
    if not text:
        logger.debug("üîç [AGE_EXTRACT] Texte vide")
        return None
    
    # üö® S√âCURIT√â: V√©rifier le cache seulement si activ√© et s√ªr
    if CACHE_ENABLED:
        cached_result = _get_cached_extraction(text, "age_days")
        if cached_result is not None:
            return cached_result
    
    logger.debug(f"üîç [AGE_EXTRACT] Analyse du texte: '{text}'")
    
    result = None
    for i, pat in enumerate(_AGE_PATTERNS):
        m = re.search(pat, text, flags=re.I)
        if m:
            try:
                val = int(m.group(1))
                logger.info(f"‚úÖ [AGE_EXTRACT] Pattern {i} trouv√©: '{pat}' -> √¢ge={val}")
                if 0 <= val <= 70:
                    result = val
                    break
                else:
                    logger.warning(f"‚ö†Ô∏è [AGE_EXTRACT] √Çge hors limites: {val}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [AGE_EXTRACT] Erreur conversion: {e}")
                continue
    
    if result is None:
        logger.warning(f"‚ùå [AGE_EXTRACT] Aucun √¢ge d√©tect√© dans: '{text}'")
    
    # üö® S√âCURIT√â: Mettre en cache seulement si s√ªr
    if CACHE_ENABLED:
        _cache_extraction_result(text, "age_days", result)
    return result

def normalize_sex_from_text(text: str) -> Optional[str]:
    """üö® VERSION S√âCURIS√âE: Normalisation du sexe depuis le texte avec cache limit√©"""
    if not text:
        return None
    
    # üö® S√âCURIT√â: Cache conditionnel
    if CACHE_ENABLED:
        cached_result = _get_cached_extraction(text, "sex")
        if cached_result is not None:
            return cached_result
    
    t = text.lower()
    logger.debug(f"üîç [SEX_EXTRACT] Analyse: '{t}'")
    
    result = None
    if any(k in t for k in ["as hatched", "as-hatched", "as_hatched", "mixte", "mixed", " ah "]):
        logger.info("‚úÖ [SEX_EXTRACT] Sexe d√©tect√©: as_hatched")
        result = "as_hatched"
    elif any(k in t for k in ["m√¢le", " male ", "male"]):
        logger.info("‚úÖ [SEX_EXTRACT] Sexe d√©tect√©: male")
        result = "male"
    elif any(k in t for k in ["femelle", " female ", "female"]):
        logger.info("‚úÖ [SEX_EXTRACT] Sexe d√©tect√©: female")
        result = "female"
    else:
        logger.debug("‚ùå [SEX_EXTRACT] Aucun sexe d√©tect√©")
    
    # üö® S√âCURIT√â: Cache conditionnel
    if CACHE_ENABLED:
        _cache_extraction_result(text, "sex", result)
    return result

def extract_line_from_text(text: str) -> Optional[str]:
    """üö® VERSION S√âCURIS√âE: Extraction de lign√©e depuis le texte avec cache limit√©"""
    if not text:
        return None
    
    if CACHE_ENABLED:
        cached_result = _get_cached_extraction(text, "line")
        if cached_result is not None:
            return cached_result
    
    t = text.lower()
    logger.debug(f"üîç [LINE_EXTRACT] Analyse: '{t}'")
    
    result = None
    if any(k in t for k in ["cobb", "cobb500", "cobb 500", "cobb-500"]):
        logger.info("‚úÖ [LINE_EXTRACT] Lign√©e d√©tect√©e: cobb500")
        result = "cobb500"
    elif any(k in t for k in ["ross", "ross308", "ross 308", "ross-308"]):
        logger.info("‚úÖ [LINE_EXTRACT] Lign√©e d√©tect√©e: ross308")
        result = "ross308"
    elif any(k in t for k in ["hubbard"]):
        logger.info("‚úÖ [LINE_EXTRACT] Lign√©e d√©tect√©e: hubbard")
        result = "hubbard"
    else:
        logger.debug("‚ùå [LINE_EXTRACT] Aucune lign√©e d√©tect√©e")
    
    if CACHE_ENABLED:
        _cache_extraction_result(text, "line", result)
    return result

def extract_species_from_text(text: str) -> Optional[str]:
    """üö® VERSION S√âCURIS√âE: Extraction d'esp√®ce depuis le texte avec cache limit√©"""
    if not text:
        return None
    
    if CACHE_ENABLED:
        cached_result = _get_cached_extraction(text, "species")
        if cached_result is not None:
            return cached_result
    
    t = text.lower()
    logger.debug(f"üîç [SPECIES_EXTRACT] Analyse: '{t}'")
    
    result = None
    if any(k in t for k in ["broiler", "poulet de chair", "chair"]):
        logger.info("‚úÖ [SPECIES_EXTRACT] Esp√®ce d√©tect√©e: broiler")
        result = "broiler"
    elif any(k in t for k in ["layer", "pondeuse", "ponte"]):
        logger.info("‚úÖ [SPECIES_EXTRACT] Esp√®ce d√©tect√©e: layer")
        result = "layer"
    else:
        logger.debug("‚ùå [SPECIES_EXTRACT] Aucune esp√®ce d√©tect√©e")
    
    if CACHE_ENABLED:
        _cache_extraction_result(text, "species", result)
    return result

def extract_signs_from_text(text: str) -> Optional[str]:
    """üö® VERSION S√âCURIS√âE: Extraction des signes cliniques avec cache TR√àS limit√© (OpenAI co√ªteux)"""
    if not text:
        return None
    
    # üö® CRITIQUE: Cache tr√®s important ici car OpenAI est co√ªteux !
    if CACHE_ENABLED:
        cached_result = _get_cached_extraction(text, "signs")
        if cached_result is not None:
            return cached_result
    
    logger.debug(f"üîç [SIGNS_EXTRACT] Analyse: '{text}'")
    
    result = None
    
    # Fallback rapide pour signes √©vidents (CONSERV√â)
    obvious_signs = [
        "diarrh√©e h√©morragique", "diarrh√©e sanglante", "diarrh√©e", 
        "mortalit√©", "boiterie", "paralysie", "convulsions", "toux"
    ]
    
    t = text.lower()
    for sign in obvious_signs:
        if sign in t:
            logger.info(f"‚úÖ [SIGNS_EXTRACT] Signe √©vident d√©tect√©: {sign}")
            result = sign
            break
    
    # üö® LIMITATION: OpenAI d√©sactiv√© si cache d√©sactiv√© (√©conomie m√©moire + co√ªt)
    if result is None and CACHE_ENABLED:
        try:
            from ..utils.openai_utils import complete_text as openai_complete
            
            extraction_prompt = f"""Tu es un v√©t√©rinaire expert. Extrais UNIQUEMENT les signes cliniques mentionn√©s dans ce texte sur l'aviculture.

Texte: "{text}"

INSTRUCTIONS:
- Extrais SEULEMENT les sympt√¥mes/signes cliniques mentionn√©s
- Si aucun signe clinique n'est mentionn√©, r√©ponds "AUCUN"
- Donne une r√©ponse courte (maximum 3-4 mots)
- Exemples de signes: diarrh√©e, boiterie, mortalit√©, convulsions, toux, etc.

Signes cliniques d√©tect√©s:"""

            response = openai_complete(
                prompt=extraction_prompt,
                max_tokens=20     # R√©ponse courte
            )
            
            if response and response.strip().upper() != "AUCUN":
                result = response.strip()
                logger.info(f"‚úÖ [SIGNS_EXTRACT] OpenAI d√©tect√©: '{result}'")
            else:
                logger.debug("‚ùå [SIGNS_EXTRACT] Aucun signe clinique d√©tect√©")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [SIGNS_EXTRACT] √âchec OpenAI: {e}")
    
    if result is None:
        logger.debug("‚ùå [SIGNS_EXTRACT] Aucun signe clinique d√©tect√©")
    
    # üö® CRITIQUE: Toujours mettre en cache les r√©sultats OpenAI pour √©viter re-appels co√ªteux
    if CACHE_ENABLED:
        _cache_extraction_result(text, "signs", result)
    return result

# ---------------------------------------------------------------------------
# GESTION M√âMOIRE CONVERSATIONNELLE (CONSERV√â)
# ---------------------------------------------------------------------------

def get_conversation_memory():
    """Retourne le singleton de m√©moire conversationnelle"""
    global _CONVERSATION_MEMORY
    if _CONVERSATION_MEMORY is None:
        try:
            if MEMORY_AVAILABLE:
                _CONVERSATION_MEMORY = PostgresMemory(dsn=os.getenv("DATABASE_URL"))
            else:
                _CONVERSATION_MEMORY = PostgresMemory()  # Fallback
            logger.info("üß† M√©moire conversationnelle initialis√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation m√©moire: {e}")
            _CONVERSATION_MEMORY = PostgresMemory()  # Fallback simple
    return _CONVERSATION_MEMORY

def merge_conversation_context(current_entities: Dict[str, Any], session_context: Dict[str, Any], question: str) -> Dict[str, Any]:
    """CONSERVATION INT√âGRALE: Fusionne le contexte de session avec les entit√©s actuelles."""
    logger.info(f"üîó [MERGE] D√©but fusion - session: {session_context.get('entities', {})}")
    logger.info(f"üîó [MERGE] Current entities: {current_entities}")
    logger.info(f"üîó [MERGE] Question: '{question}'")
    
    # 1. Commencer par le contexte de session (donn√©es persistantes) - CONSERV√â
    merged = dict(session_context.get("entities", {}))
    logger.debug(f"üîó [MERGE] Base session: {merged}")
    
    # 2. üö® S√âCURIS√â: Enrichissement automatique depuis le texte (AVEC CACHE LIMIT√â)
    auto_species = extract_species_from_text(question)    # Cache conditionnel
    auto_line = extract_line_from_text(question)          # Cache conditionnel
    auto_sex = normalize_sex_from_text(question)          # Cache conditionnel
    auto_age = extract_age_days_from_text(question)       # Cache conditionnel
    auto_signs = extract_signs_from_text(question)        # Cache conditionnel (√©vite OpenAI redondant)
    
    auto_extracted = {
        "species": auto_species,
        "line": auto_line, 
        "sex": auto_sex,
        "age_days": auto_age,
        "signs": auto_signs
    }
    logger.info(f"ü§ñ [MERGE] Auto-extraction: {auto_extracted}")
    
    # 3. CORRECTION: Fusion prioritaire - auto-extraction en premier - CONSERV√â
    for key, value in auto_extracted.items():
        if value is not None:
            merged[key] = value
            logger.debug(f"‚úÖ [MERGE] Auto-ajout: {key}={value}")
    
    # 4. CORRECTION: Current entities en dernier, mais seulement si valeurs valides - CONSERV√â
    for key, value in current_entities.items():
        if value is not None:  # Seulement les valeurs non-nulles
            # S√âCURIT√â: Ne pas √©craser un √¢ge valide par None - CONSERV√â
            if key == "age_days" and value is None and merged.get("age_days") is not None:
                logger.warning(f"‚ö†Ô∏è [MERGE] Pr√©servation √¢ge existant: {merged.get('age_days')}")
                continue
            merged[key] = value
            logger.debug(f"‚úÖ [MERGE] Current ajout: {key}={value}")
    
    logger.info(f"üéØ [MERGE] R√©sultat final: {merged}")
    
    return merged

# Les autres fonctions conserv√©es int√©gralement...
def should_continue_conversation(session_context: Dict[str, Any], current_intent) -> bool:
    """CONSERVATION INT√âGRALE"""
    if not session_context:
        return False
        
    pending_intent = session_context.get("pending_intent")
    last_timestamp = session_context.get("timestamp", 0)
    
    if time.time() - last_timestamp > 600:
        return False
        
    from ..utils.question_classifier import Intention  # Import local pour √©viter circulaire
    if pending_intent == "PerfTargets":
        return current_intent in [Intention.PerfTargets, Intention.AmbiguousGeneral]
        
    return False

def save_conversation_context(session_id: str, intent, entities: Dict[str, Any], question: str, missing_fields: List[str]):
    """CONSERVATION INT√âGRALE"""
    try:
        memory = get_conversation_memory()
        context = {
            "pending_intent": intent.name if hasattr(intent, 'name') else str(intent),
            "entities": entities,
            "question": question,
            "missing_fields": missing_fields,
            "timestamp": time.time()
        }
        memory.update(session_id, context)
        logger.info(f"üíæ Contexte sauvegard√© pour session {session_id}")
    except Exception as e:
        logger.error(f"‚ùå Erreur sauvegarde contexte: {e}")

def clear_conversation_context(session_id: str):
    """CONSERVATION INT√âGRALE"""
    try:
        memory = get_conversation_memory()
        memory.clear(session_id)
        logger.info(f"üßπ Contexte effac√© pour session {session_id}")
    except Exception as e:
        logger.error(f"‚ùå Erreur effacement contexte: {e}")

def get_memory_status() -> Dict[str, Any]:
    """üö® VERSION S√âCURIS√âE: Retourne le statut du syst√®me de m√©moire avec info cache s√©curis√©"""
    return {
        "memory_available": MEMORY_AVAILABLE,
        "postgres_enabled": MEMORY_AVAILABLE,
        "fallback_type": "in_memory" if not MEMORY_AVAILABLE else "postgresql",
        "auto_extraction_enabled": True,
        "context_expiry_minutes": 10,
        "version": "memory_safe_v1.0",
        # üö® S√âCURIS√â: Informations sur le cache d'extraction limit√©es
        "extraction_cache": {
            "enabled": CACHE_ENABLED,
            "current_size": len(_EXTRACTION_CACHE),
            "max_size": _CACHE_MAX_SIZE,
            "ttl_seconds": _CACHE_TTL_SECONDS,
            "memory_safe": True,  # üö® NOUVEAU
            "emergency_cleanup": True,  # üö® NOUVEAU
        },
        "memory_optimizations": [
            "cache_size_limited_to_25",
            "ttl_reduced_to_5min", 
            "emergency_cleanup_enabled",
            "conditional_cache_activation",
            "frequent_garbage_collection"
        ]
    }

# üö® NOUVELLES FONCTIONS DE S√âCURIT√â M√âMOIRE
def clear_extraction_cache(extraction_type: Optional[str] = None):
    """üö® VERSION S√âCURIS√âE: Vide le cache d'extraction avec garbage collection"""
    global _EXTRACTION_CACHE
    
    if extraction_type is None:
        cleared_count = len(_EXTRACTION_CACHE)
        _EXTRACTION_CACHE.clear()
        gc.collect()  # Force garbage collection
        logger.info(f"üßπ [CACHE] Cache enti√®rement vid√©: {cleared_count} entr√©es supprim√©es")
    else:
        keys_to_remove = [key for key in _EXTRACTION_CACHE.keys() if key.endswith(f":{extraction_type}")]
        for key in keys_to_remove:
            _EXTRACTION_CACHE.pop(key, None)
        gc.collect()
        logger.info(f"üßπ [CACHE] Cache {extraction_type} vid√©: {len(keys_to_remove)} entr√©es supprim√©es")

def get_cache_stats() -> Dict[str, Any]:
    """üö® VERSION S√âCURIS√âE: Statistiques de cache avec informations m√©moire"""
    type_counts = {}
    for key in _EXTRACTION_CACHE.keys():
        extraction_type = key.split(':')[1] if ':' in key else 'unknown'
        type_counts[extraction_type] = type_counts.get(extraction_type, 0) + 1
    
    return {
        "total_entries": len(_EXTRACTION_CACHE),
        "max_capacity": _CACHE_MAX_SIZE,
        "utilization_percent": (len(_EXTRACTION_CACHE) / _CACHE_MAX_SIZE) * 100 if _CACHE_MAX_SIZE > 0 else 0,
        "entries_by_type": type_counts,
        "ttl_seconds": _CACHE_TTL_SECONDS,
        "cache_enabled": CACHE_ENABLED,
        "memory_safe_mode": True,  # üö® NOUVEAU
        "emergency_threshold": 50,  # üö® NOUVEAU
        "memory_usage_estimate_kb": len(_EXTRACTION_CACHE) * 0.1  # Estimation tr√®s conservative
    }

# Les fonctions de debug conserv√©es mais simplifi√©es pour √©viter surcharge m√©moire...