"""
RAGEngine - Version corrig√©e avec gestion robuste VectorStoreClient
CONSERVE: Structure originale + logique RAG
CORRIGE: 
- Retourne un dict au lieu d'une string pour compatibilit√© DialogueManager
- ‚úÖ CORRECTION CRITIQUE: Gestion robuste r√©sultats VectorStoreClient vides/erreurs
- ‚úÖ AM√âLIORATION: Fallback gracieux si Pinecone indisponible
- ‚úÖ AM√âLIORATION: Prompt RAG restructur√© pour utiliser effectivement les documents
"""
import os
import logging
from app.api.v1.utils.integrations import VectorStoreClient
from app.api.v1.utils.openai_utils import safe_chat_completion

logger = logging.getLogger(__name__)

class RAGEngine:
    """
    Retrieval-Augmented Generation engine with fallback if no vector results.
    
    ‚úÖ CORRECTION CRITIQUE: Gestion robuste des erreurs VectorStoreClient
    - Fix TypeError "list indices must be integers or slices, not str"
    - Fallback gracieux si Pinecone indisponible
    - Validation structure documents retourn√©s
    """
    def __init__(self):
        try:
            self.vector_client = VectorStoreClient()
            self.vector_available = True
            logger.info("‚úÖ RAGEngine: VectorStoreClient initialis√©")
        except Exception as e:
            logger.error(f"‚ùå RAGEngine: Erreur init VectorStoreClient: {e}")
            self.vector_client = None
            self.vector_available = False

    def generate_answer(self, question, context):
        """
        ‚úÖ CORRECTION CRITIQUE: Gestion robuste avec validation structure docs
        
        Format de retour: {
            "response": str,
            "source": str,
            "documents_used": int,
            "warning": str|None
        }
        """
        # ‚úÖ Structure de retour standardis√©e
        result = {
            "response": "",
            "source": "",
            "documents_used": 0,
            "warning": None
        }
        
        # ‚úÖ CORRECTION CRITIQUE: Gestion robuste recherche documentaire
        docs = []
        search_error = None
        
        if self.vector_available and self.vector_client:
            try:
                logger.debug(f"üîç RAGEngine: Recherche docs pour: {question[:50]}...")
                docs = self.vector_client.query(question)
                
                # ‚úÖ VALIDATION: V√©rification structure docs retourn√©s
                if not isinstance(docs, list):
                    logger.warning(f"‚ö†Ô∏è RAGEngine: docs n'est pas une liste: {type(docs)}")
                    docs = []
                elif docs and not all(isinstance(doc, dict) for doc in docs):
                    logger.warning(f"‚ö†Ô∏è RAGEngine: docs contient des non-dict")
                    # Filtrer uniquement les dicts valides
                    docs = [doc for doc in docs if isinstance(doc, dict)]
                
                logger.info(f"‚úÖ RAGEngine: {len(docs)} documents trouv√©s")
                
            except Exception as e:
                logger.error(f"‚ùå RAGEngine: Erreur recherche docs: {type(e).__name__}: {e}")
                docs = []
                search_error = str(e)
        else:
            logger.warning("‚ö†Ô∏è RAGEngine: VectorStoreClient non disponible")
            search_error = "VectorStoreClient non disponible"
        
        # ‚úÖ CORRECTION: Logique docs trouv√©s vs fallback
        if not docs:
            # ‚úÖ FALLBACK: Pas de documents trouv√©s
            logger.info("üîÑ RAGEngine: Fallback OpenAI (pas de docs)")
            fallback_prompt = self._build_fallback_prompt(question, context, search_error)
            
            try:
                resp = safe_chat_completion(
                    model=os.getenv("OPENAI_MODEL", "gpt-4o"),
                    messages=[{"role": "user", "content": fallback_prompt}],
                    temperature=0.0,
                    max_tokens=512
                )
                
                warning_msg = "R√©ponse bas√©e sur les connaissances g√©n√©rales - aucun document sp√©cifique trouv√©"
                if search_error:
                    warning_msg += f" (Erreur recherche: {search_error})"
                
                result.update({
                    "response": resp.choices[0].message.content.strip(),
                    "source": "openai_fallback",
                    "documents_used": 0,
                    "warning": warning_msg
                })
                
            except Exception as e:
                logger.error(f"‚ùå RAGEngine: Erreur OpenAI fallback: {e}")
                result.update({
                    "response": "Je rencontre une difficult√© technique pour r√©pondre √† votre question. Veuillez r√©essayer.",
                    "source": "error_fallback",
                    "documents_used": 0,
                    "warning": f"Erreur technique: {str(e)}"
                })
        
        else:
            # ‚úÖ RAG: Documents trouv√©s
            logger.info(f"üéØ RAGEngine: G√©n√©ration RAG avec {len(docs)} docs")
            rag_prompt = self._build_rag_prompt(question, context, docs)
            
            try:
                resp = safe_chat_completion(
                    model=os.getenv("OPENAI_MODEL", "gpt-4o"),
                    messages=[{"role": "user", "content": rag_prompt}],
                    temperature=0.0,
                    max_tokens=512
                )
                
                result.update({
                    "response": resp.choices[0].message.content.strip(),
                    "source": "rag_enhanced",
                    "documents_used": len(docs),
                    "warning": None  # Pas d'avertissement pour r√©ponse RAG compl√®te
                })
                
            except Exception as e:
                logger.error(f"‚ùå RAGEngine: Erreur OpenAI RAG: {e}")
                result.update({
                    "response": f"Documents trouv√©s ({len(docs)}) mais erreur de traitement. Consultez un expert.",
                    "source": "rag_error",
                    "documents_used": len(docs),
                    "warning": f"Erreur traitement RAG: {str(e)}"
                })
        
        logger.debug(f"üìä RAGEngine: R√©ponse g√©n√©r√©e - source: {result['source']}, docs: {result['documents_used']}")
        return result

    def _build_rag_prompt(self, question: str, context: dict, docs: list) -> str:
        """
        ‚úÖ AM√âLIORATION: Construction prompt RAG avec validation docs
        """
        # ‚úÖ VALIDATION: Extraction contenu docs robuste
        doc_contents = []
        for i, doc in enumerate(docs):
            try:
                if isinstance(doc, dict):
                    # Essayer diff√©rentes cl√©s pour le contenu
                    content = (
                        doc.get('text') or 
                        doc.get('content') or 
                        doc.get('metadata', {}).get('text') or
                        str(doc)
                    )
                    doc_contents.append(f"Document {i+1}: {content}")
                else:
                    doc_contents.append(f"Document {i+1}: {str(doc)}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur extraction doc {i}: {e}")
                doc_contents.append(f"Document {i+1}: [Erreur extraction]")
        
        doc_content = "\n".join(doc_contents)
        missing_info = self._identify_missing_context(context)
        
        prompt = f"""Vous √™tes un expert v√©t√©rinaire sp√©cialis√© en aviculture et nutrition animale.

QUESTION: {question}

CONTEXTE DISPONIBLE: {context if context else "Aucun contexte sp√©cifique fourni"}

DOCUMENTS SP√âCIALIS√âS TROUV√âS:
{doc_content}

INSTRUCTIONS:
1. Utilisez PRIORITAIREMENT les informations des documents sp√©cialis√©s ci-dessus
2. Donnez une r√©ponse pratique et pr√©cise bas√©e sur ces documents
3. Si les documents contiennent des informations pertinentes (m√™me partielles), utilisez-les
4. Compl√©tez avec vos connaissances g√©n√©rales si n√©cessaire
5. Mentionnez clairement les sources (documents vs connaissances g√©n√©rales)

{missing_info}

R√©pondez de mani√®re professionnelle et pratique en utilisant les documents fournis."""

        return prompt

    def _build_fallback_prompt(self, question: str, context: dict, search_error: str = None) -> str:
        """
        ‚úÖ AM√âLIORATION: Prompt fallback avec mention erreur optionnelle
        """
        missing_info = self._identify_missing_context(context)
        
        situation_msg = "Aucun document sp√©cialis√© trouv√© dans la base de donn√©es."
        if search_error:
            situation_msg += f" (Erreur technique: {search_error})"
        
        prompt = f"""Vous √™tes un expert v√©t√©rinaire sp√©cialis√© en aviculture et nutrition animale.

QUESTION: {question}

CONTEXTE DISPONIBLE: {context if context else "Aucun contexte sp√©cifique fourni"}

SITUATION: {situation_msg}

INSTRUCTIONS:
1. R√©pondez en vous basant sur vos connaissances g√©n√©rales en aviculture
2. Donnez des informations pratiques et utiles
3. Restez professionnel et pr√©cis
4. Mentionnez que c'est une r√©ponse g√©n√©rale

{missing_info}

R√©pondez de mani√®re professionnelle en indiquant qu'il s'agit d'une r√©ponse g√©n√©rale."""

        return prompt

    def _identify_missing_context(self, context: dict) -> str:
        """
        ‚úÖ CONSERVATION: M√©thode d'identification contexte manquant
        """
        if not context:
            context = {}
            
        missing_parts = []
        
        # V√©rifier les informations cl√©s pour les questions de nutrition/poids
        if not context.get("race") and not context.get("breed"):
            missing_parts.append("la race/lign√©e g√©n√©tique (Ross, Cobb, Hubbard, etc.)")
        
        if not context.get("sexe") and not context.get("sex_category"):
            missing_parts.append("le sexe (m√¢le, femelle, mixte)")
        
        if not context.get("age_jours") and not context.get("age_phase"):
            missing_parts.append("l'√¢ge pr√©cis")
        
        if missing_parts:
            missing_text = f"""
INFORMATIONS MANQUANTES POUR PLUS DE PR√âCISION:
Pour une r√©ponse plus pr√©cise, il serait utile de conna√Ætre : {', '.join(missing_parts)}.

CONSIGNE SP√âCIALE:
- Donnez quand m√™me une r√©ponse g√©n√©rale utile
- Mentionnez que la r√©ponse serait plus pr√©cise avec ces informations
- Expliquez pourquoi ces informations sont importantes (ex: les m√¢les grandissent plus vite que les femelles, les diff√©rentes lign√©es ont des courbes de croissance diff√©rentes)
"""
        else:
            missing_text = "CONTEXTE: Informations suffisantes pour une r√©ponse pr√©cise."
        
        return missing_text

    def get_status(self) -> dict:
        """
        ‚úÖ NOUVELLE M√âTHODE: Status RAG pour diagnostics
        """
        status = {
            "vector_client_available": self.vector_available,
            "vector_client_type": type(self.vector_client).__name__ if self.vector_client else None
        }
        
        if self.vector_available and hasattr(self.vector_client, 'test_connection'):
            try:
                status["connection_test"] = self.vector_client.test_connection()
            except Exception as e:
                status["connection_test"] = {"status": "error", "error": str(e)}
        
        return status