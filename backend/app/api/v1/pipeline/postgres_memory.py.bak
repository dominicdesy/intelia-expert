import json
import math
import os
import psycopg2
import logging

def sanitize_for_json(obj):
    """
    Nettoie r√©cursivement un objet pour la s√©rialisation JSON
    Remplace NaN, Infinity par None tout en pr√©servant les vraies valeurs
    """
    if isinstance(obj, dict):
        return {k: sanitize_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_for_json(item) for item in obj]
    elif isinstance(obj, float):
        if math.isnan(obj) or math.isinf(obj):
            return None  # Convertir NaN/inf en None (valide JSON)
        return obj
    elif str(obj) in ['NaN', 'nan', 'inf', '-inf', 'Infinity', '-Infinity']:
        return None
    else:
        return obj

class PostgresMemory:
    """
    Conversation memory backend using a managed PostgreSQL instance.
    Ensures correct decoding of JSON and always closes connections.
    Includes automatic table creation/migration.
    """
    def __init__(self, dsn=None):
        self.dsn = dsn or os.getenv("DATABASE_URL")
        self.logger = logging.getLogger(__name__)
        # Automatically ensure table exists on initialization
        self._ensure_table_exists()

    def _ensure_table_exists(self):
        """
        V√©rifie si la table conversation_memory existe et la cr√©e si n√©cessaire.
        Cette m√©thode est appel√©e automatiquement lors de l'initialisation.
        """
        try:
            with psycopg2.connect(self.dsn) as conn:
                with conn.cursor() as cur:
                    # V√©rifier si la table existe
                    cur.execute("""
                        SELECT EXISTS (
                            SELECT FROM information_schema.tables 
                            WHERE table_schema = 'public' 
                            AND table_name = 'conversation_memory'
                        );
                    """)
                    
                    table_exists = cur.fetchone()[0]
                    
                    if not table_exists:
                        self.logger.info("üîß Table conversation_memory n'existe pas, cr√©ation en cours...")
                        
                        # Cr√©er la table avec tous les param√®tres optimaux
                        cur.execute("""
                            CREATE TABLE conversation_memory (
                                session_id VARCHAR(128) PRIMARY KEY,
                                context JSONB NOT NULL DEFAULT '{}',
                                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                            );
                        """)
                        
                        # Cr√©er un index sur updated_at pour optimiser les requ√™tes de nettoyage
                        cur.execute("""
                            CREATE INDEX idx_conversation_memory_updated_at 
                            ON conversation_memory(updated_at);
                        """)
                        
                        # Trigger pour mettre √† jour updated_at automatiquement
                        cur.execute("""
                            CREATE OR REPLACE FUNCTION update_updated_at_column()
                            RETURNS TRIGGER AS $$
                            BEGIN
                                NEW.updated_at = CURRENT_TIMESTAMP;
                                RETURN NEW;
                            END;
                            $$ language 'plpgsql';
                        """)
                        
                        cur.execute("""
                            CREATE TRIGGER update_conversation_memory_updated_at 
                            BEFORE UPDATE ON conversation_memory 
                            FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
                        """)
                        
                        conn.commit()
                        self.logger.info("‚úÖ Table conversation_memory cr√©√©e avec succ√®s avec indexes et triggers")
                        
                    else:
                        self.logger.info("‚úÖ Table conversation_memory existe d√©j√†")
                        
                        # Optionnel : v√©rifier que toutes les colonnes existent et les ajouter si n√©cessaire
                        self._check_and_add_missing_columns(cur, conn)
                        
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la v√©rification/cr√©ation de la table: {e}")
            raise

    def _check_and_add_missing_columns(self, cur, conn):
        """
        V√©rifie si les colonnes optionnelles existent et les ajoute si n√©cessaire.
        Migration progressive pour compatibilit√© avec des tables existantes.
        """
        try:
            # V√©rifier les colonnes existantes
            cur.execute("""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = 'conversation_memory'
            """)
            
            existing_columns = {row[0] for row in cur.fetchall()}
            
            # Colonnes requises avec leurs d√©finitions
            required_columns = {
                'created_at': 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP',
                'updated_at': 'TIMESTAMP DEFAULT CURRENT_TIMESTAMP'
            }
            
            # Ajouter les colonnes manquantes
            for column_name, column_def in required_columns.items():
                if column_name not in existing_columns:
                    self.logger.info(f"üîß Ajout de la colonne manquante: {column_name}")
                    cur.execute(f"ALTER TABLE conversation_memory ADD COLUMN {column_name} {column_def}")
                    
            # V√©rifier le type de la colonne context
            cur.execute("""
                SELECT data_type 
                FROM information_schema.columns 
                WHERE table_name = 'conversation_memory' AND column_name = 'context'
            """)
            
            context_type = cur.fetchone()
            if context_type and context_type[0] not in ['jsonb', 'json']:
                self.logger.warning("‚ö†Ô∏è  La colonne 'context' n'est pas de type JSON/JSONB, conversion recommand√©e")
            
            conn.commit()
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è  Erreur lors de la v√©rification des colonnes: {e}")

    def get(self, session_id):
        """
        Get the context dict for a session_id. Always returns a dict.
        Improved with better error handling and JSONB support.
        """
        try:
            with psycopg2.connect(self.dsn) as conn:
                with conn.cursor() as cur:
                    cur.execute("SELECT context FROM conversation_memory WHERE session_id=%s", (session_id,))
                    row = cur.fetchone()
                    
                    if not row or not row[0]:
                        return {}
                    
                    val = row[0]
                    
                    # Si c'est d√©j√† un dict (JSONB natif), le retourner directement
                    if isinstance(val, dict):
                        return val
                    
                    # Sinon, essayer de parser le JSON
                    try:
                        return json.loads(val) if val else {}
                    except (json.JSONDecodeError, TypeError) as e:
                        self.logger.warning(f"‚ö†Ô∏è  Erreur de parsing JSON pour session {session_id}: {e}")
                        return {}
                        
        except psycopg2.Error as e:
            self.logger.error(f"‚ùå Erreur PostgreSQL lors de la r√©cup√©ration de session {session_id}: {e}")
            return {}
        except Exception as e:
            self.logger.error(f"‚ùå Erreur inattendue lors de la r√©cup√©ration de session {session_id}: {e}")
            return {}

    def update(self, session_id, context: dict):
        """
        Upsert the context dict for a session_id.
        Improved with better error handling and JSONB support.
        CORRIG√â: Nettoie les valeurs NaN avant s√©rialisation JSON.
        """
        try:
            # ‚úÖ NOUVEAU: Nettoyer le contexte avant s√©rialisation
            clean_context = sanitize_for_json(context)
            
            with psycopg2.connect(self.dsn) as conn:
                with conn.cursor() as cur:
                    # Essayer d'abord avec JSONB natif
                    try:
                        cur.execute("""
                            INSERT INTO conversation_memory (session_id, context)
                            VALUES (%s, %s)
                            ON CONFLICT (session_id) DO UPDATE SET context = EXCLUDED.context
                        """, (session_id, json.dumps(clean_context)))  # Utiliser clean_context
                        
                    except psycopg2.Error as e:
                        # Fallback en cas d'erreur avec JSONB
                        self.logger.warning(f"‚ö†Ô∏è  Fallback vers JSON string pour session {session_id}: {e}")
                        ctx_json = json.dumps(clean_context)  # Utiliser clean_context
                        cur.execute("""
                            INSERT INTO conversation_memory (session_id, context)
                            VALUES (%s, %s)
                            ON CONFLICT (session_id) DO UPDATE SET context = EXCLUDED.context
                        """, (session_id, ctx_json))
                    
                    conn.commit()
                    self.logger.debug(f"‚úÖ Contexte mis √† jour pour session {session_id}")
                    
        except psycopg2.Error as e:
            self.logger.error(f"‚ùå Erreur PostgreSQL lors de la mise √† jour de session {session_id}: {e}")
            raise
        except Exception as e:
            self.logger.error(f"‚ùå Erreur inattendue lors de la mise √† jour de session {session_id}: {e}")
            raise

    def clear(self, session_id):
        """
        Delete the context for a session_id.
        Improved with better error handling.
        """
        try:
            with psycopg2.connect(self.dsn) as conn:
                with conn.cursor() as cur:
                    cur.execute("DELETE FROM conversation_memory WHERE session_id=%s", (session_id,))
                    rows_affected = cur.rowcount
                    conn.commit()
                    
                    if rows_affected > 0:
                        self.logger.debug(f"‚úÖ Session {session_id} supprim√©e")
                    else:
                        self.logger.debug(f"‚ÑπÔ∏è  Session {session_id} n'existait pas")
                        
        except psycopg2.Error as e:
            self.logger.error(f"‚ùå Erreur PostgreSQL lors de la suppression de session {session_id}: {e}")
            raise
        except Exception as e:
            self.logger.error(f"‚ùå Erreur inattendue lors de la suppression de session {session_id}: {e}")
            raise

    def cleanup_old_sessions(self, days_old=7):
        """
        Supprime les sessions plus anciennes que X jours.
        M√©thode utilitaire pour √©viter l'accumulation de donn√©es.
        """
        try:
            with psycopg2.connect(self.dsn) as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        DELETE FROM conversation_memory 
                        WHERE updated_at < CURRENT_TIMESTAMP - INTERVAL '%s days'
                    """, (days_old,))
                    
                    rows_deleted = cur.rowcount
                    conn.commit()
                    
                    if rows_deleted > 0:
                        self.logger.info(f"üßπ Nettoyage: {rows_deleted} sessions anciennes supprim√©es")
                    
                    return rows_deleted
                    
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors du nettoyage des anciennes sessions: {e}")
            return 0

    def get_stats(self):
        """
        Retourne des statistiques sur l'utilisation de la m√©moire.
        Utile pour le monitoring.
        """
        try:
            with psycopg2.connect(self.dsn) as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        SELECT 
                            COUNT(*) as total_sessions,
                            COUNT(CASE WHEN updated_at > CURRENT_TIMESTAMP - INTERVAL '1 hour' THEN 1 END) as active_last_hour,
                            COUNT(CASE WHEN updated_at > CURRENT_TIMESTAMP - INTERVAL '1 day' THEN 1 END) as active_last_day,
                            MIN(created_at) as oldest_session,
                            MAX(updated_at) as most_recent_activity
                        FROM conversation_memory
                    """)
                    
                    row = cur.fetchone()
                    if row:
                        return {
                            "total_sessions": row[0],
                            "active_last_hour": row[1],
                            "active_last_day": row[2],
                            "oldest_session": row[3].isoformat() if row[3] else None,
                            "most_recent_activity": row[4].isoformat() if row[4] else None
                        }
                    
                    return {"total_sessions": 0}
                    
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des statistiques: {e}")
            return {"error": str(e)}