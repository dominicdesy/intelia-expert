"""
ai_entity_extractor.py - EXTRACTION D'ENTIT√âS AVEC IA

üéØ REMPLACE: 300+ lignes de patterns regex par compr√©hension IA
üöÄ CAPACIT√âS:
- ‚úÖ Extraction intelligente des races, √¢ges, sexes, sympt√¥mes
- ‚úÖ Normalisation automatique (Ross 308, 21 jours, male/female)  
- ‚úÖ Compr√©hension du langage naturel ("trois semaines", "poulets m√¢les")
- ‚úÖ D√©tection contextuelle avanc√©e
- ‚úÖ Support multilingue natif
- ‚úÖ Gestion des variations et abr√©viations

Architecture:
- Prompts sp√©cialis√©s par type d'extraction
- Normalisation syst√©matique des r√©sultats
- Validation et correction automatique
- Cache intelligent pour optimisation
"""

import json
import logging
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass
from datetime import datetime

from .ai_service_manager import AIServiceType, call_ai, AIResponse

logger = logging.getLogger(__name__)

@dataclass
class ExtractedEntities:
    """Structure pour les entit√©s extraites par IA"""
    age_days: Optional[int] = None
    age_weeks: Optional[int] = None
    breed_specific: Optional[str] = None
    breed_generic: Optional[str] = None
    sex: Optional[str] = None
    weight_mentioned: bool = False
    weight_grams: Optional[float] = None
    weight_unit: Optional[str] = None
    symptoms: List[str] = None
    context_type: Optional[str] = None
    housing_conditions: Optional[str] = None
    feeding_context: Optional[str] = None
    
    # M√©tadonn√©es IA
    extraction_confidence: float = 0.0
    ai_reasoning: Optional[str] = None
    normalized_by_ai: bool = True
    
    def __post_init__(self):
        if self.symptoms is None:
            self.symptoms = []

class AIEntityExtractor:
    """Extracteur d'entit√©s avec IA - Remplace les patterns regex"""
    
    def __init__(self):
        # Configuration des mod√®les par complexit√©
        self.models = {
            "simple": "gpt-3.5-turbo",    # Questions simples
            "complex": "gpt-4",           # Questions complexes/ambigu√´s  
            "multilingual": "gpt-4"       # Support multilingue
        }
        
        # Templates de prompts optimis√©s
        self.prompts = self._initialize_prompts()
        
        # Mapping de normalisation (backup pour validation)
        self.normalization_maps = {
            "breeds": {
                "ross 308": "Ross 308", "ross308": "Ross 308", "ross trois cent huit": "Ross 308",
                "cobb 500": "Cobb 500", "cobb500": "Cobb 500", "cobb cinq cents": "Cobb 500",
                "hubbard": "Hubbard", "arbor acres": "Arbor Acres",
                "isa brown": "ISA Brown", "lohmann brown": "Lohmann Brown"
            },
            "sexes": {
                "m√¢le": "male", "male": "male", "coq": "male", "masculin": "male",
                "femelle": "female", "female": "female", "poule": "female", "f√©minin": "female", 
                "mixte": "mixed", "mixed": "mixed", "m√©lang√©": "mixed", "both": "mixed"
            },
            "contexts": {
                "poids": "performance", "weight": "performance", "croissance": "performance",
                "malade": "sant√©", "sick": "sant√©", "sympt√¥me": "sant√©", "problem": "sant√©",
                "alimentation": "alimentation", "feed": "alimentation", "nutrition": "alimentation"
            }
        }
        
        logger.info("ü§ñ [AI Entity Extractor] Initialis√© avec prompts optimis√©s")
    
    def _initialize_prompts(self) -> Dict[str, str]:
        """Initialise les templates de prompts sp√©cialis√©s"""
        return {
            "extraction_complete": """Analyse cette question d'√©levage avicole et extrait toutes les entit√©s pertinentes.

QUESTION: "{question}"

Extrait pr√©cis√©ment:

1. **RACE/SOUCHE**: Toute mention de race sp√©cifique (Ross 308, Cobb 500, Hubbard, ISA Brown, etc.) ou g√©n√©rique (poulet, poule, broiler)

2. **√ÇGE**: √Çge mentionn√© sous toute forme (21 jours, 3 semaines, trois semaines, 21j, etc.)
   - Convertis TOUJOURS en jours
   - 1 semaine = 7 jours

3. **SEXE**: M√¢le, femelle, mixte, coq, poule, etc.
   - Normalise: m√¢le/coq/masculin ‚Üí "male"
   - Normalise: femelle/poule/f√©minin ‚Üí "female"  
   - Normalise: mixte/m√©lang√©/both ‚Üí "mixed"

4. **POIDS**: Toute mention de poids, grammes, kg
   - Convertis en grammes
   - Note si c'est mentionn√© m√™me sans valeur

5. **SYMPT√îMES**: Probl√®mes de sant√©, maladies, comportements anormaux

6. **CONTEXTE**: Type de question (performance/poids, sant√©, alimentation, g√©n√©ral)

7. **CONDITIONS**: Logement, environnement, temp√©rature mentionn√©s

R√©ponds UNIQUEMENT en JSON valide:
```json
{{
  "age_days": null|number,
  "age_weeks": null|number,
  "breed_specific": null|"Ross 308"|"Cobb 500"|etc,
  "breed_generic": null|"poulet"|"poule"|"broiler"|etc,
  "sex": null|"male"|"female"|"mixed",
  "weight_mentioned": true|false,
  "weight_grams": null|number,
  "weight_unit": null|"g"|"kg",
  "symptoms": [],
  "context_type": "performance"|"sant√©"|"alimentation"|"g√©n√©ral",
  "housing_conditions": null|"description",
  "feeding_context": null|"description",
  "extraction_confidence": 0.0-1.0,
  "ai_reasoning": "explication courte du raisonnement"
}}
```

IMPORTANT: 
- Sois pr√©cis et conservateur
- Si incertain, mets null plut√¥t que deviner
- Normalise SYST√âMATIQUEMENT les races (Ross 308, Cobb 500, etc.)
- Convertis TOUJOURS les √¢ges en jours
- Utilise uniquement "male", "female", "mixed" pour le sexe""",

            "validation_normalization": """Valide et corrige ces entit√©s extraites selon les standards avicoles.

ENTIT√âS BRUTES: {entities}

CORRECTIONS N√âCESSAIRES:

1. **RACES**: Normalise selon standards:
   - ross 308/ross308/Ross trois cent huit ‚Üí "Ross 308"
   - cobb 500/cobb500/Cobb cinq cents ‚Üí "Cobb 500"  
   - hubbard/Hubbard ‚Üí "Hubbard"
   - isa brown/ISA Brown ‚Üí "ISA Brown"

2. **√ÇGES**: V√©rifie conversions:
   - Semaines √ó 7 = jours
   - Coh√©rence age_days et age_weeks

3. **SEXE**: Standardise:
   - m√¢le/coq/masculin ‚Üí "male"
   - femelle/poule/f√©minin ‚Üí "female"
   - mixte/m√©lang√© ‚Üí "mixed"

4. **COH√âRENCE**: V√©rifie logique des combinaisons

R√©ponds avec les entit√©s CORRIG√âES en JSON:
```json
{{
  "age_days": number|null,
  "age_weeks": number|null, 
  "breed_specific": "forme_normalis√©e"|null,
  "breed_generic": "forme_standard"|null,
  "sex": "male"|"female"|"mixed"|null,
  "weight_mentioned": true|false,
  "weight_grams": number|null,
  "weight_unit": "g"|"kg"|null,
  "symptoms": ["sympt√¥me1", "sympt√¥me2"],
  "context_type": "performance"|"sant√©"|"alimentation"|"g√©n√©ral",
  "housing_conditions": "description"|null,
  "feeding_context": "description"|null,
  "extraction_confidence": 0.0-1.0,
  "validation_notes": "corrections appliqu√©es"
}}
```""",

            "multilingual_extraction": """Extract poultry farming entities from this question in any language.

QUESTION: "{question}"
DETECTED LANGUAGE: {language}

Extract and normalize to standard English format:

1. **BREED**: Any breed mention (Ross 308, Cobb 500, Hubbard, etc.)
2. **AGE**: Convert to days (semanas/weeks √ó 7)
3. **SEX**: Normalize to "male", "female", "mixed"
4. **WEIGHT**: Convert to grams  
5. **SYMPTOMS**: Health issues
6. **CONTEXT**: Question type

Respond in JSON:
```json
{{
  "age_days": null|number,
  "breed_specific": null|"Ross 308"|"Cobb 500"|etc,
  "sex": null|"male"|"female"|"mixed",
  "weight_mentioned": true|false,
  "weight_grams": null|number,
  "symptoms": [],
  "context_type": "performance"|"health"|"feeding"|"general",
  "extraction_confidence": 0.0-1.0,
  "source_language": "{language}"
}}
```"""
        }
    
    async def extract_entities(self, question: str, language: str = "fr") -> ExtractedEntities:
        """
        Point d'entr√©e principal - Extraction compl√®te des entit√©s avec IA
        
        Args:
            question: Question de l'utilisateur
            language: Langue d√©tect√©e (fr, en, es)
            
        Returns:
            ExtractedEntities avec toutes les informations extraites et normalis√©es
        """
        try:
            logger.info(f"ü§ñ [AI Entity Extractor] Extraction: '{question[:50]}...'")
            
            # D√©terminer le mod√®le selon la complexit√©
            model = self._select_model(question, language)
            
            # Choisir le prompt appropri√©
            if language != "fr":
                prompt = self.prompts["multilingual_extraction"].format(
                    question=question, 
                    language=language
                )
            else:
                prompt = self.prompts["extraction_complete"].format(question=question)
            
            # Appel IA pour extraction
            ai_response = await call_ai(
                service_type=AIServiceType.ENTITY_EXTRACTION,
                prompt=prompt,
                model=model,
                max_tokens=800,
                temperature=0.1,
                cache_key=f"extract_{hash(question)}_{language}"
            )
            
            # Parser la r√©ponse JSON
            raw_entities = self._parse_ai_response(ai_response.content)
            
            # Validation et normalisation suppl√©mentaire
            validated_entities = await self._validate_and_normalize(raw_entities, question)
            
            # Convertir en objet ExtractedEntities
            entities = self._build_extracted_entities(validated_entities, ai_response)
            
            logger.info(f"‚úÖ [AI Entity Extractor] Extraction r√©ussie: {entities.breed_specific or 'race inconnue'}, {entities.age_days or '√¢ge inconnu'}j, {entities.sex or 'sexe inconnu'}")
            
            return entities
            
        except Exception as e:
            logger.error(f"‚ùå [AI Entity Extractor] Erreur extraction: {e}")
            # Retourner entit√©s vides plut√¥t que faire √©chouer
            return self._create_empty_entities(question, str(e))
    
    def _select_model(self, question: str, language: str) -> str:
        """S√©lectionne le mod√®le optimal selon la complexit√©"""
        
        # Multilingue ‚Üí GPT-4
        if language != "fr":
            return self.models["multilingual"]
        
        # Question complexe ‚Üí GPT-4  
        complexity_indicators = [
            len(question.split()) > 15,  # Question longue
            any(word in question.lower() for word in ["comment", "pourquoi", "expliquer", "diff√©rence"]),  # Questions conceptuelles
            question.count(',') > 2,  # Multiples √©l√©ments
            any(word in question.lower() for word in ["sympt√¥me", "probl√®me", "malade"])  # Sant√© complexe
        ]
        
        if sum(complexity_indicators) >= 2:
            return self.models["complex"]
        
        return self.models["simple"]
    
    def _parse_ai_response(self, content: str) -> Dict[str, Any]:
        """Parse la r√©ponse JSON de l'IA avec gestion d'erreurs"""
        
        try:
            # Nettoyer le contenu (supprimer markdown, etc.)
            content = content.strip()
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            # Parser JSON
            entities = json.loads(content)
            
            # Validation basique de structure
            required_fields = ["age_days", "breed_specific", "sex", "weight_mentioned", "context_type"]
            for field in required_fields:
                if field not in entities:
                    entities[field] = None
            
            return entities
            
        except json.JSONDecodeError as e:
            logger.warning(f"‚ö†Ô∏è [AI Entity Extractor] Erreur parsing JSON: {e}")
            return self._parse_fallback(content)
        except Exception as e:
            logger.error(f"‚ùå [AI Entity Extractor] Erreur parsing: {e}")
            return {}
    
    def _parse_fallback(self, content: str) -> Dict[str, Any]:
        """Parsing de fallback si JSON invalide"""
        
        entities = {
            "age_days": None, "breed_specific": None, "sex": None,
            "weight_mentioned": False, "context_type": "g√©n√©ral",
            "extraction_confidence": 0.3,
            "ai_reasoning": "Parsing fallback - JSON invalide"
        }
        
        # Extraction basique par mots-cl√©s
        content_lower = content.lower()
        
        # Recherche √¢ge
        import re
        age_match = re.search(r'(\d+)\s*(?:jour|day)s?', content_lower)
        if age_match:
            entities["age_days"] = int(age_match.group(1))
        
        # Recherche race
        for normalized, standard in self.normalization_maps["breeds"].items():
            if normalized in content_lower:
                entities["breed_specific"] = standard
                break
        
        # Recherche sexe  
        for raw, normalized in self.normalization_maps["sexes"].items():
            if raw in content_lower:
                entities["sex"] = normalized
                break
        
        return entities
    
    async def _validate_and_normalize(self, entities: Dict[str, Any], original_question: str) -> Dict[str, Any]:
        """Validation et normalisation suppl√©mentaire avec IA"""
        
        try:
            # Si confiance √©lev√©e, validation l√©g√®re
            if entities.get("extraction_confidence", 0) > 0.8:
                return self._normalize_locally(entities)
            
            # Sinon, validation IA compl√®te
            prompt = self.prompts["validation_normalization"].format(
                entities=json.dumps(entities, ensure_ascii=False)
            )
            
            ai_response = await call_ai(
                service_type=AIServiceType.VALIDATION,
                prompt=prompt,
                model="gpt-4",
                max_tokens=600,
                temperature=0.05,
                cache_key=f"validate_{hash(str(entities))}"
            )
            
            validated = self._parse_ai_response(ai_response.content)
            return validated if validated else self._normalize_locally(entities)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [AI Entity Extractor] Erreur validation IA: {e}")
            return self._normalize_locally(entities)
    
    def _normalize_locally(self, entities: Dict[str, Any]) -> Dict[str, Any]:
        """Normalisation locale avec les mappings de backup"""
        
        # Normaliser race
        breed = entities.get("breed_specific", "").lower()
        for raw, normalized in self.normalization_maps["breeds"].items():
            if raw in breed:
                entities["breed_specific"] = normalized
                break
        
        # Normaliser sexe
        sex = entities.get("sex", "").lower()
        for raw, normalized in self.normalization_maps["sexes"].items():
            if raw in sex:
                entities["sex"] = normalized
                break
        
        # Calculer age_weeks si age_days disponible
        age_days = entities.get("age_days")
        if age_days and isinstance(age_days, int):
            entities["age_weeks"] = age_days // 7
        
        # Normaliser contexte
        context = entities.get("context_type", "").lower()
        for raw, normalized in self.normalization_maps["contexts"].items():
            if raw in context:
                entities["context_type"] = normalized
                break
        
        return entities
    
    def _build_extracted_entities(self, validated_entities: Dict[str, Any], ai_response: AIResponse) -> ExtractedEntities:
        """Construit l'objet ExtractedEntities final"""
        
        return ExtractedEntities(
            age_days=validated_entities.get("age_days"),
            age_weeks=validated_entities.get("age_weeks"),
            breed_specific=validated_entities.get("breed_specific"),
            breed_generic=validated_entities.get("breed_generic"),
            sex=validated_entities.get("sex"),
            weight_mentioned=validated_entities.get("weight_mentioned", False),
            weight_grams=validated_entities.get("weight_grams"),
            weight_unit=validated_entities.get("weight_unit"),
            symptoms=validated_entities.get("symptoms", []),
            context_type=validated_entities.get("context_type"),
            housing_conditions=validated_entities.get("housing_conditions"),
            feeding_context=validated_entities.get("feeding_context"),
            extraction_confidence=validated_entities.get("extraction_confidence", 0.7),
            ai_reasoning=validated_entities.get("ai_reasoning") or validated_entities.get("validation_notes"),
            normalized_by_ai=True
        )
    
    def _create_empty_entities(self, question: str, error: str) -> ExtractedEntities:
        """Cr√©e un objet entit√©s vide en cas d'erreur"""
        
        return ExtractedEntities(
            context_type="g√©n√©ral",
            extraction_confidence=0.0,
            ai_reasoning=f"Erreur extraction: {error}",
            normalized_by_ai=False
        )
    
    async def extract_entities_batch(self, questions: List[str], language: str = "fr") -> List[ExtractedEntities]:
        """Extraction par lot pour optimisation"""
        
        logger.info(f"ü§ñ [AI Entity Extractor] Extraction par lot: {len(questions)} questions")
        
        # Traitement parall√®le avec asyncio
        import asyncio
        tasks = [self.extract_entities(q, language) for q in questions]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filtrer les erreurs
        entities_list = []
        for result in results:
            if isinstance(result, Exception):
                entities_list.append(self._create_empty_entities("", str(result)))
            else:
                entities_list.append(result)
        
        logger.info(f"‚úÖ [AI Entity Extractor] Extraction par lot termin√©e: {len(entities_list)} r√©sultats")
        return entities_list
    
    def get_extraction_stats(self) -> Dict[str, Any]:
        """Statistiques d'extraction pour monitoring"""
        # Ces stats seraient collect√©es via AIServiceManager
        from .ai_service_manager import get_ai_service_manager
        
        manager = get_ai_service_manager()
        health = manager.get_service_health()
        
        return {
            "service_name": "AI Entity Extractor",
            "extraction_requests": health.get("requests_by_service", {}).get("entity_extraction", 0),
            "models_available": list(self.models.keys()),
            "normalization_maps": {k: len(v) for k, v in self.normalization_maps.items()},
            "supported_languages": ["fr", "en", "es"],
            "ai_service_health": health
        }

# Instance globale pour utilisation facile
_ai_entity_extractor = None

def get_ai_entity_extractor() -> AIEntityExtractor:
    """R√©cup√®re l'instance singleton de l'extracteur IA"""
    global _ai_entity_extractor
    if _ai_entity_extractor is None:
        _ai_entity_extractor = AIEntityExtractor()
    return _ai_entity_extractor