# app/main.py - VERSION 4.0 AVEC SYST√àME DE CACHE STATISTIQUES INT√âGR√â
# ‚úÖ CONSERVATION INT√âGRALE DU CODE ORIGINAL + AJOUTS CACHE SAFE
# üöÄ NOUVEAU: Syst√®me de cache statistiques automatique
# üîß CORRECTION CORS POUR CREDENTIALS: 'INCLUDE' - VERSION FINALE CONSERV√âE
# üéØ FIX: Ajout du router stats_admin manquant
from __future__ import annotations

import os
import logging
import time
import asyncio
import psutil
from datetime import datetime
from contextlib import asynccontextmanager
from typing import Any, Optional, Dict, List

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

# .env (facultatif)
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

logger = logging.getLogger("app.main")
logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"))

# üÜï ACTIVATION SYNTH√àSE LLM AU D√âMARRAGE (CONSERV√â)
synthesis_enabled = str(os.getenv("ENABLE_SYNTH_PROMPT", "0")).lower() in ("1", "true", "yes", "on")
if synthesis_enabled:
    logger.info("‚úÖ Synth√®se LLM activ√©e (ENABLE_SYNTH_PROMPT=1)")
else:
    logger.info("‚ÑπÔ∏è Synth√®se LLM d√©sactiv√©e (ENABLE_SYNTH_PROMPT=0)")

# ========== VARIABLES GLOBALES DE MONITORING (CONSERV√âES) ==========
request_counter = 0
error_counter = 0
start_time = time.time()
active_requests = 0

# üöÄ NOUVEAU: Variables pour le syst√®me de cache statistiques
stats_scheduler_task = None
cache_update_counter = 0
cache_error_counter = 0

# üöÄ NOUVEAU: Import du syst√®me de cache (SAFE - avec gestion d'erreur)
STATS_CACHE_AVAILABLE = False
try:
    from app.api.v1.stats_cache import get_stats_cache, is_cache_available, force_cache_refresh
    from app.api.v1.stats_updater import get_stats_updater, run_update_cycle, force_update_all
    STATS_CACHE_AVAILABLE = True
    logger.info("‚úÖ Syst√®me de cache statistiques import√© avec succ√®s")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Syst√®me de cache statistiques non disponible: {e}")
    logger.info("‚ÑπÔ∏è L'application fonctionnera normalement sans le cache optimis√©")

# ========== FONCTION DE MONITORING P√âRIODIQUE AM√âLIOR√âE (CONSERV√âE) ==========
async def periodic_monitoring():
    """Monitoring p√©riodique des performances serveur avec logging en base"""
    while True:
        try:
            await asyncio.sleep(300)  # Toutes les 5 minutes
            
            # Calcul des m√©triques
            current_time = time.time()
            uptime_hours = (current_time - start_time) / 3600
            requests_per_minute = request_counter / (uptime_hours * 60) if uptime_hours > 0 else 0
            error_rate_percent = (error_counter / max(request_counter, 1)) * 100
            
            # M√©triques syst√®me
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            # D√©terminer le status de sant√©
            if error_rate_percent > 10 or cpu_percent > 90 or memory_percent > 90:
                health_status = "critical"
            elif error_rate_percent > 5 or cpu_percent > 70 or memory_percent > 70:
                health_status = "degraded"
            else:
                health_status = "healthy"
            
            # Log des m√©triques serveur dans la base
            try:
                from app.api.v1.logging import get_analytics_manager
                analytics = get_analytics_manager()
                
                # Calculer l'heure tronqu√©e pour le groupement
                current_hour = datetime.now().replace(minute=0, second=0, microsecond=0)
                
                # Log des m√©triques (cette fonction devra √™tre ajout√©e dans logging.py)
                analytics.log_server_performance(
                    timestamp_hour=current_hour,
                    total_requests=request_counter,
                    successful_requests=request_counter - error_counter,
                    failed_requests=error_counter,
                    avg_response_time_ms=int(250),  # √Ä calculer r√©ellement si n√©cessaire
                    health_status=health_status,
                    error_rate_percent=error_rate_percent
                )
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur logging m√©triques en base: {e}")
                
            # üöÄ NOUVEAU: Ajouter les m√©triques du cache
            cache_info = ""
            if STATS_CACHE_AVAILABLE:
                cache_info = f", cache: {cache_update_counter} updates, {cache_error_counter} erreurs"
                
            logger.info(f"üìä M√©triques: {requests_per_minute:.1f} req/min, "
                       f"erreurs: {error_rate_percent:.1f}%, "
                       f"CPU: {cpu_percent:.1f}%, RAM: {memory_percent:.1f}%, "
                       f"sant√©: {health_status}{cache_info}")
            
        except Exception as e:
            logger.error(f"‚åõ Erreur monitoring p√©riodique: {e}")
            await asyncio.sleep(60)  # Retry dans 1 minute en cas d'erreur

# üöÄ NOUVEAU: Fonction de mise √† jour p√©riodique du cache statistiques
async def periodic_stats_update():
    """üîÑ Mise √† jour p√©riodique du cache statistiques toutes les heures"""
    global cache_update_counter, cache_error_counter
    
    if not STATS_CACHE_AVAILABLE:
        logger.warning("‚ö†Ô∏è Cache statistiques non disponible - arr√™t scheduler")
        return
    
    # Attendre 5 minutes avant la premi√®re mise √† jour (laisser le syst√®me s'initialiser)
    await asyncio.sleep(300)
    
    # Premi√®re mise √† jour au d√©marrage
    logger.info("üöÄ Lancement premi√®re mise √† jour cache statistiques au d√©marrage")
    try:
        result = await run_update_cycle()
        if result.get("status") == "completed":
            cache_update_counter += 1
            logger.info("‚úÖ Premi√®re mise √† jour cache r√©ussie au d√©marrage")
        else:
            cache_error_counter += 1
            logger.warning(f"‚ö†Ô∏è Premi√®re mise √† jour cache √©chou√©e: {result.get('error', 'Unknown')}")
    except Exception as e:
        cache_error_counter += 1
        logger.error(f"‚ùå Erreur premi√®re mise √† jour cache: {e}")
    
    # Boucle principale - mise √† jour toutes les heures
    while True:
        try:
            # Attendre 1 heure (3600 secondes)
            await asyncio.sleep(3600)
            
            logger.info("üîÑ D√©but mise √† jour p√©riodique cache statistiques")
            start_update = time.time()
            
            # Lancer la mise √† jour
            result = await run_update_cycle()
            
            update_duration = (time.time() - start_update) * 1000  # en ms
            
            if result.get("status") == "completed":
                cache_update_counter += 1
                successful = result.get("successful_updates", 0)
                total = result.get("total_updates", 0)
                duration = result.get("duration_ms", update_duration)
                
                logger.info(f"‚úÖ Cache mis √† jour: {successful}/{total} succ√®s en {duration:.0f}ms")
                
                # Log d√©taill√© si des erreurs
                errors = result.get("errors", [])
                if errors:
                    logger.warning(f"‚ö†Ô∏è Erreurs durant la mise √† jour: {errors}")
                
            elif result.get("status") == "failed":
                cache_error_counter += 1
                error_msg = result.get("error", "Erreur inconnue")
                logger.error(f"‚ùå Mise √† jour cache √©chou√©e: {error_msg}")
                
            else:
                cache_error_counter += 1
                logger.warning(f"‚ö†Ô∏è Mise √† jour cache statut inattendu: {result}")
            
        except Exception as e:
            cache_error_counter += 1
            logger.error(f"‚ùå Erreur durant mise √† jour p√©riodique cache: {e}")
            # Attendre 10 minutes avant de retry en cas d'erreur
            await asyncio.sleep(600)

# -------------------------------------------------------------------
# FONCTION RAG COMPL√àTE - 3 RAG (CONSERV√âE INT√âGRALEMENT)
# -------------------------------------------------------------------
def get_rag_paths() -> Dict[str, str]:
    """üéØ TOUS LES RAG : Global + Broiler + Layer"""
    base_path = "/workspace/backend/rag_index"
    return {
        "global": f"{base_path}/global",
        "broiler": f"{base_path}/broiler",
        "layer": f"{base_path}/layer"
    }

# -------------------------------------------------------------------
# Lifespan: init Supabase + 3 RAG COMPLETS + MONITORING + CACHE (√âTENDU)
# -------------------------------------------------------------------
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ========== INITIALISATION AU D√âMARRAGE ==========
    logger.info("üöÄ D√©marrage de l'application Expert API avec syst√®me complet + cache statistiques")
    
    # ========== INITIALISATION DES SERVICES AM√âLIOR√âE (CONSERV√âE) ==========
    try:
        logger.info("üìä Initialisation des services analytics et facturation...")
        
        # V√©rifier la base de donn√©es
        database_url = os.getenv("DATABASE_URL")
        if database_url:
            logger.info("‚úÖ DATABASE_URL configur√©e")
            
            # Initialiser les services avec gestion d'erreur
            try:
                from app.api.v1.logging import get_analytics
                analytics_status = get_analytics()
                logger.info(f"‚úÖ Service analytics: {analytics_status.get('status', 'unknown')}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Service analytics partiellement disponible: {e}")
            
            try:
                from app.api.v1.billing import get_billing_manager
                billing = get_billing_manager()
                logger.info(f"‚úÖ Service billing: {len(billing.plans)} plans charg√©s")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Service billing partiellement disponible: {e}")
            
            # üöÄ NOUVEAU: Initialiser le syst√®me de cache statistiques
            if STATS_CACHE_AVAILABLE:
                try:
                    cache = get_stats_cache()
                    cache_stats = cache.get_cache_stats()
                    logger.info(f"‚úÖ Cache statistiques initialis√©: {cache_stats}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Cache statistiques partiellement disponible: {e}")
            
            # Nettoyer les anciennes sessions (plus de 7 jours)
            try:
                from app.api.v1.pipeline.postgres_memory import PostgresMemory
                memory = PostgresMemory()
                cleaned = memory.cleanup_old_sessions(days_old=7)
                if cleaned > 0:
                    logger.info(f"üßπ {cleaned} anciennes sessions nettoy√©es")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Nettoyage sessions √©chou√©: {e}")
                
        else:
            logger.warning("‚ö†Ô∏è DATABASE_URL manquante - services analytics d√©sactiv√©s")
            
    except Exception as e:
        logger.error(f"‚åõ Erreur initialisation services: {e}")
        # Ne pas emp√™cher le d√©marrage
    
    # Initialisation Supabase (CONSERV√âE)
    app.state.supabase = None
    try:
        from supabase import create_client
        url, key = os.getenv("SUPABASE_URL"), os.getenv("SUPABASE_ANON_KEY")
        if url and key:
            app.state.supabase = create_client(url, key)
            logger.info("‚úÖ Supabase pr√™t")
        else:
            logger.info("‚ÑπÔ∏è Supabase non configur√©")
    except Exception as e:
        logger.warning("‚ÑπÔ∏è Supabase indisponible: %s", e)

    # üöÄ CHARGEMENT DES 3 RAG (CONSERV√â INT√âGRALEMENT)
    app.state.rag = None
    app.state.rag_broiler = None
    app.state.rag_layer = None

    try:
        from rag.embedder import FastRAGEmbedder

        rag_paths = get_rag_paths()
        logger.info(f"üîç Chargement des 3 RAG: {list(rag_paths.keys())}")

        # Variables d'environnement (override si d√©finies)
        env_override = {
            "global": os.getenv("RAG_INDEX_GLOBAL"),
            "broiler": os.getenv("RAG_INDEX_BROILER"),
            "layer": os.getenv("RAG_INDEX_LAYER"),
        }

        # Appliquer les overrides ENV
        for key, env_path in env_override.items():
            if env_path and os.path.exists(env_path):
                rag_paths[key] = env_path
                logger.info(f"üîß Override ENV pour {key}: {env_path}")

        # Helper pour logguer proprement une instance
        def _log_loaded(name: str, path: str, emb) -> None:
            try:
                stats = emb.get_index_stats() if hasattr(emb, "get_index_stats") else {}
                n_docs = stats.get("n_docs")
                faiss_total = stats.get("faiss_total")
                chunks_loaded = stats.get("chunks_loaded", faiss_total)
                dim = stats.get("embedding_dim", "unknown")
                model = stats.get("model_name", "unknown")
                logger.info(
                    f"‚úÖ RAG {name.capitalize()} charg√©: {path} "
                    f"(docs={n_docs if n_docs is not None else 'unknown'}, "
                    f"chunks={chunks_loaded if chunks_loaded is not None else 'unknown'}, "
                    f"dim={dim}, model={model})"
                )
            except Exception:
                logger.info(f"‚úÖ RAG {name.capitalize()} charg√©: {path}")

        # üöÄ GLOBAL
        global_path = rag_paths["global"]
        logger.info(f"üîç Chargement RAG Global: {global_path}")
        if os.path.exists(global_path):
            global_embedder = FastRAGEmbedder(debug=True, cache_embeddings=True, max_workers=2)
            if global_embedder.load_index(global_path) and global_embedder.has_search_engine():
                app.state.rag = global_embedder
                _log_loaded("global", global_path, global_embedder)
            else:
                logger.error(f"‚åõ RAG Global: √âchec chargement depuis {global_path}")
        else:
            logger.error(f"‚åõ RAG Global: Chemin inexistant {global_path}")

        # üöÄ BROILER
        broiler_path = rag_paths["broiler"]
        logger.info(f"üîç Chargement RAG Broiler: {broiler_path}")
        if os.path.exists(broiler_path):
            try:
                broiler_embedder = FastRAGEmbedder(debug=False, cache_embeddings=True, max_workers=2)
                if broiler_embedder.load_index(broiler_path) and broiler_embedder.has_search_engine():
                    app.state.rag_broiler = broiler_embedder
                    _log_loaded("broiler", broiler_path, broiler_embedder)
                else:
                    logger.warning(f"‚ö†Ô∏è RAG Broiler: √âchec chargement depuis {broiler_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è RAG Broiler: Erreur {e}")
        else:
            logger.warning(f"‚ö†Ô∏è RAG Broiler: Chemin inexistant {broiler_path}")

        # üöÄ LAYER
        layer_path = rag_paths["layer"]
        logger.info(f"üîç Chargement RAG Layer: {layer_path}")
        if os.path.exists(layer_path):
            try:
                layer_embedder = FastRAGEmbedder(debug=False, cache_embeddings=True, max_workers=2)
                if layer_embedder.load_index(layer_path) and layer_embedder.has_search_engine():
                    app.state.rag_layer = layer_embedder
                    _log_loaded("layer", layer_path, layer_embedder)
                else:
                    logger.warning(f"‚ö†Ô∏è RAG Layer: √âchec chargement depuis {layer_path}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è RAG Layer: Erreur {e}")
        else:
            logger.warning(f"‚ö†Ô∏è RAG Layer: Chemin inexistant {layer_path}")

        # üìä R√©sum√© final des 3 RAG
        total_rags = sum(1 for rag in [app.state.rag, app.state.rag_broiler, app.state.rag_layer] if rag)

        rag_summary = {
            "global": "‚úÖ Actif" if app.state.rag else "‚åõ CRITIQUE",
            "broiler": "‚úÖ Actif" if app.state.rag_broiler else "‚åõ Absent",
            "layer": "‚úÖ Actif" if app.state.rag_layer else "‚åõ Absent",
            "total_loaded": total_rags
        }
        logger.info(f"üìä Status final des RAG: {rag_summary}")

        if total_rags == 3:
            logger.info("üéâ PARFAIT: Les 3 RAG sont charg√©s (Global + Broiler + Layer)")
        elif total_rags == 1:
            logger.warning("‚ö†Ô∏è Seulement 1 RAG charg√© - potentiel g√¢ch√©")
        else:
            logger.warning(f"‚ö†Ô∏è Seulement {total_rags}/3 RAG charg√©s")

    except Exception as e:
        logger.error("‚åõ Erreur critique initialisation RAG: %s", e)

    # ========== D√âMARRAGE DU MONITORING P√âRIODIQUE (CONSERV√â) ==========
    monitoring_task = None
    try:
        monitoring_task = asyncio.create_task(periodic_monitoring())
        logger.info("üìä Monitoring p√©riodique d√©marr√©")
    except Exception as e:
        logger.error(f"‚åõ Erreur d√©marrage monitoring: {e}")

    # üöÄ NOUVEAU: D√âMARRAGE DU SCHEDULER CACHE STATISTIQUES
    global stats_scheduler_task
    if STATS_CACHE_AVAILABLE:
        try:
            stats_scheduler_task = asyncio.create_task(periodic_stats_update())
            logger.info("üîÑ Scheduler cache statistiques d√©marr√© (mise √† jour toutes les heures)")
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©marrage scheduler cache: {e}")
    else:
        logger.info("‚ÑπÔ∏è Scheduler cache statistiques d√©sactiv√© (module non disponible)")

    # ========== L'APPLICATION D√âMARRE ==========
    system_features = []
    if STATS_CACHE_AVAILABLE:
        system_features.append("cache statistiques optimis√©")
    system_features.extend(["3 RAG", "monitoring", "analytics", "billing"])
    
    logger.info(f"üéØ Application Expert API pr√™te avec: {', '.join(system_features)}")
    yield  # --- L'APPLICATION FONCTIONNE ---

    # ========== NETTOYAGE √Ä L'ARR√äT ==========
    logger.info("üõë Arr√™t de l'application Expert API")
    
    # Arr√™ter le monitoring
    if monitoring_task:
        try:
            monitoring_task.cancel()
            logger.info("üìä Monitoring p√©riodique arr√™t√©")
        except Exception as e:
            logger.error(f"‚åõ Erreur arr√™t monitoring: {e}")
    
    # üöÄ NOUVEAU: Arr√™ter le scheduler cache
    if stats_scheduler_task:
        try:
            stats_scheduler_task.cancel()
            logger.info("üîÑ Scheduler cache statistiques arr√™t√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur arr√™t scheduler cache: {e}")
    
    # Statistiques finales
    uptime_hours = (time.time() - start_time) / 3600
    final_stats = f"{request_counter} requ√™tes en {uptime_hours:.1f}h, {error_counter} erreurs ({(error_counter/max(request_counter,1)*100):.1f}%)"
    
    if STATS_CACHE_AVAILABLE and cache_update_counter > 0:
        cache_success_rate = ((cache_update_counter / max(cache_update_counter + cache_error_counter, 1)) * 100)
        final_stats += f", cache: {cache_update_counter} mises √† jour ({cache_success_rate:.1f}% succ√®s)"
    
    logger.info(f"üìà Statistiques finales: {final_stats}")

# -------------------------------------------------------------------
# FastAPI (CONSERV√â INT√âGRALEMENT)
# -------------------------------------------------------------------
app = FastAPI(
    title="Intelia Expert API",
    version="4.0.0",  # üöÄ NOUVEAU: Version mise √† jour
    root_path="/api",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    lifespan=lifespan,
)

# =============================================================================
# üî• CORRECTION CORS CRITIQUE - FIXED POUR CREDENTIALS: 'INCLUDE' (CONSERV√âE)
# =============================================================================
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://expert.intelia.com",
        "https://expert-app-cngws.ondigitalocean.app",
        "http://localhost:3000",
        "http://localhost:8080",
        # üîß SUPPRIM√â: "*"  # ‚ùå Incompatible avec allow_credentials=True
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],
    allow_headers=[
        "Accept",
        "Accept-Language", 
        "Content-Language",
        "Content-Type",
        "Authorization",
        "X-Requested-With",
        "Origin",
        "Access-Control-Request-Method",
        "Access-Control-Request-Headers",
        "X-Session-ID"
    ],
    expose_headers=[
        "Access-Control-Allow-Origin",
        "Access-Control-Allow-Credentials",
        "Access-Control-Allow-Methods",
        "Access-Control-Allow-Headers"
    ]
)

# =============================================================================
# MIDDLEWARE DE MONITORING DES REQU√äTES (CONSERV√â)
# =============================================================================
@app.middleware("http")
async def monitoring_middleware(request: Request, call_next):
    """Middleware pour tracker les performances en temps r√©el"""
    global request_counter, error_counter, active_requests
    
    start_time_req = time.time()
    active_requests += 1
    request_counter += 1
    
    try:
        response = await call_next(request)
        
        # Tracker les erreurs
        if response.status_code >= 400:
            error_counter += 1
            
        return response
        
    except Exception as e:
        error_counter += 1
        logger.error(f"‚åõ Erreur dans middleware monitoring: {e}")
        raise
        
    finally:
        active_requests -= 1
        processing_time = (time.time() - start_time_req) * 1000
        
        # Log des requ√™tes lentes
        if processing_time > 5000:  # Plus de 5 secondes
            logger.warning(f"üåÄ Requ√™te lente: {request.method} {request.url.path} - {processing_time:.0f}ms")

# üîç AJOUT DU MIDDLEWARE D'AUTHENTIFICATION (CONSERV√â)
try:
    from app.middleware.auth_middleware import auth_middleware
    app.middleware("http")(auth_middleware)
    logger.info("‚úÖ Middleware d'authentification activ√©")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Middleware d'authentification non disponible: {e}")
except Exception as e:
    logger.error(f"‚åõ Erreur lors de l'activation du middleware d'auth: {e}")

# -------------------------------------------------------------------
# üîß CORRECTION MAJEURE : Montage des routers avec AUTH ROUTING FIX√â (CONSERV√â)
# -------------------------------------------------------------------
# üîß CREATION D'UN ROUTER V1 TEMPORAIRE SI LE FICHIER __init__.py EST VIDE
try:
    from app.api.v1 import router as api_v1_router
    app.include_router(api_v1_router)
    logger.info("‚úÖ Router API v1 charg√© depuis __init__.py")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Impossible de charger le router v1 depuis __init__.py: {e}")
    logger.info("üîß Cr√©ation d'un router v1 temporaire...")
    
    # Cr√©er un router temporaire et inclure manuellement les composants
    from fastapi import APIRouter
    temp_v1_router = APIRouter(prefix="/v1", tags=["v1"])
    
    # Importer et monter les routers individuellement
    try:
        from app.api.v1.expert import router as expert_router
        temp_v1_router.include_router(expert_router, tags=["expert"])
        logger.info("‚úÖ Expert router ajout√©")
    except ImportError as e:
        logger.error(f"‚åõ Impossible de charger expert router: {e}")
    
    # ‚úÖ CORRECTION CRITIQUE DU ROUTING AUTH - R√©sout le catch-22 (CONSERV√â)
    try:
        from app.api.v1.auth import router as auth_router
        
        # üîç Debug du router auth avant montage
        logger.info(f"üîç Auth router prefix avant montage: {getattr(auth_router, 'prefix', 'None')}")
        logger.info(f"üîç Auth router routes count: {len(auth_router.routes)}")
        
        # Debug d√©taill√© des routes auth
        for route in auth_router.routes:
            if hasattr(route, 'path') and hasattr(route, 'methods'):
                methods_list = list(route.methods) if hasattr(route, 'methods') else ['UNKNOWN']
                logger.info(f"üîç Route auth: {route.path} {methods_list}")
        
        # ‚úÖ MONTAGE CORRIG√â - Pas de prefix car auth.py a d√©j√† /auth
        temp_v1_router.include_router(
            auth_router, 
            prefix="",  # ‚≠ê CRITIQUE: Pas de prefix car auth.py d√©finit d√©j√† router = APIRouter(prefix="/auth")
            tags=["auth"]
        )
        
        logger.info("‚úÖ Auth router ajout√© avec montage corrig√©")
        logger.info("‚úÖ Auth routes maintenant disponibles sur /v1/auth/*")
        
    except ImportError as e:
        logger.error(f"‚åõ Import Error auth router: {e}")
        import traceback
        logger.error(f"‚åõ Traceback: {traceback.format_exc()}")
    except Exception as e:
        logger.error(f"‚åõ Erreur inattendue auth router: {e}")
        import traceback
        logger.error(f"‚åõ Traceback: {traceback.format_exc()}")
    
    # üöÄ NOUVEAU: Montage des routers cache statistiques (SAFE)
    if STATS_CACHE_AVAILABLE:
        try:
            from app.api.v1.stats_fast import router as stats_fast_router
            temp_v1_router.include_router(stats_fast_router, tags=["statistics-fast"])
            logger.info("‚úÖ Stats Fast router ajout√© (endpoints ultra-rapides)")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Stats Fast router non disponible: {e}")
        
        try:
            # üéØ FIX PRINCIPAL: Cette ligne √©tait manquante !
            from app.api.v1.stats_admin import router as stats_admin_router
            temp_v1_router.include_router(stats_admin_router, tags=["statistics-admin"])
            logger.info("‚úÖ Stats Admin router ajout√© (administration cache)")
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è Stats Admin router non disponible: {e}")
    else:
        logger.info("‚ÑπÔ∏è Routers cache statistiques non mont√©s (module non disponible)")
    
    # ‚úÖ ENDPOINTS DE TEST TEMPORAIRES pour v√©rifier le fix (CONSERV√âS)
    @temp_v1_router.get("/auth/test-routing")
    async def test_auth_routing():
        """Endpoint temporaire pour v√©rifier que le routing auth fonctionne"""
        return {
            "status": "success",
            "message": "Auth routing fonctionne correctement",
            "available_endpoints": [
                "GET /v1/auth/test-routing (ce endpoint)",
                "POST /v1/auth/test-login",
                "GET /v1/auth/me", 
                "POST /v1/auth/login",
                "GET /v1/auth/debug/jwt-config"
            ],
            "note": "Si vous voyez ce message, le catch-22 est r√©solu"
        }
    
    @temp_v1_router.post("/auth/test-login")
    async def test_login_method():
        """Endpoint temporaire pour tester que POST fonctionne sur auth"""
        return {
            "status": "method_works", 
            "message": "POST sur auth routing fonctionne",
            "note": "Le vrai login est sur /v1/auth/login"
        }
    
    # üöÄ NOUVEAU: Endpoints de test pour le cache
    if STATS_CACHE_AVAILABLE:
        @temp_v1_router.get("/stats/test")
        async def test_stats_cache():
            """Test du syst√®me de cache statistiques"""
            try:
                cache = get_stats_cache()
                
                # Test simple d'√©criture/lecture
                test_data = {"test": True, "timestamp": datetime.now().isoformat()}
                cache.set_cache("test:endpoint", test_data, ttl_hours=1)
                cached_result = cache.get_cache("test:endpoint")
                
                return {
                    "status": "success",
                    "message": "Syst√®me de cache statistiques fonctionnel",
                    "cache_test": "ok" if cached_result else "failed",
                    "available_endpoints": [
                        "GET /v1/stats-fast/dashboard (dashboard ultra-rapide)",
                        "GET /v1/stats-fast/questions (questions ultra-rapides)", 
                        "GET /v1/stats-admin/status (administration cache)",
                        "POST /v1/stats-admin/force-update/all (force mise √† jour)"
                    ],
                    "scheduler_active": stats_scheduler_task is not None and not stats_scheduler_task.done(),
                    "cache_updates": cache_update_counter,
                    "cache_errors": cache_error_counter
                }
            except Exception as e:
                return {
                    "status": "error",
                    "message": f"Erreur test cache: {e}",
                    "cache_available": False
                }
    
    # Continuer avec les autres routers (CONSERV√â)
    try:
        from app.api.v1.health import router as health_router
        temp_v1_router.include_router(health_router, tags=["health"])
        logger.info("‚úÖ Health router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Health router non disponible: {e}")
    
    try:
        from app.api.v1.system import router as system_router
        temp_v1_router.include_router(system_router, tags=["system"])
        logger.info("‚úÖ System router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è System router non disponible: {e}")
    
    try:
        from app.api.v1.admin import router as admin_router
        temp_v1_router.include_router(admin_router, tags=["admin"])
        logger.info("‚úÖ Admin router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Admin router non disponible: {e}")
    
    try:
        from app.api.v1.invitations import router as invitations_router
        temp_v1_router.include_router(invitations_router, tags=["invitations"])
        logger.info("‚úÖ Invitations router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Invitations router non disponible: {e}")

    # üÜï NOUVEAU: Router auth invitations (CONSERV√â)
    try:
        from app.api.v1.auth_invitations import router as auth_invitations_router
        temp_v1_router.include_router(auth_invitations_router, tags=["auth-invitations"])
        logger.info("‚úÖ Auth invitations router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Auth invitations router non disponible: {e}")
    
    try:
        from app.api.v1.logging import router as logging_router
        temp_v1_router.include_router(logging_router, tags=["logging"])
        logger.info("‚úÖ Logging router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Logging router non disponible: {e}")
    
    try:
        from app.api.v1.conversations import router as conversations_router
        temp_v1_router.include_router(conversations_router, prefix="/conversations", tags=["conversations"])
        logger.info("‚úÖ Conversations router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Conversations router non disponible: {e}")
    
    try:
        from app.api.v1.billing import router as billing_router
        temp_v1_router.include_router(billing_router, tags=["billing"])
        logger.info("‚úÖ Billing router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Billing router non disponible: {e}")
    
    # üî• NOUVEAU: Ajout du billing OpenAI router (CONSERV√â)
    try:
        from app.api.v1.billing_openai import router as billing_openai_router
        temp_v1_router.include_router(billing_openai_router, prefix="/billing", tags=["billing-openai"])
        logger.info("‚úÖ Billing OpenAI router ajout√©")
    except ImportError as e:
        logger.warning(f"‚ö†Ô∏è Billing OpenAI router non disponible: {e}")
    
    # Monter le router temporaire
    app.include_router(temp_v1_router)
    logger.info("‚úÖ Router v1 temporaire mont√© avec succ√®s (incluant cache statistiques + stats_admin)")

# -------------------------------------------------------------------
# Debug RAG - 3 RAG COMPLETS (CONSERV√â INT√âGRALEMENT)
# -------------------------------------------------------------------
@app.get("/rag/debug", tags=["Debug"])
async def rag_debug():
    """üîç Debug des 3 RAG (Global + Broiler + Layer)"""
    rag_paths = get_rag_paths()
    env_vars = {
        "RAG_INDEX_GLOBAL": os.getenv("RAG_INDEX_GLOBAL"),
        "RAG_INDEX_BROILER": os.getenv("RAG_INDEX_BROILER"),
        "RAG_INDEX_LAYER": os.getenv("RAG_INDEX_LAYER"),
    }

    path_status = {}
    for name, path in rag_paths.items():
        try:
            exists = os.path.exists(path)
            is_dir = os.path.isdir(path) if exists else False
            files = sorted(os.listdir(path))[:10] if exists and is_dir else []

            path_status[name] = {
                "path": path,
                "exists": exists,
                "is_directory": is_dir,
                "files_found": len(files),
                "sample_files": files[:3],
                "has_faiss": "index.faiss" in files,
                "has_pkl": "index.pkl" in files,
                "has_meta": "meta.json" in files,
                "complete": exists and "index.faiss" in files and "index.pkl" in files
            }
        except Exception as e:
            path_status[name] = {
                "path": path,
                "exists": False,
                "error": str(e)
            }

    instances_status = {}
    for name, attr in [("global", "rag"), ("broiler", "rag_broiler"), ("layer", "rag_layer")]:
        embedder = getattr(app.state, attr, None)
        instance_info = {
            "loaded": embedder is not None,
            "functional": False,
            "documents": 0
        }

        if embedder:
            try:
                instance_info["functional"] = embedder.has_search_engine()
                if hasattr(embedder, 'get_document_count'):
                    instance_info["documents"] = embedder.get_document_count()
                elif hasattr(embedder, 'documents') and embedder.documents:
                    instance_info["documents"] = len(embedder.documents)
            except Exception as e:
                instance_info["error"] = str(e)

        instances_status[name] = instance_info

    total_available = sum(1 for info in path_status.values() if info.get("complete", False))
    total_loaded = sum(1 for info in instances_status.values() if info.get("functional", False))
    total_documents = sum(info.get("documents", 0) for info in instances_status.values() if isinstance(info.get("documents"), int))

    return {
        "approach": "three_rag_system",
        "environment_variables": env_vars,
        "rag_paths": rag_paths,
        "path_verification": path_status,
        "rag_instances": instances_status,
        "summary": {
            "total_available_on_disk": total_available,
            "total_loaded_in_memory": total_loaded,
            "total_documents": total_documents,
            "performance": "optimal" if total_loaded == 3 else "suboptimal"
        },
        "optimization": {
            "all_three_rags_enabled": True,
            "direct_loading": True,
            "failed_attempts": 0
        }
    }

@app.get("/rag/test", tags=["Debug"])
async def test_rag_access():
    """üß™ Test complet des 3 RAG"""
    results = {
        "timestamp": datetime.utcnow().isoformat(),
        "tests": {},
        "summary": {}
    }
    rag_paths = get_rag_paths()

    filesystem_test = {
        "base_path": "/workspace/backend/rag_index",
        "base_exists": os.path.exists("/workspace/backend/rag_index"),
        "rags": {}
    }

    for rag_type, rag_path in rag_paths.items():
        rag_info = {
            "path": rag_path,
            "exists": os.path.exists(rag_path),
            "is_directory": os.path.isdir(rag_path) if os.path.exists(rag_path) else False,
            "files": [],
            "file_sizes": {}
        }

        if rag_info["exists"] and rag_info["is_directory"]:
            try:
                files = os.listdir(rag_path)
                rag_info["files"] = sorted(files)
                rag_info["has_faiss"] = "index.faiss" in files
                rag_info["has_pkl"] = "index.pkl" in files
                rag_info["has_meta"] = "meta.json" in files
                rag_info["complete"] = rag_info["has_faiss"] and rag_info["has_pkl"]

                for file in files:
                    try:
                        file_path = os.path.join(rag_path, file)
                        size = os.path.getsize(file_path)
                        rag_info["file_sizes"][file] = f"{size / 1024 / 1024:.2f} MB"
                    except Exception:
                        rag_info["file_sizes"][file] = "unknown"

            except Exception as e:
                rag_info["error"] = str(e)

        filesystem_test["rags"][rag_type] = rag_info

    results["tests"]["filesystem"] = filesystem_test

    current_instances = {}
    for name, attr in [("global", "rag"), ("broiler", "rag_broiler"), ("layer", "rag_layer")]:
        embedder = getattr(app.state, attr, None)
        instance_info = {
            "exists": embedder is not None,
            "functional": False,
            "document_count": 0,
            "search_ready": False
        }

        if embedder:
            try:
                instance_info["functional"] = True
                instance_info["search_ready"] = embedder.has_search_engine()
                if hasattr(embedder, 'get_document_count'):
                    instance_info["document_count"] = embedder.get_document_count()
                elif hasattr(embedder, 'documents') and embedder.documents:
                    instance_info["document_count"] = len(embedder.documents)
            except Exception as e:
                instance_info["error"] = str(e)

        current_instances[name] = instance_info

    available_rags = sum(1 for info in filesystem_test["rags"].values() if info.get("complete", False))
    loaded_rags = sum(1 for info in current_instances.values() if info.get("functional", False))
    total_documents = sum(info.get("document_count", 0) for info in current_instances.values() if isinstance(info.get("document_count"), int))

    results["summary"] = {
        "available_on_disk": available_rags,
        "loaded_in_memory": loaded_rags,
        "total_documents": total_documents,
        "functional_rags": [name for name, info in current_instances.items() if info.get("search_ready", False)],
        "missing_rags": [name for name, info in filesystem_test["rags"].items() if not info.get("complete", False)],
        "recommendations": []
    }

    if available_rags == 3 and loaded_rags == 3:
        results["summary"]["recommendations"].append("üéâ PARFAIT: Les 3 RAG sont disponibles et charg√©s!")
    elif available_rags == 3 and loaded_rags < 3:
        results["summary"]["recommendations"].append(f"‚ö†Ô∏è 3 RAG disponibles mais seulement {loaded_rags} charg√©(s)")
    elif available_rags < 3:
        results["summary"]["recommendations"].append(f"‚åõ Seulement {available_rags}/3 RAG trouv√©s sur le disque")

    return results

# ========== HEALTH CHECK COMPLET AM√âLIOR√â AVEC CACHE (√âTENDU) ==========
@app.get("/health/complete", tags=["Health"])
async def complete_health_check():
    """ü•º Check de sant√© complet du syst√®me avec billing, analytics et cache"""
    try:
        health_status = {
            "timestamp": datetime.utcnow().isoformat(),
            "status": "healthy",
            "components": {}
        }
        
        # Check base de donn√©es et analytics
        try:
            from app.api.v1.logging import get_analytics_manager
            analytics = get_analytics_manager()
            health_status["components"]["analytics"] = {
                "status": "healthy",
                "type": "postgresql",
                "tables_created": True
            }
        except Exception as e:
            health_status["components"]["analytics"] = {
                "status": "unhealthy",
                "error": str(e)
            }
            health_status["status"] = "degraded"
        
        # Check syst√®me de facturation
        try:
            from app.api.v1.billing import get_billing_manager
            billing = get_billing_manager()
            health_status["components"]["billing"] = {
                "status": "healthy",
                "plans_loaded": len(billing.plans),
                "quota_enforcement": True
            }
        except Exception as e:
            health_status["components"]["billing"] = {
                "status": "unhealthy",
                "error": str(e)
            }
            health_status["status"] = "degraded"
        
        # üöÄ NOUVEAU: Check syst√®me de cache statistiques
        if STATS_CACHE_AVAILABLE:
            try:
                cache = get_stats_cache()
                cache_stats = cache.get_cache_stats()
                
                scheduler_active = stats_scheduler_task is not None and not stats_scheduler_task.done()
                cache_success_rate = 100
                if cache_update_counter + cache_error_counter > 0:
                    cache_success_rate = (cache_update_counter / (cache_update_counter + cache_error_counter)) * 100
                
                health_status["components"]["statistics_cache"] = {
                    "status": "healthy" if cache_stats and scheduler_active else "degraded",
                    "scheduler_active": scheduler_active,
                    "cache_updates": cache_update_counter,
                    "cache_errors": cache_error_counter,
                    "success_rate": round(cache_success_rate, 1),
                    "cache_entries": cache_stats
                }
            except Exception as e:
                health_status["components"]["statistics_cache"] = {
                    "status": "unhealthy",
                    "error": str(e)
                }
                health_status["status"] = "degraded"
        else:
            health_status["components"]["statistics_cache"] = {
                "status": "not_available",
                "message": "Module cache statistiques non import√©"
            }
        
        # Check RAG
        total_rags = sum(1 for rag in [
            getattr(app.state, "rag", None),
            getattr(app.state, "rag_broiler", None), 
            getattr(app.state, "rag_layer", None)
        ] if rag and hasattr(rag, 'has_search_engine') and rag.has_search_engine())
        
        health_status["components"]["rag"] = {
            "status": "healthy" if total_rags >= 2 else "degraded" if total_rags >= 1 else "unhealthy",
            "loaded_rags": total_rags,
            "total_rags": 3
        }
        
        # Check OpenAI (si configur√©)
        openai_key = os.getenv("OPENAI_API_KEY")
        health_status["components"]["openai"] = {
            "status": "configured" if openai_key else "not_configured"
        }
        
        # üî• NOUVEAU: Check OpenAI Billing API (CONSERV√â)
        try:
            from app.api.v1.billing_openai import get_openai_organization_id
            org_id = get_openai_organization_id()
            openai_billing_status = {
                "status": "configured" if (openai_key and org_id) else "partially_configured" if openai_key else "not_configured",
                "has_api_key": bool(openai_key),
                "has_org_id": bool(org_id)
            }
            health_status["components"]["openai_billing"] = openai_billing_status
        except Exception as e:
            health_status["components"]["openai_billing"] = {
                "status": "error",
                "error": str(e)
            }
        
        # ‚úÖ NOUVEAU: Check Auth system (CONSERV√â)
        try:
            jwt_secret = os.getenv("JWT_SECRET") or os.getenv("SUPABASE_JWT_SECRET")
            supabase_url = os.getenv("SUPABASE_URL") 
            supabase_key = os.getenv("SUPABASE_ANON_KEY")
            
            auth_status = "healthy"
            if not (jwt_secret and supabase_url and supabase_key):
                auth_status = "partially_configured"
            if not jwt_secret:
                auth_status = "not_configured"
                
            health_status["components"]["auth"] = {
                "status": auth_status,
                "has_jwt_secret": bool(jwt_secret),
                "has_supabase_config": bool(supabase_url and supabase_key),
                "routing_fixed": True  # ‚úÖ Apr√®s notre correction
            }
        except Exception as e:
            health_status["components"]["auth"] = {
                "status": "error",
                "error": str(e)
            }
        
        # M√©triques syst√®me (√âTENDUES)
        uptime_hours = (time.time() - start_time) / 3600
        health_status["metrics"] = {
            "uptime_hours": round(uptime_hours, 2),
            "total_requests": request_counter,
            "error_rate_percent": round((error_counter / max(request_counter, 1)) * 100, 2),
            "active_requests": active_requests,
            # üöÄ NOUVEAU: M√©triques cache
            "cache_updates": cache_update_counter,
            "cache_errors": cache_error_counter,
            "scheduler_active": stats_scheduler_task is not None and not stats_scheduler_task.done() if STATS_CACHE_AVAILABLE else False
        }
        
        # D√©terminer le statut global
        component_statuses = [comp["status"] for comp in health_status["components"].values() 
                            if comp["status"] in ["healthy", "degraded", "unhealthy"]]
        
        if any(status == "unhealthy" for status in component_statuses):
            health_status["status"] = "unhealthy"
        elif any(status == "degraded" for status in component_statuses):
            health_status["status"] = "degraded"
        
        return health_status
        
    except Exception as e:
        logger.error(f"‚åõ Erreur health check: {e}")
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "status": "error",
            "error": str(e)
        }

@app.get("/metrics", tags=["Monitoring"])
async def system_metrics():
    """üìä M√©triques syst√®me pour monitoring externe (√âTENDUES)"""
    try:
        uptime_seconds = time.time() - start_time
        
        base_metrics = {
            "uptime_seconds": uptime_seconds,
            "requests_total": request_counter,
            "errors_total": error_counter,
            "requests_active": active_requests,
            "error_rate": (error_counter / max(request_counter, 1)) * 100,
            "requests_per_second": request_counter / max(uptime_seconds, 1),
            "rag_status": {
                "global": bool(getattr(app.state, "rag", None)),
                "broiler": bool(getattr(app.state, "rag_broiler", None)),
                "layer": bool(getattr(app.state, "rag_layer", None))
            },
            "synthesis_enabled": synthesis_enabled,
            "auth_routing_fixed": True,  # ‚úÖ Flag pour confirmer la correction
            "cors_middleware_fixed": True,  # ‚úÖ NOUVEAU FLAG CORS
            "direct_auth_endpoints": True,  # ‚úÖ NOUVEAU FLAG AUTH DIRECT
            "cors_credentials_fixed": True,  # üîß NOUVEAU FLAG CORS CREDENTIALS
            "stats_admin_router_fixed": True,  # üéØ NOUVEAU FLAG STATS ADMIN
        }
        
        # üöÄ NOUVEAU: Ajouter m√©triques cache si disponible
        if STATS_CACHE_AVAILABLE:
            base_metrics.update({
                "cache_system_enabled": True,
                "cache_updates_total": cache_update_counter,
                "cache_errors_total": cache_error_counter,
                "cache_success_rate": (cache_update_counter / max(cache_update_counter + cache_error_counter, 1)) * 100,
                "scheduler_active": stats_scheduler_task is not None and not stats_scheduler_task.done()
            })
        else:
            base_metrics["cache_system_enabled"] = False
        
        return base_metrics
        
    except Exception as e:
        return {"error": str(e)}

# ========== NOUVEAU ENDPOINT DE STATISTIQUES ADMIN √âTENDU ==========
@app.get("/admin/stats", tags=["Admin"])
async def admin_statistics():
    """üìà Statistiques administrateur compl√®tes avec cache"""
    try:
        from app.api.v1.billing import get_billing_manager
        from app.api.v1.logging import get_analytics_manager
        
        # Stats billing
        billing = get_billing_manager()
        
        # Stats analytics (approximatives - √† adapter selon les besoins)
        uptime_hours = (time.time() - start_time) / 3600
        
        base_stats = {
            "system_health": {
                "uptime_hours": round(uptime_hours, 2),
                "total_requests": request_counter,
                "error_rate": round((error_counter / max(request_counter, 1)) * 100, 2),
                "rag_status": {
                    "global": bool(getattr(app.state, "rag", None)),
                    "broiler": bool(getattr(app.state, "rag_broiler", None)),
                    "layer": bool(getattr(app.state, "rag_layer", None))
                }
            },
            "billing_stats": {
                "plans_available": len(billing.plans),
                "plan_names": list(billing.plans.keys())
            },
            "features_enabled": {
                "analytics": bool(os.getenv("DATABASE_URL")),
                "billing": True,
                "authentication": bool(os.getenv("JWT_SECRET") or os.getenv("SUPABASE_JWT_SECRET")),
                "openai_fallback": bool(os.getenv("OPENAI_API_KEY")),
                "openai_billing_api": bool(os.getenv("OPENAI_API_KEY") and os.getenv("OPENAI_ORG_ID")),
                "auth_routing_fixed": True,  # ‚úÖ NOUVEAU
                "cors_middleware_fixed": True,  # ‚úÖ NOUVEAU FLAG CORS
                "direct_auth_endpoints": True,  # ‚úÖ NOUVEAU FLAG AUTH DIRECT
                "cors_credentials_fixed": True,  # üîß NOUVEAU FLAG CORS CREDENTIALS
                "statistics_cache_system": STATS_CACHE_AVAILABLE,  # üöÄ NOUVEAU
                "stats_admin_router_enabled": True,  # üéØ NOUVEAU FLAG STATS ADMIN
            }
        }
        
        # üöÄ NOUVEAU: Ajouter stats cache si disponible
        if STATS_CACHE_AVAILABLE:
            try:
                cache = get_stats_cache()
                cache_stats = cache.get_cache_stats()
                
                base_stats["cache_system"] = {
                    "enabled": True,
                    "scheduler_active": stats_scheduler_task is not None and not stats_scheduler_task.done(),
                    "updates_total": cache_update_counter,
                    "errors_total": cache_error_counter,
                    "success_rate": round((cache_update_counter / max(cache_update_counter + cache_error_counter, 1)) * 100, 1),
                    "cache_statistics": cache_stats
                }
            except Exception as e:
                base_stats["cache_system"] = {
                    "enabled": True,
                    "status": "error",
                    "error": str(e)
                }
        else:
            base_stats["cache_system"] = {
                "enabled": False,
                "reason": "Module non import√©"
            }
        
        return base_stats
        
    except Exception as e:
        return {"error": str(e)}

# üöÄ NOUVEAU: Endpoint pour contr√¥le manuel du cache
@app.post("/admin/cache/force-update", tags=["Admin"])
async def admin_force_cache_update():
    """üîÑ Force une mise √† jour manuelle du cache (admin)"""
    if not STATS_CACHE_AVAILABLE:
        return {
            "status": "unavailable",
            "message": "Syst√®me de cache non disponible"
        }
    
    try:
        logger.info("üîÑ Force update cache demand√© via admin endpoint")
        result = await force_update_all()
        
        global cache_update_counter, cache_error_counter
        if result.get("status") == "completed":
            cache_update_counter += 1
        else:
            cache_error_counter += 1
        
        return {
            "status": "success",
            "message": "Mise √† jour cache forc√©e",
            "result": result,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        cache_error_counter += 1
        logger.error(f"‚ùå Erreur force update admin: {e}")
        return {
            "status": "error",
            "message": f"Erreur mise √† jour: {e}",
            "timestamp": datetime.utcnow().isoformat()
        }

@app.get("/admin/cache/status", tags=["Admin"])
async def admin_cache_status():
    """üìä Statut d√©taill√© du syst√®me de cache (admin)"""
    if not STATS_CACHE_AVAILABLE:
        return {
            "status": "unavailable",
            "message": "Syst√®me de cache non disponible",
            "enabled": False
        }
    
    try:
        cache = get_stats_cache()
        updater = get_stats_updater()
        
        cache_stats = cache.get_cache_stats()
        update_status = updater.get_update_status()
        
        return {
            "status": "available",
            "enabled": True,
            "scheduler": {
                "active": stats_scheduler_task is not None and not stats_scheduler_task.done(),
                "task_done": stats_scheduler_task.done() if stats_scheduler_task else True
            },
            "counters": {
                "updates_successful": cache_update_counter,
                "updates_failed": cache_error_counter,
                "success_rate": round((cache_update_counter / max(cache_update_counter + cache_error_counter, 1)) * 100, 1)
            },
            "cache_statistics": cache_stats,
            "last_update": update_status,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        return {
            "status": "error",
            "message": str(e),
            "enabled": True
        }

# ===============================================================================
# ROUTER AUTH DIRECT - CONTOURNEMENT DU PROBL√àME DE MONTAGE (CONSERV√â)
# ===============================================================================

# ‚úÖ ENDPOINTS AUTH DIRECTS - √âvite le probl√®me de montage du router (CONSERV√âS INT√âGRALEMENT)
@app.post("/v1/auth/login")
async def auth_login_direct(request: Request):
    """Endpoint login direct - contournement du probl√®me de router"""
    try:
        # Importer la logique auth existante
        from app.api.v1.auth import LoginRequest, create_access_token
        
        # Lire le body de la requ√™te
        body = await request.json()
        login_data = LoginRequest(**body)
        
        # Authentification Supabase
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_ANON_KEY")
        
        if not supabase_url or not supabase_key:
            return JSONResponse(
                status_code=500,
                content={"detail": "Authentication service unavailable"}
            )
        
        try:
            from supabase import create_client
            supabase = create_client(supabase_url, supabase_key)
            
            # üîß CORRECTION API SUPABASE - Nouvelle m√©thode
            result = supabase.auth.sign_in_with_password({
                "email": login_data.email,
                "password": login_data.password
            })
            
        except Exception as e:
            return JSONResponse(
                status_code=401,
                content={"detail": "Invalid credentials", "error": str(e)}
            )
        
        user = result.user
        if user is None:
            return JSONResponse(
                status_code=401,
                content={"detail": "Invalid credentials"}
            )
        
        # Cr√©er le token
        from datetime import timedelta
        expires = timedelta(minutes=60)
        token = create_access_token(
            {"user_id": user.id, "email": login_data.email}, 
            expires
        )
        
        return {
            "access_token": token,
            "token_type": "bearer",
            "expires_at": (datetime.utcnow() + expires).isoformat(),
            "user": {
                "id": user.id,
                "email": user.email,
                "user_metadata": user.user_metadata
            }
        }
        
    except Exception as e:
        logger.error(f"‚åõ Erreur login direct: {e}")
        return JSONResponse(
            status_code=500,
            content={"detail": "Login failed", "error": str(e)}
        )

@app.get("/v1/auth/debug/jwt-config")
async def auth_debug_direct():
    """Endpoint debug JWT direct - contournement du probl√®me de router"""
    return {
        "supabase_jwt_secret_configured": bool(os.getenv("SUPABASE_JWT_SECRET")),
        "supabase_anon_key_configured": bool(os.getenv("SUPABASE_ANON_KEY")),
        "supabase_service_key_configured": bool(os.getenv("SUPABASE_SERVICE_KEY")),
        "jwt_algorithm": "HS256",
        "direct_endpoint": True,
        "bypassed_router_issue": True,
        "api_corrected": True,  # üîß NOUVEAU FLAG
        "routing_fixed": True,   # üîß NOUVEAU FLAG
        "cors_credentials_fixed": True,  # üîß NOUVEAU FLAG CORS CREDENTIALS
        "cache_system_enabled": STATS_CACHE_AVAILABLE,  # üöÄ NOUVEAU
        "stats_admin_router_enabled": True,  # üéØ NOUVEAU FLAG STATS ADMIN
        "secrets_available": [
            name for name, value in [
                ("SUPABASE_JWT_SECRET", os.getenv("SUPABASE_JWT_SECRET")),
                ("SUPABASE_ANON_KEY", os.getenv("SUPABASE_ANON_KEY")),
                ("SUPABASE_SERVICE_KEY", os.getenv("SUPABASE_SERVICE_KEY")),
            ] if value
        ]
    }

@app.get("/v1/auth/me")
async def auth_me_direct(request: Request):
    """Endpoint me direct - contournement du probl√®me de router"""
    try:
        # Importer la logique auth existante
        from app.api.v1.auth import get_current_user
        from fastapi.security import HTTPAuthorizationCredentials
        
        # Extraire le token
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return JSONResponse(
                status_code=401,
                content={"detail": "Missing or invalid authorization header"}
            )
        
        credentials = HTTPAuthorizationCredentials(
            scheme="Bearer",
            credentials=auth_header.replace("Bearer ", "")
        )
        
        # Utiliser la fonction existante
        user_info = await get_current_user(credentials)
        
        return {
            "user_id": user_info.get("user_id"),
            "email": user_info.get("email"),
            "user_type": user_info.get("user_type"),
            "full_name": user_info.get("full_name"),
            "is_admin": user_info.get("is_admin"),
            "preferences": user_info.get("preferences", {}),
            "profile_id": user_info.get("profile_id"),
            "direct_endpoint": True,
            "routing_corrected": True  # üîß NOUVEAU FLAG
        }
        
    except Exception as e:
        logger.error(f"‚åõ Erreur me direct: {e}")
        return JSONResponse(
            status_code=401,
            content={"detail": "Authentication failed", "error": str(e)}
        )

@app.post("/v1/auth/delete-data")
async def auth_delete_data_direct(request: Request):
    """Endpoint delete data direct - contournement du probl√®me de router"""
    try:
        # Importer la logique auth existante
        from app.api.v1.auth import get_current_user
        from fastapi.security import HTTPAuthorizationCredentials
        
        # Extraire le token
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return JSONResponse(
                status_code=401,
                content={"detail": "Missing or invalid authorization header"}
            )
        
        credentials = HTTPAuthorizationCredentials(
            scheme="Bearer",
            credentials=auth_header.replace("Bearer ", "")
        )
        
        # Utiliser la fonction existante
        user_info = await get_current_user(credentials)
        
        user_id = user_info["user_id"]
        user_email = user_info["email"]
        logger.info("GDPR deletion requested for %s (%s)", user_email, user_id)
        
        return {
            "success": True,
            "message": "Demande de suppression enregistr√©e",
            "note": "Vos donn√©es seront supprim√©es sous 30 jours",
            "timestamp": datetime.utcnow().isoformat(),
            "direct_endpoint": True,
            "routing_corrected": True  # üîß NOUVEAU FLAG
        }
        
    except Exception as e:
        logger.error(f"‚åõ Erreur delete data direct: {e}")
        return JSONResponse(
            status_code=401,
            content={"detail": "Authentication failed", "error": str(e)}
        )

@app.get("/v1/auth/test-direct")
async def auth_test_direct():
    """Test pour confirmer que les endpoints directs fonctionnent"""
    return {
        "message": "Auth endpoints directs fonctionnent",
        "status": "success",
        "available_endpoints": [
            "POST /api/v1/auth/login",  # Maintenant /api/v1/ au lieu de /api/api/v1/
            "GET /api/v1/auth/debug/jwt-config", 
            "GET /api/v1/auth/me",
            "POST /api/v1/auth/delete-data",
            "GET /api/v1/auth/test-direct"
        ],
        "catch_22_resolved": True,
        "routing_fixed": True,  # üîß NOUVEAU FLAG
        "cors_credentials_fixed": True,  # üîß NOUVEAU FLAG CORS CREDENTIALS
        "cache_system_available": STATS_CACHE_AVAILABLE,  # üöÄ NOUVEAU
        "stats_admin_router_enabled": True,  # üéØ NOUVEAU FLAG STATS ADMIN
        "solution": "direct_endpoints_bypass",
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/cors-test", tags=["Debug"])
async def cors_test_fixed(request: Request):
    """Test pour v√©rifier que CORS fonctionne"""
    return {
        "message": "CORS test fixed successful",
        "origin": request.headers.get("Origin"),
        "timestamp": datetime.utcnow().isoformat(),
        "cors_fixed": True,
        "cors_credentials_fixed": True,  # üîß NOUVEAU FLAG CORS CREDENTIALS
        "cache_system_available": STATS_CACHE_AVAILABLE,  # üöÄ NOUVEAU
        "stats_admin_router_enabled": True  # üéØ NOUVEAU FLAG STATS ADMIN
    }

@app.get("/", tags=["Root"])
async def root():
    def rag_status() -> str:
        total_rags = sum(1 for rag in [
            getattr(app.state, "rag", None),
            getattr(app.state, "rag_broiler", None),
            getattr(app.state, "rag_layer", None)
        ] if rag and hasattr(rag, 'has_search_engine') and rag.has_search_engine())

        if total_rags == 3:
            return "optimal_3_rags"
        elif total_rags == 1:
            return "suboptimal_1_rag"
        else:
            return f"partial_{total_rags}_rags"

    # Calculer l'uptime
    uptime_hours = (time.time() - start_time) / 3600
    
    # üöÄ NOUVEAU: Statut cache
    cache_status = "not_available"
    if STATS_CACHE_AVAILABLE:
        if stats_scheduler_task and not stats_scheduler_task.done():
            cache_status = "active"
        else:
            cache_status = "available_but_inactive"
    
    return {
        "status": "running",
        "version": "4.0.0",  # üöÄ NOUVEAU: Version mise √† jour
        "environment": os.getenv("ENV", "production"),
        "database": bool(getattr(app.state, "supabase", None)),
        "postgresql": bool(os.getenv("DATABASE_URL")),
        "rag": rag_status(),
        "synthesis_enabled": synthesis_enabled,
        "cors_fix": "applied_v3_credentials",  # üîß NOUVEAU
        "optimization": "three_rag_system_enabled",
        "auth_routing_fix": "applied",  # ‚úÖ NOUVEAU FLAG
        "catch_22_resolved": True,      # ‚úÖ NOUVEAU FLAG
        "cors_middleware_fixed": True,  # ‚úÖ NOUVEAU FLAG CORS
        "direct_auth_endpoints": True,  # ‚úÖ NOUVEAU FLAG AUTH DIRECT
        "cors_credentials_fixed": True,  # üîß NOUVEAU FLAG CORS CREDENTIALS
        "statistics_cache_system": cache_status,  # üöÄ NOUVEAU
        "stats_admin_router_enabled": True,  # üéØ NOUVEAU FLAG STATS ADMIN
        "new_features": {
            "billing_system": True,
            "analytics_tracking": True,
            "quota_enforcement": True,
            "multilingual_support": True,
            "openai_fallback": True,
            "performance_monitoring": True,
            "server_metrics_logging": True,
            "cost_tracking": True,
            "user_behavior_analytics": True,
            "real_time_quota_limits": True,
            "automated_invoicing": True,
            "openai_billing_integration": True,
            "auth_routing_fixed": True,  # ‚úÖ NOUVEAU
            "cors_middleware_fixed": True,  # ‚úÖ NOUVEAU FLAG CORS
            "direct_auth_endpoints": True,  # ‚úÖ NOUVEAU FLAG AUTH DIRECT
            "cors_credentials_support": True,  # üîß NOUVEAU FLAG CORS CREDENTIALS
            "statistics_cache_optimized": STATS_CACHE_AVAILABLE,  # üöÄ NOUVEAU
            "hourly_cache_updates": STATS_CACHE_AVAILABLE,  # üöÄ NOUVEAU
            "ultra_fast_endpoints": STATS_CACHE_AVAILABLE,  # üöÄ NOUVEAU
            "stats_admin_management": True,  # üéØ NOUVEAU FLAG STATS ADMIN
        },
        "uptime_hours": round(uptime_hours, 2),
        "requests_processed": request_counter,
        "cache_updates": cache_update_counter if STATS_CACHE_AVAILABLE else 0,  # üöÄ NOUVEAU
        "last_update": "2025-08-23T02:45:00Z",  # üöÄ NOUVEAU: Updated timestamp
        "deployment_version": "v4.0.0-with-stats-admin-fixed"  # üöÄ NOUVEAU: Updated version
    }

# ===============================================================================
# ENDPOINTS AUTH TEMPORAIRES - SOLUTION GARANTIE (CONSERV√âS)
# ===============================================================================

@app.post("/auth-temp/login")
async def temp_auth_login(request: Request):
    """Endpoint auth temporaire - garantit de fonctionner"""
    try:
        # Lire le body de la requ√™te
        body = await request.json()
        email = body.get("email")
        password = body.get("password")
        
        if not email or not password:
            return JSONResponse(
                status_code=400,
                content={"detail": "Email and password required"}
            )
        
        # Authentification Supabase
        supabase_url = os.getenv("SUPABASE_URL")
        supabase_key = os.getenv("SUPABASE_ANON_KEY")
        
        if not supabase_url or not supabase_key:
            return JSONResponse(
                status_code=500,
                content={"detail": "Authentication service unavailable"}
            )
        
        try:
            from supabase import create_client
            supabase = create_client(supabase_url, supabase_key)
            
            # Essayer la nouvelle API d'abord
            try:
                result = supabase.auth.sign_in_with_password({
                    "email": email,
                    "password": password
                })
            except AttributeError:
                # Fallback pour ancienne API
                result = supabase.auth.sign_in(email=email, password=password)
            
        except Exception as e:
            return JSONResponse(
                status_code=401,
                content={"detail": "Invalid credentials", "error": str(e)}
            )
        
        user = result.user
        if user is None:
            return JSONResponse(
                status_code=401,
                content={"detail": "Invalid credentials"}
            )
        
        # Cr√©er un token simple (ou utiliser Supabase session)
        from datetime import timedelta
        import jwt
        
        jwt_secret = os.getenv("SUPABASE_JWT_SECRET") or os.getenv("JWT_SECRET") or "fallback-secret"
        expires = timedelta(minutes=60)
        
        token_payload = {
            "user_id": user.id,
            "email": email,
            "exp": datetime.utcnow() + expires
        }
        
        token = jwt.encode(token_payload, jwt_secret, algorithm="HS256")
        
        return {
            "access_token": token,
            "token_type": "bearer",
            "expires_at": (datetime.utcnow() + expires).isoformat(),
            "user": {
                "id": user.id,
                "email": user.email,
                "user_metadata": getattr(user, 'user_metadata', {})
            },
            "endpoint": "temp_auth_login",
            "api_version": "compatible"
        }
        
    except Exception as e:
        logger.error(f"‚åõ Erreur temp login: {e}")
        return JSONResponse(
            status_code=500,
            content={"detail": "Login failed", "error": str(e)}
        )

@app.get("/auth-temp/me")
async def temp_auth_me(request: Request):
    """Endpoint me temporaire - garantit de fonctionner"""
    try:
        # Extraire le token
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            return JSONResponse(
                status_code=401,
                content={"detail": "Missing or invalid authorization header"}
            )
        
        token = auth_header.replace("Bearer ", "")
        
        # D√©coder le token
        import jwt
        jwt_secret = os.getenv("SUPABASE_JWT_SECRET") or os.getenv("JWT_SECRET") or "fallback-secret"
        
        try:
            payload = jwt.decode(token, jwt_secret, algorithms=["HS256"])
        except jwt.ExpiredSignatureError:
            return JSONResponse(
                status_code=401,
                content={"detail": "Token expired"}
            )
        except jwt.InvalidTokenError:
            return JSONResponse(
                status_code=401,
                content={"detail": "Invalid token"}
            )
        
        return {
            "user_id": payload.get("user_id"),
            "email": payload.get("email"),
            "authenticated": True,
            "endpoint": "temp_auth_me",
            "token_valid": True
        }
        
    except Exception as e:
        logger.error(f"‚åõ Erreur temp me: {e}")
        return JSONResponse(
            status_code=401,
            content={"detail": "Authentication failed", "error": str(e)}
        )

@app.get("/auth-temp/test")
async def temp_auth_test():
    """Test pour confirmer que les endpoints temporaires fonctionnent"""
    return {
        "message": "Endpoints auth temporaires fonctionnent",
        "status": "success",
        "available_endpoints": [
            "POST /api/auth-temp/login",
            "GET /api/auth-temp/me",
            "GET /api/auth-temp/test"
        ],
        "deployment_confirmed": True,
        "timestamp": datetime.utcnow().isoformat(),
        "version": "temp-auth-v1",
        "cors_credentials_fixed": True,  # üîß NOUVEAU FLAG CORS CREDENTIALS
        "cache_system_available": STATS_CACHE_AVAILABLE,  # üöÄ NOUVEAU
        "stats_admin_router_enabled": True  # üéØ NOUVEAU FLAG STATS ADMIN
    }

@app.get("/deployment-debug")
async def deployment_debug():
    """üîß DEBUG - Confirmer que cette version est d√©ploy√©e"""
    return {
        "deployment_status": "SUCCESS",
        "version": "4.0.0-with-stats-admin-fixed",  # üéØ UPDATED
        "timestamp": datetime.utcnow().isoformat(),
        "last_update": "2025-08-23T02:45:00Z",  # üéØ UPDATED
        "cors_status": "FIXED_CREDENTIALS",  # üîß UPDATED
        "auth_endpoints": {
            "v1_direct": "UPDATED",
            "temp_endpoints": "ADDED",
            "routing_fixed": True
        },
        "cors_fixes": {
            "wildcard_removed": True,
            "credentials_support": True,
            "specific_origins_only": True
        },
        "new_systems": {  # üöÄ NOUVEAU
            "statistics_cache": {
                "enabled": STATS_CACHE_AVAILABLE,
                "scheduler_active": stats_scheduler_task is not None and not stats_scheduler_task.done() if STATS_CACHE_AVAILABLE else False,
                "cache_updates": cache_update_counter,
                "cache_errors": cache_error_counter
            },
            "ultra_fast_endpoints": STATS_CACHE_AVAILABLE,
            "admin_cache_control": STATS_CACHE_AVAILABLE,
            "stats_admin_router": True  # üéØ NOUVEAU
        },
        "fixes_applied": {  # üéØ NOUVEAU
            "stats_admin_router_mounted": True,
            "endpoints_now_available": [
                "POST /api/v1/stats-admin/force-update/all",
                "GET /api/v1/stats-admin/status",
                "GET /api/v1/stats-admin/cache/keys",
                "POST /api/v1/stats-admin/debug/test-components"
            ]
        },
        "confirmation": "Cette version contient TOUTES les corrections CORS + Auth + Cache + STATS-ADMIN",
        "next_test": "L'endpoint POST /api/v1/stats-admin/force-update/all devrait maintenant retourner 200 au lieu de 404"
    }

# Exception handlers (CONSERV√âS INT√âGRALEMENT MAIS AVEC CORS CORRIG√â)
@app.exception_handler(HTTPException)
async def http_exc_handler(request: Request, exc: HTTPException):
    response = JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail, "timestamp": datetime.utcnow().isoformat() + "Z"},
        headers={"content-type": "application/json; charset=utf-8"},
    )

    origin = request.headers.get("Origin")
    
    # üîß CORS CORRIG√â - Pas de wildcard avec credentials
    allowed_origins = [
        "https://expert.intelia.com",
        "https://expert-app-cngws.ondigitalocean.app",
        "http://localhost:3000",
        "http://localhost:8080"
    ]
    
    if origin and origin in allowed_origins:
        response.headers["Access-Control-Allow-Origin"] = origin
        response.headers["Access-Control-Allow-Credentials"] = "true"
    else:
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Credentials"] = "false"
    
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Session-ID"

    return response

@app.exception_handler(Exception)
async def generic_exc_handler(request: Request, exc: Exception):
    logger.exception("Unhandled: %s", exc)

    response = JSONResponse(
        status_code=500,
        content={"detail": "Internal server error", "timestamp": datetime.utcnow().isoformat() + "Z"},
        headers={"content-type": "application/json; charset=utf-8"},
    )

    origin = request.headers.get("Origin")
    
    # üîß CORS CORRIG√â - Pas de wildcard avec credentials
    allowed_origins = [
        "https://expert.intelia.com",
        "https://expert-app-cngws.ondigitalocean.app",
        "http://localhost:3000",
        "http://localhost:8080"
    ]
    
    if origin and origin in allowed_origins:
        response.headers["Access-Control-Allow-Origin"] = origin
        response.headers["Access-Control-Allow-Credentials"] = "true"
    else:
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Credentials"] = "false"
    
    response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS, PATCH"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, X-Session-ID"

    return response

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host=os.getenv("HOST", "0.0.0.0"), port=int(os.getenv("PORT", "8000")))