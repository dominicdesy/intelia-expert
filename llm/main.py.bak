# -*- coding: utf-8 -*-
"""
main.py - Intelia Expert Backend avec RAG Enhanced + LangSmith + RRF Intelligent
Version CORRIGÃ‰E: RÃ©solution des problÃ¨mes critiques de sÃ©rialisation JSON et erreurs internes
CORRECTIONS APPLIQUÃ‰ES:
- FIX: SÃ©rialisation JSON robuste avec conversion des enums
- FIX: Gestion d'erreurs robuste pour le RAG Engine
- FIX: Validation stricte des types pour Ã©viter les erreurs 'str' object has no attribute 'get'
- FIX: Health check sÃ©curisÃ© avec fallbacks
- FIX: Endpoints de diagnostic amÃ©liorÃ©s
"""

import os
import json
import asyncio
import time
import logging
import uuid
import tracemalloc
from typing import Any, Dict, AsyncGenerator, Optional, Union
from collections import OrderedDict
from contextlib import asynccontextmanager
from enum import Enum

# CORRECTION: Activation de tracemalloc pour diagnostic
tracemalloc.start()

from fastapi import FastAPI, APIRouter, Request, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

# Import du systÃ¨me de dÃ©pendances corrigÃ©
from imports_and_dependencies import (
    dependency_manager, 
    require_critical_dependencies,
    get_full_status_report,
    quick_connectivity_check,
    OPENAI_AVAILABLE,
    WEAVIATE_AVAILABLE
)

# === NOUVEAU: Imports configuration enrichie ===
from config import (
    # Core
    RAG_ENABLED, CACHE_ENABLED, OPENAI_API_KEY, WEAVIATE_URL, REDIS_URL,
    # LangSmith
    LANGSMITH_ENABLED, LANGSMITH_API_KEY, LANGSMITH_PROJECT,
    # RRF Intelligent
    ENABLE_INTELLIGENT_RRF, RRF_LEARNING_MODE, RRF_GENETIC_BOOST,
    # Autres
    MAX_CONVERSATION_CONTEXT, HYBRID_SEARCH_ENABLED,
    validate_config, get_config_status
)

# Configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
load_dotenv()

# Validation critique au dÃ©marrage
if not OPENAI_AVAILABLE:
    raise RuntimeError("OpenAI non disponible - dÃ©pendance critique manquante")

if not WEAVIATE_AVAILABLE:
    raise RuntimeError("Weaviate non disponible - dÃ©pendance critique manquante")

# === NOUVEAU: Validation configuration enrichie ===
config_valid, config_errors = validate_config()
if not config_valid:
    logger.error(f"Configuration invalide: {config_errors}")
    # En production, on peut continuer avec warnings
    for error in config_errors:
        logger.warning(f"Config: {error}")

# Variables globales pour les services
rag_engine_enhanced = None
agent_rag_engine = None
cache_core = None

# Configuration d'application
BASE_PATH = os.environ.get("BASE_PATH", "/llm").rstrip("/")

# Validation configuration critique
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY is required")

# ParamÃ¨tres systÃ¨me
STREAM_CHUNK_LEN = int(os.environ.get("STREAM_CHUNK_LEN", "400"))
MAX_REQUEST_SIZE = int(os.getenv("MAX_REQUEST_SIZE", "10000"))
MAX_TENANTS = int(os.getenv("MAX_TENANTS", "200"))
TENANT_TTL = int(os.getenv("TENANT_TTL_SEC", "86400"))

# Configuration CORS
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "https://expert.intelia.com").split(",")

# ParamÃ¨tres fonctionnalitÃ©s
ENABLE_RESPONSE_STREAMING = os.getenv("ENABLE_RESPONSE_STREAMING", "true").lower() == "true"
ENABLE_METRICS_LOGGING = os.getenv("ENABLE_METRICS_LOGGING", "true").lower() == "true"

# ParamÃ¨tres RAG Enhanced
USE_AGENT_RAG = os.getenv("USE_AGENT_RAG", "false").lower() == "true"
PREFER_ENHANCED_RAG = os.getenv("PREFER_ENHANCED_RAG", "true").lower() == "true"

# ParamÃ¨tres debug et monitoring
ENABLE_SEMANTIC_DEBUG = os.getenv("ENABLE_SEMANTIC_DEBUG", "true").lower() == "true"
ENABLE_STARTUP_VALIDATION = os.getenv("ENABLE_STARTUP_VALIDATION", "true").lower() == "true"
ENABLE_HEALTH_MONITORING = os.getenv("ENABLE_HEALTH_MONITORING", "true").lower() == "true"
STARTUP_TIMEOUT = int(os.getenv("STARTUP_TIMEOUT", "30"))

# === NOUVEAU: ParamÃ¨tres Digital Ocean ===
DO_APP_NAME = os.getenv("DO_APP_NAME", "intelia-expert")
DO_APP_TIER = os.getenv("DO_APP_TIER", "basic")

# ParamÃ¨tres langue
LANG_DETECTION_MIN_LENGTH = int(os.getenv("LANG_DETECTION_MIN_LENGTH", "20"))

logger.info(f"Mode RAG Enhanced: LangSmith + RRF Intelligent v4.0")
logger.info(f"Configuration: LangSmith={LANGSMITH_ENABLED}, RRF={ENABLE_INTELLIGENT_RRF}")

# === CORRECTION: Utilitaires de sÃ©rialisation JSON ===
def safe_serialize_for_json(obj: Any) -> Any:
    """Convertit rÃ©cursivement les objets en types JSON-safe"""
    if obj is None:
        return None
    elif isinstance(obj, (str, int, float, bool)):
        return obj
    elif isinstance(obj, Enum):
        return obj.value  # FIX: Conversion des enums
    elif isinstance(obj, dict):
        return {k: safe_serialize_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [safe_serialize_for_json(item) for item in obj]
    elif hasattr(obj, '__dict__'):
        return safe_serialize_for_json(obj.__dict__)
    else:
        return str(obj)  # Fallback pour types inconnus

def safe_get_attribute(obj: Any, attr: str, default: Any = None) -> Any:
    """RÃ©cupÃ©ration sÃ©curisÃ©e d'attributs avec validation de type"""
    try:
        if obj is None:
            return default
        
        if isinstance(obj, dict):
            return obj.get(attr, default)
        elif hasattr(obj, attr):
            return getattr(obj, attr, default)
        else:
            return default
    except Exception as e:
        logger.debug(f"Erreur rÃ©cupÃ©ration attribut {attr}: {e}")
        return default

def safe_dict_get(obj: Any, key: str, default: Any = None) -> Any:
    """Version sÃ©curisÃ©e de dict.get() qui Ã©vite les erreurs sur les strings"""
    try:
        if isinstance(obj, dict):
            return obj.get(key, default)
        else:
            logger.debug(f"Tentative d'appel .get() sur type {type(obj)}: {str(obj)[:100]}")
            return default
    except Exception as e:
        logger.debug(f"Erreur safe_dict_get pour {key}: {e}")
        return default

class StartupValidationError(Exception):
    """Exception pour les erreurs de validation au dÃ©marrage"""
    pass

class SystemHealthMonitor:
    """Moniteur de santÃ© systÃ¨me robuste avec LangSmith et RRF"""
    
    def __init__(self):
        self.startup_time = time.time()
        self.last_health_check = 0.0
        self.health_status = "initializing"
        self.component_status = {}
        self.validation_report = {}
    
    async def validate_startup_requirements(self) -> Dict[str, Any]:
        """Valide tous les prÃ©requis au dÃ©marrage avec gestion d'erreurs stricte"""
        validation_report = {
            "timestamp": time.time(),
            "startup_duration": 0.0,
            "critical_dependencies": {},
            "service_connectivity": {},
            "configuration_validation": {},
            "langsmith_validation": {},
            "rrf_validation": {},
            "overall_status": "unknown",
            "errors": [],
            "warnings": []
        }
        
        start_time = time.time()
        
        try:
            # 1. Validation des dÃ©pendances critiques
            logger.info("Validation des dÃ©pendances critiques...")
            
            try:
                require_critical_dependencies()
                dependency_status = get_full_status_report()
                validation_report["critical_dependencies"] = dependency_status
                
                if not dependency_status["critical_dependencies_ok"]:
                    raise StartupValidationError(
                        f"DÃ©pendances critiques manquantes: {dependency_status['critical_missing']}"
                    )
                
                logger.info("âœ… DÃ©pendances critiques validÃ©es")
                
            except Exception as e:
                validation_report["errors"].append(f"DÃ©pendances critiques: {e}")
                raise StartupValidationError(f"Validation dÃ©pendances Ã©chouÃ©e: {e}")
            
            # 2. Validation de la configuration OpenAI
            logger.info("Validation configuration OpenAI...")
            
            if not OPENAI_API_KEY:
                raise StartupValidationError("OPENAI_API_KEY non configurÃ©e")
            
            try:
                from openai import AsyncOpenAI
                test_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
                
                # Test simple avec timeout
                await asyncio.wait_for(
                    test_client.models.list(),
                    timeout=10.0
                )
                validation_report["configuration_validation"]["openai"] = "ok"
                logger.info("âœ… Configuration OpenAI validÃ©e")
                
            except Exception as e:
                validation_report["errors"].append(f"OpenAI: {e}")
                raise StartupValidationError(f"Configuration OpenAI invalide: {e}")
            
            # === NOUVEAU: 3. Validation LangSmith ===
            logger.info("Validation configuration LangSmith...")
            
            if LANGSMITH_ENABLED:
                if not LANGSMITH_API_KEY:
                    validation_report["warnings"].append("LangSmith activÃ© mais API key manquante")
                    validation_report["langsmith_validation"]["status"] = "disabled"
                else:
                    try:
                        # Test basique LangSmith
                        validation_report["langsmith_validation"] = {
                            "enabled": True,
                            "api_key_present": bool(LANGSMITH_API_KEY),
                            "project": LANGSMITH_PROJECT,
                            "status": "configured"
                        }
                        logger.info("âœ… LangSmith configurÃ©")
                    except Exception as e:
                        validation_report["warnings"].append(f"LangSmith: {e}")
                        validation_report["langsmith_validation"]["status"] = "error"
            else:
                validation_report["langsmith_validation"]["status"] = "disabled"
            
            # === NOUVEAU: 4. Validation RRF Intelligent ===
            logger.info("Validation RRF Intelligent...")
            
            if ENABLE_INTELLIGENT_RRF:
                validation_report["rrf_validation"] = {
                    "enabled": True,
                    "learning_mode": RRF_LEARNING_MODE,
                    "genetic_boost": RRF_GENETIC_BOOST,
                    "redis_required": True,
                    "status": "configured"
                }
                logger.info("âœ… RRF Intelligent configurÃ©")
            else:
                validation_report["rrf_validation"]["status"] = "disabled"
            
            # 5. Initialisation des services principaux
            logger.info("Initialisation des services...")
            
            service_errors = await self._initialize_core_services()
            if service_errors:
                validation_report["errors"].extend(service_errors)
                raise StartupValidationError(f"Ã‰chec initialisation services: {service_errors}")
            
            # 6. Tests de connectivitÃ©
            logger.info("Tests de connectivitÃ©...")
            
            connectivity_status = await self._test_service_connectivity()
            validation_report["service_connectivity"] = connectivity_status
            
            # VÃ©rification connectivitÃ© critique - CORRIGÃ‰E
            if not connectivity_status.get("weaviate", False):
                # NOUVEAU: Ne pas ajouter le warning si le RAG est initialisÃ© avec un client Weaviate
                if not (rag_engine_enhanced and rag_engine_enhanced.is_initialized and
                        getattr(rag_engine_enhanced, "weaviate_client", None)):
                    validation_report["warnings"].append("Weaviate non accessible - mode dÃ©gradÃ©")
            
            if not connectivity_status.get("redis", False):
                validation_report["warnings"].append("Redis non accessible - cache dÃ©sactivÃ©")
                if ENABLE_INTELLIGENT_RRF:
                    validation_report["warnings"].append("RRF Intelligent dÃ©sactivÃ© (Redis requis)")
            
            # 7. Validation finale
            validation_report["startup_duration"] = time.time() - start_time
            
            if validation_report["errors"]:
                validation_report["overall_status"] = "failed"
            elif validation_report["warnings"]:
                validation_report["overall_status"] = "degraded"
            else:
                validation_report["overall_status"] = "healthy"
            
            self.validation_report = validation_report
            return validation_report
            
        except StartupValidationError:
            validation_report["startup_duration"] = time.time() - start_time
            validation_report["overall_status"] = "failed"
            self.validation_report = validation_report
            raise
        except Exception as e:
            validation_report["errors"].append(f"Erreur validation inattendue: {e}")
            validation_report["startup_duration"] = time.time() - start_time
            validation_report["overall_status"] = "failed"
            self.validation_report = validation_report
            raise StartupValidationError(f"Validation Ã©chouÃ©e: {e}")
    
    async def _initialize_core_services(self) -> list:
        """Initialise les services principaux avec support LangSmith + RRF"""
        global rag_engine_enhanced, agent_rag_engine, cache_core
        errors = []
        
        try:
            # Cache Core
            logger.info("  Initialisation Cache Core...")
            try:
                from cache_core import create_cache_core
                cache_core = create_cache_core()
                await cache_core.initialize()
                
                if cache_core.initialized:
                    logger.info("âœ… cache_core: Cache Core initialisÃ©")
                else:
                    logger.warning("âš ï¸ cache_core: Cache Core en mode dÃ©gradÃ©")
                    
            except Exception as e:
                errors.append(f"Cache Core: {e}")
                logger.warning(f"cache_core: Cache Core erreur: {e}")
            
            # RAG Engine Enhanced avec LangSmith + RRF
            logger.info("  Initialisation RAG Engine Enhanced...")
            try:
                from rag_engine import InteliaRAGEngine
                rag_engine_enhanced = InteliaRAGEngine()
                await rag_engine_enhanced.initialize()
                
                if rag_engine_enhanced.is_initialized:
                    logger.info("âœ… RAG Engine Enhanced initialisÃ©")
                    
                    # VÃ©rifier intÃ©grations
                    status = rag_engine_enhanced.get_status()
                    
                    # Log statut LangSmith
                    langsmith_status = safe_dict_get(status, "langsmith", {})
                    if safe_dict_get(langsmith_status, "enabled", False):
                        project = safe_dict_get(langsmith_status, "project", "")
                        logger.info(f"âœ… LangSmith actif - Projet: {project}")
                    
                    # Log statut RRF Intelligent
                    rrf_status = safe_dict_get(status, "intelligent_rrf", {})
                    if safe_dict_get(rrf_status, "enabled", False):
                        learning_mode = safe_dict_get(rrf_status, "learning_mode", False)
                        logger.info(f"âœ… RRF Intelligent actif - Learning: {learning_mode}")
                    
                    # Log optimisations activÃ©es
                    optimizations = safe_dict_get(status, "optimizations", {})
                    cache_enabled = safe_dict_get(optimizations, "external_cache_enabled", False)
                    logger.info(f"Optimisations: Cache={cache_enabled}")
                    
                    hybrid_enabled = safe_dict_get(optimizations, "hybrid_search_enabled", False)
                    langsmith_enabled = safe_dict_get(optimizations, "langsmith_enabled", False)
                    rrf_enabled = safe_dict_get(optimizations, "intelligent_rrf_enabled", False)
                    
                    logger.info(f"   - Hybrid Search: {hybrid_enabled}")
                    logger.info(f"   - LangSmith: {langsmith_enabled}")
                    logger.info(f"   - RRF Intelligent: {rrf_enabled}")
                        
                else:
                    logger.warning("âš ï¸ RAG Engine en mode dÃ©gradÃ©")
                    
            except Exception as e:
                errors.append(f"RAG Engine: {e}")
                logger.error(f"RAG Engine erreur: {e}")
            
            # Agent RAG (optionnel)
            if USE_AGENT_RAG:
                logger.info("  Initialisation Agent RAG...")
                try:
                    from agent_rag_extension import create_agent_rag_engine
                    agent_rag_engine = create_agent_rag_engine()
                    logger.info("âœ… Agent RAG disponible")
                except ImportError:
                    logger.info("Agent RAG non disponible (optionnel)")
                    agent_rag_engine = None
                except Exception as e:
                    logger.warning(f"Agent RAG erreur: {e}")
                    agent_rag_engine = None
            
        except Exception as e:
            errors.append(f"Erreur initialisation services: {e}")
        
        return errors
    
    async def _test_service_connectivity(self) -> Dict[str, bool]:
        """Teste la connectivitÃ© aux services externes avec timeout - VERSION CORRIGÃ‰E"""
        
        # Clients pour tests
        redis_client = cache_core.client if cache_core and getattr(cache_core, 'initialized', False) else None
        weaviate_client = getattr(rag_engine_enhanced, 'weaviate_client', None) if rag_engine_enhanced else None
        
        try:
            # CORRECTION: Gestion d'erreur pour Ã©viter le RuntimeWarning Redis
            try:
                connectivity = await asyncio.wait_for(
                    quick_connectivity_check(redis_client, weaviate_client),
                    timeout=10.0
                )
                return connectivity
            except Exception as connectivity_error:
                # Log l'erreur sans la propager pour Ã©viter le RuntimeWarning
                logger.debug(f"Test connectivitÃ© Ã©chouÃ© (utilisation Ã©tat rÃ©el): {connectivity_error}")
                
                # NOUVEAU: Retourner un statut "optimiste" basÃ© sur l'Ã©tat d'initialisation rÃ©el
                return {
                    "redis": bool(cache_core and getattr(cache_core, "initialized", False)),
                    "weaviate": bool(
                        rag_engine_enhanced and rag_engine_enhanced.is_initialized and
                        getattr(rag_engine_enhanced, "weaviate_client", None)
                    ),
                    "openai": True  # SupposÃ© fonctionnel si on arrive ici
                }
                
        except asyncio.TimeoutError:
            logger.warning("Timeout test connectivitÃ©")
            return {"redis": False, "weaviate": False, "timeout": True}
        except Exception as e:
            logger.error(f"Erreur test connectivitÃ©: {e}")
            return {"redis": False, "weaviate": False, "error": str(e)}

    async def get_health_status(self) -> Dict[str, Any]:
        """Health check enrichi avec sÃ©rialisation JSON sÃ©curisÃ©e"""
        current_time = time.time()
        
        # Statut global - SÃ‰RIALISABLE
        global_status = {
            "overall_status": "healthy",
            "timestamp": current_time,
            "uptime_seconds": current_time - self.startup_time,
            "startup_validation": safe_serialize_for_json(self.validation_report),
            "services": {},
            "integrations": {},
            "warnings": []
        }
        
        try:
            # === CORRECTION: Statut services avec sÃ©rialisation sÃ©curisÃ©e ===
            
            # RAG Engine
            if rag_engine_enhanced and safe_get_attribute(rag_engine_enhanced, 'is_initialized', False):
                try:
                    rag_status = rag_engine_enhanced.get_status()
                    
                    # SÃ©rialisation sÃ©curisÃ©e du statut RAG
                    safe_rag_status = safe_serialize_for_json(rag_status)
                    
                    global_status["services"]["rag_engine"] = {
                        "status": "healthy" if not getattr(rag_engine_enhanced, 'degraded_mode', False) else "degraded",
                        "approach": safe_dict_get(safe_rag_status, "approach", "unknown"),
                        "optimizations": safe_dict_get(safe_rag_status, "optimizations", {}),
                        "metrics": safe_dict_get(safe_rag_status, "optimization_stats", {})
                    }
                    
                    # === CORRECTION: IntÃ©grations spÃ©cialisÃ©es avec validation ===
                    
                    # LangSmith - SÃ©rialisation sÃ©curisÃ©e
                    langsmith_info = safe_dict_get(safe_rag_status, "langsmith", {})
                    if isinstance(langsmith_info, dict):
                        global_status["integrations"]["langsmith"] = {
                            "available": safe_dict_get(langsmith_info, "available", False),
                            "enabled": safe_dict_get(langsmith_info, "enabled", False),
                            "configured": safe_dict_get(langsmith_info, "configured", False),
                            "project": str(safe_dict_get(langsmith_info, "project", "")),
                            "traces_count": int(safe_dict_get(langsmith_info, "traces_count", 0)),
                            "errors_count": int(safe_dict_get(langsmith_info, "errors_count", 0))
                        }
                        
                        if langsmith_info.get("enabled") and not langsmith_info.get("configured"):
                            global_status["warnings"].append("LangSmith activÃ© mais non configurÃ©")
                    
                    # RRF Intelligent - SÃ©rialisation sÃ©curisÃ©e
                    rrf_info = safe_dict_get(safe_rag_status, "intelligent_rrf", {})
                    if isinstance(rrf_info, dict):
                        global_status["integrations"]["intelligent_rrf"] = {
                            "available": safe_dict_get(rrf_info, "available", False),
                            "enabled": safe_dict_get(rrf_info, "enabled", False),
                            "configured": safe_dict_get(rrf_info, "configured", False),
                            "learning_mode": safe_dict_get(rrf_info, "learning_mode", False),
                            "usage_count": int(safe_dict_get(rrf_info, "usage_count", 0)),
                            "performance_stats": safe_dict_get(rrf_info, "performance_stats", {})
                        }
                        
                        if rrf_info.get("enabled") and not rrf_info.get("configured"):
                            global_status["warnings"].append("RRF Intelligent activÃ© mais non configurÃ©")
                
                except Exception as e:
                    logger.error(f"Erreur rÃ©cupÃ©ration statut RAG: {e}")
                    global_status["services"]["rag_engine"] = {
                        "status": "error", 
                        "reason": f"status_error: {str(e)}"
                    }
                    global_status["overall_status"] = "degraded"
                
            else:
                global_status["services"]["rag_engine"] = {"status": "error", "reason": "not_initialized"}
                global_status["overall_status"] = "degraded"
            
            # Cache - SÃ©rialisation sÃ©curisÃ©e
            if cache_core and getattr(cache_core, 'initialized', False):
                try:
                    if hasattr(cache_core, 'get_health_status'):
                        cache_status = cache_core.get_health_status()
                        global_status["services"]["cache"] = safe_serialize_for_json(cache_status)
                    else:
                        global_status["services"]["cache"] = {"status": "unknown"}
                except Exception as e:
                    logger.error(f"Erreur statut cache: {e}")
                    global_status["services"]["cache"] = {"status": "error", "error": str(e)}
            else:
                global_status["services"]["cache"] = {"status": "disabled"}
            
            # Agent RAG
            if agent_rag_engine:
                global_status["services"]["agent_rag"] = {"status": "available"}
            else:
                global_status["services"]["agent_rag"] = {"status": "disabled"}
            
            # === CORRECTION: Configuration et environnement avec sÃ©rialisation ===
            try:
                config_status = get_config_status()
                global_status["configuration"] = safe_serialize_for_json(config_status)
            except Exception as e:
                logger.error(f"Erreur statut configuration: {e}")
                global_status["configuration"] = {"error": str(e)}
            
            # Digital Ocean info
            global_status["environment"] = {
                "platform": "digital_ocean",
                "app_name": str(DO_APP_NAME),
                "app_tier": str(DO_APP_TIER),
                "base_path": str(BASE_PATH)
            }
            
            # DÃ©terminer statut global final
            if global_status["warnings"]:
                if global_status["overall_status"] == "healthy":
                    global_status["overall_status"] = "healthy_with_warnings"
            
            return global_status
            
        except Exception as e:
            logger.error(f"Erreur health check: {e}")
            return {
                "overall_status": "error",
                "error": str(e),
                "timestamp": current_time,
                "safe_mode": True
            }

health_monitor = SystemHealthMonitor()

# Clients OpenAI globaux avec validation
try:
    from imports_and_dependencies import get_openai_sync, get_openai_async
    openai_client_sync = get_openai_sync()
    openai_client_async = get_openai_async()
    logger.info("Clients OpenAI (sync + async) initialisÃ©s")
except Exception as e:
    logger.error(f"Erreur initialisation clients OpenAI: {e}")
    raise RuntimeError(f"Impossible d'initialiser les clients OpenAI: {e}")

# MÃ©moire de conversation (existante)
class TenantMemory(OrderedDict):
    """Cache LRU avec TTL pour la mÃ©moire de conversation - Version robuste"""
    
    def set(self, tenant_id: str, item: list):
        if not tenant_id or not isinstance(item, list):
            logger.warning(f"ParamÃ¨tres invalides pour TenantMemory.set: {tenant_id}, {type(item)}")
            return
        
        now = time.time()
        self[tenant_id] = {"data": item, "ts": now, "last_query": ""}
        self.move_to_end(tenant_id)
        
        # Purge TTL
        try:
            expired_keys = [k for k, v in self.items() if now - v.get("ts", 0) > TENANT_TTL]
            for k in expired_keys:
                del self[k]
                logger.debug(f"Tenant {k} expirÃ© (TTL)")
        except Exception as e:
            logger.warning(f"Erreur purge TTL: {e}")
        
        # Purge LRU
        try:
            while len(self) > MAX_TENANTS:
                oldest_tenant, _ = self.popitem(last=False)
                logger.debug(f"Tenant {oldest_tenant} purgÃ© (LRU)")
        except Exception as e:
            logger.warning(f"Erreur purge LRU: {e}")
    
    def get(self, tenant_id: str, default=None):
        if not tenant_id or tenant_id not in self:
            return default
        
        try:
            now = time.time()
            if now - self[tenant_id].get("ts", 0) > TENANT_TTL:
                del self[tenant_id]
                return default
            
            self[tenant_id]["ts"] = now
            self.move_to_end(tenant_id)
            return self[tenant_id]
        except Exception as e:
            logger.warning(f"Erreur rÃ©cupÃ©ration tenant {tenant_id}: {e}")
            return default
    
    def update_last_query(self, tenant_id: str, query: str):
        """Met Ã  jour la derniÃ¨re requÃªte pour un tenant"""
        if tenant_id in self and isinstance(query, str):
            try:
                self[tenant_id]["last_query"] = query[:500]  # Limiter la taille
            except Exception as e:
                logger.warning(f"Erreur mise Ã  jour last_query: {e}")

conversation_memory = TenantMemory()

def add_to_conversation_memory(tenant_id: str, question: str, answer: str, source: str = "rag_enhanced"):
    """Ajoute un Ã©change Ã  la mÃ©moire de conversation avec validation"""
    if not tenant_id or not question or not answer:
        logger.warning("ParamÃ¨tres invalides pour add_to_conversation_memory")
        return
    
    try:
        tenant_data = conversation_memory.get(tenant_id, {"data": []})
        history = tenant_data.get("data", [])
        
        history.append({
            "question": question[:1000],  # Limiter la taille
            "answer": answer[:2000],      # Limiter la taille
            "timestamp": time.time(),
            "answer_source": source
        })
        
        # Limiter selon la configuration
        if len(history) > MAX_CONVERSATION_CONTEXT:
            history = history[-MAX_CONVERSATION_CONTEXT:]
        
        conversation_memory.set(tenant_id, history)
        conversation_memory.update_last_query(tenant_id, question)
    except Exception as e:
        logger.error(f"Erreur ajout conversation memory: {e}")

# === NOUVEAU: Collecteur de mÃ©triques enrichi ===
class MetricsCollector:
    """Collecteur de mÃ©triques avec support LangSmith et RRF"""
    
    def __init__(self):
        self.metrics = {
            "total_queries": 0,
            "rag_enhanced_queries": 0,
            "agent_queries": 0,
            "simple_queries": 0,
            "complex_queries": 0,
            "rag_standard_queries": 0,
            "ood_filtered": 0,
            "fallback_queries": 0,
            "verified_responses": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "semantic_cache_hits": 0,
            "fallback_cache_hits": 0,
            "hybrid_searches": 0,
            "guardrail_violations": 0,
            "api_corrections": 0,
            "errors": 0,
            # === NOUVEAU: MÃ©triques LangSmith ===
            "langsmith_traces": 0,
            "langsmith_errors": 0,
            "hallucination_alerts": 0,
            # === NOUVEAU: MÃ©triques RRF Intelligent ===
            "intelligent_rrf_queries": 0,
            "genetic_boosts_applied": 0,
            "rrf_learning_updates": 0,
            "avg_processing_time": 0.0,
            "avg_confidence": 0.0,
        }
        self.recent_processing_times = []
        self.recent_confidences = []
        self.latency_percentiles = {"p50": 0.0, "p95": 0.0, "p99": 0.0}
        self.max_recent_samples = 100
    
    def record_query(self, result, source_type: str = "unknown", endpoint_time: float = 0.0):
        """Enregistre les mÃ©triques avec support LangSmith et RRF - VERSION SÃ‰CURISÃ‰E"""
        if not ENABLE_METRICS_LOGGING:
            return
        
        try:
            self.metrics["total_queries"] += 1
            
            # Gestion selon le type de source
            if source_type == "rag_enhanced":
                self.metrics["rag_enhanced_queries"] += 1
            elif source_type == "agent_rag":
                self.metrics["agent_queries"] += 1
            elif source_type == "error":
                self.metrics["errors"] += 1
            
            # Traitement selon le type de rÃ©sultat - VERSION SÃ‰CURISÃ‰E
            if result and hasattr(result, 'source'):
                try:
                    source_obj = safe_get_attribute(result, 'source')
                    if source_obj:
                        source_value = safe_get_attribute(source_obj, 'value', str(source_obj))
                        source_value_str = str(source_value).lower()
                        
                        if "rag" in source_value_str:
                            self.metrics["rag_standard_queries"] += 1
                        elif "ood" in source_value_str:
                            self.metrics["ood_filtered"] += 1
                        else:
                            self.metrics["fallback_queries"] += 1
                except Exception as e:
                    logger.debug(f"Erreur traitement source metrics: {e}")
                    self.metrics["fallback_queries"] += 1
            
            # === CORRECTION: MÃ©triques LangSmith et RRF avec validation ===
            metadata = safe_get_attribute(result, 'metadata')
            if metadata and isinstance(metadata, dict):
                try:
                    # LangSmith
                    langsmith_data = safe_dict_get(metadata, "langsmith", {})
                    if safe_dict_get(langsmith_data, "traced", False):
                        self.metrics["langsmith_traces"] += 1
                    
                    if safe_dict_get(metadata, "alerts_aviculture"):
                        self.metrics["hallucination_alerts"] += 1
                    
                    # RRF Intelligent
                    rrf_data = safe_dict_get(metadata, "intelligent_rrf", {})
                    if safe_dict_get(rrf_data, "used", False):
                        self.metrics["intelligent_rrf_queries"] += 1
                    
                    opt_stats = safe_dict_get(metadata, "optimization_stats", {})
                    if isinstance(opt_stats, dict):
                        self.metrics["cache_hits"] += int(safe_dict_get(opt_stats, "cache_hits", 0))
                        self.metrics["cache_misses"] += int(safe_dict_get(opt_stats, "cache_misses", 0))
                        self.metrics["semantic_cache_hits"] += int(safe_dict_get(opt_stats, "semantic_cache_hits", 0))
                        self.metrics["hybrid_searches"] += int(safe_dict_get(opt_stats, "hybrid_searches", 0))
                        self.metrics["genetic_boosts_applied"] += int(safe_dict_get(opt_stats, "genetic_boosts_applied", 0))
                        self.metrics["rrf_learning_updates"] += int(safe_dict_get(opt_stats, "rrf_learning_updates", 0))
                    
                except Exception as e:
                    logger.debug(f"Erreur traitement mÃ©triques metadata: {e}")
            
            # Calcul des mÃ©triques temporelles
            processing_time = endpoint_time if endpoint_time > 0 else safe_get_attribute(result, 'processing_time', 0)
            
            if processing_time > 0:
                self.recent_processing_times.append(float(processing_time))
                if len(self.recent_processing_times) > self.max_recent_samples:
                    self.recent_processing_times.pop(0)
                
                # Calcul de la moyenne
                if self.recent_processing_times:
                    self.metrics["avg_processing_time"] = (
                        sum(self.recent_processing_times) / len(self.recent_processing_times)
                    )
                
                # Calcul des percentiles
                if len(self.recent_processing_times) >= 10:
                    try:
                        sorted_times = sorted(self.recent_processing_times)
                        n = len(sorted_times)
                        self.latency_percentiles["p50"] = sorted_times[int(n * 0.5)]
                        self.latency_percentiles["p95"] = sorted_times[int(n * 0.95)]
                        self.latency_percentiles["p99"] = sorted_times[int(n * 0.99)]
                    except Exception as e:
                        logger.debug(f"Erreur calcul percentiles: {e}")
            
            # Confiance
            confidence = safe_get_attribute(result, 'confidence', 0)
            if confidence > 0:
                self.recent_confidences.append(float(confidence))
                if len(self.recent_confidences) > self.max_recent_samples:
                    self.recent_confidences.pop(0)
                
                if self.recent_confidences:
                    self.metrics["avg_confidence"] = (
                        sum(self.recent_confidences) / len(self.recent_confidences)
                    )
        
        except Exception as e:
            logger.warning(f"Erreur enregistrement mÃ©triques: {e}")
            self.metrics["errors"] = self.metrics.get("errors", 0) + 1
    
    def get_metrics(self) -> Dict:
        """Retourne les mÃ©triques enrichies avec protection contre les erreurs"""
        try:
            total_queries = max(1, self.metrics["total_queries"])
            total_cache_requests = max(1, self.metrics["cache_hits"] + self.metrics["cache_misses"])
            
            return {
                **self.metrics,
                "success_rate": (
                    (self.metrics["rag_enhanced_queries"] + self.metrics["verified_responses"] + self.metrics["agent_queries"]) / total_queries
                ),
                "enhanced_rag_usage_rate": self.metrics["rag_enhanced_queries"] / total_queries,
                "cache_hit_rate": self.metrics["cache_hits"] / total_cache_requests,
                "semantic_cache_hit_rate": self.metrics["semantic_cache_hits"] / total_cache_requests,
                "error_rate": self.metrics["errors"] / total_queries,
                "latency_percentiles": self.latency_percentiles,
                # === NOUVEAU: Taux spÃ©cialisÃ©s ===
                "langsmith_usage_rate": self.metrics["langsmith_traces"] / total_queries,
                "rrf_intelligent_usage_rate": self.metrics["intelligent_rrf_queries"] / total_queries,
                "hallucination_alert_rate": self.metrics["hallucination_alerts"] / total_queries
            }
        except Exception as e:
            logger.error(f"Erreur calcul mÃ©triques: {e}")
            return self.metrics

metrics_collector = MetricsCollector()

# Helpers de streaming et fonctions utilitaires
def sse_event(obj: Dict[str, Any]) -> bytes:
    """Formatage SSE avec gestion d'erreurs robuste"""
    try:
        # CORRECTION: SÃ©rialisation sÃ©curisÃ©e pour SSE
        safe_obj = safe_serialize_for_json(obj)
        data = json.dumps(safe_obj, ensure_ascii=False)
        return f"data: {data}\n\n".encode("utf-8")
    except Exception as e:
        logger.error(f"Erreur formatage SSE: {e}")
        error_obj = {"type": "error", "message": "Erreur formatage donnÃ©es"}
        data = json.dumps(error_obj, ensure_ascii=False)
        return f"data: {data}\n\n".encode("utf-8")

def smart_chunk_text(text: str, max_chunk_size: int = None) -> list:
    """DÃ©coupe intelligente du texte avec validation"""
    if not isinstance(text, str):
        return []
    
    max_chunk_size = max_chunk_size or STREAM_CHUNK_LEN
    if not text or len(text) <= max_chunk_size:
        return [text] if text else []
    
    try:
        chunks = []
        remaining_text = text
        
        while remaining_text:
            if len(remaining_text) <= max_chunk_size:
                chunks.append(remaining_text)
                break
            
            # Recherche de points de coupure optimaux
            cut_point = max_chunk_size
            
            # PrÃ©fÃ©rer les points aprÃ¨s ponctuation
            for i in range(max_chunk_size, max(max_chunk_size // 2, 0), -1):
                if i < len(remaining_text) and remaining_text[i] in '.!?:':
                    cut_point = i + 1
                    break
            
            # Sinon, couper sur un espace
            if cut_point == max_chunk_size:
                for i in range(max_chunk_size, max(max_chunk_size // 2, 0), -1):
                    if i < len(remaining_text) and remaining_text[i] == ' ':
                        cut_point = i
                        break
            
            chunks.append(remaining_text[:cut_point])
            remaining_text = remaining_text[cut_point:].lstrip()
        
        return chunks
        
    except Exception as e:
        logger.error(f"Erreur dÃ©coupe texte: {e}")
        return [text[:max_chunk_size]] if text else []

def get_out_of_domain_message(lang: Optional[str] = None) -> str:
    """Messages out of domain multilingue"""
    OUT_OF_DOMAIN_MESSAGES = {
        "fr": "DÃ©solÃ©, cette question sort du domaine avicole. Pose-moi une question sur l'aviculture, l'Ã©levage de volailles, la nutrition, la santÃ© des oiseaux, ou les performances.",
        "en": "Sorry, this question is outside the poultry domain. Ask me about poultry farming, bird nutrition, health, or performance.",
        "es": "Lo siento, esta pregunta estÃ¡ fuera del dominio avÃ­cola. PregÃºntame sobre avicultura, nutriciÃ³n, salud o rendimiento de aves.",
        "default": "Questions outside poultry domain not supported. Ask about poultry farming, nutrition, health, or performance."
    }
    
    code = (lang or "").lower()
    msg = OUT_OF_DOMAIN_MESSAGES.get(code)
    if msg:
        return msg
    
    short = code.split("-")[0]
    return OUT_OF_DOMAIN_MESSAGES.get(short, OUT_OF_DOMAIN_MESSAGES.get("default", "Questions outside domain not supported."))

def detect_language(text: str, min_length: int = None) -> str:
    """DÃ©tection de langue avec fallback pattern"""
    min_length = min_length or LANG_DETECTION_MIN_LENGTH
    
    if len(text) < min_length:
        return 'fr'  # DÃ©faut franÃ§ais pour textes courts
    
    try:
        # Tentative avec langdetect si disponible
        try:
            from langdetect import detect
            detected = detect(text)
            
            # Mapping normalisÃ©
            lang_mapping = {
                'de': 'de',
                'fr': 'fr', 'fra': 'fr', 
                'en': 'en', 'eng': 'en',
                'es': 'es', 'spa': 'es',
                'it': 'it', 'ita': 'it',
                'nl': 'nl', 'nld': 'nl',
                'pl': 'pl', 'pol': 'pl',
                'pt': 'pt', 'por': 'pt'
            }
            
            result = lang_mapping.get(detected, detected)
            logger.debug(f"DÃ©tection: {result} pour '{text[:30]}...'")
            return result
            
        except ImportError:
            logger.debug("langdetect non disponible, utilisation patterns")
        except Exception as e:
            logger.debug(f"Erreur langdetect: {e}, fallback patterns")
        
        # Fallback par patterns Ã©tendus
        text_lower = text.lower()
        
        lang_patterns = {
            'fr': ['poulet', 'aviculture', 'qu\'est', 'comment', 'quelle', 'combien'],
            'en': ['chicken', 'poultry', 'what', 'how', 'which', 'where'],
            'es': ['pollo', 'avicultura', 'quÃ©', 'cÃ³mo', 'cuÃ¡l', 'dÃ³nde'],
            'de': ['huhn', 'geflÃ¼gel', 'was', 'wie', 'welche', 'wo']
        }
        
        for lang, patterns in lang_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                logger.debug(f"Fallback pattern: {lang} pour '{text[:20]}...'")
                return lang
        
        return 'fr'  # DÃ©faut franÃ§ais final
        
    except Exception as e:
        logger.warning(f"Erreur dÃ©tection langue pour '{text[:50]}...': {e}")
        return 'fr'  # DÃ©faut franÃ§ais en cas d'erreur

# Gestion du cycle de vie de l'application
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gestion du cycle de vie avec validation stricte et monitoring enrichi"""
    
    logger.info("DÃ©marrage Intelia Expert Backend...")
    
    try:
        if ENABLE_STARTUP_VALIDATION:
            # Validation complÃ¨te au dÃ©marrage
            validation_result = await asyncio.wait_for(
                health_monitor.validate_startup_requirements(),
                timeout=STARTUP_TIMEOUT
            )
            
            if validation_result["overall_status"] == "failed":
                logger.error("Validation startup Ã©chouÃ©e - ArrÃªt de l'application")
                raise RuntimeError(f"Startup validation failed: {validation_result['errors']}")
            
            elif validation_result["overall_status"] == "degraded":
                logger.warning("Application dÃ©marrÃ©e en mode dÃ©gradÃ©")
                logger.warning(f"Warnings: {validation_result['warnings']}")
            
            else:
                logger.info("Application dÃ©marrÃ©e avec succÃ¨s")
                
                # Log statut des intÃ©grations
                langsmith_status = validation_result.get("langsmith_validation", {})
                if langsmith_status.get("status") == "configured":
                    logger.info(f"ðŸ§  LangSmith actif - Projet: {langsmith_status.get('project')}")
                
                rrf_status = validation_result.get("rrf_validation", {})
                if rrf_status.get("status") == "configured":
                    logger.info(f"âš¡ RRF Intelligent actif - Learning: {rrf_status.get('learning_mode')}")
        
        else:
            logger.info("Validation startup dÃ©sactivÃ©e")
            # Initialisation minimale
            await health_monitor._initialize_core_services()
        
        # Application prÃªte
        logger.info(f"API disponible sur {BASE_PATH}")
        logger.info(f"Environment: DO App={DO_APP_NAME}, Tier={DO_APP_TIER}")
        
        yield
        
    except asyncio.TimeoutError:
        logger.error(f"Timeout startup aprÃ¨s {STARTUP_TIMEOUT}s")
        raise RuntimeError("Startup timeout")
    
    except Exception as e:
        logger.error(f"Erreur critique au dÃ©marrage: {e}")
        raise
    
    finally:
        # Nettoyage
        logger.info("Nettoyage des ressources...")
        
        try:
            global rag_engine_enhanced, agent_rag_engine, cache_core
            
            if cache_core and hasattr(cache_core, 'cleanup'):
                await cache_core.cleanup()
            
            if rag_engine_enhanced and hasattr(rag_engine_enhanced, 'cleanup'):
                await rag_engine_enhanced.cleanup()
            
            if agent_rag_engine and hasattr(agent_rag_engine, 'cleanup'):
                await agent_rag_engine.cleanup()
            
            # Fermer les clients OpenAI
            if hasattr(openai_client_async, 'http_client'):
                await openai_client_async.http_client.aclose()
            
            # Nettoyer les variables globales
            rag_engine_enhanced = None
            agent_rag_engine = None
            cache_core = None
            conversation_memory.clear()
            
        except Exception as e:
            logger.error(f"Erreur nettoyage: {e}")
        
        logger.info("Application arrÃªtÃ©e")

# CrÃ©ation de l'application FastAPI
app = FastAPI(
    title="Intelia Expert Backend",
    description="API RAG Enhanced avec LangSmith et RRF Intelligent",
    version="4.0.0-langsmith-rrf",
    lifespan=lifespan
)

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# Router principal
router = APIRouter()

@router.get("/health")
async def health_check():
    """Health check complet avec dÃ©tails LangSmith et RRF - VERSION CORRIGÃ‰E"""
    try:
        health_status = await health_monitor.get_health_status()
        
        # Code de statut HTTP selon l'Ã©tat
        if health_status["overall_status"] in ["healthy", "healthy_with_warnings"]:
            status_code = 200
        elif health_status["overall_status"] == "degraded":
            status_code = 200  # Toujours 200 mais avec warnings
        else:
            status_code = 503  # Service Unavailable
        
        return JSONResponse(
            status_code=status_code,
            content=health_status
        )
        
    except Exception as e:
        logger.error(f"Erreur health check: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "overall_status": "error",
                "error": str(e),
                "timestamp": time.time(),
                "safe_mode": True
            }
        )

# === CORRECTION: Ajout endpoint /health direct sur app ===
@app.get("/health")
async def health_direct():
    """Endpoint health direct sur l'app pour rÃ©soudre l'erreur 404"""
    return await health_check()

@router.get(f"{BASE_PATH}/status/dependencies")
async def dependencies_status():
    """Statut dÃ©taillÃ© des dÃ©pendances"""
    try:
        return get_full_status_report()
    except Exception as e:
        return {"error": str(e)}

# === CORRECTION: AJOUT DES ENDPOINTS MANQUANTS ===

@router.get(f"{BASE_PATH}/status/rag")
async def rag_status():
    """Statut dÃ©taillÃ© du RAG Engine - VERSION SÃ‰CURISÃ‰E"""
    try:
        if not rag_engine_enhanced:
            return {
                "initialized": False,
                "error": "RAG Engine non disponible",
                "timestamp": time.time()
            }
        
        # CORRECTION: RÃ©cupÃ©ration sÃ©curisÃ©e du statut
        try:
            status = rag_engine_enhanced.get_status()
            safe_status = safe_serialize_for_json(status)
        except Exception as e:
            logger.error(f"Erreur rÃ©cupÃ©ration statut RAG: {e}")
            safe_status = {"error": f"status_error: {str(e)}"}
        
        return {
            "initialized": safe_get_attribute(rag_engine_enhanced, 'is_initialized', False),
            "degraded_mode": safe_get_attribute(rag_engine_enhanced, 'degraded_mode', False),
            "approach": safe_dict_get(safe_status, "approach", "unknown"),
            "optimizations": safe_dict_get(safe_status, "optimizations", {}),
            "langsmith": safe_dict_get(safe_status, "langsmith", {}),
            "intelligent_rrf": safe_dict_get(safe_status, "intelligent_rrf", {}),
            "optimization_stats": safe_dict_get(safe_status, "optimization_stats", {}),
            "weaviate_connected": bool(safe_get_attribute(rag_engine_enhanced, 'weaviate_client')),
            "timestamp": time.time()
        }
        
    except Exception as e:
        logger.error(f"Erreur RAG status: {e}")
        return {
            "initialized": False,
            "error": str(e),
            "timestamp": time.time()
        }

@router.get(f"{BASE_PATH}/status/cache")
async def cache_status():
    """Statut dÃ©taillÃ© du cache Redis - VERSION SÃ‰CURISÃ‰E"""
    try:
        if not cache_core:
            return {
                "enabled": False,
                "initialized": False,
                "error": "Cache Core non disponible",
                "timestamp": time.time()
            }
        
        # CORRECTION: RÃ©cupÃ©ration sÃ©curisÃ©e des stats cache
        try:
            cache_health = cache_core.get_health_status() if hasattr(cache_core, 'get_health_status') else {}
            cache_stats = cache_core.get_stats() if hasattr(cache_core, 'get_stats') else {}
        except Exception as e:
            logger.error(f"Erreur rÃ©cupÃ©ration stats cache: {e}")
            cache_health = {"error": str(e)}
            cache_stats = {}
        
        return {
            "enabled": safe_get_attribute(cache_core, 'enabled', False),
            "initialized": safe_get_attribute(cache_core, 'initialized', False),
            "status": safe_dict_get(cache_health, "status", "unknown"),
            "stats": safe_serialize_for_json(cache_stats),
            "configuration": {
                "memory_limit_mb": safe_get_attribute(
                    safe_get_attribute(cache_core, 'config'), 
                    'total_memory_limit_mb', 0
                ),
                "compression_enabled": safe_get_attribute(
                    safe_get_attribute(cache_core, 'config'), 
                    'enable_compression', False
                )
            },
            "timestamp": time.time()
        }
        
    except Exception as e:
        logger.error(f"Erreur cache status: {e}")
        return {
            "enabled": False,
            "initialized": False,
            "error": str(e),
            "timestamp": time.time()
        }

@router.get(f"{BASE_PATH}/status/connectivity")
async def connectivity_status():
    """Test de connectivitÃ© aux services externes"""
    try:
        redis_client = cache_core.client if cache_core and getattr(cache_core, 'initialized', False) else None
        weaviate_client = getattr(rag_engine_enhanced, 'weaviate_client', None) if rag_engine_enhanced else None
        
        connectivity = await quick_connectivity_check(redis_client, weaviate_client)
        
        return {
            "timestamp": time.time(),
            "services": connectivity,
            "overall": all(connectivity.values())
        }
        
    except Exception as e:
        return {"error": str(e), "overall": False}

@router.get(f"{BASE_PATH}/metrics")
async def get_metrics():
    """Endpoint pour rÃ©cupÃ©rer les mÃ©triques de performance enrichies"""
    try:
        base_metrics = {
            "application_metrics": metrics_collector.get_metrics(),
            "system_metrics": {
                "conversation_memory": {
                    "tenants": len(conversation_memory),
                    "max_tenants": MAX_TENANTS,
                    "ttl_seconds": TENANT_TTL
                }
            }
        }
        
        # === CORRECTION: MÃ©triques RAG Engine enrichies avec sÃ©rialisation sÃ©curisÃ©e ===
        if rag_engine_enhanced and safe_get_attribute(rag_engine_enhanced, 'is_initialized', False):
            try:
                rag_status = rag_engine_enhanced.get_status()
                safe_rag_status = safe_serialize_for_json(rag_status)
                
                base_metrics["rag_engine"] = {
                    "approach": safe_dict_get(safe_rag_status, "approach", "unknown"),
                    "optimizations": safe_dict_get(safe_rag_status, "optimizations", {}),
                    "langsmith": safe_dict_get(safe_rag_status, "langsmith", {}),
                    "intelligent_rrf": safe_dict_get(safe_rag_status, "intelligent_rrf", {}),
                    "optimization_stats": safe_dict_get(safe_rag_status, "optimization_stats", {}),
                    "weaviate_capabilities": safe_dict_get(safe_rag_status, "api_capabilities", {})
                }
            except Exception as e:
                logger.error(f"Erreur mÃ©triques RAG: {e}")
                base_metrics["rag_engine"] = {"error": str(e)}
        
        # Cache stats externe
        if cache_core and getattr(cache_core, 'initialized', False):
            try:
                cache_stats = cache_core.get_stats() if hasattr(cache_core, 'get_stats') else {}
                base_metrics["cache"] = safe_serialize_for_json(cache_stats)
            except Exception as e:
                logger.error(f"Erreur mÃ©triques cache: {e}")
                base_metrics["cache"] = {"error": str(e)}
        
        return base_metrics
        
    except Exception as e:
        logger.error(f"Erreur rÃ©cupÃ©ration mÃ©triques: {e}")
        return {"error": str(e), "timestamp": time.time()}

@router.get(f"{BASE_PATH}/status/configuration")
async def configuration_status():
    """Statut dÃ©taillÃ© de la configuration"""
    try:
        config_status = get_config_status()
        
        # Enrichir avec informations runtime
        config_status["runtime"] = {
            "environment_variables": {
                "langsmith_enabled": LANGSMITH_ENABLED,
                "rrf_enabled": ENABLE_INTELLIGENT_RRF,
                "cache_enabled": CACHE_ENABLED,
                "rag_enabled": RAG_ENABLED
            },
            "digital_ocean": {
                "app_name": DO_APP_NAME,
                "app_tier": DO_APP_TIER,
                "base_path": BASE_PATH
            }
        }
        
        return safe_serialize_for_json(config_status)
        
    except Exception as e:
        return {"error": str(e)}

# === CORRECTION CRITIQUE: ENDPOINT CHAT AVEC GESTION D'ERREURS ROBUSTE ===
@router.post(f"{BASE_PATH}/chat")
async def chat(request: Request):
    """Chat endpoint avec validation stricte et gestion d'erreurs robuste - VERSION CORRIGÃ‰E"""
    total_start_time = time.time()
    
    if not rag_engine_enhanced:
        metrics_collector.record_query({"source": "error"}, "error", time.time() - total_start_time)
        raise HTTPException(status_code=503, detail="RAG Engine Enhanced non disponible")
    
    try:
        # Validation de la requÃªte
        try:
            body = await request.json()
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"JSON invalide: {e}")
        
        message = body.get("message", "").strip()
        language = body.get("language", "").strip()
        tenant_id = body.get("tenant_id", str(uuid.uuid4())[:8])
        
        # Validations
        if not message:
            raise HTTPException(status_code=400, detail="Message vide")
        
        if len(message) > MAX_REQUEST_SIZE:
            raise HTTPException(status_code=413, detail=f"Message trop long (max {MAX_REQUEST_SIZE})")
        
        # DÃ©tection de langue si non fournie
        if not language:
            language = detect_language(message)
        
        # Validation tenant_id
        if not tenant_id or len(tenant_id) > 50:
            tenant_id = str(uuid.uuid4())[:8]
        
        # Messages trop courts -> rÃ©ponse OOD
        if len(message.split()) < 3:
            out_of_domain_msg = get_out_of_domain_message(language)
            
            async def simple_response():
                yield sse_event({"type": "start", "reason": "too_short"})
                yield sse_event({"type": "chunk", "content": out_of_domain_msg})
                yield sse_event({"type": "end", "confidence": 0.9})
            
            metrics_collector.record_query({"source": "ood"}, "ood", time.time() - total_start_time)
            return StreamingResponse(simple_response(), media_type="text/plain")
        
        # === CORRECTION CRITIQUE: Gestion robuste du RAG Engine ===
        try:
            # VÃ©rifier que le RAG engine est initialisÃ©
            if not safe_get_attribute(rag_engine_enhanced, 'is_initialized', False):
                logger.error("RAG Engine non initialisÃ©")
                raise HTTPException(status_code=503, detail="RAG Engine non initialisÃ©")
            
            # CORRECTION: Utiliser une mÃ©thode plus robuste ou fallback
            rag_result = None
            
            # Essayer d'abord generate_response
            try:
                if hasattr(rag_engine_enhanced, 'generate_response'):
                    rag_result = await rag_engine_enhanced.generate_response(
                        query=message,
                        tenant_id=tenant_id,
                        language=language
                    )
                else:
                    raise AttributeError("generate_response method not available")
                    
            except Exception as generate_error:
                logger.warning(f"generate_response Ã©chouÃ©: {generate_error}")
                
                # FALLBACK: Essayer process_query si generate_response Ã©choue
                try:
                    if hasattr(rag_engine_enhanced, 'process_query'):
                        rag_result = await rag_engine_enhanced.process_query(
                            query=message,
                            tenant_id=tenant_id,
                            language=language
                        )
                    else:
                        raise AttributeError("process_query method not available either")
                        
                except Exception as process_error:
                    logger.error(f"process_query Ã©chouÃ© aussi: {process_error}")
                    
                    # DERNIER FALLBACK: RÃ©ponse OOD si tout Ã©choue
                    logger.error("Toutes les mÃ©thodes RAG ont Ã©chouÃ©, fallback vers OOD")
                    out_of_domain_msg = get_out_of_domain_message(language)
                    
                    async def fallback_response():
                        yield sse_event({"type": "start", "reason": "rag_engine_error"})
                        yield sse_event({"type": "chunk", "content": out_of_domain_msg})
                        yield sse_event({"type": "end", "confidence": 0.5, "fallback": True})
                    
                    metrics_collector.record_query({"source": "error"}, "error", time.time() - total_start_time)
                    return StreamingResponse(fallback_response(), media_type="text/plain")
            
            # VÃ©rifier que nous avons un rÃ©sultat valide
            if not rag_result:
                logger.error("RAG result is None")
                raise HTTPException(status_code=500, detail="Aucun rÃ©sultat du RAG Engine")
                
        except Exception as e:
            logger.error(f"Erreur traitement RAG: {e}")
            metrics_collector.record_query({"source": "error"}, "error", time.time() - total_start_time)
            raise HTTPException(status_code=500, detail=f"Erreur traitement: {str(e)}")
        
        # Enregistrer mÃ©triques
        total_processing_time = time.time() - total_start_time
        metrics_collector.record_query(rag_result, "rag_enhanced", total_processing_time)
        
        # === CORRECTION: Streaming de la rÃ©ponse avec gestion d'erreurs robuste ===
        async def generate_response():
            try:
                # CORRECTION: Informations de dÃ©but avec accÃ¨s sÃ©curisÃ©
                metadata = safe_get_attribute(rag_result, 'metadata', {}) or {}
                source = safe_get_attribute(rag_result, 'source', 'unknown')
                confidence = safe_get_attribute(rag_result, 'confidence', 0.5)
                processing_time = safe_get_attribute(rag_result, 'processing_time', 0)
                
                # Convertir source enum si nÃ©cessaire
                if hasattr(source, 'value'):
                    source = source.value
                else:
                    source = str(source)
                
                yield sse_event({
                    "type": "start", 
                    "source": source,
                    "confidence": float(confidence),
                    "processing_time": float(processing_time)
                })
                
                # CORRECTION: Contenu de la rÃ©ponse avec validation
                answer = safe_get_attribute(rag_result, 'answer', '')
                if not answer:
                    # Essayer d'autres attributs possibles
                    answer = safe_get_attribute(rag_result, 'response', '')
                    if not answer:
                        answer = safe_get_attribute(rag_result, 'text', '')
                        if not answer:
                            answer = "DÃ©solÃ©, je n'ai pas pu gÃ©nÃ©rer une rÃ©ponse."
                
                if answer:
                    chunks = smart_chunk_text(str(answer), STREAM_CHUNK_LEN)
                    
                    for i, chunk in enumerate(chunks):
                        yield sse_event({
                            "type": "chunk", 
                            "content": chunk,
                            "chunk_index": i
                        })
                        await asyncio.sleep(0.01)  # Streaming fluide
                
                # CORRECTION: Informations finales avec validation
                context_docs = safe_get_attribute(rag_result, 'context_docs', [])
                if not isinstance(context_docs, list):
                    context_docs = []
                
                yield sse_event({
                    "type": "end",
                    "total_time": total_processing_time,
                    "confidence": float(confidence),
                    "documents_used": len(context_docs)
                })
                
                # Enregistrer en mÃ©moire si tout est OK
                if answer and source:
                    add_to_conversation_memory(tenant_id, message, str(answer), "rag_enhanced")
                
            except Exception as e:
                logger.error(f"Erreur streaming: {e}")
                yield sse_event({"type": "error", "message": str(e)})
        
        return StreamingResponse(generate_response(), media_type="text/plain")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur chat endpoint: {e}")
        metrics_collector.record_query({"source": "error"}, "error", time.time() - total_start_time)
        return JSONResponse(
            status_code=500,
            content={"error": f"Erreur traitement: {str(e)}"}
        )

# Route OOD pour compatibilitÃ©
@router.post(f"{BASE_PATH}/ood")
async def ood_endpoint(request: Request):
    """Point de terminaison pour messages hors domaine"""
    try:
        body = await request.json()
        language = body.get("language", "fr")
        message = get_out_of_domain_message(language)
        
        async def ood_response():
            yield sse_event({"type": "start", "reason": "out_of_domain"})
            
            chunks = smart_chunk_text(message, STREAM_CHUNK_LEN)
            for chunk in chunks:
                yield sse_event({"type": "chunk", "content": chunk})
                await asyncio.sleep(0.05)
            
            yield sse_event({"type": "end", "confidence": 1.0})
        
        return StreamingResponse(ood_response(), media_type="text/plain")
        
    except Exception as e:
        logger.error(f"Erreur OOD endpoint: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})

# === CORRECTION: Endpoint de diagnostic pour tests spÃ©cifiques ===
@router.post(f"{BASE_PATH}/diagnostic/chat")
async def diagnostic_chat(request: Request):
    """Endpoint de diagnostic pour tester le chat avec informations dÃ©taillÃ©es"""
    try:
        body = await request.json()
        message = body.get("message", "test")
        
        diagnostic_info = {
            "timestamp": time.time(),
            "rag_engine_status": {
                "available": rag_engine_enhanced is not None,
                "initialized": safe_get_attribute(rag_engine_enhanced, 'is_initialized', False),
                "degraded_mode": safe_get_attribute(rag_engine_enhanced, 'degraded_mode', False)
            },
            "methods_available": {},
            "test_result": None,
            "error": None
        }
        
        if rag_engine_enhanced:
            # VÃ©rifier les mÃ©thodes disponibles
            diagnostic_info["methods_available"] = {
                "generate_response": hasattr(rag_engine_enhanced, 'generate_response'),
                "process_query": hasattr(rag_engine_enhanced, 'process_query'),
                "get_status": hasattr(rag_engine_enhanced, 'get_status')
            }
            
            # Test simple
            try:
                if hasattr(rag_engine_enhanced, 'generate_response'):
                    test_result = await rag_engine_enhanced.generate_response(
                        query=message,
                        tenant_id="diagnostic",
                        language="fr"
                    )
                    diagnostic_info["test_result"] = {
                        "method_used": "generate_response",
                        "success": True,
                        "has_answer": bool(safe_get_attribute(test_result, 'answer')),
                        "answer_length": len(str(safe_get_attribute(test_result, 'answer', ''))),
                        "confidence": safe_get_attribute(test_result, 'confidence', 0),
                        "source": str(safe_get_attribute(test_result, 'source', 'unknown'))
                    }
                elif hasattr(rag_engine_enhanced, 'process_query'):
                    test_result = await rag_engine_enhanced.process_query(
                        query=message,
                        tenant_id="diagnostic",
                        language="fr"
                    )
                    diagnostic_info["test_result"] = {
                        "method_used": "process_query",
                        "success": True,
                        "result_type": type(test_result).__name__
                    }
                else:
                    diagnostic_info["error"] = "Aucune mÃ©thode de traitement disponible"
                    
            except Exception as e:
                diagnostic_info["error"] = str(e)
                diagnostic_info["test_result"] = {
                    "success": False,
                    "error": str(e)
                }
        
        return diagnostic_info
        
    except Exception as e:
        return {"error": str(e), "timestamp": time.time()}

# Inclusion du router dans l'app
app.include_router(router)

# === CORRECTION: Endpoint de test JSON simple ===
@app.get("/test-json")
async def test_json():
    """Test simple de sÃ©rialisation JSON"""
    try:
        # Test avec enum
        from intent_types import IntentType
        
        test_data = {
            "string": "test",
            "number": 42,
            "boolean": True,
            "list": [1, 2, 3],
            "dict": {"nested": "value"},
            "enum_value": IntentType.METRIC_QUERY.value,  # CORRECTION: .value
            "enum_direct": str(IntentType.PROTOCOL_QUERY),  # CORRECTION: str()
        }
        
        # Test de sÃ©rialisation
        safe_data = safe_serialize_for_json(test_data)
        
        return {
            "status": "success",
            "original_data": test_data,
            "serialized_data": safe_data,
            "json_test": "OK"
        }
        
    except Exception as e:
        return {
            "status": "error", 
            "error": str(e),
            "json_test": "FAILED"
        }

# DÃ©marrage de l'application
if __name__ == "__main__":
    import uvicorn
    
    port = int(os.getenv("PORT", "8000"))
    host = os.getenv("HOST", "0.0.0.0")
    
    logger.info(f"DÃ©marrage serveur sur {host}:{port}")
    logger.info(f"LangSmith: {LANGSMITH_ENABLED}, RRF: {ENABLE_INTELLIGENT_RRF}")
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=False,  # DÃ©sactivÃ© en production
        log_level="info"
    )