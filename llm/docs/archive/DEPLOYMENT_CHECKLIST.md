# Checklist de DÃ©ploiement - Digital Ocean App Platform

**Date:** 2025-10-05
**Objectif:** DÃ©ployer les Quick Wins en production

---

## âœ… PrÃ©-requis

- [x] Code poussÃ© sur GitHub (branche main)
- [x] requirements.txt mis Ã  jour avec nouvelles dÃ©pendances :
  - `cohere>=5.0.0`
  - `anthropic>=0.40.0`
  - `ragas==0.1.19`
  - `datasets>=2.14.0`
  - `langchain-openai>=0.0.5`

---

## ğŸ”‘ Ã‰tape 1 : Obtenir les ClÃ©s API

### 1.1 Cohere API Key

**URL:** https://dashboard.cohere.com/api-keys

1. CrÃ©er compte gratuit Cohere
2. Aller dans "API Keys"
3. CrÃ©er nouvelle clÃ© â†’ Copier `COHERE_API_KEY`
4. Plan gratuit : 1000 req/mois (suffisant pour dÃ©marrer)

**Format:** `co-xxxxxxxxxxxxxxxxxxxxxxxx`

---

### 1.2 Anthropic API Key (Claude)

**URL:** https://console.anthropic.com/

1. CrÃ©er compte Anthropic
2. Aller dans "API Keys"
3. CrÃ©er nouvelle clÃ© â†’ Copier `ANTHROPIC_API_KEY`
4. Ajouter crÃ©dits ($5 minimum recommandÃ©)

**Format:** `sk-ant-xxxxxxxxxxxxxxxxxxxxx`

---

### 1.3 DeepSeek API Key

**URL:** https://platform.deepseek.com/

1. CrÃ©er compte DeepSeek
2. Aller dans "API Keys"
3. CrÃ©er nouvelle clÃ© â†’ Copier `DEEPSEEK_API_KEY`
4. Ajouter crÃ©dits ($5 recommandÃ©)

**Format:** `sk-xxxxxxxxxxxxxxxxxxxxxxxx`

---

## âš™ï¸ Ã‰tape 2 : Configurer Digital Ocean App Platform

### 2.1 AccÃ©der aux Variables d'Environnement

1. Ouvrir Digital Ocean Console
2. Aller dans "Apps" â†’ SÃ©lectionner "intelia-expert"
3. Aller dans "Settings" â†’ "Environment Variables"
4. Cliquer "Edit" pour le composant LLM

---

### 2.2 Ajouter Nouvelles Variables

**Copier-coller ces variables :**

```bash
# === COHERE RERANK (+25% PRECISION) ===
COHERE_API_KEY=co-xxxxxxxxxxxxxxxxxxxxxxxx
COHERE_RERANK_MODEL=rerank-multilingual-v3.0
COHERE_RERANK_TOP_N=3

# === MULTI-LLM ROUTER (-79% COÃ›T) ===
ENABLE_LLM_ROUTING=true
DEFAULT_LLM_PROVIDER=gpt4o
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxx
DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx

# === EMBEDDINGS 3-LARGE (+15% RECALL) ===
OPENAI_EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIMENSIONS=1536
```

**âš ï¸ Remplacer les `xxx` par les vraies clÃ©s API obtenues Ã  l'Ã©tape 1**

---

### 2.3 Sauvegarder et RedÃ©marrer

1. Cliquer "Save" en bas de la page
2. Digital Ocean va automatiquement :
   - Installer les nouvelles dÃ©pendances (requirements.txt)
   - Configurer les variables d'environnement
   - RedÃ©marrer le service LLM

**DurÃ©e estimÃ©e:** 5-10 minutes

---

## ğŸ§ª Ã‰tape 3 : Valider le DÃ©ploiement

### 3.1 VÃ©rifier Logs de DÃ©marrage

**Aller dans:** Apps â†’ intelia-expert â†’ Runtime Logs

**Chercher ces messages:**
```
âœ… RAG Engine initialisÃ©
âœ… Cohere Reranker initialisÃ© (model: rerank-multilingual-v3.0)
âœ… Multi-LLM Router activÃ© (3 providers)
ğŸ“Š ModÃ¨le d'embedding: text-embedding-3-large
ğŸ“Š Dimensions: 1536
```

**Si erreur:**
- VÃ©rifier que les clÃ©s API sont correctes
- VÃ©rifier qu'il n'y a pas d'espaces avant/aprÃ¨s les clÃ©s

---

### 3.2 Tester une Query Simple

**Endpoint:** `https://votre-app.ondigitalocean.app/api/v1/query`

**cURL:**
```bash
curl -X POST https://votre-app.ondigitalocean.app/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Quel est le poids cible pour des mÃ¢les Ross 308 Ã  35 jours?",
    "language": "fr"
  }'
```

**VÃ©rifier dans la rÃ©ponse:**
- âœ… RÃ©ponse cohÃ©rente
- âœ… Score de confiance > 0.7
- âœ… Documents pertinents retournÃ©s

---

### 3.3 VÃ©rifier MÃ©triques

**Endpoint:** `https://votre-app.ondigitalocean.app/metrics`

**Chercher ces mÃ©triques:**
```
cohere_reranking_used{...} 1
llm_provider_usage{provider="deepseek"} X
llm_provider_usage{provider="claude"} Y
llm_provider_usage{provider="gpt4o"} Z
embedding_model{model="text-embedding-3-large"} 1
```

---

## ğŸ”„ Ã‰tape 4 : Migration des Embeddings

**âš ï¸ Cette Ã©tape doit Ãªtre faite APRÃˆS le redÃ©marrage du service**

### 4.1 Se Connecter au Serveur

**Option A : Console Digital Ocean**
1. Aller dans Apps â†’ intelia-expert â†’ Console
2. Cliquer "Launch Console"

**Option B : SSH (si configurÃ©)**
```bash
ssh your-server
```

---

### 4.2 Dry-Run (Test Sans Modification)

**ExÃ©cuter:**
```bash
cd /app
python scripts/migrate_embeddings.py --dry-run
```

**VÃ©rifier la sortie:**
```
ğŸ”§ Initialisation des clients...
âœ… Client OpenAI initialisÃ©
ğŸ“Š ModÃ¨le d'embedding: text-embedding-3-large
ğŸ“Š Dimensions cibles: 1536
âœ… Weaviate connectÃ©
ğŸ“Š Documents trouvÃ©s: XXXX
ğŸ” DRY RUN: XXXX documents seraient migrÃ©s
```

**Si erreur "OPENAI_API_KEY non trouvÃ©e":**
- Attendre 5 min et rÃ©essayer (variables env en cours de propagation)
- VÃ©rifier que le service a bien redÃ©marrÃ©

---

### 4.3 Migration RÃ©elle

**âš ï¸ IMPORTANT:** Cette opÃ©ration modifie tous les vecteurs dans Weaviate

**ExÃ©cuter:**
```bash
python scripts/migrate_embeddings.py --batch-size 100
```

**DurÃ©e estimÃ©e:**
- 1000 documents: ~2-3 minutes
- 5000 documents: ~10-15 minutes
- 10000 documents: ~20-25 minutes

**Suivre la progression:**
```
ğŸ“¦ Batch 1 (documents 1-100/1234)...
   âœ… Success: 100, âŒ Failed: 0
   ğŸ“Š Progress: 8.1% (100/1234) - Rate: 45.2 docs/s - ETA: 0.4 min

ğŸ“¦ Batch 2 (documents 101-200/1234)...
   âœ… Success: 100, âŒ Failed: 0
   ğŸ“Š Progress: 16.2% (200/1234) - Rate: 48.1 docs/s - ETA: 0.4 min
...
```

**RÃ©sultat attendu:**
```
======================================================================
ğŸ“Š RÃ‰SUMÃ‰ MIGRATION
======================================================================
Documents total:  1234
âœ… TraitÃ©s:        1234
âŒ Ã‰checs:         0
DurÃ©e:            25.7s (0.4 min)
Rate:             48.0 docs/s
======================================================================
ğŸ‰ Migration terminÃ©e avec succÃ¨s!
```

---

### 4.4 Validation Post-Migration

**Tester la mÃªme query qu'avant:**
```bash
curl -X POST https://votre-app.ondigitalocean.app/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Quel est le poids cible pour des mÃ¢les Ross 308 Ã  35 jours?",
    "language": "fr"
  }'
```

**Comparer:**
- Score de confiance devrait Ãªtre plus Ã©levÃ©
- Documents retournÃ©s devraient Ãªtre plus pertinents
- Temps de rÃ©ponse similaire ou meilleur

---

## ğŸ“Š Ã‰tape 5 : Ã‰valuation RAGAS (Baseline)

**âš ï¸ Cette Ã©tape est OPTIONNELLE mais fortement recommandÃ©e**

### 5.1 Installer DÃ©pendances RAGAS (si pas dÃ©jÃ  fait)

```bash
cd /app
pip install ragas==0.1.19 datasets langchain-openai
```

---

### 5.2 ExÃ©cuter Ã‰valuation Baseline

```bash
python scripts/run_ragas_evaluation.py --test-cases 5
```

**DurÃ©e:** ~2-3 minutes pour 5 cas de test

**Sortie attendue:**
```
ğŸš€ RAGAS EVALUATION - Intelia Expert LLM
ğŸ“Š GÃ©nÃ©ration dataset golden...
   âœ… 5 cas de test gÃ©nÃ©rÃ©s
ğŸ” Interrogation du systÃ¨me RAG (5 questions)...
   [1/5] Quel est le poids cible pour des mÃ¢les Ross 308 Ã  35 jours?...
   [2/5] Quel FCR est attendu pour des Ross 308 mixte Ã  42 jours?...
   ...
ğŸ“Š Ã‰valuation RAGAS en cours...

=================================================================
ğŸ“Š RAGAS EVALUATION REPORT - Intelia Expert LLM
=================================================================
Overall Score:          XX.X%

Context Precision:      XX.X%
Context Recall:         XX.X%
Faithfulness:           XX.X%
Answer Relevancy:       XX.X%
=================================================================
```

---

### 5.3 Documenter Scores Baseline

**Copier les scores dans un fichier texte pour rÃ©fÃ©rence future:**

```
Date: 2025-10-05
AprÃ¨s Quick Wins Deployment:

Overall Score: XX.X%
Context Precision: XX.X%
Context Recall: XX.X%
Faithfulness: XX.X%
Answer Relevancy: XX.X%
```

**Objectifs:**
- Overall Score: â‰¥ 85%
- Context Precision: â‰¥ 85%
- Context Recall: â‰¥ 80%
- Faithfulness: â‰¥ 90%
- Answer Relevancy: â‰¥ 85%

---

## ğŸ¯ Ã‰tape 6 : Monitoring Post-DÃ©ploiement

### 6.1 MÃ©triques Ã  Surveiller (24-48h)

**Endpoint:** `/metrics`

**KPIs:**
```bash
# Cohere Rerank usage
cohere_reranking_used

# Multi-LLM distribution
llm_provider_usage{provider="deepseek"}
llm_provider_usage{provider="claude"}
llm_provider_usage{provider="gpt4o"}

# Embeddings model
embedding_model{model="text-embedding-3-large"}

# Cache hit rate
cache_hits_total / (cache_hits_total + cache_misses_total)
```

---

### 6.2 Logs Ã  Surveiller

**Chercher ces patterns:**

**âœ… Bon signe:**
```
ğŸ”„ Cohere Rerank: 20 docs â†’ 3 docs (top ranked)
ğŸ¤– LLM Router: DeepSeek selected (PostgreSQL hit, confidence=0.95)
ğŸ“Š Embedding generated: text-embedding-3-large (1536 dims)
```

**âš ï¸ Avertissement:**
```
âš ï¸ Cohere API rate limit approached
âš ï¸ DeepSeek API error, fallback to GPT-4o
âš ï¸ Embedding generation slow (>2s)
```

**âŒ Erreur:**
```
âŒ Cohere API key invalid
âŒ Anthropic API quota exceeded
âŒ Weaviate connection failed
```

---

### 6.3 CoÃ»ts Ã  Tracker

**OpenAI (Embeddings + GPT-4o):**
- Dashboard: https://platform.openai.com/usage
- Objectif: <$15/mois (GPT-4o uniquement pour queries complexes)

**Anthropic (Claude 3.5):**
- Dashboard: https://console.anthropic.com/settings/billing
- Objectif: <$20/mois (RAG complexe et multi-docs)

**DeepSeek:**
- Dashboard: https://platform.deepseek.com/usage
- Objectif: <$3/mois (queries simples)

**Cohere:**
- Dashboard: https://dashboard.cohere.com/billing
- Objectif: Plan gratuit (1000 req/mois)

**Total attendu: ~$38/mois** (vs $180/mois avant)

---

## âœ… Checklist Finale

### Code et Configuration
- [x] Code poussÃ© sur GitHub
- [x] requirements.txt mis Ã  jour
- [ ] Variables d'environnement configurÃ©es sur Digital Ocean
- [ ] Service LLM redÃ©marrÃ©

### ClÃ©s API
- [ ] COHERE_API_KEY obtenue et configurÃ©e
- [ ] ANTHROPIC_API_KEY obtenue et configurÃ©e
- [ ] DEEPSEEK_API_KEY obtenue et configurÃ©e

### DÃ©ploiement
- [ ] Logs de dÃ©marrage vÃ©rifiÃ©s (pas d'erreur)
- [ ] Query test rÃ©ussie
- [ ] MÃ©triques `/metrics` accessibles

### Migration Embeddings
- [ ] Dry-run exÃ©cutÃ© avec succÃ¨s
- [ ] Migration rÃ©elle terminÃ©e sans erreur
- [ ] Validation post-migration (query test)

### Ã‰valuation
- [ ] RAGAS Ã©valuation baseline exÃ©cutÃ©e
- [ ] Scores documentÃ©s
- [ ] Objectifs atteints (â‰¥85% overall)

### Monitoring
- [ ] MÃ©triques surveillÃ©es 24h
- [ ] Logs surveillÃ©s (pas d'erreur rÃ©currente)
- [ ] CoÃ»ts API trackÃ©s

---

## ğŸš¨ Troubleshooting

### Erreur: "COHERE_API_KEY invalid"
**Solution:** VÃ©rifier que la clÃ© commence par `co-` et n'a pas d'espaces

### Erreur: "Anthropic API quota exceeded"
**Solution:** Ajouter crÃ©dits sur https://console.anthropic.com/settings/billing

### Erreur: "Migration failed - Weaviate connection refused"
**Solution:** VÃ©rifier `WEAVIATE_URL` et `WEAVIATE_API_KEY` dans env vars

### Erreur: "RAGAS evaluation timeout"
**Solution:** RÃ©duire nombre de cas de test: `--test-cases 3`

### Warning: "Cohere rate limit approached"
**Solution:** Passer au plan payant Cohere ou rÃ©duire `COHERE_RERANK_TOP_N=2`

---

## ğŸ“ Support

**Documentation:**
- Guide migration: `MIGRATION_EMBEDDINGS_GUIDE.md`
- Guide RAGAS: `RAGAS_IMPLEMENTATION_GUIDE.md`
- RÃ©sumÃ© Quick Wins: `QUICK_WINS_DEPLOYMENT_SUMMARY.md`

**Logs:**
- Digital Ocean: Apps â†’ intelia-expert â†’ Runtime Logs
- Fichiers locaux: `logs/` directory

**Contact:**
- GitHub Issues: intelia-expert/llm
- Email: support@intelia.com

---

## ğŸ‰ SuccÃ¨s !

Une fois toutes les Ã©tapes complÃ©tÃ©es, vous aurez :

âœ… **+25% prÃ©cision** retrieval (Cohere Rerank)
âœ… **-79% coÃ»t** LLM (Multi-LLM Router)
âœ… **+15% recall** (Embeddings 3-large)
âœ… **MÃ©triques objectives** (RAGAS)
âœ… **SystÃ¨me production-ready** pour devenir meilleur au monde

**Prochaines Ã©tapes:**
1. Monitorer 1-2 semaines
2. Fine-tuner embeddings (semaines 3-4)
3. Enrichir knowledge base (10k+ documents)
4. Atteindre 92% overall score Q1 2025

---

**Date de crÃ©ation:** 2025-10-05
**DerniÃ¨re mise Ã  jour:** 2025-10-05
**Status:** âœ… PrÃªt pour dÃ©ploiement
