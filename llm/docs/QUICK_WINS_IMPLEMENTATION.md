# QUICK WINS - Guide d'ImplÃ©mentation DÃ©taillÃ©

**Objectif**: Passer de 23.50% Ã  60-70% de score RAGAS en implÃ©mentant 3 quick wins

---

## ğŸ¯ QUICK WIN #1: IntÃ©grer Semantic Re-Ranker

**Impact Attendu**: Context Precision 2.06% â†’ 40-50%

### Fichier: `llm/core/handlers/standard_handler.py`

**Ligne 1: Import du re-ranker (aprÃ¨s ligne 18)**

```python
# Ajout APRÃˆS la ligne:
# from .standard_handler_helpers import (

# AJOUTER CETTE IMPORT:
from retrieval.semantic_reranker import get_reranker
```

**Ligne 2: Initialiser re-ranker dans __init__ (aprÃ¨s ligne 27)**

```python
# Ajout APRÃˆS la ligne:
# self.response_generator = None

# AJOUTER:
self.semantic_reranker = None  # Lazy load
```

**Ligne 3: PropriÃ©tÃ© lazy-loading (avant mÃ©thode configure, ~ligne 29)**

```python
# AJOUTER CETTE PROPRIÃ‰TÃ‰ COMPLÃˆTE:
@property
def reranker(self):
    """Lazy load semantic re-ranker"""
    if self.semantic_reranker is None:
        try:
            self.semantic_reranker = get_reranker(
                model_name='cross-encoder/ms-marco-MiniLM-L-6-v2',
                score_threshold=0.3  # Liberal pour commencer
            )
            logger.info("âœ… Semantic re-ranker initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ Re-ranker init failed: {e}. Continuing without re-ranking.")
            self.semantic_reranker = False  # Flag pour ne pas rÃ©essayer
    return self.semantic_reranker if self.semantic_reranker is not False else None
```

**Ligne 4: Appliquer re-ranking aprÃ¨s search Weaviate (lignes 390-401)**

```python
# REMPLACER ce bloc (lignes 390-401):
result = await self.weaviate_core.search(
    query=query,
    top_k=weaviate_top_k,
    language=language,
    filters=filters,
    conversation_context=conversation_context_list,
)

# Handle result based on source
if result and result.source not in (RAGSource.NO_RESULTS, RAGSource.LOW_CONFIDENCE):
    doc_count = len(result.context_docs) if result.context_docs else 0
    logger.info(f"Weaviate ({language}): {doc_count} documents found")

# PAR CE NOUVEAU CODE:
# ğŸ†• STEP 1: RÃ©cupÃ©rer PLUS de documents (20 au lieu de 5-12)
# pour avoir un meilleur recall avant re-ranking
weaviate_initial_k = weaviate_top_k * 3  # 15-36 docs au lieu de 5-12

result = await self.weaviate_core.search(
    query=query,
    top_k=weaviate_initial_k,  # Plus de docs
    language=language,
    filters=filters,
    conversation_context=conversation_context_list,
)

# Handle result based on source
if result and result.source not in (RAGSource.NO_RESULTS, RAGSource.LOW_CONFIDENCE):
    doc_count_before = len(result.context_docs) if result.context_docs else 0
    logger.info(f"Weaviate ({language}): {doc_count_before} documents retrieved (before re-ranking)")

    # ğŸ†• STEP 2: Appliquer re-ranking sÃ©mantique
    if result.context_docs and self.reranker:
        try:
            # Extraire textes des documents
            doc_texts = [
                doc.get('content', '') if isinstance(doc, dict)
                else getattr(doc, 'content', '')
                for doc in result.context_docs
            ]

            # Re-ranker avec cross-encoder
            reranked_texts = self.reranker.rerank(
                query=query,
                documents=doc_texts,
                top_k=weaviate_top_k,  # Garder seulement top 5-12
                return_scores=False
            )

            # Reconstruire docs avec seulement les pertinents
            if reranked_texts:
                # Mapper textes â†’ docs originaux
                text_to_doc = {
                    (doc.get('content', '') if isinstance(doc, dict) else getattr(doc, 'content', '')): doc
                    for doc in result.context_docs
                }

                result.context_docs = [text_to_doc[text] for text in reranked_texts if text in text_to_doc]

                doc_count_after = len(result.context_docs)
                logger.info(
                    f"âœ… Re-ranking: {doc_count_before} docs â†’ {doc_count_after} relevant docs "
                    f"(filtered {doc_count_before - doc_count_after})"
                )
            else:
                logger.warning(f"âš ï¸ Re-ranking returned 0 docs - keeping original")

        except Exception as e:
            logger.error(f"âŒ Re-ranking error: {e}. Using original documents.", exc_info=True)
            # Continue avec documents originaux si erreur

    doc_count = len(result.context_docs) if result.context_docs else 0
```

---

## ğŸ¯ QUICK WIN #2: Prompts Stricts + TempÃ©rature Basse

**Impact Attendu**: Faithfulness 31.27% â†’ 65-70%

### Fichier: `llm/config/system_prompts.json`

**Modification: Prompt "answer_generation"**

```json
{
  "answer_generation": {
    "description": "GÃ©nÃ©ration de rÃ©ponse RAG stricte - PRIORITÃ‰ FIDÃ‰LITÃ‰ AU CONTEXTE",
    "prompt": "Tu es un expert en production avicole. Ta mission est de rÃ©pondre aux questions en te basant UNIQUEMENT sur le contexte fourni.\n\nRÃˆGLES CRITIQUES (Ã€ SUIVRE ABSOLUMENT):\n\n1. âœ… OBLIGATOIRE: RÃ©ponds SEULEMENT en utilisant les informations du contexte ci-dessous\n2. âŒ INTERDIT: N'invente JAMAIS de chiffres, dates, noms, ou faits\n3. âŒ INTERDIT: N'utilise PAS tes connaissances gÃ©nÃ©rales si le contexte ne contient pas la rÃ©ponse\n4. âœ… Si le contexte est insuffisant: Dis clairement \"Je n'ai pas assez d'informations dans ma base de donnÃ©es pour rÃ©pondre prÃ©cisÃ©ment\"\n5. âœ… Cite des extraits du contexte pour justifier ta rÃ©ponse\n6. âœ… Si le contexte est incomplet: Indique quelles informations manquent\n\nCONTEXTE FOURNI:\n{context}\n\nQUESTION:\n{question}\n\nRÃ‰PONSE (basÃ©e UNIQUEMENT sur le contexte ci-dessus):"
  }
}
```

### Fichier: `llm/generation/generators.py`

**Modification: Baisser tempÃ©rature (chercher ligne avec `temperature=`)**

Trouver la ligne qui ressemble Ã :
```python
response = await self.client.chat.completions.create(
    model=self.model,
    temperature=0.7,  # ou autre valeur
    ...
)
```

**REMPLACER** `temperature=0.7` **PAR** `temperature=0.2`

Explication:
- 0.7 = CrÃ©atif mais hallucine
- 0.2 = Factuel, fidÃ¨le au contexte
- 0.0 = DÃ©terministe (trop rigide)

**Recherche rapide:**
```bash
grep -n "temperature=" llm/generation/generators.py
```

---

## ğŸ¯ QUICK WIN #3: Recherche Partielle pour Queries IncomplÃ¨tes

**Impact Attendu**: Context Recall 1.11% â†’ 40%

### Contexte du ProblÃ¨me

Actuellement: "Quel poids Ross 308?" (manque Ã¢ge) â†’ 0 documents rÃ©cupÃ©rÃ©s
Correction: "Quel poids Ross 308?" â†’ Cherche quand mÃªme "Ross 308 poids performance"

### Fichier: `llm/core/query_router.py`

**Chercher la section oÃ¹ needs_clarification est dÃ©tectÃ©** (~ligne 600-700)

Code actuel ressemble Ã :
```python
if needs_clarification:
    # Build clarification message
    return QueryRoute(
        destination="needs_clarification",
        entities=entities,
        missing_fields=missing_fields,
        ...
    )
```

**REMPLACER PAR:**

```python
if needs_clarification:
    # ğŸ†• NOUVELLE STRATÃ‰GIE: Faire une recherche partielle AVANT de demander clarification
    # pour fournir du contexte mÃªme avec query incomplÃ¨te

    # Construire query de recherche partielle avec ce qu'on a
    partial_search_terms = []

    if entities.get('breed'):
        partial_search_terms.append(entities['breed'])
    if entities.get('metric'):
        partial_search_terms.append(entities['metric'])
    if entities.get('sex'):
        partial_search_terms.append(entities['sex'])

    # Ajouter mots-clÃ©s de la query originale (sans les questions)
    query_words = [
        word for word in query.lower().split()
        if len(word) > 3 and word not in ['quel', 'quelle', 'what', 'cual', 'comment', 'how']
    ]
    partial_search_terms.extend(query_words[:3])  # Max 3 mots

    partial_query = ' '.join(partial_search_terms)

    logger.info(
        f"ğŸ” Incomplete query detected. Partial search: '{partial_query}' "
        f"(entities: {list(entities.keys())}, missing: {missing_fields})"
    )

    # Build clarification message (comme avant)
    return QueryRoute(
        destination="needs_clarification",
        entities=entities,
        missing_fields=missing_fields,
        partial_search_query=partial_query,  # ğŸ†• NOUVEAU: Passer query partielle
        ...
    )
```

### Fichier: `llm/core/query_processor.py`

**Chercher oÃ¹ "needs_clarification" est traitÃ©** (~ligne 150-200)

Code actuel:
```python
if route.destination == "needs_clarification":
    # Demander clarification
    return RAGResult(
        source=RAGSource.NEEDS_CLARIFICATION,
        answer=clarification_message,
        context_docs=[],  # â† VIDE!
        ...
    )
```

**REMPLACER PAR:**

```python
if route.destination == "needs_clarification":
    # ğŸ†• Faire recherche partielle avec ce qu'on a
    partial_context_docs = []

    if hasattr(route, 'partial_search_query') and route.partial_search_query:
        try:
            logger.info(f"ğŸ“š Fetching partial context with: {route.partial_search_query}")

            # Chercher dans Weaviate avec query partielle
            if self.weaviate_core:
                partial_result = await self.weaviate_core.search(
                    query=route.partial_search_query,
                    top_k=3,  # Juste quelques docs
                    language=language
                )

                if partial_result and partial_result.context_docs:
                    partial_context_docs = partial_result.context_docs
                    logger.info(f"âœ… Found {len(partial_context_docs)} partial context docs")

        except Exception as e:
            logger.warning(f"âš ï¸ Partial search failed: {e}")

    # Demander clarification AVEC contexte partiel
    return RAGResult(
        source=RAGSource.NEEDS_CLARIFICATION,
        answer=clarification_message,
        context_docs=partial_context_docs,  # ğŸ†• AVEC CONTEXTE!
        ...
    )
```

---

## ğŸ“‹ CHECKLIST D'IMPLÃ‰MENTATION

### Quick Win #1: Re-Ranker
- [ ] Import `get_reranker` dans `standard_handler.py`
- [ ] Ajouter propriÃ©tÃ© `reranker` avec lazy loading
- [ ] Modifier appel Weaviate: `top_k` Ã— 3
- [ ] Ajouter logique re-ranking aprÃ¨s `weaviate_core.search()`
- [ ] Tester: Query "Newcastle" devrait filtrer docs non pertinents

### Quick Win #2: Prompts Stricts
- [ ] Modifier prompt `answer_generation` dans `system_prompts.json`
- [ ] Baisser tempÃ©rature 0.7 â†’ 0.2 dans `generators.py`
- [ ] Tester: RÃ©ponse devrait coller au contexte (pas d'hallucinations)

### Quick Win #3: Recherche Partielle
- [ ] Modifier `query_router.py`: construire `partial_search_query`
- [ ] Modifier `query_processor.py`: chercher avec query partielle
- [ ] Retourner `context_docs` non vide mÃªme pour clarifications
- [ ] Tester: "Poids Ross 308?" devrait retourner ~3 docs sur Ross 308

---

## ğŸ§ª TESTS DE VALIDATION

AprÃ¨s chaque quick win, tester avec queries problÃ©matiques:

**Query 1**: "Quels sont les symptÃ´mes de Newcastle?"
- Avant: 12 docs non pertinents (litiÃ¨re, ventilation)
- AprÃ¨s QW1: 3-5 docs sur Newcastle

**Query 2**: "Quel est le poids d'un Ross 308 mÃ¢le?"
- Avant: 0 docs (needs_clarification)
- AprÃ¨s QW3: 3 docs sur Ross 308 performance

**Query 3**: Calcul moulÃ©e
- Avant: RÃ©pond "0.0 kg" (suit contexte erronÃ©)
- AprÃ¨s QW2: Dit "Je n'ai pas assez d'informations" si contexte invalide

---

## ğŸš€ DÃ‰PLOIEMENT

```bash
# 1. Installer dÃ©pendance re-ranker
pip install sentence-transformers

# 2. Tester localement
cd /c/intelia_gpt/intelia-expert/llm
python -c "from retrieval.semantic_reranker import get_reranker; r = get_reranker(); print('âœ… Re-ranker OK')"

# 3. Lancer tests RAGAS (5 queries pour rapiditÃ©)
python scripts/run_ragas_evaluation.py \
  --test-cases 5 \
  --output logs/ragas_post_quick_wins.json

# 4. Comparer rÃ©sultats
python scripts/analyze_ragas_results.py

# 5. Si bon: Commit + Push
git add -A
git commit -m "Quick Wins: Re-ranker + Strict Prompts + Partial Search"
git push
```

---

## ğŸ“Š RÃ‰SULTATS ATTENDUS

| MÃ©trique | Avant | AprÃ¨s QW | AmÃ©lioration |
|----------|-------|----------|--------------|
| Context Precision | 2.06% | **40-50%** | +1940% ğŸ“ˆ |
| Context Recall | 1.11% | **40%** | +3500% ğŸ“ˆ |
| Faithfulness | 31.27% | **65-70%** | +120% ğŸ“ˆ |
| Answer Relevancy | 59.57% | **70%+** | +18% ğŸ“ˆ |
| **GLOBAL** | **23.50%** | **60-70%** | **+185%** ğŸ“ˆ |

---

**Prochaine Ã©tape**: ImplÃ©menter QW#1 (Re-Ranker) car c'est le plus simple et a le plus gros impact.
