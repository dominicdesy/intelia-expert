# QUICK WINS - Guide d'Impl√©mentation D√©taill√©

**Objectif**: Passer de 23.50% √† 60-70% de score RAGAS en impl√©mentant 3 quick wins

---

## üéØ QUICK WIN #1: Int√©grer Semantic Re-Ranker

**Impact Attendu**: Context Precision 2.06% ‚Üí 40-50%

### Fichier: `llm/core/handlers/standard_handler.py`

**Ligne 1: Import du re-ranker (apr√®s ligne 18)**

```python
# Ajout APR√àS la ligne:
# from .standard_handler_helpers import (

# AJOUTER CETTE IMPORT:
from retrieval.semantic_reranker import get_reranker
```

**Ligne 2: Initialiser re-ranker dans __init__ (apr√®s ligne 27)**

```python
# Ajout APR√àS la ligne:
# self.response_generator = None

# AJOUTER:
self.semantic_reranker = None  # Lazy load
```

**Ligne 3: Propri√©t√© lazy-loading (avant m√©thode configure, ~ligne 29)**

```python
# AJOUTER CETTE PROPRI√âT√â COMPL√àTE:
@property
def reranker(self):
    """Lazy load semantic re-ranker"""
    if self.semantic_reranker is None:
        try:
            self.semantic_reranker = get_reranker(
                model_name='cross-encoder/ms-marco-MiniLM-L-6-v2',
                score_threshold=0.3  # Liberal pour commencer
            )
            logger.info("‚úÖ Semantic re-ranker initialized")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Re-ranker init failed: {e}. Continuing without re-ranking.")
            self.semantic_reranker = False  # Flag pour ne pas r√©essayer
    return self.semantic_reranker if self.semantic_reranker is not False else None
```

**Ligne 4: Appliquer re-ranking apr√®s search Weaviate (lignes 390-401)**

```python
# REMPLACER ce bloc (lignes 390-401):
result = await self.weaviate_core.search(
    query=query,
    top_k=weaviate_top_k,
    language=language,
    filters=filters,
    conversation_context=conversation_context_list,
)

# Handle result based on source
if result and result.source not in (RAGSource.NO_RESULTS, RAGSource.LOW_CONFIDENCE):
    doc_count = len(result.context_docs) if result.context_docs else 0
    logger.info(f"Weaviate ({language}): {doc_count} documents found")

# PAR CE NOUVEAU CODE:
# üÜï STEP 1: R√©cup√©rer PLUS de documents (20 au lieu de 5-12)
# pour avoir un meilleur recall avant re-ranking
weaviate_initial_k = weaviate_top_k * 3  # 15-36 docs au lieu de 5-12

result = await self.weaviate_core.search(
    query=query,
    top_k=weaviate_initial_k,  # Plus de docs
    language=language,
    filters=filters,
    conversation_context=conversation_context_list,
)

# Handle result based on source
if result and result.source not in (RAGSource.NO_RESULTS, RAGSource.LOW_CONFIDENCE):
    doc_count_before = len(result.context_docs) if result.context_docs else 0
    logger.info(f"Weaviate ({language}): {doc_count_before} documents retrieved (before re-ranking)")

    # üÜï STEP 2: Appliquer re-ranking s√©mantique
    if result.context_docs and self.reranker:
        try:
            # Extraire textes des documents
            doc_texts = [
                doc.get('content', '') if isinstance(doc, dict)
                else getattr(doc, 'content', '')
                for doc in result.context_docs
            ]

            # Re-ranker avec cross-encoder
            reranked_texts = self.reranker.rerank(
                query=query,
                documents=doc_texts,
                top_k=weaviate_top_k,  # Garder seulement top 5-12
                return_scores=False
            )

            # Reconstruire docs avec seulement les pertinents
            if reranked_texts:
                # Mapper textes ‚Üí docs originaux
                text_to_doc = {
                    (doc.get('content', '') if isinstance(doc, dict) else getattr(doc, 'content', '')): doc
                    for doc in result.context_docs
                }

                result.context_docs = [text_to_doc[text] for text in reranked_texts if text in text_to_doc]

                doc_count_after = len(result.context_docs)
                logger.info(
                    f"‚úÖ Re-ranking: {doc_count_before} docs ‚Üí {doc_count_after} relevant docs "
                    f"(filtered {doc_count_before - doc_count_after})"
                )
            else:
                logger.warning(f"‚ö†Ô∏è Re-ranking returned 0 docs - keeping original")

        except Exception as e:
            logger.error(f"‚ùå Re-ranking error: {e}. Using original documents.", exc_info=True)
            # Continue avec documents originaux si erreur

    doc_count = len(result.context_docs) if result.context_docs else 0
```

---

## üéØ QUICK WIN #2: Prompts Stricts + Temp√©rature Basse

**Impact Attendu**: Faithfulness 31.27% ‚Üí 65-70%

### Fichier: `llm/config/system_prompts.json`

**Modification: Prompt "answer_generation"**

```json
{
  "answer_generation": {
    "description": "G√©n√©ration de r√©ponse RAG stricte - PRIORIT√â FID√âLIT√â AU CONTEXTE",
    "prompt": "Tu es un expert en production avicole. Ta mission est de r√©pondre aux questions en te basant UNIQUEMENT sur le contexte fourni.\n\nR√àGLES CRITIQUES (√Ä SUIVRE ABSOLUMENT):\n\n1. ‚úÖ OBLIGATOIRE: R√©ponds SEULEMENT en utilisant les informations du contexte ci-dessous\n2. ‚ùå INTERDIT: N'invente JAMAIS de chiffres, dates, noms, ou faits\n3. ‚ùå INTERDIT: N'utilise PAS tes connaissances g√©n√©rales si le contexte ne contient pas la r√©ponse\n4. ‚úÖ Si le contexte est insuffisant: Dis clairement \"Je n'ai pas assez d'informations dans ma base de donn√©es pour r√©pondre pr√©cis√©ment\"\n5. ‚úÖ Cite des extraits du contexte pour justifier ta r√©ponse\n6. ‚úÖ Si le contexte est incomplet: Indique quelles informations manquent\n\nCONTEXTE FOURNI:\n{context}\n\nQUESTION:\n{question}\n\nR√âPONSE (bas√©e UNIQUEMENT sur le contexte ci-dessus):"
  }
}
```

### Fichier: `llm/generation/generators.py`

**Modification: Baisser temp√©rature (chercher ligne avec `temperature=`)**

Trouver la ligne qui ressemble √†:
```python
response = await self.client.chat.completions.create(
    model=self.model,
    temperature=0.7,  # ou autre valeur
    ...
)
```

**REMPLACER** `temperature=0.7` **PAR** `temperature=0.2`

Explication:
- 0.7 = Cr√©atif mais hallucine
- 0.2 = Factuel, fid√®le au contexte
- 0.0 = D√©terministe (trop rigide)

**Recherche rapide:**
```bash
grep -n "temperature=" llm/generation/generators.py
```

---

## üéØ QUICK WIN #3: Recherche Partielle pour Queries Incompl√®tes

**Impact Attendu**: Context Recall 1.11% ‚Üí 40%

### Contexte du Probl√®me

Actuellement: "Quel poids Ross 308?" (manque √¢ge) ‚Üí 0 documents r√©cup√©r√©s
Correction: "Quel poids Ross 308?" ‚Üí Cherche quand m√™me "Ross 308 poids performance"

### Fichier: `llm/core/query_router.py`

**Chercher la section o√π needs_clarification est d√©tect√©** (~ligne 600-700)

Code actuel ressemble √†:
```python
if needs_clarification:
    # Build clarification message
    return QueryRoute(
        destination="needs_clarification",
        entities=entities,
        missing_fields=missing_fields,
        ...
    )
```

**REMPLACER PAR:**

```python
if needs_clarification:
    # üÜï NOUVELLE STRAT√âGIE: Faire une recherche partielle AVANT de demander clarification
    # pour fournir du contexte m√™me avec query incompl√®te

    # Construire query de recherche partielle avec ce qu'on a
    partial_search_terms = []

    if entities.get('breed'):
        partial_search_terms.append(entities['breed'])
    if entities.get('metric'):
        partial_search_terms.append(entities['metric'])
    if entities.get('sex'):
        partial_search_terms.append(entities['sex'])

    # Ajouter mots-cl√©s de la query originale (sans les questions)
    query_words = [
        word for word in query.lower().split()
        if len(word) > 3 and word not in ['quel', 'quelle', 'what', 'cual', 'comment', 'how']
    ]
    partial_search_terms.extend(query_words[:3])  # Max 3 mots

    partial_query = ' '.join(partial_search_terms)

    logger.info(
        f"üîç Incomplete query detected. Partial search: '{partial_query}' "
        f"(entities: {list(entities.keys())}, missing: {missing_fields})"
    )

    # Build clarification message (comme avant)
    return QueryRoute(
        destination="needs_clarification",
        entities=entities,
        missing_fields=missing_fields,
        partial_search_query=partial_query,  # üÜï NOUVEAU: Passer query partielle
        ...
    )
```

### Fichier: `llm/core/query_processor.py`

**Chercher o√π "needs_clarification" est trait√©** (~ligne 150-200)

Code actuel:
```python
if route.destination == "needs_clarification":
    # Demander clarification
    return RAGResult(
        source=RAGSource.NEEDS_CLARIFICATION,
        answer=clarification_message,
        context_docs=[],  # ‚Üê VIDE!
        ...
    )
```

**REMPLACER PAR:**

```python
if route.destination == "needs_clarification":
    # üÜï Faire recherche partielle avec ce qu'on a
    partial_context_docs = []

    if hasattr(route, 'partial_search_query') and route.partial_search_query:
        try:
            logger.info(f"üìö Fetching partial context with: {route.partial_search_query}")

            # Chercher dans Weaviate avec query partielle
            if self.weaviate_core:
                partial_result = await self.weaviate_core.search(
                    query=route.partial_search_query,
                    top_k=3,  # Juste quelques docs
                    language=language
                )

                if partial_result and partial_result.context_docs:
                    partial_context_docs = partial_result.context_docs
                    logger.info(f"‚úÖ Found {len(partial_context_docs)} partial context docs")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Partial search failed: {e}")

    # Demander clarification AVEC contexte partiel
    return RAGResult(
        source=RAGSource.NEEDS_CLARIFICATION,
        answer=clarification_message,
        context_docs=partial_context_docs,  # üÜï AVEC CONTEXTE!
        ...
    )
```

---

## üìã CHECKLIST D'IMPL√âMENTATION

### Quick Win #1: Re-Ranker
- [ ] Import `get_reranker` dans `standard_handler.py`
- [ ] Ajouter propri√©t√© `reranker` avec lazy loading
- [ ] Modifier appel Weaviate: `top_k` √ó 3
- [ ] Ajouter logique re-ranking apr√®s `weaviate_core.search()`
- [ ] Tester: Query "Newcastle" devrait filtrer docs non pertinents

### Quick Win #2: Prompts Stricts
- [ ] Modifier prompt `answer_generation` dans `system_prompts.json`
- [ ] Baisser temp√©rature 0.7 ‚Üí 0.2 dans `generators.py`
- [ ] Tester: R√©ponse devrait coller au contexte (pas d'hallucinations)

### Quick Win #3: Recherche Partielle
- [ ] Modifier `query_router.py`: construire `partial_search_query`
- [ ] Modifier `query_processor.py`: chercher avec query partielle
- [ ] Retourner `context_docs` non vide m√™me pour clarifications
- [ ] Tester: "Poids Ross 308?" devrait retourner ~3 docs sur Ross 308

---

## üß™ TESTS DE VALIDATION

Apr√®s chaque quick win, tester avec queries probl√©matiques:

**Query 1**: "Quels sont les sympt√¥mes de Newcastle?"
- Avant: 12 docs non pertinents (liti√®re, ventilation)
- Apr√®s QW1: 3-5 docs sur Newcastle

**Query 2**: "Quel est le poids d'un Ross 308 m√¢le?"
- Avant: 0 docs (needs_clarification)
- Apr√®s QW3: 3 docs sur Ross 308 performance

**Query 3**: Calcul moul√©e
- Avant: R√©pond "0.0 kg" (suit contexte erron√©)
- Apr√®s QW2: Dit "Je n'ai pas assez d'informations" si contexte invalide

---

## üöÄ D√âPLOIEMENT

```bash
# 1. Installer d√©pendance re-ranker
pip install sentence-transformers

# 2. Tester localement
cd /c/intelia_gpt/intelia-expert/llm
python -c "from retrieval.semantic_reranker import get_reranker; r = get_reranker(); print('‚úÖ Re-ranker OK')"

# 3. Lancer tests RAGAS (5 queries pour rapidit√©)
python scripts/run_ragas_evaluation.py \
  --test-cases 5 \
  --output logs/ragas_post_quick_wins.json

# 4. Comparer r√©sultats
python scripts/analyze_ragas_results.py

# 5. Si bon: Commit + Push
git add -A
git commit -m "Quick Wins: Re-ranker + Strict Prompts + Partial Search"
git push
```

---

## üìä R√âSULTATS ATTENDUS

| M√©trique | Avant | Apr√®s QW | Am√©lioration |
|----------|-------|----------|--------------|
| Context Precision | 2.06% | **40-50%** | +1940% üìà |
| Context Recall | 1.11% | **40%** | +3500% üìà |
| Faithfulness | 31.27% | **65-70%** | +120% üìà |
| Answer Relevancy | 59.57% | **70%+** | +18% üìà |
| **GLOBAL** | **23.50%** | **60-70%** | **+185%** üìà |

---

**Prochaine √©tape**: Impl√©menter QW#1 (Re-Ranker) car c'est le plus simple et a le plus gros impact.
