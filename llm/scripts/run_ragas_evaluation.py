#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
run_ragas_evaluation.py - Script d'√©valuation RAGAS pour Intelia Expert

√âvalue le syst√®me RAG avec un dataset de questions avicoles.
G√©n√®re un rapport d√©taill√© avec scores RAGAS.

Usage:
    python scripts/run_ragas_evaluation.py [--test-cases N] [--output PATH]

Options:
    --test-cases N    Nombre de cas de test (d√©faut: tous)
    --output PATH     Chemin fichier de sortie (d√©faut: logs/ragas_evaluation_{timestamp}.json)
    --llm MODEL       Mod√®le LLM √©valuateur (d√©faut: gpt-4o)
"""

import asyncio
import os
import sys
import argparse
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

# Ajouter r√©pertoire parent au path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Imports apr√®s path setup
from evaluation.ragas_evaluator import RAGASEvaluator
from evaluation.golden_dataset_intelia import get_intelia_test_dataset

# Import du syst√®me RAG r√©el
try:
    from core.rag_engine import InteliaRAGEngine

    RAG_ENGINE_AVAILABLE = True
except ImportError:
    RAG_ENGINE_AVAILABLE = False
    logging.warning("‚ö†Ô∏è InteliaRAGEngine non disponible, mode simulation")

# Configuration logging
os.makedirs("logs", exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(
            f'logs/ragas_evaluation_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        ),
    ],
)
logger = logging.getLogger(__name__)


async def query_rag_system(
    question: str, rag_engine: Optional[object] = None
) -> Dict[str, Any]:
    """
    Interroge le syst√®me RAG et retourne r√©ponse + contextes.

    Args:
        question: Question √† poser
        rag_engine: Instance de InteliaRAGEngine (optionnel)

    Returns:
        Dictionnaire avec:
            - answer: R√©ponse g√©n√©r√©e (str)
            - contexts: Liste de contextes r√©cup√©r√©s (List[str])
    """
    if rag_engine and RAG_ENGINE_AVAILABLE:
        try:
            # Appel r√©el au RAG (m√©thode correcte: generate_response)
            result = await rag_engine.generate_response(
                query=question,
                language="fr",  # D√©tection automatique dans le vrai syst√®me
                conversation_id=f"ragas_eval_{datetime.now().timestamp()}",
            )

            # Extraire answer (RAGResult.answer)
            answer = result.answer or "[PAS DE R√âPONSE]"

            # Extraire contextes des documents (RAGResult.context_docs: List[Dict])
            contexts = []
            for doc in result.context_docs:
                # doc est un dictionnaire avec 'content' ou 'text'
                content = doc.get("content") or doc.get("text") or doc.get("page_content", "")
                if content:
                    contexts.append(content)

            return {"answer": answer, "contexts": contexts}

        except Exception as e:
            logger.error(f"‚ùå Erreur query RAG: {e}", exc_info=True)
            return {"answer": f"[ERREUR: {str(e)}]", "contexts": []}
    else:
        # Mode simulation (si RAG non disponible)
        logger.warning(f"‚ö†Ô∏è Simulation r√©ponse pour: {question[:50]}...")
        return {
            "answer": f"[SIMULATION] R√©ponse pour: {question}",
            "contexts": [
                f"[SIMULATION] Contexte 1 pour {question}",
                f"[SIMULATION] Contexte 2 pour {question}",
            ],
        }


async def run_evaluation(
    num_test_cases: int = None,
    output_path: str = None,
    llm_model: str = "gpt-4o",
    use_real_rag: bool = True,
):
    """
    Ex√©cute l'√©valuation RAGAS compl√®te.

    Args:
        num_test_cases: Nombre de cas de test (None = tous)
        output_path: Chemin fichier de sortie
        llm_model: Mod√®le LLM √©valuateur
        use_real_rag: Utiliser vrai RAG (True) ou simulation (False)
    """
    logger.info("=" * 70)
    logger.info("üöÄ RAGAS EVALUATION - Intelia Expert LLM")
    logger.info("=" * 70)

    # G√©n√©rer dataset golden
    logger.info("üìä Chargement dataset golden Intelia...")
    golden_dataset = get_intelia_test_dataset()

    # Limiter nombre de cas si sp√©cifi√©
    if num_test_cases:
        golden_dataset = golden_dataset[:num_test_cases]
        logger.info(f"   Limit√© √† {num_test_cases} cas de test")

    logger.info(f"   ‚úÖ {len(golden_dataset)} cas de test g√©n√©r√©s")

    # Initialiser RAG engine si disponible
    rag_engine = None
    if use_real_rag and RAG_ENGINE_AVAILABLE:
        try:
            logger.info("üîß Initialisation InteliaRAGEngine...")
            rag_engine = InteliaRAGEngine()
            await rag_engine.initialize()
            logger.info("   ‚úÖ RAG Engine initialis√©")
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è Impossible d'initialiser RAG: {e}")
            logger.info("   ‚Üí Mode simulation activ√©")
            rag_engine = None
    else:
        logger.info("üîç Mode simulation (RAG Engine non disponible)")

    # Interroger le RAG pour chaque cas
    logger.info(f"üîç Interrogation du syst√®me RAG ({len(golden_dataset)} questions)...")

    for i, case in enumerate(golden_dataset, 1):
        logger.info(f"   [{i}/{len(golden_dataset)}] {case['question'][:60]}...")

        # Query RAG
        rag_result = await query_rag_system(
            question=case["question"], rag_engine=rag_engine
        )

        # Mettre √† jour cas de test
        case["answer"] = rag_result["answer"]
        case["contexts"] = rag_result["contexts"]

        # Pause pour √©viter rate limiting
        await asyncio.sleep(0.5)

    logger.info("   ‚úÖ Toutes les questions trait√©es")

    # Initialiser √©valuateur RAGAS
    logger.info(f"üîß Initialisation RAGASEvaluator (mod√®le: {llm_model})...")
    evaluator = RAGASEvaluator(llm_model=llm_model, temperature=0.0)
    logger.info("   ‚úÖ √âvaluateur initialis√©")

    # √âvaluer avec RAGAS
    logger.info("üìä √âvaluation RAGAS en cours...")
    results = await evaluator.evaluate_async(golden_dataset)

    # Afficher r√©sum√©
    print("\n" + results["summary"])

    # Sauvegarder r√©sultats
    if not output_path:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = f"logs/ragas_evaluation_{timestamp}.json"

    evaluator.save_results(results, output_path)

    logger.info(f"üíæ R√©sultats sauvegard√©s: {output_path}")

    # Cleanup RAG engine
    if rag_engine:
        try:
            await rag_engine.close()
            logger.info("‚úÖ RAG Engine ferm√©")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur fermeture RAG: {e}")

    logger.info("=" * 70)
    logger.info("‚úÖ √âVALUATION TERMIN√âE")
    logger.info("=" * 70)

    return results


def main():
    """Point d'entr√©e principal"""

    # Parser arguments
    parser = argparse.ArgumentParser(
        description="√âvaluation RAGAS pour Intelia Expert LLM"
    )
    parser.add_argument(
        "--test-cases",
        type=int,
        default=None,
        help="Nombre de cas de test (d√©faut: tous)",
    )
    parser.add_argument(
        "--output", type=str, default=None, help="Chemin fichier de sortie JSON"
    )
    parser.add_argument(
        "--llm",
        type=str,
        default="gpt-4o",
        help="Mod√®le LLM √©valuateur (d√©faut: gpt-4o)",
    )
    parser.add_argument(
        "--simulate",
        action="store_true",
        help="Mode simulation (ne pas utiliser vrai RAG)",
    )

    args = parser.parse_args()

    # V√©rifier variable d'environnement OpenAI
    if not os.getenv("OPENAI_API_KEY"):
        logger.error("‚ùå OPENAI_API_KEY non configur√©e")
        sys.exit(1)

    # Ex√©cuter √©valuation
    try:
        asyncio.run(
            run_evaluation(
                num_test_cases=args.test_cases,
                output_path=args.output,
                llm_model=args.llm,
                use_real_rag=not args.simulate,
            )
        )
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è √âvaluation interrompue par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    # Compatibilit√© Windows
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    main()
