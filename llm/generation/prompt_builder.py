# -*- coding: utf-8 -*-
"""
prompt_builder.py - Constructeur de prompts sp√©cialis√©s
Version 2.0 - Utilise system_prompts.json centralis√©
"""

import logging
from typing import Dict, Optional, Any

from processing.intent_types import IntentType, IntentResult

# Import du gestionnaire de prompts centralis√©
try:
    from llm.config.system_prompts import get_prompts_manager

    PROMPTS_AVAILABLE = True
except ImportError:
    logging.warning("SystemPromptsManager non disponible, utilisation prompts fallback")
    PROMPTS_AVAILABLE = False

logger = logging.getLogger(__name__)


class PromptBuilder:
    """
    Constructeur de prompts sp√©cialis√©s pour les diff√©rents types d'intentions
    Version 2.0: Charge les prompts depuis system_prompts.json
    """

    def __init__(
        self,
        intents_config: dict,
        language: str = "fr",
        prompts_path: Optional[str] = None,
    ):
        """
        Initialise le constructeur de prompts

        Args:
            intents_config: Configuration des intentions (h√©ritage)
            language: Langue par d√©faut ("fr" ou "en")
            prompts_path: Chemin custom vers system_prompts.json (optionnel)
        """
        self.intents_config = intents_config
        self.language = language

        # Charger le gestionnaire de prompts centralis√©
        if PROMPTS_AVAILABLE:
            try:
                if prompts_path:
                    self.prompts_manager = get_prompts_manager(prompts_path)
                else:
                    self.prompts_manager = get_prompts_manager()
                logger.info("‚úÖ PromptBuilder initialis√© avec system_prompts.json")
            except Exception as e:
                logger.error(f"‚ùå Erreur chargement prompts: {e}")
                self.prompts_manager = None
        else:
            self.prompts_manager = None
            logger.warning("‚ö†Ô∏è PromptBuilder en mode fallback (prompts hardcod√©s)")

    def build_specialized_prompt(
        self, intent_result: IntentResult, language: Optional[str] = None
    ) -> Optional[str]:
        """
        G√©n√®re un prompt sp√©cialis√© selon le type d'intention

        Args:
            intent_result: R√©sultat de la classification d'intention
            language: Langue (override du d√©faut)

        Returns:
            Prompt sp√©cialis√© ou None
        """
        intent_type = intent_result.intent_type
        entities = intent_result.detected_entities
        lang = language or self.language

        # Mapping IntentType ‚Üí cl√© prompt
        intent_to_prompt_key = {
            IntentType.METRIC_QUERY: "metric_query",
            IntentType.ENVIRONMENT_SETTING: "environment_setting",
            IntentType.DIAGNOSIS_TRIAGE: "diagnosis_triage",
            IntentType.ECONOMICS_COST: "economics_cost",
            IntentType.PROTOCOL_QUERY: "protocol_query",
            IntentType.GENERAL_POULTRY: "general_poultry",
        }

        prompt_key = intent_to_prompt_key.get(intent_type)

        if not prompt_key:
            logger.warning(f"Type d'intention non support√©: {intent_type}")
            return None

        # R√©cup√©rer le prompt depuis le gestionnaire centralis√©
        if self.prompts_manager:
            base_prompt = self.prompts_manager.get_specialized_prompt(prompt_key, lang)

            if not base_prompt:
                logger.warning(
                    f"Prompt non trouv√© pour {prompt_key}/{lang}, "
                    f"utilisation fallback"
                )
                base_prompt = self._get_fallback_prompt(prompt_key)
        else:
            # Fallback si gestionnaire non disponible
            base_prompt = self._get_fallback_prompt(prompt_key)

        if not base_prompt:
            logger.error(f"Impossible de g√©n√©rer prompt pour {prompt_key}")
            return None

        # Enrichissement contextuel avec entit√©s et m√©triques
        if entities:
            entity_context = self._build_entity_context(entities)
            expansion_context = self._build_expansion_context(
                intent_result.expansion_quality
            )
            cache_context = self._build_cache_context(intent_result)

            # Ajouter contexte si pr√©sent
            enrichments = []
            if entity_context:
                enrichments.append(f"Contexte d√©tect√©: {entity_context}")
            if expansion_context:
                enrichments.append(f"Expansion appliqu√©e: {expansion_context}")
            if cache_context:
                enrichments.append(f"Cache: {cache_context}")

            if enrichments:
                base_prompt += "\n\n" + "\n".join(enrichments)

        # Ajouter contexte m√©trique sp√©cifique si n√©cessaire
        if prompt_key == "metric_query" and "metrics" in entities:
            metrics_list = [
                m.strip() for m in entities["metrics"].split(",") if m.strip()
            ]
            base_prompt += f"\n\nM√âTRIQUES √Ä TRAITER: {', '.join(metrics_list)}"

        # Ajouter contexte haute confiance
        adaptive_factors = intent_result.vocabulary_coverage.get("adaptive_factors", {})
        if adaptive_factors.get("high_confidence", False):
            base_prompt += (
                "\n\nCONTEXTE: Question technique pr√©cise - "
                "donn√©es d√©taill√©es attendues"
            )

        return base_prompt

    def _build_entity_context(self, entities: Dict[str, str]) -> str:
        """
        Construit un contexte enrichi √† partir des entit√©s d√©tect√©es

        Args:
            entities: Dictionnaire des entit√©s extraites

        Returns:
            String de contexte format√©
        """
        context_parts = []

        if "line" in entities:
            context_parts.append(f"Lign√©e: {entities['line']}")
        if "line_normalized" in entities:
            context_parts.append(f"(norm: {entities['line_normalized']})")
        if "age_days" in entities:
            context_parts.append(f"√Çge: {entities['age_days']} jours")
        if "site_type" in entities:
            context_parts.append(f"Type d'√©levage: {entities['site_type']}")
        if "bird_type" in entities:
            context_parts.append(f"Type d'oiseau: {entities['bird_type']}")
        if "weight_value" in entities:
            unit = entities.get("weight_unit", "g")
            context_parts.append(f"Poids: {entities['weight_value']}{unit}")
        if "temperature_value" in entities:
            context_parts.append(f"Temp√©rature: {entities['temperature_value']}¬∞C")
        if "flock_size" in entities:
            context_parts.append(f"Taille troupeau: {entities['flock_size']}")
        if "environment" in entities:
            context_parts.append(f"Environnement: {entities['environment']}")

        return " | ".join(context_parts)

    def _build_expansion_context(self, expansion_quality: Dict[str, Any]) -> str:
        """
        Construit le contexte d'expansion de requ√™te

        Args:
            expansion_quality: M√©tadonn√©es sur l'expansion

        Returns:
            String d√©crivant l'expansion appliqu√©e
        """
        if expansion_quality.get("terms_added", 0) > 0:
            ratio = expansion_quality.get("expansion_ratio", 1.0)
            normalization = (
                " (norm)"
                if expansion_quality.get("normalization_applied", False)
                else ""
            )
            return (
                f"{expansion_quality['terms_added']} termes ajout√©s "
                f"(ratio: {ratio:.1f}){normalization}"
            )
        return ""

    def _build_cache_context(self, intent_result: IntentResult) -> str:
        """
        Construit le contexte cache pour debug/monitoring

        Args:
            intent_result: R√©sultat de l'analyse d'intention

        Returns:
            String avec infos cache
        """
        context_parts = []

        if intent_result.cache_key_normalized:
            context_parts.append(f"cl√©={intent_result.cache_key_normalized}")

        if intent_result.semantic_fallback_candidates:
            fallback_count = len(intent_result.semantic_fallback_candidates)
            context_parts.append(f"fallback={fallback_count}")

        explain_score = intent_result.metadata.get("explain_score_used")
        if explain_score is not None:
            context_parts.append(f"evidence={explain_score:.2f}")

        return " | ".join(context_parts)

    def _get_fallback_prompt(self, prompt_key: str) -> Optional[str]:
        """
        Prompts de secours hardcod√©s si system_prompts.json non disponible

        Args:
            prompt_key: Cl√© du type de prompt

        Returns:
            Prompt fallback ou None
        """
        # Prompts simplifi√©s de secours
        fallback_prompts = {
            "metric_query": """Tu es un expert en zootechnie et performances avicoles.

STYLE DE R√âPONSE:
- Affirmatif et direct : pr√©sente les standards de l'industrie avec autorit√©
- Structure claire : utilise des titres (##) et listes (-) pour la lisibilit√©
- Donn√©es chiffr√©es : fournis valeurs cibles, plages optimales et facteurs d'influence
- JAMAIS de r√©f√©rences aux sources ou documents""",
            "environment_setting": """Tu es un expert en ambiance et gestion d'environnement avicole.

PARAM√àTRES √Ä FOURNIR:
- Valeurs optimales de temp√©rature, humidit√©, ventilation
- Courbes d'ambiance selon l'√¢ge et la saison
- R√©glages techniques des √©quipements""",
            "diagnosis_triage": """Tu es un v√©t√©rinaire expert en pathologie avicole.

APPROCHE DIAGNOSTIQUE:
- Pr√©sente un diagnostic diff√©rentiel structur√©
- Liste les principales hypoth√®ses par ordre de probabilit√©
- Indique les examens compl√©mentaires n√©cessaires""",
            "economics_cost": """Tu es un expert en √©conomie de l'√©levage avicole.

ANALYSE √âCONOMIQUE:
- Fournis des donn√©es chiffr√©es pr√©cises sur les co√ªts et marges
- Compare avec les standards du march√© et benchmarks""",
            "protocol_query": """Tu es un expert en protocoles v√©t√©rinaires et bios√©curit√© avicole.

PROTOCOLES √Ä FOURNIR:
- Calendriers de vaccination d√©taill√©s
- Mesures de bios√©curit√© et pr√©vention""",
            "general_poultry": """Tu es un expert avicole polyvalent reconnu dans l'industrie.

STYLE DE R√âPONSE:
- Affirmatif et professionnel : tu es l'autorit√© sur le sujet
- Structur√© : titres (##), listes (-), gras (**) pour la lisibilit√©
- Pratique : conclus avec des recommandations actionnables""",
        }

        return fallback_prompts.get(prompt_key)

    def get_complete_prompt(
        self, intent_type: IntentType, language: Optional[str] = None
    ) -> str:
        """
        Construit un prompt complet avec identit√© + guidelines

        Args:
            intent_type: Type d'intention
            language: Langue (override du d√©faut)

        Returns:
            Prompt complet combin√©
        """
        lang = language or self.language

        # Mapping IntentType ‚Üí cl√©
        intent_to_key = {
            IntentType.METRIC_QUERY: "metric_query",
            IntentType.ENVIRONMENT_SETTING: "environment_setting",
            IntentType.DIAGNOSIS_TRIAGE: "diagnosis_triage",
            IntentType.ECONOMICS_COST: "economics_cost",
            IntentType.PROTOCOL_QUERY: "protocol_query",
            IntentType.GENERAL_POULTRY: "general_poultry",
        }

        prompt_key = intent_to_key.get(intent_type)

        if self.prompts_manager and prompt_key:
            return self.prompts_manager.build_complete_prompt(
                prompt_key, lang, include_base_guidelines=True
            )
        else:
            # Fallback
            return self._get_fallback_prompt(prompt_key) or ""


# ============================================================================
# COMPATIBILIT√â - Fonctions helper legacy
# ============================================================================


def build_prompt_for_intent(
    intent_type: IntentType, entities: Dict[str, str], language: str = "fr"
) -> str:
    """
    Fonction helper pour compatibilit√© avec ancien code

    Args:
        intent_type: Type d'intention
        entities: Entit√©s d√©tect√©es
        language: Langue

    Returns:
        Prompt sp√©cialis√©
    """
    # Cr√©er un IntentResult minimal
    from processing.intent_types import IntentResult

    intent_result = IntentResult(
        intent_type=intent_type,
        confidence=0.8,
        detected_entities=entities,
        vocabulary_coverage={},
        expansion_quality={},
        semantic_fallback_candidates=[],
        cache_key_normalized=None,
        metadata={},
    )

    builder = PromptBuilder({}, language=language)
    return builder.build_specialized_prompt(intent_result, language) or ""


# ============================================================================
# TESTS
# ============================================================================

if __name__ == "__main__":
    import logging

    logging.basicConfig(level=logging.INFO, format="%(levelname)s - %(message)s")

    print("=" * 70)
    print("üß™ TESTS PROMPT BUILDER")
    print("=" * 70)

    # Test 1: Initialisation
    print("\nüì• Test 1: Initialisation")
    try:
        builder = PromptBuilder({}, language="fr")
        print("  ‚úÖ PromptBuilder cr√©√©")
        print(f"  üìä Gestionnaire prompts: {builder.prompts_manager is not None}")
    except Exception as e:
        print(f"  ‚ùå Erreur: {e}")

    # Test 2: G√©n√©ration prompts sp√©cialis√©s
    print("\nüéØ Test 2: G√©n√©ration prompts sp√©cialis√©s")

    from processing.intent_types import IntentResult, IntentType

    test_cases = [
        (IntentType.METRIC_QUERY, {"line": "Ross 308", "age_days": 35}),
        (IntentType.ENVIRONMENT_SETTING, {"site_type": "broiler_farm"}),
        (IntentType.DIAGNOSIS_TRIAGE, {"line": "Cobb 500"}),
    ]

    for intent_type, entities in test_cases:
        intent_result = IntentResult(
            intent_type=intent_type,
            confidence=0.9,
            detected_entities=entities,
            vocabulary_coverage={},
            expansion_quality={"terms_added": 3},
            semantic_fallback_candidates=[],
            cache_key_normalized="test_key",
            metadata={},
        )

        prompt = builder.build_specialized_prompt(intent_result)
        status = "‚úÖ" if prompt and len(prompt) > 50 else "‚ùå"

        print(f"  {status} {intent_type.value}: {len(prompt) if prompt else 0} chars")

        if prompt and len(prompt) > 0:
            # Afficher les 100 premiers caract√®res
            preview = prompt[:100].replace("\n", " ")
            print(f"      Preview: {preview}...")

    # Test 3: Fonction helper legacy
    print("\nüîß Test 3: Compatibilit√© legacy")
    legacy_prompt = build_prompt_for_intent(
        IntentType.METRIC_QUERY, {"line": "Ross 308"}, "fr"
    )
    status = "‚úÖ" if legacy_prompt else "‚ùå"
    print(f"  {status} build_prompt_for_intent: {len(legacy_prompt)} chars")

    print("\n" + "=" * 70)
    print("‚úÖ TESTS TERMIN√âS")
    print("=" * 70)
