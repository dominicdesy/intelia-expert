# -*- coding: utf-8 -*-
"""
api/conversation_context.py - Gestionnaire de contexte conversationnel
Version 4.4.0 - M√âMOIRE CONVERSATIONNELLE POUR R√âSOLUTION CONTEXTUELLE
"""

import time
import re
import logging
from typing import Dict, List, Optional, Any
from pathlib import Path
import json

logger = logging.getLogger(__name__)


class ConversationContextManager:
    """
    Gestionnaire de contexte conversationnel pour clarifications
    VERSION 4.4.0 - M√âMOIRE CONVERSATIONNELLE + AM√âLIORATION D√âTECTION √ÇGE + FUSION D'ENTIT√âS

    ‚úÖ NOUVELLES FONCTIONNALIT√âS v4.4:
    - Stockage de la derni√®re requ√™te r√©ussie (store_last_successful_query)
    - R√©cup√©ration du contexte conversationnel (get_last_context)
    - R√©solution des r√©f√©rences contextuelles ("at the same age", "for females too")

    ‚úÖ CORRECTIONS PR√âC√âDENTES (v4.3.1):
    - Stockage des entit√©s partielles dans pending_clarifications
    - Fusion intelligente des entit√©s lors de update_accumulated_query
    - Retour des entit√©s fusionn√©es via get_pending()
    - Pr√©servation de tous les champs (age_days, metric_type, breed, sex, etc.)
    - Meilleure d√©tection des r√©ponses d'√¢ge (patterns √©tendus)
    """

    # NOUVEAUX PATTERNS D'AMBIGU√èT√â
    AMBIGUOUS_PATTERNS = [
        r"je ne sais pas",
        r"pas s√ªr",
        r"peut-√™tre",
        r"probablement",
        r"je pense",
        r"environ",
        r"√† peu pr√®s",
        r"not sure",
        r"maybe",
        r"probably",
        r"i think",
        r"approximately",
    ]

    # NOUVEAUX PATTERNS D'ABANDON
    ABANDON_PATTERNS = [
        r"peu importe",
        r"laisse tomber",
        r"oublie",
        r"moyenne g√©n√©rale",
        r"sans pr√©cision",
        r"approximativement",
        r"never mind",
        r"forget it",
        r"skip",
        r"general average",
        r"no importa",
    ]

    def __init__(self, intents_config_path: str = None):
        self.pending_clarifications = {}
        self.clarification_patterns = self._load_clarification_patterns(
            intents_config_path
        )
        # ‚úÖ NOUVEAU v4.4: Stockage de la derni√®re requ√™te r√©ussie
        self.last_successful_context = {}  # {tenant_id: {entities, query, timestamp}}

    def _load_clarification_patterns(self, config_path: str = None) -> Dict:
        """Charge les patterns de clarification depuis intents.json"""

        if config_path is None:
            # Chemins par d√©faut
            possible_paths = [
                Path(__file__).parent.parent / "config" / "intents.json",
                Path(__file__).parent / "config" / "intents.json",
                Path.cwd() / "config" / "intents.json",
                Path.cwd() / "llm" / "config" / "intents.json",
            ]

            for path in possible_paths:
                if path.exists():
                    config_path = str(path)
                    break

        if not config_path or not Path(config_path).exists():
            logger.warning("intents.json non trouv√© - utilisation patterns par d√©faut")
            return self._get_default_patterns()

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                config = json.load(f)

            # Extraire les patterns pertinents
            patterns = {
                "age": self._extract_age_patterns(config),
                "breed": self._extract_breed_patterns(config),
                "sex": self._extract_sex_patterns(config),
                "metric": self._extract_metric_patterns(config),
            }

            logger.info(f"Patterns de clarification charg√©s depuis {config_path}")
            return patterns

        except Exception as e:
            logger.error(f"Erreur chargement intents.json: {e}")
            return self._get_default_patterns()

    def _extract_age_patterns(self, config: Dict) -> Dict:
        """Extrait les patterns d'√¢ge depuis intents.json"""
        return {"regex": r"\d+\s*(jour|day|j\b|d\b|semaine|week|sem)", "keywords": []}

    def _extract_breed_patterns(self, config: Dict) -> Dict:
        """
        Extrait les patterns de races depuis intents.json

        ‚úÖ Version 2.0: Utilise UNIQUEMENT intents.json (pas de hardcod√©s)
        """
        breeds = []
        aliases = config.get("aliases", {}).get("line", {})

        # Extraire TOUS les aliases depuis intents.json
        for line, line_breeds in aliases.items():
            if isinstance(line_breeds, list):
                breeds.extend([b.lower() for b in line_breeds])

        # ‚úÖ PAS de hardcod√©s - intents.json contient d√©j√† tout !
        logger.info(
            f"‚úÖ {len(set(breeds))} aliases de races charg√©s depuis intents.json"
        )

        return {"regex": None, "keywords": list(set(breeds))}

    def _extract_sex_patterns(self, config: Dict) -> Dict:
        """Extrait les patterns de sexe depuis intents.json"""
        sex_aliases = config.get("aliases", {}).get("sex", {})

        keywords = []
        for sex_type, variants in sex_aliases.items():
            if isinstance(variants, list):
                keywords.extend([v.lower() for v in variants])

        return {"regex": None, "keywords": keywords}

    def _extract_metric_patterns(self, config: Dict) -> Dict:
        """Extrait les patterns de m√©triques depuis intents.json"""
        metric_aliases = config.get("aliases", {}).get("metric", {})

        keywords = []
        for metric_type, variants in metric_aliases.items():
            if isinstance(variants, list):
                keywords.extend([v.lower() for v in variants])

        return {"regex": None, "keywords": keywords}

    def _get_default_patterns(self) -> Dict:
        """Patterns par d√©faut en cas d'√©chec de chargement"""
        return {
            "age": {"regex": r"\d+\s*(jour|day|j\b|d\b|semaine|week)", "keywords": []},
            "breed": {
                "regex": None,
                "keywords": ["ross", "cobb", "hubbard", "aviagen", "308", "500", "700"],
            },
            "sex": {
                "regex": None,
                "keywords": ["m√¢le", "femelle", "male", "female", "mixte", "mixed"],
            },
            "metric": {
                "regex": None,
                "keywords": [
                    "poids",
                    "weight",
                    "fcr",
                    "conversion",
                    "mortalit√©",
                    "gain",
                ],
            },
        }

    # ‚úÖ ================================================================
    # NOUVELLES M√âTHODES v4.4: M√âMOIRE CONVERSATIONNELLE
    # ================================================================

    def store_last_successful_query(
        self, tenant_id: str, query: str, entities: Dict[str, Any], language: str = "en"
    ):
        """
        Stocke le contexte de la derni√®re requ√™te r√©ussie

        Args:
            tenant_id: Identifiant du tenant
            query: Requ√™te utilisateur compl√®te
            entities: Entit√©s extraites (breed, age_days, sex, metric_type, etc.)
            language: Langue de la requ√™te
        """
        self.last_successful_context[tenant_id] = {
            "query": query,
            "entities": entities,
            "language": language,
            "timestamp": time.time(),
        }

        logger.info(f"üíæ Contexte conversationnel stock√© pour {tenant_id}")
        logger.debug(f"   Query: {query}")
        logger.debug(f"   Entities: {entities}")

    def get_last_context(self, tenant_id: str) -> Optional[Dict[str, Any]]:
        """
        R√©cup√®re le contexte de la derni√®re requ√™te r√©ussie

        Args:
            tenant_id: Identifiant du tenant

        Returns:
            Dict avec query, entities, language, timestamp ou None si pas de contexte
        """
        context = self.last_successful_context.get(tenant_id)

        if context:
            # V√©rifier que le contexte n'est pas trop ancien (max 5 minutes)
            age = time.time() - context.get("timestamp", 0)
            if age > 300:  # 5 minutes
                logger.info(
                    f"‚è∞ Contexte trop ancien pour {tenant_id} ({age:.0f}s), ignor√©"
                )
                del self.last_successful_context[tenant_id]
                return None

            logger.info(f"üìñ R√©cup√©ration contexte conversationnel pour {tenant_id}")
            logger.debug(f"   Previous query: {context.get('query')}")
            logger.debug(f"   Previous entities: {context.get('entities')}")
            return context

        return None

    def clear_last_context(self, tenant_id: str):
        """Efface le contexte de la derni√®re requ√™te"""
        if tenant_id in self.last_successful_context:
            del self.last_successful_context[tenant_id]
            logger.info(f"üóëÔ∏è Contexte conversationnel effac√© pour {tenant_id}")

    # ================================================================
    # FIN NOUVELLES M√âTHODES v4.4
    # ================================================================

    def mark_pending(
        self,
        tenant_id: str,
        original_query: str,
        missing_fields: List[str],
        suggestions: Dict,
        language: str,
        partial_entities: Dict[str, Any] = None,  # ‚úÖ AJOUT
    ):
        """
        Marque une conversation en attente de clarification

        ‚úÖ NOUVEAU: Stocke les entit√©s partielles d√©j√† extraites
        """
        self.pending_clarifications[tenant_id] = {
            "original_query": original_query,
            "missing_fields": missing_fields,
            "suggestions": suggestions,
            "language": language,
            "original_language": language,
            "timestamp": time.time(),
            "clarification_count": 0,
            "clarification_attempts": 0,
            "partial_entities": partial_entities or {},  # ‚úÖ AJOUT
        }
        logger.info(
            f"Clarification en attente pour {tenant_id}: {missing_fields} (langue: {language})"
        )
        logger.info(f"Entit√©s partielles stock√©es: {partial_entities}")

    def get_pending(self, tenant_id: str) -> Optional[Dict]:
        """R√©cup√®re le contexte en attente avec les entit√©s fusionn√©es"""
        return self.pending_clarifications.get(tenant_id)

    def clear_pending(self, tenant_id: str):
        """Efface le contexte en attente"""
        if tenant_id in self.pending_clarifications:
            del self.pending_clarifications[tenant_id]
            logger.info(f"Clarification r√©solue pour {tenant_id}")

    def update_accumulated_query(self, tenant_id: str, new_info: str):
        """
        Accumule les informations de clarification de mani√®re intelligente

        ‚úÖ Version 4.4 - Support target_age_days:
        - Fusion s√©mantique de la requ√™te
        - Fusion des entit√©s extraites
        - ‚úÖ NOUVEAU: D√©tection explicite "Jour X" ‚Üí target_age_days
        - Distinction age_days (d√©part) vs target_age_days (cible)
        - Pr√©servation de TOUS les champs (age_days, metric_type, breed, sex)
        - Maintien de la lisibilit√© de la requ√™te
        """
        if tenant_id not in self.pending_clarifications:
            return

        context = self.pending_clarifications[tenant_id]
        original = context["original_query"]

        # Extraire entit√©s de la r√©ponse
        try:
            from llm.core.entity_extractor import EntityExtractor

            extractor = EntityExtractor()
            response_entities = extractor.extract(new_info)

            # ‚úÖ NOUVELLE SECTION: FUSION DES ENTIT√âS
            partial_entities = context.get("partial_entities", {})

            logger.info(f"üîÑ Fusion entit√©s - Avant: {partial_entities}")
            logger.info(
                f"üîÑ Nouvelles entit√©s extraites: {response_entities.to_dict()}"
            )

            # ‚úÖ NOUVEAU: D√©tecter explicitement les r√©ponses de type "Jour X"
            target_age_match = re.search(
                r"jour\s+(\d+)|day\s+(\d+)|d√≠a\s+(\d+)", new_info.lower()
            )
            if target_age_match:
                target_age = int(
                    target_age_match.group(1)
                    or target_age_match.group(2)
                    or target_age_match.group(3)
                )
                partial_entities["target_age_days"] = target_age
                logger.info(f"‚úÖ √Çge cible d√©tect√©: {target_age} jours")

            # Fusion des autres entit√©s
            for key, value in response_entities.to_dict().items():
                if value is not None:
                    # Ne pas √©craser si d√©j√† pr√©sent, sauf pour les champs explicites
                    if key not in partial_entities or key in [
                        "breed",
                        "sex",
                        "metric_type",
                        "genetic_line",
                    ]:
                        partial_entities[key] = value
                        logger.info(f"‚úÖ {key} ajout√©/mis √† jour: {value}")

            # Sauvegarder les entit√©s fusionn√©es
            context["partial_entities"] = partial_entities

            logger.info(f"‚úÖ Entit√©s fusionn√©es - Apr√®s: {partial_entities}")
            # FIN NOUVELLE SECTION

            # Construire requ√™te enrichie intelligemment
            merged = original

            if target_age_match:
                # "quel est le poids" + "Jour 33" ‚Üí "quel est le poids | Jour 33"
                merged = f"{original} | Jour {target_age}"
                logger.info(f"‚úÖ Requ√™te enrichie avec √¢ge cible: {merged}")

            elif response_entities.breed and response_entities.has_explicit_breed:
                # "quel est le poids" + "Cobb 500" ‚Üí "quel est le poids pour Cobb 500"
                merged = f"{original} pour {response_entities.breed}"
                logger.info(f"‚úÖ Requ√™te enrichie avec race: {merged}")

            elif response_entities.age_days and response_entities.has_explicit_age:
                # "quel est le poids" + "35 jours" ‚Üí "quel est le poids √† 35 jours"
                merged = f"{original} √† {response_entities.age_days} jours"
                logger.info(f"‚úÖ Requ√™te enrichie avec √¢ge: {merged}")

            elif response_entities.sex and response_entities.has_explicit_sex:
                # "quel est le poids" + "m√¢les" ‚Üí "quel est le poids pour les m√¢les"
                sex_label = {"male": "les m√¢les", "female": "les femelles"}.get(
                    response_entities.sex, response_entities.sex
                )
                merged = f"{original} pour {sex_label}"
                logger.info(f"‚úÖ Requ√™te enrichie avec sexe: {merged}")

            else:
                # Fallback: ajout simple
                merged = f"{original} | {new_info}"
                logger.debug(f"Fusion simple: {merged}")

            context["original_query"] = merged

        except Exception as e:
            # Fallback en cas d'erreur
            logger.warning(
                f"Erreur fusion intelligente: {e}, fallback s√©parateur simple"
            )
            context["original_query"] = f"{original} | {new_info}"

        context["clarification_count"] = context.get("clarification_count", 0) + 1
        context["timestamp"] = time.time()

        logger.info(
            f"Requ√™te accumul√©e (tour {context['clarification_count']}): {context['original_query'][:100]}..."
        )

    def increment_clarification_attempt(self, tenant_id: str):
        """Incr√©mente le compteur de tentatives de clarification"""
        if tenant_id in self.pending_clarifications:
            context = self.pending_clarifications[tenant_id]
            context["clarification_attempts"] = (
                context.get("clarification_attempts", 0) + 1
            )
            logger.info(
                f"Tentative de clarification #{context['clarification_attempts']} pour {tenant_id}"
            )

    def is_clarification_response(self, message: str, pending_context: Dict) -> bool:
        """
        D√©tecte si le message est une r√©ponse √† une demande de clarification

        ‚úÖ Version 2.1 - AM√âLIORATION D√âTECTION √ÇGE:
        - Utilise entity_extractor pour robustesse (Test 11)
        - Supporte TOUTES les races via breeds_registry (51 races)
        - G√®re phrases compl√®tes, pas seulement mots courts
        - ‚úÖ NOUVEAU: Patterns √©tendus pour √¢ge cible ("35", "jour 35", etc.)
        - Fallback sur patterns intents.json si extraction √©choue
        """
        if not pending_context:
            return False

        missing = pending_context.get("missing_fields", [])
        msg = message.lower().strip()

        # ========================================
        # ‚úÖ NOUVEAU: Pattern sp√©cifique pour √¢ge cible
        # ========================================
        if any("√¢ge" in f or "age" in f or "poids" in f for f in missing):
            age_patterns = [
                r"^\s*(\d+)\s*$",  # "35"
                r"^\s*(\d+)\s*(?:jours?|days?|j|d)\s*$",  # "35 jours"
                r"^\s*jour\s*(\d+)\s*$",  # "jour 35"
                r"^\s*day\s*(\d+)\s*$",  # "day 35"
                r"^\s*√†\s*(\d+)\s*(?:jours?|j)?\s*$",  # "√† 35 jours"
                r"^\s*(\d+)\s*semaines?\s*$",  # "3 semaines"
                r"^\s*(\d+)\s*weeks?\s*$",  # "3 weeks"
            ]

            for pattern in age_patterns:
                if re.search(pattern, msg, re.IGNORECASE):
                    logger.info(f"‚úÖ √Çge cible d√©tect√©: {message}")
                    return True

        # ========================================
        # APPROCHE 1: Utiliser entity_extractor (PRIORITAIRE)
        # ========================================
        try:
            from llm.core.entity_extractor import EntityExtractor

            # Extraire les entit√©s depuis le message
            extractor = EntityExtractor()
            extracted = extractor.extract(message)

            # V√©rifier si une entit√© manquante a √©t√© fournie
            if any("breed" in f.lower() or "race" in f.lower() for f in missing):
                if extracted.breed and extracted.has_explicit_breed:
                    logger.info(
                        f"‚úÖ Race d√©tect√©e via entity_extractor: {extracted.breed}"
                    )
                    return True

            if any("age" in f.lower() for f in missing):
                if extracted.age_days and extracted.has_explicit_age:
                    logger.info(
                        f"‚úÖ √Çge d√©tect√© via entity_extractor: {extracted.age_days} jours"
                    )
                    return True

            if any("sex" in f.lower() or "sexe" in f.lower() for f in missing):
                if extracted.sex and extracted.has_explicit_sex:
                    logger.info(
                        f"‚úÖ Sexe d√©tect√© via entity_extractor: {extracted.sex}"
                    )
                    return True

        except Exception as e:
            logger.warning(
                f"entity_extractor non disponible, fallback sur patterns: {e}"
            )

        # ========================================
        # APPROCHE 2: Patterns depuis intents.json (FALLBACK)
        # ========================================
        for field in missing:
            normalized = field.replace("_days", "").replace("_type", "")

            if normalized not in self.clarification_patterns:
                continue

            pattern_config = self.clarification_patterns[normalized]

            # V√©rifier regex
            if pattern_config.get("regex"):
                if re.search(pattern_config["regex"], msg):
                    logger.info(
                        f"‚úÖ Champ d√©tect√© via regex intents.json: {normalized}"
                    )
                    return True

            # V√©rifier keywords
            if pattern_config.get("keywords"):
                if any(kw in msg for kw in pattern_config["keywords"]):
                    logger.info(
                        f"‚úÖ Champ d√©tect√© via keywords intents.json: {normalized}"
                    )
                    return True

        logger.debug(f"‚ùå Pas de r√©ponse de clarification d√©tect√©e: {message}")
        return False

    def detect_ambiguous_response(self, message: str) -> bool:
        """
        D√©tecte si la r√©ponse est ambigu√´/incertaine
        """
        msg_lower = message.lower()

        for pattern in self.AMBIGUOUS_PATTERNS:
            if re.search(pattern, msg_lower):
                logger.info(f"R√©ponse ambigu√´ d√©tect√©e: {message}")
                return True

        return False

    def detect_clarification_abandon(self, message: str) -> bool:
        """
        D√©tecte si l'utilisateur abandonne la clarification
        """
        msg_lower = message.lower()

        for pattern in self.ABANDON_PATTERNS:
            if re.search(pattern, msg_lower):
                logger.info(f"Abandon de clarification d√©tect√©: {message}")
                return True

        return False

    def generate_clarification_retry(
        self, original_message: str, missing_field: str, language: str = "fr"
    ) -> str:
        """
        G√©n√®re une demande de clarification plus pr√©cise
        apr√®s d√©tection d'ambigu√Øt√©
        """
        retry_templates = {
            "fr": {
                "breed": "Pourriez-vous confirmer la race exacte parmi ces options ?\n‚Ä¢ Ross 308\n‚Ä¢ Cobb 500\n‚Ä¢ Hubbard Classic\n‚Ä¢ Autre (pr√©cisez)",
                "age": "Pourriez-vous confirmer l'√¢ge exact en jours ? (exemple: 21, 35, 42)",
                "sex": "Pourriez-vous pr√©ciser le sexe ?\n‚Ä¢ M√¢le\n‚Ä¢ Femelle\n‚Ä¢ Mixte",
            },
            "en": {
                "breed": "Could you confirm the exact breed from these options?\n‚Ä¢ Ross 308\n‚Ä¢ Cobb 500\n‚Ä¢ Hubbard Classic\n‚Ä¢ Other (specify)",
                "age": "Could you confirm the exact age in days? (example: 21, 35, 42)",
                "sex": "Could you specify the sex?\n‚Ä¢ Male\n‚Ä¢ Female\n‚Ä¢ Mixed",
            },
        }

        field_normalized = missing_field.replace("_days", "").replace("_type", "")
        templates = retry_templates.get(language, retry_templates["fr"])

        return templates.get(field_normalized, "Pourriez-vous √™tre plus pr√©cis ?")


def generate_clarification_question(
    missing_fields: List[str], suggestions: Dict, language: str
) -> str:
    """G√©n√®re une question de clarification naturelle selon la langue"""

    clarification_templates = {
        "fr": {
            "breed": "Pour vous donner une r√©ponse pr√©cise, pourriez-vous me dire quelle race/souche vous √©levez ? (par exemple : Ross 308, Cobb 500, Hubbard)",
            "age_days": "√Ä quel √¢ge (en jours) souhaitez-vous conna√Ætre cette information ?",
            "sex": "Cette information concerne-t-elle des m√¢les, des femelles, ou un √©levage mixte ?",
            "metric_type": "Quelle m√©trique sp√©cifique vous int√©resse ? (poids, FCR, mortalit√©, etc.)",
            "multiple": "Pour vous aider au mieux, j'ai besoin de quelques pr√©cisions :\n{details}",
        },
        "en": {
            "breed": "To give you an accurate answer, could you tell me which breed/strain you're raising? (e.g., Ross 308, Cobb 500, Hubbard)",
            "age_days": "At what age (in days) would you like this information?",
            "sex": "Is this information for males, females, or mixed flock?",
            "metric_type": "Which specific metric are you interested in? (weight, FCR, mortality, etc.)",
            "multiple": "To help you best, I need a few clarifications:\n{details}",
        },
    }

    templates = clarification_templates.get(language, clarification_templates["fr"])

    if len(missing_fields) == 1:
        field = missing_fields[0]
        question = templates.get(field, templates.get("breed"))

        if suggestions and field in suggestions:
            field_suggestions = suggestions[field]
            if field_suggestions:
                if language == "fr":
                    question += f"\n\nSuggestions : {', '.join(field_suggestions[:5])}"
                else:
                    question += f"\n\nSuggestions: {', '.join(field_suggestions[:5])}"

        return question

    else:
        details = []
        for field in missing_fields:
            field_template = templates.get(field, "")
            if field_template and field != "multiple":
                question_part = field_template.split("?")[0] + "?"
                details.append(f"- {question_part}")

        if details:
            return templates["multiple"].format(details="\n".join(details))
        else:
            return templates.get("breed", "Pouvez-vous pr√©ciser votre question ?")
