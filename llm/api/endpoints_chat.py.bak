# -*- coding: utf-8 -*-
"""
api/endpoints_chat.py - Endpoints de chat et streaming avec Système RAG JSON
Gestion des conversations, streaming SSE, validation JSON, ingestion avicole
Version 4.2.3 - DÉTECTION AMÉLIORÉE + GESTION AMBIGUÏTÉ + ABANDON
"""

import time
import uuid
import asyncio
import logging
import json
import re
from typing import Dict, Any, List, Optional
from fastapi import APIRouter, Request, HTTPException, File, UploadFile, Form
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel, Field, field_validator

from config.config import BASE_PATH, MAX_REQUEST_SIZE, STREAM_CHUNK_LEN
from utils.utilities import (
    safe_get_attribute,
    safe_dict_get,
    sse_event,
    smart_chunk_text,
    get_out_of_domain_message,
    get_aviculture_response,
    detect_language_enhanced,
)
from .endpoints_utils import (
    safe_serialize_for_json,
    metrics_collector,
    add_to_conversation_memory,
)

logger = logging.getLogger(__name__)


# === NOUVEAUX MODÈLES PYDANTIC POUR JSON ===


class JSONValidationRequest(BaseModel):
    """Requête de validation JSON avicole"""

    json_data: Dict[str, Any] = Field(..., description="Données JSON à valider")
    strict_mode: bool = Field(False, description="Mode de validation strict")
    auto_enrich: bool = Field(
        True, description="Enrichissement automatique des métadonnées"
    )

    model_config = {
        "json_schema_extra": {
            "example": {
                "json_data": {
                    "title": "Ross 308 Performance Guide",
                    "text": "Performance objectives for Ross 308 broilers...",
                    "metadata": {"genetic_line": "ross308"},
                    "tables": [],
                },
                "strict_mode": False,
                "auto_enrich": True,
            }
        }
    }


class IngestionRequest(BaseModel):
    """Requête d'ingestion de fichiers JSON"""

    json_files: List[Dict[str, Any]] = Field(..., description="Liste des fichiers JSON")
    batch_size: int = Field(5, ge=1, le=20, description="Taille des lots de traitement")
    force_reprocess: bool = Field(
        False, description="Forcer le retraitement des fichiers existants"
    )

    @field_validator("json_files")
    @classmethod
    def validate_json_files(cls, v):
        if len(v) > 100:
            raise ValueError("Maximum 100 fichiers par lot")
        return v


class ExpertQueryRequest(BaseModel):
    """Requête d'expertise avicole avec support JSON"""

    question: str = Field(
        ..., min_length=5, max_length=500, description="Question de l'utilisateur"
    )
    language: str = Field(
        "fr", pattern="^(fr|en|es|zh|ar)$", description="Langue de la réponse"
    )
    genetic_line: Optional[str] = Field(None, description="Lignée génétique spécifique")
    user_id: Optional[str] = Field(None, description="Identifiant utilisateur")
    context: Optional[Dict[str, Any]] = Field(None, description="Contexte additionnel")
    response_format: str = Field(
        "detailed", pattern="^(ultra_concise|concise|standard|detailed)$"
    )
    use_json_search: bool = Field(
        True, description="Utiliser la recherche JSON prioritaire"
    )
    performance_metrics: Optional[List[str]] = Field(
        None, description="Métriques de performance à filtrer"
    )
    age_range: Optional[Dict[str, int]] = Field(
        None, description="Plage d'âge en jours"
    )

    model_config = {
        "json_schema_extra": {
            "example": {
                "question": "Quel est le poids cible à 35 jours pour du Ross 308 mâle?",
                "language": "fr",
                "genetic_line": "ross308",
                "use_json_search": True,
                "performance_metrics": ["poids", "fcr"],
                "age_range": {"min": 30, "max": 40},
            }
        }
    }


class ChatRequest(BaseModel):
    """Requête de chat étendue avec support JSON"""

    message: str = Field(
        ..., min_length=1, max_length=2000, description="Message utilisateur"
    )
    language: Optional[str] = Field(None, description="Langue de la réponse")
    tenant_id: Optional[str] = Field(None, description="Identifiant du tenant")
    genetic_line_filter: Optional[str] = Field(
        None, description="Filtre lignée génétique"
    )
    use_json_search: bool = Field(True, description="Utiliser le système JSON")
    performance_context: Optional[Dict[str, Any]] = Field(
        None, description="Contexte performance"
    )


# === SYSTÈME DE MÉMOIRE CONVERSATIONNELLE POUR CONTEXTUALISATION ===


class ConversationContextManager:
    """
    Gestionnaire de contexte conversationnel pour clarifications
    VERSION 4.2.3 - DÉTECTION AMÉLIORÉE + AMBIGUÏTÉ + ABANDON
    """

    # NOUVEAUX PATTERNS D'AMBIGUÏTÉ
    AMBIGUOUS_PATTERNS = [
        r"je ne sais pas",
        r"pas sûr",
        r"peut-être",
        r"probablement",
        r"je pense",
        r"environ",
        r"à peu près",
        r"not sure",
        r"maybe",
        r"probably",
        r"i think",
        r"approximately",
    ]

    # NOUVEAUX PATTERNS D'ABANDON
    ABANDON_PATTERNS = [
        r"peu importe",
        r"laisse tomber",
        r"oublie",
        r"moyenne générale",
        r"sans précision",
        r"approximativement",
        r"never mind",
        r"forget it",
        r"skip",
        r"general average",
        r"no importa",
    ]

    def __init__(self, intents_config_path: str = None):
        self.pending_clarifications = {}
        self.clarification_patterns = self._load_clarification_patterns(
            intents_config_path
        )

    def _load_clarification_patterns(self, config_path: str = None) -> Dict:
        """Charge les patterns de clarification depuis intents.json"""
        from pathlib import Path
        import json

        if config_path is None:
            # Chemins par défaut
            possible_paths = [
                Path(__file__).parent.parent / "config" / "intents.json",
                Path(__file__).parent / "config" / "intents.json",
                Path.cwd() / "config" / "intents.json",
                Path.cwd() / "llm" / "config" / "intents.json",
            ]

            for path in possible_paths:
                if path.exists():
                    config_path = str(path)
                    break

        if not config_path or not Path(config_path).exists():
            logger.warning("intents.json non trouvé - utilisation patterns par défaut")
            return self._get_default_patterns()

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                config = json.load(f)

            # Extraire les patterns pertinents
            patterns = {
                "age": self._extract_age_patterns(config),
                "breed": self._extract_breed_patterns(config),
                "sex": self._extract_sex_patterns(config),
                "metric": self._extract_metric_patterns(config),
            }

            logger.info(f"Patterns de clarification chargés depuis {config_path}")
            return patterns

        except Exception as e:
            logger.error(f"Erreur chargement intents.json: {e}")
            return self._get_default_patterns()

    def _extract_age_patterns(self, config: Dict) -> Dict:
        """Extrait les patterns d'âge depuis intents.json"""
        return {"regex": r"\d+\s*(jour|day|j\b|d\b|semaine|week|sem)", "keywords": []}

    def _extract_breed_patterns(self, config: Dict) -> Dict:
        """Extrait les patterns de races depuis intents.json"""
        breeds = []
        aliases = config.get("aliases", {}).get("line", {})

        for line, line_breeds in aliases.items():
            if isinstance(line_breeds, list):
                breeds.extend([b.lower() for b in line_breeds])

        # Ajouter patterns communs
        breeds.extend(
            ["ross", "cobb", "hubbard", "aviagen", "308", "500", "700", "708"]
        )

        return {"regex": None, "keywords": list(set(breeds))}

    def _extract_sex_patterns(self, config: Dict) -> Dict:
        """Extrait les patterns de sexe depuis intents.json"""
        sex_aliases = config.get("aliases", {}).get("sex", {})

        keywords = []
        for sex_type, variants in sex_aliases.items():
            if isinstance(variants, list):
                keywords.extend([v.lower() for v in variants])

        return {"regex": None, "keywords": keywords}

    def _extract_metric_patterns(self, config: Dict) -> Dict:
        """Extrait les patterns de métriques depuis intents.json"""
        metric_aliases = config.get("aliases", {}).get("metric", {})

        keywords = []
        for metric_type, variants in metric_aliases.items():
            if isinstance(variants, list):
                keywords.extend([v.lower() for v in variants])

        return {"regex": None, "keywords": keywords}

    def _get_default_patterns(self) -> Dict:
        """Patterns par défaut en cas d'échec de chargement"""
        return {
            "age": {"regex": r"\d+\s*(jour|day|j\b|d\b|semaine|week)", "keywords": []},
            "breed": {
                "regex": None,
                "keywords": ["ross", "cobb", "hubbard", "aviagen", "308", "500", "700"],
            },
            "sex": {
                "regex": None,
                "keywords": ["mâle", "femelle", "male", "female", "mixte", "mixed"],
            },
            "metric": {
                "regex": None,
                "keywords": [
                    "poids",
                    "weight",
                    "fcr",
                    "conversion",
                    "mortalité",
                    "gain",
                ],
            },
        }

    def mark_pending(
        self,
        tenant_id: str,
        original_query: str,
        missing_fields: List[str],
        suggestions: Dict,
        language: str,
    ):
        """Marque une conversation en attente de clarification"""
        self.pending_clarifications[tenant_id] = {
            "original_query": original_query,
            "missing_fields": missing_fields,
            "suggestions": suggestions,
            "language": language,
            "original_language": language,
            "timestamp": time.time(),
            "clarification_count": 0,
            "clarification_attempts": 0,
        }
        logger.info(
            f"Clarification en attente pour {tenant_id}: {missing_fields} (langue: {language})"
        )

    def get_pending(self, tenant_id: str) -> Optional[Dict]:
        """Récupère le contexte en attente"""
        return self.pending_clarifications.get(tenant_id)

    def clear_pending(self, tenant_id: str):
        """Efface le contexte en attente"""
        if tenant_id in self.pending_clarifications:
            del self.pending_clarifications[tenant_id]
            logger.info(f"Clarification résolue pour {tenant_id}")

    def update_accumulated_query(self, tenant_id: str, new_info: str):
        """Met à jour la requête accumulée sans effacer le contexte"""
        if tenant_id in self.pending_clarifications:
            context = self.pending_clarifications[tenant_id]
            original = context["original_query"]

            # Accumuler avec séparateur
            context["original_query"] = f"{original} | {new_info}"
            context["clarification_count"] = context.get("clarification_count", 0) + 1
            context["timestamp"] = time.time()

            logger.info(
                f"Requête accumulée (tour {context['clarification_count']}): {context['original_query'][:100]}..."
            )

    def increment_clarification_attempt(self, tenant_id: str):
        """Incrémente le compteur de tentatives de clarification"""
        if tenant_id in self.pending_clarifications:
            context = self.pending_clarifications[tenant_id]
            context["clarification_attempts"] = (
                context.get("clarification_attempts", 0) + 1
            )
            logger.info(
                f"Tentative de clarification #{context['clarification_attempts']} pour {tenant_id}"
            )

    def is_clarification_response(self, message: str, pending_context: Dict) -> bool:
        """
        Détecte si le message est une réponse à une clarification

        VERSION 4.2.3 - AMÉLIORATION CRITIQUE:
        - Détection robuste âges numériques simples ("35", "35 jours")
        - Détection races courtes (1-3 mots)
        - Patterns depuis intents.json (existant)
        """
        if not pending_context:
            return False

        missing = pending_context.get("missing_fields", [])
        msg = message.lower().strip()

        # PRIORITÉ 1: Détection âge numérique simple
        if any("age" in field.lower() for field in missing):
            age_patterns = [
                r"^\s*(\d+)\s*$",
                r"^\s*(\d+)\s*(?:jours?|days?|j)\s*$",
                r"^\s*à\s*(\d+)\s*(?:jours?|j)?\s*$",
                r"^\s*(\d+)\s*semaines?\s*$",
                r"^\s*(\d+)\s*weeks?\s*$",
            ]

            for pattern in age_patterns:
                if re.search(pattern, msg):
                    logger.info(f"Détection âge numérique: {message}")
                    return True

        # PRIORITÉ 2: Détection race simple (mots seuls)
        if any(
            "breed" in field.lower() or "race" in field.lower() for field in missing
        ):
            words = msg.split()

            if 1 <= len(words) <= 3:
                known_breeds = [
                    "ross",
                    "cobb",
                    "hubbard",
                    "aviagen",
                    "isa",
                    "lohmann",
                    "hy-line",
                    "but",
                    "308",
                    "500",
                    "700",
                    "708",
                ]

                if any(breed in msg for breed in known_breeds):
                    logger.info(f"Détection race courte: {message}")
                    return True

                if len(words) == 1 and words[0].isdigit() and len(words[0]) == 3:
                    logger.info(f"Détection variante numérique: {message}")
                    return True

        # EXISTANT: Vérifier patterns depuis intents.json
        for field in missing:
            normalized = field.replace("_days", "").replace("_type", "")

            if normalized not in self.clarification_patterns:
                continue

            pattern_config = self.clarification_patterns[normalized]

            if pattern_config.get("regex"):
                if re.search(pattern_config["regex"], msg):
                    return True

            if pattern_config.get("keywords"):
                if any(kw in msg for kw in pattern_config["keywords"]):
                    return True

        return False

    def detect_ambiguous_response(self, message: str) -> bool:
        """
        Détecte si la réponse est ambiguë/incertaine
        """
        msg_lower = message.lower()

        for pattern in self.AMBIGUOUS_PATTERNS:
            if re.search(pattern, msg_lower):
                logger.info(f"Réponse ambiguë détectée: {message}")
                return True

        return False

    def detect_clarification_abandon(self, message: str) -> bool:
        """
        Détecte si l'utilisateur abandonne la clarification
        """
        msg_lower = message.lower()

        for pattern in self.ABANDON_PATTERNS:
            if re.search(pattern, msg_lower):
                logger.info(f"Abandon de clarification détecté: {message}")
                return True

        return False

    def generate_clarification_retry(
        self, original_message: str, missing_field: str, language: str = "fr"
    ) -> str:
        """
        Génère une demande de clarification plus précise
        après détection d'ambiguïté
        """
        retry_templates = {
            "fr": {
                "breed": "Pourriez-vous confirmer la race exacte parmi ces options ?\n• Ross 308\n• Cobb 500\n• Hubbard Classic\n• Autre (précisez)",
                "age": "Pourriez-vous confirmer l'âge exact en jours ? (exemple: 21, 35, 42)",
                "sex": "Pourriez-vous préciser le sexe ?\n• Mâle\n• Femelle\n• Mixte",
            },
            "en": {
                "breed": "Could you confirm the exact breed from these options?\n• Ross 308\n• Cobb 500\n• Hubbard Classic\n• Other (specify)",
                "age": "Could you confirm the exact age in days? (example: 21, 35, 42)",
                "sex": "Could you specify the sex?\n• Male\n• Female\n• Mixed",
            },
        }

        field_normalized = missing_field.replace("_days", "").replace("_type", "")
        templates = retry_templates.get(language, retry_templates["fr"])

        return templates.get(field_normalized, "Pourriez-vous être plus précis ?")


# Instance globale du gestionnaire
context_manager = ConversationContextManager()


def generate_clarification_question(
    missing_fields: List[str], suggestions: Dict, language: str
) -> str:
    """Génère une question de clarification naturelle selon la langue"""

    clarification_templates = {
        "fr": {
            "breed": "Pour vous donner une réponse précise, pourriez-vous me dire quelle race/souche vous élevez ? (par exemple : Ross 308, Cobb 500, Hubbard)",
            "age_days": "À quel âge (en jours) souhaitez-vous connaître cette information ?",
            "sex": "Cette information concerne-t-elle des mâles, des femelles, ou un élevage mixte ?",
            "metric_type": "Quelle métrique spécifique vous intéresse ? (poids, FCR, mortalité, etc.)",
            "multiple": "Pour vous aider au mieux, j'ai besoin de quelques précisions :\n{details}",
        },
        "en": {
            "breed": "To give you an accurate answer, could you tell me which breed/strain you're raising? (e.g., Ross 308, Cobb 500, Hubbard)",
            "age_days": "At what age (in days) would you like this information?",
            "sex": "Is this information for males, females, or mixed flock?",
            "metric_type": "Which specific metric are you interested in? (weight, FCR, mortality, etc.)",
            "multiple": "To help you best, I need a few clarifications:\n{details}",
        },
    }

    templates = clarification_templates.get(language, clarification_templates["fr"])

    if len(missing_fields) == 1:
        field = missing_fields[0]
        question = templates.get(field, templates.get("breed"))

        if suggestions and field in suggestions:
            field_suggestions = suggestions[field]
            if field_suggestions:
                if language == "fr":
                    question += f"\n\nSuggestions : {', '.join(field_suggestions[:5])}"
                else:
                    question += f"\n\nSuggestions: {', '.join(field_suggestions[:5])}"

        return question

    else:
        details = []
        for field in missing_fields:
            field_template = templates.get(field, "")
            if field_template and field != "multiple":
                question_part = field_template.split("?")[0] + "?"
                details.append(f"- {question_part}")

        if details:
            return templates["multiple"].format(details="\n".join(details))
        else:
            return templates.get("breed", "Pouvez-vous préciser votre question ?")


def create_chat_endpoints(services: Dict[str, Any]) -> APIRouter:
    """Crée les endpoints de chat et streaming avec système JSON"""

    router = APIRouter()

    def get_service(name: str) -> Any:
        """Helper pour récupérer un service"""
        return services.get(name)

    def get_rag_engine():
        """Helper pour récupérer le RAG Engine"""
        health_monitor = get_service("health_monitor")
        if health_monitor:
            return health_monitor.get_service("rag_engine_enhanced")
        return None

    # ========================================================================
    # ENDPOINTS SYSTÈME JSON AVICOLE
    # ========================================================================

    @router.post(f"{BASE_PATH}/json/validate")
    async def validate_json_document(request: JSONValidationRequest):
        """Valide un document JSON selon les schémas avicoles"""
        start_time = time.time()

        try:
            rag_engine = get_rag_engine()
            if not rag_engine:
                raise HTTPException(status_code=503, detail="RAG Engine non disponible")

            if not hasattr(rag_engine, "validate_json_document"):
                raise HTTPException(
                    status_code=501, detail="Validation JSON non disponible"
                )

            result = await rag_engine.validate_json_document(
                json_data=request.json_data, strict_mode=request.strict_mode
            )

            response = {
                **result,
                "processing_time": time.time() - start_time,
                "timestamp": time.time(),
                "version": "4.2.3_improved_detection",
            }

            return JSONResponse(content=safe_serialize_for_json(response))

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erreur validation JSON: {e}")
            return JSONResponse(
                status_code=500,
                content={
                    "valid": False,
                    "error": str(e),
                    "processing_time": time.time() - start_time,
                },
            )

    @router.post(f"{BASE_PATH}/json/ingest")
    async def ingest_json_documents(request: IngestionRequest):
        """Ingère des documents JSON dans le système"""
        start_time = time.time()

        try:
            rag_engine = get_rag_engine()
            if not rag_engine:
                raise HTTPException(status_code=503, detail="RAG Engine non disponible")

            if not hasattr(rag_engine, "ingest_json_documents"):
                raise HTTPException(
                    status_code=501, detail="Ingestion JSON non disponible"
                )

            result = await rag_engine.ingest_json_documents(
                json_files=request.json_files, batch_size=request.batch_size
            )

            response = {
                **result,
                "processing_time": time.time() - start_time,
                "timestamp": time.time(),
                "batch_size_used": request.batch_size,
                "force_reprocess": request.force_reprocess,
            }

            return JSONResponse(content=safe_serialize_for_json(response))

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erreur ingestion JSON: {e}")
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "error": str(e),
                    "processing_time": time.time() - start_time,
                },
            )

    @router.post(f"{BASE_PATH}/json/search")
    async def search_json_enhanced(
        query: str = Form(...),
        genetic_line: Optional[str] = Form(None),
        performance_metrics: Optional[str] = Form(None),
        age_range: Optional[str] = Form(None),
    ):
        """Recherche avancée dans les documents JSON avec filtres avicoles"""
        start_time = time.time()

        try:
            rag_engine = get_rag_engine()
            if not rag_engine:
                raise HTTPException(status_code=503, detail="RAG Engine non disponible")

            if not hasattr(rag_engine, "search_json_enhanced"):
                raise HTTPException(
                    status_code=501, detail="Recherche JSON non disponible"
                )

            parsed_metrics = None
            if performance_metrics:
                try:
                    parsed_metrics = json.loads(performance_metrics)
                except json.JSONDecodeError:
                    parsed_metrics = [performance_metrics]

            parsed_age_range = None
            if age_range:
                try:
                    parsed_age_range = json.loads(age_range)
                except json.JSONDecodeError:
                    logger.warning(f"Âge range invalide: {age_range}")

            results = await rag_engine.search_json_enhanced(
                query=query,
                genetic_line=genetic_line,
                performance_metrics=parsed_metrics,
                age_range=parsed_age_range,
            )

            response = {
                "success": True,
                "results": results,
                "results_count": len(results),
                "query": query,
                "filters": {
                    "genetic_line": genetic_line,
                    "performance_metrics": parsed_metrics,
                    "age_range": parsed_age_range,
                },
                "processing_time": time.time() - start_time,
                "timestamp": time.time(),
            }

            return JSONResponse(content=safe_serialize_for_json(response))

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erreur recherche JSON: {e}")
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "error": str(e),
                    "processing_time": time.time() - start_time,
                },
            )

    @router.post(f"{BASE_PATH}/json/upload")
    async def upload_json_files(
        files: List[UploadFile] = File(...),
        batch_size: int = Form(5),
        auto_validate: bool = Form(True),
    ):
        """Upload et traitement de fichiers JSON avicoles"""
        start_time = time.time()

        try:
            if len(files) > 50:
                raise HTTPException(
                    status_code=413, detail="Maximum 50 fichiers par upload"
                )

            json_files = []
            errors = []

            for file in files:
                try:
                    if not file.filename.endswith(".json"):
                        errors.append(
                            f"{file.filename}: Format non supporté (JSON requis)"
                        )
                        continue

                    content = await file.read()
                    json_data = json.loads(content.decode("utf-8"))

                    json_files.append(
                        {
                            "filename": file.filename,
                            "data": json_data,
                            "size_bytes": len(content),
                        }
                    )

                except json.JSONDecodeError as e:
                    errors.append(f"{file.filename}: JSON invalide - {str(e)}")
                except Exception as e:
                    errors.append(f"{file.filename}: Erreur lecture - {str(e)}")

            if not json_files:
                raise HTTPException(
                    status_code=400, detail="Aucun fichier JSON valide trouvé"
                )

            validation_results = []
            if auto_validate:
                rag_engine = get_rag_engine()
                if rag_engine and hasattr(rag_engine, "validate_json_document"):
                    for json_file in json_files:
                        try:
                            validation = await rag_engine.validate_json_document(
                                json_data=json_file["data"], strict_mode=False
                            )
                            validation_results.append(
                                {
                                    "filename": json_file["filename"],
                                    "valid": validation.get("valid", False),
                                    "errors": validation.get("errors", []),
                                    "warnings": validation.get("warnings", []),
                                }
                            )
                        except Exception as e:
                            validation_results.append(
                                {
                                    "filename": json_file["filename"],
                                    "valid": False,
                                    "error": str(e),
                                }
                            )

            ingestion_result = None
            if auto_validate and validation_results:
                valid_files = [
                    jf
                    for jf, vr in zip(json_files, validation_results)
                    if vr.get("valid", False)
                ]

                if valid_files:
                    rag_engine = get_rag_engine()
                    if rag_engine and hasattr(rag_engine, "ingest_json_documents"):
                        try:
                            ingestion_result = await rag_engine.ingest_json_documents(
                                json_files=[f["data"] for f in valid_files],
                                batch_size=batch_size,
                            )
                        except Exception as e:
                            logger.error(f"Erreur ingestion: {e}")

            response = {
                "success": True,
                "files_uploaded": len(files),
                "files_parsed": len(json_files),
                "parsing_errors": errors,
                "validation_enabled": auto_validate,
                "validation_results": validation_results,
                "ingestion_result": ingestion_result,
                "processing_time": time.time() - start_time,
                "timestamp": time.time(),
            }

            return JSONResponse(content=safe_serialize_for_json(response))

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erreur upload JSON: {e}")
            return JSONResponse(
                status_code=500,
                content={
                    "success": False,
                    "error": str(e),
                    "processing_time": time.time() - start_time,
                },
            )

    # ========================================================================
    # ENDPOINT CHAT PRINCIPAL AVEC DÉTECTION AMÉLIORÉE + AMBIGUÏTÉ + ABANDON
    # ========================================================================

    @router.post(f"{BASE_PATH}/chat")
    async def chat(request: Request):
        """Chat endpoint avec contextualisation intelligente et détection améliorée"""
        total_start_time = time.time()

        try:
            try:
                body = await request.json()
            except Exception as e:
                raise HTTPException(status_code=400, detail=f"JSON invalide: {e}")

            message = body.get("message", "").strip()
            language = body.get("language", "").strip()
            tenant_id = body.get("tenant_id", str(uuid.uuid4())[:8])

            genetic_line_filter = body.get("genetic_line_filter")
            use_json_search = body.get("use_json_search", True)
            performance_context = body.get("performance_context")

            if not message:
                raise HTTPException(status_code=400, detail="Message vide")

            if len(message) > MAX_REQUEST_SIZE:
                raise HTTPException(
                    status_code=413,
                    detail=f"Message trop long (max {MAX_REQUEST_SIZE})",
                )

            # Détection automatique de la langue
            language_result = detect_language_enhanced(message)
            detected_language = (
                language_result.language
                if hasattr(language_result, "language")
                else language_result
            )

            # Vérifier si on est en contexte de clarification
            pending_context = context_manager.get_pending(tenant_id)
            if pending_context:
                original_language = pending_context.get("original_language")
                if original_language:
                    logger.info(
                        f"Langue préservée du contexte: {original_language} "
                        f"(détection actuelle ignorée: {detected_language})"
                    )
                    detected_language = original_language

            logger.info(
                f"Langue détectée: {detected_language} "
                f"(confiance: {getattr(language_result, 'confidence', 'N/A')})"
            )

            language = detected_language

            if not tenant_id or len(tenant_id) > 50:
                tenant_id = str(uuid.uuid4())[:8]

            # NOUVEAU: Vérifier abandon de clarification
            pending_context = context_manager.get_pending(tenant_id)
            rag_result = None

            if pending_context and context_manager.detect_clarification_abandon(
                message
            ):
                logger.info(f"Abandon clarification pour {tenant_id}")

                # Effacer le contexte en attente
                context_manager.clear_pending(tenant_id)

                # Extraire contexte partiel
                partial_entities = pending_context.get("partial_entities", {})
                age = partial_entities.get("age_days")

                # Générer réponse générique
                generic_responses = {
                    "fr": f"Je comprends. Voici une moyenne générale pour les poulets de chair{' à ' + str(age) + ' jours' if age else ''}: Le poids moyen se situe entre 300-2500g selon la souche et l'âge. L'indice de conversion (FCR) est généralement de 1.5-1.9.",
                    "en": f"I understand. Here's a general average for broilers{' at ' + str(age) + ' days' if age else ''}: Average weight ranges from 300-2500g depending on strain and age. Feed conversion ratio (FCR) is typically 1.5-1.9.",
                }

                generic_answer = generic_responses.get(
                    language, generic_responses["fr"]
                )

                # Créer résultat générique
                class GenericResult:
                    def __init__(self, answer):
                        self.answer = answer
                        self.source = "generic_fallback"
                        self.confidence = 0.6
                        self.processing_time = time.time() - total_start_time
                        self.metadata = {
                            "clarification_abandoned": True,
                            "fallback_used": True,
                        }
                        self.context_docs = []

                rag_result = GenericResult(generic_answer)

            # ÉTAPE 1: Vérifier si c'est une réponse à une clarification
            if rag_result is None:
                pending_context = context_manager.get_pending(tenant_id)

                if pending_context and context_manager.is_clarification_response(
                    message, pending_context
                ):
                    logger.info(f"Détection réponse clarification pour {tenant_id}")

                    # NOUVEAU: Vérifier ambiguïté AVANT accumulation
                    if context_manager.detect_ambiguous_response(message):
                        logger.warning(f"Réponse ambiguë détectée: {message}")

                        # Générer demande de clarification plus précise
                        missing_fields = pending_context.get("missing_fields", [])
                        retry_message = context_manager.generate_clarification_retry(
                            message,
                            missing_fields[0] if missing_fields else "breed",
                            language,
                        )

                        # Incrémenter compteur de tentatives
                        context_manager.increment_clarification_attempt(tenant_id)

                        # Créer résultat de clarification
                        class AmbiguityResult:
                            def __init__(self, question):
                                self.answer = question
                                self.source = "needs_clarification"
                                self.confidence = 0.8
                                self.processing_time = time.time() - total_start_time
                                self.metadata = {
                                    "needs_clarification": True,
                                    "ambiguous_response_detected": True,
                                    "clarification_pending": True,
                                }
                                self.context_docs = []

                        rag_result = AmbiguityResult(retry_message)

                    else:
                        # FLUX EXISTANT (accumulation normale)
                        context_manager.update_accumulated_query(tenant_id, message)

                        # Récupérer la requête accumulée mise à jour
                        pending_context = context_manager.get_pending(tenant_id)
                        combined_query = pending_context["original_query"]

                        # Préserver la langue originale
                        original_language = pending_context.get("original_language")
                        if original_language:
                            language = original_language
                            logger.info(
                                f"Langue restaurée depuis contexte: {original_language}"
                            )

                        logger.info(f"Requête accumulée complète: {combined_query}")

                        # Traiter la requête complète
                        message = combined_query

            # Si aucun résultat n'a été défini (pas d'abandon, pas d'ambiguïté)
            if rag_result is None:
                # Logique de réponse avec système JSON
                use_fallback = False
                fallback_reason = ""

                rag_engine = get_rag_engine()
                if rag_engine and safe_get_attribute(
                    rag_engine, "is_initialized", False
                ):
                    try:
                        if hasattr(rag_engine, "generate_response"):
                            try:
                                rag_result = await rag_engine.generate_response(
                                    query=message,
                                    tenant_id=tenant_id,
                                    language=language,
                                    use_json_search=use_json_search,
                                    genetic_line_filter=genetic_line_filter,
                                    performance_context=performance_context,
                                    enable_preprocessing=True,
                                )

                                # ÉTAPE 2: Vérifier si contexte insuffisant
                                if hasattr(rag_result, "metadata"):
                                    validation_status = rag_result.metadata.get(
                                        "validation_status"
                                    )

                                    if validation_status == "needs_fallback":
                                        logger.warning(
                                            f"Contexte insuffisant détecté pour {tenant_id}"
                                        )

                                        missing_fields = rag_result.metadata.get(
                                            "missing_fields", []
                                        )
                                        suggestions = rag_result.metadata.get(
                                            "suggestions", {}
                                        )

                                        # Si pas encore en attente, marquer maintenant
                                        pending_context = context_manager.get_pending(
                                            tenant_id
                                        )
                                        if not pending_context:
                                            context_manager.mark_pending(
                                                tenant_id=tenant_id,
                                                original_query=message,
                                                missing_fields=missing_fields,
                                                suggestions=suggestions,
                                                language=language,
                                            )
                                        # Sinon, mettre à jour les champs manquants
                                        else:
                                            context_manager.pending_clarifications[
                                                tenant_id
                                            ]["missing_fields"] = missing_fields
                                            context_manager.pending_clarifications[
                                                tenant_id
                                            ]["suggestions"] = suggestions

                                        # Utiliser le message déjà généré par le validator
                                        clarification_msg = rag_result.answer

                                        # Fallback si pas de message dans answer (sécurité)
                                        if not clarification_msg:
                                            clarification_msg = (
                                                generate_clarification_question(
                                                    missing_fields=missing_fields,
                                                    suggestions=suggestions,
                                                    language=language,
                                                )
                                            )

                                        logger.info(
                                            f"Question de clarification: {clarification_msg[:100]}..."
                                        )

                                        # Créer un résultat spécial pour la clarification
                                        class ClarificationResult:
                                            def __init__(self, question, missing):
                                                self.answer = question
                                                self.source = "needs_clarification"
                                                self.confidence = 0.9
                                                self.processing_time = (
                                                    time.time() - total_start_time
                                                )
                                                self.metadata = {
                                                    "needs_clarification": True,
                                                    "missing_fields": missing,
                                                    "original_query": message,
                                                    "clarification_pending": True,
                                                }
                                                self.context_docs = []

                                        rag_result = ClarificationResult(
                                            clarification_msg, missing_fields
                                        )

                                    else:
                                        # Validation réussie: effacer le contexte en attente
                                        pending_context = context_manager.get_pending(
                                            tenant_id
                                        )
                                        if pending_context:
                                            logger.info(
                                                f"Requête complète validée pour {tenant_id}"
                                            )
                                            context_manager.clear_pending(tenant_id)

                                logger.info(
                                    f"RAG generate_response réussi (JSON: {use_json_search}, preprocessing: enabled)"
                                )

                            except Exception as generate_error:
                                logger.warning(
                                    f"generate_response échoué: {generate_error}"
                                )
                                use_fallback = True
                                fallback_reason = (
                                    f"generate_response_failed: {str(generate_error)}"
                                )
                        else:
                            use_fallback = True
                            fallback_reason = "generate_response_not_available"

                    except Exception as e:
                        logger.error(f"Erreur générale RAG: {e}")
                        use_fallback = True
                        fallback_reason = f"rag_general_error: {str(e)}"
                else:
                    use_fallback = True
                    fallback_reason = "rag_not_initialized"

                if use_fallback or not rag_result:
                    logger.info(
                        f"Utilisation fallback aviculture - Raison: {fallback_reason}"
                    )

                    aviculture_response = get_aviculture_response(message, language)

                    class FallbackResult:
                        def __init__(self, answer, reason):
                            self.answer = answer
                            self.source = "aviculture_fallback"
                            self.confidence = 0.8
                            self.processing_time = time.time() - total_start_time
                            self.metadata = {
                                "fallback_used": True,
                                "fallback_reason": reason,
                                "source_type": "integrated_knowledge",
                                "json_system_attempted": use_json_search,
                                "genetic_line_filter": genetic_line_filter,
                                "preprocessing_enabled": True,
                            }
                            self.context_docs = []

                    rag_result = FallbackResult(aviculture_response, fallback_reason)

            total_processing_time = time.time() - total_start_time
            metrics_collector.record_query(
                rag_result, "rag_enhanced_json", total_processing_time
            )

            # Streaming de la réponse
            async def generate_response():
                try:
                    metadata = safe_get_attribute(rag_result, "metadata", {}) or {}
                    source = safe_get_attribute(rag_result, "source", "unknown")
                    confidence = safe_get_attribute(rag_result, "confidence", 0.5)
                    processing_time = safe_get_attribute(
                        rag_result, "processing_time", 0
                    )

                    if hasattr(source, "value"):
                        source = source.value
                    else:
                        source = str(source)

                    # Récupérer le contexte actuel pour les métadonnées
                    current_pending = context_manager.get_pending(tenant_id)

                    start_data = {
                        "type": "start",
                        "source": source,
                        "confidence": float(confidence),
                        "processing_time": float(processing_time),
                        "fallback_used": safe_dict_get(
                            metadata, "fallback_used", False
                        ),
                        "architecture": "modular-endpoints-json-improved",
                        "serialization_version": "optimized_cached",
                        "preprocessing_enabled": True,
                        "needs_clarification": metadata.get(
                            "needs_clarification", False
                        ),
                        "clarification_count": (
                            current_pending.get("clarification_count", 0)
                            if current_pending
                            else 0
                        ),
                        "clarification_attempts": (
                            current_pending.get("clarification_attempts", 0)
                            if current_pending
                            else 0
                        ),
                        "ambiguous_response_detected": metadata.get(
                            "ambiguous_response_detected", False
                        ),
                        "clarification_abandoned": metadata.get(
                            "clarification_abandoned", False
                        ),
                        "json_system_used": metadata.get("json_system", {}).get(
                            "used", False
                        ),
                        "json_results_count": metadata.get("json_system", {}).get(
                            "results_count", 0
                        ),
                        "genetic_line_detected": metadata.get("json_system", {}).get(
                            "genetic_line_filter"
                        ),
                    }

                    yield sse_event(safe_serialize_for_json(start_data))

                    answer = safe_get_attribute(rag_result, "answer", "")
                    if not answer:
                        answer = safe_get_attribute(rag_result, "response", "")
                        if not answer:
                            answer = safe_get_attribute(rag_result, "text", "")
                            if not answer:
                                answer = get_aviculture_response(message, language)

                    if answer:
                        chunks = smart_chunk_text(str(answer), STREAM_CHUNK_LEN)
                        for i, chunk in enumerate(chunks):
                            yield sse_event(
                                {"type": "chunk", "content": chunk, "chunk_index": i}
                            )
                            await asyncio.sleep(0.01)

                    context_docs = safe_get_attribute(rag_result, "context_docs", [])
                    if not isinstance(context_docs, list):
                        context_docs = []

                    documents_used = 0
                    if hasattr(rag_result, "metadata") and rag_result.metadata:
                        documents_used = rag_result.metadata.get("documents_used", 0)

                    if documents_used == 0:
                        documents_used = len(context_docs)

                    end_data = {
                        "type": "end",
                        "total_time": total_processing_time,
                        "confidence": float(confidence),
                        "documents_used": documents_used,
                        "source": source,
                        "architecture": "modular-endpoints-json-improved",
                        "preprocessing_enabled": True,
                        "needs_clarification": metadata.get(
                            "needs_clarification", False
                        ),
                        "clarification_pending": metadata.get(
                            "clarification_pending", False
                        ),
                        "clarification_count": (
                            current_pending.get("clarification_count", 0)
                            if current_pending
                            else 0
                        ),
                        "clarification_attempts": (
                            current_pending.get("clarification_attempts", 0)
                            if current_pending
                            else 0
                        ),
                        "ambiguous_response_detected": metadata.get(
                            "ambiguous_response_detected", False
                        ),
                        "clarification_abandoned": metadata.get(
                            "clarification_abandoned", False
                        ),
                        "json_system_used": metadata.get("json_system", {}).get(
                            "used", False
                        ),
                        "json_results_count": metadata.get("json_system", {}).get(
                            "results_count", 0
                        ),
                        "genetic_lines_detected": metadata.get("json_system", {}).get(
                            "genetic_lines_detected", []
                        ),
                        "detection_version": "4.2.3_improved",
                    }

                    yield sse_event(safe_serialize_for_json(end_data))

                    if answer and source and not metadata.get("needs_clarification"):
                        add_to_conversation_memory(
                            tenant_id, message, str(answer), "rag_enhanced_json"
                        )

                except Exception as e:
                    logger.error(f"Erreur streaming: {e}")
                    yield sse_event({"type": "error", "message": str(e)})

            return StreamingResponse(generate_response(), media_type="text/plain")

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erreur chat endpoint: {e}")
            metrics_collector.record_query(
                {"source": "error"}, "error", time.time() - total_start_time
            )
            return JSONResponse(
                status_code=500, content={"error": f"Erreur traitement: {str(e)}"}
            )

    @router.post(f"{BASE_PATH}/chat/expert")
    async def expert_chat(request: ExpertQueryRequest):
        """Endpoint de chat expert avec paramètres avancés et streaming"""
        total_start_time = time.time()

        try:
            performance_context = None
            if request.performance_metrics or request.age_range:
                performance_context = {}
                if request.performance_metrics:
                    performance_context["metrics"] = request.performance_metrics
                if request.age_range:
                    performance_context["age_range"] = request.age_range

            rag_result = None
            rag_engine = get_rag_engine()

            if rag_engine and safe_get_attribute(rag_engine, "is_initialized", False):
                try:
                    rag_result = await rag_engine.generate_response(
                        query=request.question,
                        tenant_id=request.user_id or str(uuid.uuid4())[:8],
                        language=request.language,
                        use_json_search=request.use_json_search,
                        genetic_line_filter=request.genetic_line,
                        performance_context=performance_context,
                        enable_preprocessing=True,
                    )
                except Exception as e:
                    logger.error(f"Erreur expert chat: {e}")
                    raise HTTPException(
                        status_code=500, detail=f"Erreur traitement: {str(e)}"
                    )
            else:
                raise HTTPException(status_code=503, detail="RAG Engine non disponible")

            async def generate_expert_response():
                try:
                    metadata = safe_get_attribute(rag_result, "metadata", {}) or {}

                    expert_metadata = {
                        "type": "expert_start",
                        "question": request.question,
                        "genetic_line_requested": request.genetic_line,
                        "performance_metrics": request.performance_metrics,
                        "age_range": request.age_range,
                        "response_format": request.response_format,
                        "json_search_used": request.use_json_search,
                        "preprocessing_enabled": True,
                        "confidence": float(
                            safe_get_attribute(rag_result, "confidence", 0.5)
                        ),
                        "json_system": metadata.get("json_system", {}),
                        "architecture": "expert_chat_json_improved",
                    }

                    yield sse_event(safe_serialize_for_json(expert_metadata))

                    answer = safe_get_attribute(rag_result, "answer", "")
                    if answer:
                        if request.response_format == "ultra_concise":
                            chunks = smart_chunk_text(
                                str(answer)[:200] + "...", STREAM_CHUNK_LEN
                            )
                        elif request.response_format == "concise":
                            chunks = smart_chunk_text(
                                str(answer)[:500] + "...", STREAM_CHUNK_LEN
                            )
                        else:
                            chunks = smart_chunk_text(str(answer), STREAM_CHUNK_LEN)

                        for i, chunk in enumerate(chunks):
                            yield sse_event(
                                {
                                    "type": "expert_chunk",
                                    "content": chunk,
                                    "chunk_index": i,
                                    "format": request.response_format,
                                }
                            )
                            await asyncio.sleep(0.01)

                    end_metadata = {
                        "type": "expert_end",
                        "total_time": time.time() - total_start_time,
                        "documents_used": metadata.get("documents_used", 0),
                        "json_results_count": metadata.get("json_system", {}).get(
                            "results_count", 0
                        ),
                        "genetic_lines_detected": metadata.get("json_system", {}).get(
                            "genetic_lines_detected", []
                        ),
                        "confidence": float(
                            safe_get_attribute(rag_result, "confidence", 0.5)
                        ),
                        "response_format_applied": request.response_format,
                        "preprocessing_enabled": True,
                    }

                    yield sse_event(safe_serialize_for_json(end_metadata))

                except Exception as e:
                    logger.error(f"Erreur streaming expert: {e}")
                    yield sse_event({"type": "error", "message": str(e)})

            return StreamingResponse(
                generate_expert_response(), media_type="text/plain"
            )

        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Erreur expert chat endpoint: {e}")
            return JSONResponse(
                status_code=500,
                content={"error": f"Erreur traitement expert: {str(e)}"},
            )

    # ========================================================================
    # ENDPOINT OOD
    # ========================================================================

    @router.post(f"{BASE_PATH}/ood")
    async def ood_endpoint(request: Request):
        """Point de terminaison pour messages hors domaine"""
        try:
            body = await request.json()
            language = body.get("language", "fr")
            message = get_out_of_domain_message(language)

            async def ood_response():
                yield sse_event(
                    {
                        "type": "start",
                        "reason": "out_of_domain",
                        "architecture": "modular-endpoints-json-improved",
                    }
                )

                chunks = smart_chunk_text(message, STREAM_CHUNK_LEN)
                for chunk in chunks:
                    yield sse_event({"type": "chunk", "content": chunk})
                    await asyncio.sleep(0.05)

                yield sse_event(
                    {
                        "type": "end",
                        "confidence": 1.0,
                        "architecture": "modular-endpoints-json-improved",
                    }
                )

            return StreamingResponse(ood_response(), media_type="text/plain")

        except Exception as e:
            logger.error(f"Erreur OOD endpoint: {e}")
            return JSONResponse(status_code=500, content={"error": str(e)})

    # ========================================================================
    # ENDPOINTS DE TEST
    # ========================================================================

    @router.post(f"{BASE_PATH}/chat/test-json-system")
    async def test_json_system():
        """Test complet du système JSON intégré"""
        try:
            test_results = {}
            rag_engine = get_rag_engine()

            if not rag_engine:
                return {"error": "RAG Engine non disponible"}

            try:
                test_json = {
                    "title": "Test Ross 308 Performance",
                    "text": "Performance objectives for Ross 308 broilers at 35 days.",
                    "metadata": {"genetic_line": "ross308"},
                    "tables": [],
                }

                if hasattr(rag_engine, "validate_json_document"):
                    validation_result = await rag_engine.validate_json_document(
                        test_json
                    )
                    test_results["json_validation"] = {
                        "success": True,
                        "valid": validation_result.get("valid", False),
                        "errors": validation_result.get("errors", []),
                    }
                else:
                    test_results["json_validation"] = {
                        "success": False,
                        "reason": "Méthode non disponible",
                    }
            except Exception as e:
                test_results["json_validation"] = {"success": False, "error": str(e)}

            try:
                if hasattr(rag_engine, "search_json_enhanced"):
                    search_results = await rag_engine.search_json_enhanced(
                        query="Ross 308 poids 35 jours", genetic_line="ross308"
                    )
                    test_results["json_search"] = {
                        "success": True,
                        "results_count": len(search_results),
                        "has_results": len(search_results) > 0,
                    }
                else:
                    test_results["json_search"] = {
                        "success": False,
                        "reason": "Méthode non disponible",
                    }
            except Exception as e:
                test_results["json_search"] = {"success": False, "error": str(e)}

            try:
                generation_result = await rag_engine.generate_response(
                    query="Quel est le poids cible Ross 308 à 35 jours ?",
                    use_json_search=True,
                    genetic_line_filter="ross308",
                    enable_preprocessing=True,
                )

                metadata = getattr(generation_result, "metadata", {})
                json_system_info = metadata.get("json_system", {})

                test_results["json_generation"] = {
                    "success": True,
                    "json_system_used": json_system_info.get("used", False),
                    "json_results_count": json_system_info.get("results_count", 0),
                    "confidence": getattr(generation_result, "confidence", 0),
                    "has_answer": bool(getattr(generation_result, "answer", "")),
                    "preprocessing_enabled": True,
                }
            except Exception as e:
                test_results["json_generation"] = {"success": False, "error": str(e)}

            try:
                status = rag_engine.get_status()
                json_system_status = status.get("json_system", {})
                test_results["json_system_status"] = {
                    "available": json_system_status.get("available", False),
                    "components": json_system_status.get("components", {}),
                    "stats": json_system_status.get("stats", {}),
                }
            except Exception as e:
                test_results["json_system_status"] = {"success": False, "error": str(e)}

            successful_tests = sum(
                1 for result in test_results.values() if result.get("success", False)
            )
            total_tests = len(test_results)

            analysis = {
                "timestamp": time.time(),
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "success_rate": (
                    successful_tests / total_tests if total_tests > 0 else 0
                ),
                "test_results": test_results,
                "system_health": (
                    "OK"
                    if successful_tests == total_tests
                    else "DEGRADED" if successful_tests > 0 else "FAILED"
                ),
                "version": "4.2.3_improved_detection",
            }

            return safe_serialize_for_json(analysis)

        except Exception as e:
            logger.error(f"Erreur test_json_system: {e}")
            return {"error": str(e), "timestamp": time.time()}

    @router.post(f"{BASE_PATH}/chat/test-ross308")
    async def test_ross308_query():
        """Endpoint de test spécifique pour les requêtes Ross 308 avec JSON"""
        try:
            test_queries = [
                "Quel est le poids d'un poulet Ross 308 de 17 jours ?",
                "Ross 308 female performance weight table day 17",
                "broiler performance objectives Ross 308",
                "RossxRoss308 BroilerPerformanceObjectives weight",
            ]

            results = {}
            rag_engine = get_rag_engine()

            if not rag_engine:
                return {"error": "RAG Engine non disponible"}

            for query in test_queries:
                try:
                    start_time = time.time()

                    result = await rag_engine.generate_response(
                        query=query,
                        tenant_id="test_ross308",
                        language="fr",
                        use_json_search=True,
                        genetic_line_filter="ross308",
                        enable_preprocessing=True,
                    )

                    processing_time = time.time() - start_time

                    source = getattr(result, "source", None)
                    source_value = (
                        source.value if hasattr(source, "value") else str(source)
                    )

                    metadata = getattr(result, "metadata", {}) or {}
                    json_system_info = metadata.get("json_system", {})
                    docs_used = metadata.get("documents_used", 0)
                    docs_found = metadata.get("documents_found", 0)
                    confidence = getattr(result, "confidence", 0)

                    response_text = getattr(result, "answer", "") or getattr(
                        result, "response", ""
                    )

                    has_specific_data = any(
                        term in response_text.lower()
                        for term in ["gramme", "kg", "g)", "poids", "weight", "17"]
                    )

                    has_generic_response = any(
                        pattern in response_text.lower()
                        for pattern in [
                            "documents fournis ne contiennent pas",
                            "information spécifique",
                            "données générales",
                        ]
                    )

                    results[query] = {
                        "source": source_value,
                        "confidence": float(confidence),
                        "processing_time": processing_time,
                        "documents_used": docs_used,
                        "documents_found": docs_found,
                        "json_system_used": json_system_info.get("used", False),
                        "json_results_count": json_system_info.get("results_count", 0),
                        "genetic_lines_detected": json_system_info.get(
                            "genetic_lines_detected", []
                        ),
                        "has_specific_data": has_specific_data,
                        "has_generic_response": has_generic_response,
                        "preprocessing_enabled": True,
                        "response_preview": (
                            response_text[:200] + "..."
                            if len(response_text) > 200
                            else response_text
                        ),
                    }

                except Exception as e:
                    results[query] = {"error": str(e), "success": False}

            total_docs_used = sum(
                r.get("documents_used", 0)
                for r in results.values()
                if isinstance(r, dict)
            )
            total_json_results = sum(
                r.get("json_results_count", 0)
                for r in results.values()
                if isinstance(r, dict)
            )
            queries_with_json = sum(
                1 for r in results.values() if r.get("json_system_used", False)
            )
            queries_with_specific_data = sum(
                1 for r in results.values() if r.get("has_specific_data", False)
            )
            queries_with_generic_response = sum(
                1 for r in results.values() if r.get("has_generic_response", False)
            )

            analysis = {
                "timestamp": time.time(),
                "test_queries": test_queries,
                "results": results,
                "analysis": {
                    "total_documents_used": total_docs_used,
                    "total_json_results": total_json_results,
                    "avg_docs_per_query": total_docs_used / len(test_queries),
                    "queries_using_json_system": queries_with_json,
                    "queries_with_specific_data": queries_with_specific_data,
                    "queries_with_generic_response": queries_with_generic_response,
                    "success_rate": queries_with_specific_data / len(test_queries),
                    "json_system_effectiveness": queries_with_json / len(test_queries),
                },
                "recommendations": [],
                "version": "4.2.3_improved_detection",
            }

            if total_json_results == 0 and queries_with_json == 0:
                analysis["recommendations"].append(
                    "CRITIQUE: Système JSON non utilisé - vérifier l'intégration"
                )
            elif total_docs_used == 0:
                analysis["recommendations"].append(
                    "CRITIQUE: Aucun document utilisé - problème de récupération"
                )
            elif queries_with_specific_data == 0:
                analysis["recommendations"].append(
                    "PROBLÈME: Aucune réponse spécifique - document Ross 308 non indexé"
                )
            elif queries_with_generic_response > len(test_queries) // 2:
                analysis["recommendations"].append(
                    "ATTENTION: Majorité de réponses génériques - optimiser l'indexation JSON"
                )

            return safe_serialize_for_json(analysis)

        except Exception as e:
            logger.error(f"Erreur test_ross308_query: {e}")
            return {"error": str(e), "timestamp": time.time()}

    @router.get(f"{BASE_PATH}/chat/conversation-stats")
    async def conversation_stats():
        """Statistiques des conversations en mémoire"""
        try:
            from .endpoints_utils import conversation_memory

            stats = conversation_memory.get_stats()

            detailed_stats = {**stats, "recent_tenants": [], "memory_usage_bytes": 0}

            recent_count = 0
            for tenant_id, tenant_data in conversation_memory.items():
                if recent_count >= 5:
                    break

                if isinstance(tenant_data, dict):
                    detailed_stats["recent_tenants"].append(
                        {
                            "tenant_id": tenant_id[:8] + "...",
                            "conversation_count": len(tenant_data.get("data", [])),
                            "last_query_preview": tenant_data.get("last_query", "")[:50]
                            + "...",
                            "last_update": tenant_data.get("ts", 0),
                        }
                    )
                    recent_count += 1

            try:
                import sys

                detailed_stats["memory_usage_bytes"] = sys.getsizeof(
                    conversation_memory
                )
            except Exception:
                detailed_stats["memory_usage_bytes"] = "unknown"

            return safe_serialize_for_json(detailed_stats)

        except Exception as e:
            logger.error(f"Erreur conversation_stats: {e}")
            return {"error": str(e), "timestamp": time.time()}

    return router
