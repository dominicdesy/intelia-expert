# -*- coding: utf-8 -*-
"""
rag_engine.py - RAG Engine Principal Refactoris√©
Point d'entr√©e principal avec d√©l√©gation vers modules sp√©cialis√©s
VERSION 4.8.1 - INT√âGRATION HISTORIQUE CONVERSATIONNEL:
- ‚úÖ NOUVEAU: R√©cup√©ration automatique de l'historique via ConversationMemory
- ‚úÖ Int√©gration de get_contextual_memory() avant routage
- ‚úÖ Transmission de l'historique √† tous les handlers
- ‚úÖ Support natif de NEEDS_CLARIFICATION via QueryRouter
- ‚úÖ G√©n√©ration automatique de r√©ponse LLM apr√®s r√©cup√©ration documents
- ‚úÖ Support des entit√©s pr√©-extraites pour fusion conversationnelle
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any

from config.config import RAG_ENABLED

try:
    from .data_models import RAGResult, RAGSource
except ImportError as e:
    logging.error(f"Erreur import data_models: {e}")
    raise

try:
    from utils.imports_and_dependencies import OPENAI_AVAILABLE, AsyncOpenAI
except ImportError:
    OPENAI_AVAILABLE = False
    AsyncOpenAI = None

# Import des modules refactoris√©s
from .rag_engine_core import RAGEngineCore
from .rag_engine_handlers import (
    TemporalQueryHandler,
    ComparativeQueryHandler,
    StandardQueryHandler,
)

# NOUVEAUX IMPORTS - QueryRouter remplace plusieurs modules
from .query_router import QueryRouter
from .entity_extractor import EntityExtractor
from .query_enricher import ConversationalQueryEnricher  # ‚úÖ NOUVEAU

# ‚úÖ NOUVEAU: Import de ConversationMemory pour l'historique
try:
    from core.memory import ConversationMemory

    CONVERSATION_MEMORY_AVAILABLE = True
except ImportError as e:
    CONVERSATION_MEMORY_AVAILABLE = False
    ConversationMemory = None
    logging.warning(f"‚ö†Ô∏è ConversationMemory non disponible: {e}")

logger = logging.getLogger(__name__)

# Imports conditionnels des modules externes
POSTGRESQL_RETRIEVER_AVAILABLE = False
COMPARISON_HANDLER_AVAILABLE = False
WEAVIATE_CORE_AVAILABLE = False

PostgreSQLRetriever = None
ComparisonHandler = None
WeaviateCore = None

# Import s√©par√© du Retriever
try:
    from .rag_postgresql_retriever import PostgreSQLRetriever

    POSTGRESQL_RETRIEVER_AVAILABLE = True
    logger.info("‚úÖ PostgreSQL Retriever import√©")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è PostgreSQL Retriever non disponible: {e}")

try:
    from .comparison_handler import ComparisonHandler

    COMPARISON_HANDLER_AVAILABLE = True
    logger.info("‚úÖ Comparison Handler import√© (wrapper)")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Comparison Handler non disponible: {e}")

try:
    from .rag_weaviate_core import WeaviateCore

    WEAVIATE_CORE_AVAILABLE = True
    logger.info("‚úÖ Weaviate Core import√©")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Weaviate Core non disponible: {e}")


class InteliaRAGEngine:
    """
    RAG Engine principal avec architecture modulaire refactoris√©e

    VERSION 4.8.1 - INT√âGRATION HISTORIQUE CONVERSATIONNEL:
    - QueryRouter unifie classification, validation et routage
    - Support natif de NEEDS_CLARIFICATION
    - Configuration PostgreSQL charg√©e automatiquement depuis rag_postgresql_config.py
    - Instanciation PostgreSQLRetriever avec config centralis√©e
    - Transmission correcte du param√®tre language √† tous les handlers
    - ‚úÖ CORRECTION CRITIQUE: G√©n√©ration LLM automatique apr√®s r√©cup√©ration documents
    - ‚úÖ NOUVEAU: M√©thode generate_response_with_entities() pour fusion conversationnelle
    - ‚úÖ Support du param√®tre conversation_context dans generate_response()
    - ‚úÖ NOUVEAU: Int√©gration ConversationMemory pour historique contextuel
    """

    def __init__(self, openai_client: AsyncOpenAI = None):
        """Initialisation avec QueryRouter centralis√© et ConversationMemory"""
        # Core engine
        self.core = RAGEngineCore(openai_client)

        # NOUVEAU MODULE CENTRALIS√â - QueryRouter
        self.query_router = QueryRouter(config_dir="/app/config")
        self.entity_extractor = EntityExtractor()

        # ‚úÖ NOUVEAU: ConversationMemory pour historique
        # DEBUG CRITIQUE - INITIALISATION
        logger.info(f"üîç INIT - openai_client type: {type(openai_client)}")
        logger.info(f"üîç INIT - openai_client is None: {openai_client is None}")
        logger.info(
            f"üîç INIT - CONVERSATION_MEMORY_AVAILABLE: {CONVERSATION_MEMORY_AVAILABLE}"
        )

        self.conversation_memory = None
        if CONVERSATION_MEMORY_AVAILABLE and ConversationMemory:
            logger.info("üîç INIT - Tentative d'initialisation ConversationMemory...")
            try:
                self.conversation_memory = ConversationMemory(client=openai_client)
                logger.info(
                    f"‚úÖ ConversationMemory initialis√©e - Type: {type(self.conversation_memory)}"
                )
            except Exception as e:
                logger.error(
                    f"‚ùå INIT - √âchec initialisation ConversationMemory: {e}",
                    exc_info=True,
                )
        else:
            logger.warning(
                f"‚ö†Ô∏è INIT - ConversationMemory NON disponible (AVAILABLE={CONVERSATION_MEMORY_AVAILABLE})"
            )

        # Handlers sp√©cialis√©s
        self.temporal_handler = TemporalQueryHandler()
        self.comparative_handler = ComparativeQueryHandler()
        self.standard_handler = StandardQueryHandler()

        # Modules externes (Retriever uniquement, plus de Validator)
        self.postgresql_retriever = None
        self.comparison_handler = None
        self.weaviate_core = None

        # √âtat
        self.is_initialized = False
        self.degraded_mode = False
        self.initialization_errors = []

        # Stats
        self.optimization_stats = {
            "requests_total": 0,
            "routing_success": 0,
            "routing_failures": 0,
            "clarification_needed": 0,
            "comparative_queries": 0,
            "comparative_success": 0,
            "comparative_failures": 0,
            "comparative_fallbacks": 0,
            "temporal_queries": 0,
            "optimization_queries": 0,
            "calculation_queries": 0,
            "economic_queries": 0,
            "diagnostic_queries": 0,
            "postgresql_queries": 0,
            "llm_generations": 0,
            "errors_count": 0,
            "preextracted_entities_queries": 0,
            "contextual_memory_queries": 0,
            "queries_enriched": 0,  # ‚úÖ NOUVEAU
        }

    async def initialize(self):
        """Initialisation modulaire avec QueryRouter"""
        if self.is_initialized:
            return

        logger.info(
            "üöÄ Initialisation RAG Engine v4.8.1 (QueryRouter + ConversationMemory)"
        )
        self.initialization_errors = []

        try:
            # Initialiser le core
            await self.core.initialize()

            # Initialiser les modules externes
            await self._initialize_external_modules()

            # Configurer les handlers avec les modules
            await self._configure_handlers()

            self.is_initialized = True

            active_modules = [
                name
                for name, module in [
                    ("QueryRouter", self.query_router),
                    ("PostgreSQLRetriever", self.postgresql_retriever),
                    ("WeaviateCore", self.weaviate_core),
                    ("ComparisonHandler", self.comparison_handler),
                    ("EntityExtractor", self.entity_extractor),
                    ("LLMGenerator", self.core.generator),
                    ("ConversationMemory", self.conversation_memory),
                ]
                if module is not None
            ]

            logger.info(
                f"‚úÖ RAG Engine initialis√© - Modules: {', '.join(active_modules)}"
            )

            if self.initialization_errors:
                logger.warning(
                    f"‚ö†Ô∏è Erreurs d'initialisation: {self.initialization_errors}"
                )

        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation critique: {e}")
            self.degraded_mode = True
            self.is_initialized = True
            self.initialization_errors.append(str(e))

    async def _initialize_external_modules(self):
        """Initialise Retriever avec config centralis√©e"""

        # PostgreSQL Retriever (pour search_metrics)
        if POSTGRESQL_RETRIEVER_AVAILABLE and PostgreSQLRetriever:
            try:
                # Import de la configuration centralis√©e
                from .rag_postgresql_config import POSTGRESQL_CONFIG

                # Validation de la config
                if not POSTGRESQL_CONFIG.get("password"):
                    logger.warning(
                        "‚ö†Ô∏è PostgreSQL config incompl√®te - variables d'environnement manquantes"
                    )
                    raise ValueError(
                        "PostgreSQL password manquant dans la configuration"
                    )

                # Instanciation avec config centralis√©e
                self.postgresql_retriever = PostgreSQLRetriever(
                    config=POSTGRESQL_CONFIG,
                    intents_file_path="/app/config/intents.json",
                )
                await self.postgresql_retriever.initialize()
                logger.info(
                    "‚úÖ PostgreSQL Retriever initialis√© avec config centralis√©e"
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è PostgreSQL Retriever √©chou√©: {e}")
                self.initialization_errors.append(f"PostgreSQLRetriever: {e}")

        # Weaviate Core
        if WEAVIATE_CORE_AVAILABLE and WeaviateCore and self.core.openai_client:
            try:
                self.weaviate_core = WeaviateCore(self.core.openai_client)
                await self.weaviate_core.initialize()
                logger.info("‚úÖ Weaviate Core initialis√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Weaviate Core √©chou√©: {e}")
                self.initialization_errors.append(f"WeaviateCore: {e}")

        # Comparison Handler (utilise le Retriever)
        if COMPARISON_HANDLER_AVAILABLE and ComparisonHandler:
            try:
                self.comparison_handler = ComparisonHandler(self.postgresql_retriever)
                if not self.postgresql_retriever:
                    logger.warning(
                        "‚ö†Ô∏è Comparison Handler en mode d√©grad√© (pas de PostgreSQL)"
                    )
                else:
                    logger.info("‚úÖ Comparison Handler initialis√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Comparison Handler √©chou√©: {e}")
                self.initialization_errors.append(f"ComparisonHandler: {e}")

    async def _configure_handlers(self):
        """Configure handlers avec Retriever"""

        # Configuration temporal handler (utilise le Retriever)
        self.temporal_handler.configure(postgresql_system=self.postgresql_retriever)

        # Configuration comparative handler (utilise le Retriever)
        self.comparative_handler.configure(
            comparison_handler=self.comparison_handler,
            weaviate_core=self.weaviate_core,
            postgresql_system=self.postgresql_retriever,
        )

        # Configuration standard handler (utilise RETRIEVER, plus de VALIDATOR)
        self.standard_handler.configure(
            postgresql_system=self.postgresql_retriever,
            weaviate_core=self.weaviate_core,
            postgresql_validator=None,  # Plus de validator s√©par√©
            response_generator=self.core.generator,  # ‚úÖ AJOUTER LE G√âN√âRATEUR
        )

        logger.debug(
            f"üîç HANDLER CONFIGURED - postgresql_system type: {type(self.standard_handler.postgresql_system)}"
        )
        logger.debug(
            f"üîç HANDLER CONFIGURED - postgresql_system is None: {self.standard_handler.postgresql_system is None}"
        )

    async def generate_response(
        self,
        query: str,
        tenant_id: str = "default",
        conversation_context: List[Dict] = None,
        language: Optional[str] = None,
        enable_preprocessing: bool = True,
        **kwargs,
    ) -> RAGResult:
        """Point d'entr√©e principal avec routage intelligent via QueryRouter

        Args:
            query: Requ√™te utilisateur
            tenant_id: Identifiant du tenant
            conversation_context: Historique de conversation (format liste)
            language: Langue de la requ√™te
            enable_preprocessing: Activer le preprocessing (ignor√©, toujours via QueryRouter)
            **kwargs: Param√®tres additionnels (peut contenir conversation_context au format dict)
        """

        if not self.is_initialized:
            logger.warning("‚ö†Ô∏è RAG Engine non initialis√©, tentative d'initialisation")
            try:
                await self.initialize()
            except Exception as e:
                logger.error(f"‚ùå √âchec initialisation: {e}")

        start_time = time.time()
        self.optimization_stats["requests_total"] += 1

        # Validation
        if not query or not query.strip():
            return RAGResult(
                source=RAGSource.ERROR,
                metadata={"error": "Query vide"},
            )

        effective_language = language or "fr"
        logger.info(f"üåê generate_response re√ßoit langue: {effective_language}")

        # Fallback si syst√®me indisponible
        if self.degraded_mode and not self.postgresql_retriever:
            return RAGResult(
                source=RAGSource.FALLBACK_NEEDED,
                answer="Le syst√®me RAG n'est pas disponible.",
                metadata={"reason": "syst√®me_indisponible"},
            )

        # ‚úÖ Extraire conversation_context au format dict depuis kwargs si pr√©sent
        context_dict = kwargs.get("conversation_context")

        # ‚úÖ NOUVEAU: R√©cup√©rer l'historique conversationnel contextuel
        # DEBUG CRITIQUE - AVANT R√âCUP√âRATION
        logger.info(
            f"üîç GENERATE - self.conversation_memory: {self.conversation_memory}"
        )
        logger.info(
            f"üîç GENERATE - conversation_memory is None: {self.conversation_memory is None}"
        )
        logger.info(f"üîç GENERATE - tenant_id: {tenant_id}")
        logger.info(f"üîç GENERATE - query: {query[:50]}...")

        contextual_history = None
        if self.conversation_memory:
            logger.info("üîç GENERATE - TENTATIVE de r√©cup√©ration historique...")
            try:
                contextual_history = (
                    await self.conversation_memory.get_contextual_memory(
                        tenant_id, query
                    )
                )
                logger.info(
                    f"üîç GENERATE - R√âSULTAT brut: type={type(contextual_history)}, value={contextual_history}"
                )

                if contextual_history:
                    self.optimization_stats["contextual_memory_queries"] += 1
                    logger.info(
                        f"üìö Historique contextuel r√©cup√©r√©: {len(contextual_history)} √©l√©ments"
                    )
                else:
                    logger.warning(
                        f"‚ö†Ô∏è GENERATE - Historique VIDE retourn√© (contextual_history={contextual_history})"
                    )
            except Exception as e:
                logger.error(
                    f"‚ùå GENERATE - Exception r√©cup√©ration historique: {e}",
                    exc_info=True,
                )
        else:
            logger.warning(
                "‚ö†Ô∏è GENERATE - conversation_memory est None, impossible de r√©cup√©rer l'historique"
            )

        # ‚úÖ NOUVEAU : Enrichissement conversationnel
        original_query = query
        if contextual_history:
            try:
                enricher = ConversationalQueryEnricher()
                query = enricher.enrich(query, contextual_history, effective_language)

                if query != original_query:
                    logger.info(f"üîÑ Query enrichie: '{original_query}' ‚Üí '{query}'")
                    self.optimization_stats["queries_enriched"] = (
                        self.optimization_stats.get("queries_enriched", 0) + 1
                    )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec enrichissement query: {e}")
                # En cas d'erreur, on garde la query originale
                query = original_query

        try:
            return await self._process_query(
                query,  # ‚Üê Query possiblement enrichie
                effective_language,
                tenant_id,
                start_time,
                conversation_context=context_dict,
                contextual_history=contextual_history,
            )
        except Exception as e:
            logger.error(f"‚ùå Erreur generate_response: {e}")
            self.optimization_stats["errors_count"] += 1
            return RAGResult(
                source=RAGSource.INTERNAL_ERROR,
                metadata={"error": str(e)},
            )

    async def generate_response_with_entities(
        self,
        query: str,
        entities: Dict[str, Any],
        tenant_id: str = "default",
        language: Optional[str] = None,
        **kwargs,
    ) -> RAGResult:
        """
        Point d'entr√©e sp√©cial pour requ√™tes avec entit√©s pr√©-extraites

        UTILIS√â POUR LA M√âMOIRE CONVERSATIONNELLE:
        - Permet de passer directement les entit√©s fusionn√©es depuis la session
        - Bypass l'extraction normale du QueryRouter
        - Garantit que les entit√©s accumul√©es sont utilis√©es

        Args:
            query: Requ√™te utilisateur (peut √™tre accumul√©e)
            entities: Entit√©s pr√©-extraites et fusionn√©es
            tenant_id: Identifiant du tenant
            language: Langue de la requ√™te

        Returns:
            RAGResult avec r√©ponse g√©n√©r√©e
        """

        if not self.is_initialized:
            logger.warning("‚ö†Ô∏è RAG Engine non initialis√©, tentative d'initialisation")
            try:
                await self.initialize()
            except Exception as e:
                logger.error(f"‚ùå √âchec initialisation: {e}")

        start_time = time.time()
        self.optimization_stats["requests_total"] += 1
        self.optimization_stats["preextracted_entities_queries"] += 1

        # Validation
        if not query or not query.strip():
            return RAGResult(
                source=RAGSource.ERROR,
                metadata={"error": "Query vide"},
            )

        effective_language = language or "fr"
        logger.info(
            f"üåê generate_response_with_entities re√ßoit langue: {effective_language}"
        )
        logger.info(f"üìã Entit√©s pr√©-extraites fournies: {entities}")

        # Fallback si syst√®me indisponible
        if self.degraded_mode and not self.postgresql_retriever:
            return RAGResult(
                source=RAGSource.FALLBACK_NEEDED,
                answer="Le syst√®me RAG n'est pas disponible.",
                metadata={"reason": "syst√®me_indisponible"},
            )

        # ‚úÖ Extraire conversation_context depuis kwargs si pr√©sent
        context_dict = kwargs.get("conversation_context")

        # ‚úÖ NOUVEAU: R√©cup√©rer l'historique conversationnel contextuel
        contextual_history = None
        if self.conversation_memory:
            try:
                contextual_history = (
                    await self.conversation_memory.get_contextual_memory(
                        tenant_id, query
                    )
                )
                if contextual_history:
                    self.optimization_stats["contextual_memory_queries"] += 1
                    logger.info(
                        f"üìö Historique contextuel r√©cup√©r√©: {len(contextual_history)} √©l√©ments"
                    )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec r√©cup√©ration historique: {e}")

        # ‚úÖ NOUVEAU : Enrichissement conversationnel
        original_query = query
        if contextual_history:
            try:
                enricher = ConversationalQueryEnricher()
                query = enricher.enrich(query, contextual_history, effective_language)

                if query != original_query:
                    logger.info(f"üîÑ Query enrichie: '{original_query}' ‚Üí '{query}'")
                    self.optimization_stats["queries_enriched"] = (
                        self.optimization_stats.get("queries_enriched", 0) + 1
                    )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec enrichissement query: {e}")
                # En cas d'erreur, on garde la query originale
                query = original_query

        try:
            return await self._process_query_with_entities(
                query,  # ‚Üê Query possiblement enrichie
                entities,
                effective_language,
                tenant_id,
                start_time,
                conversation_context=context_dict,
                contextual_history=contextual_history,
            )
        except Exception as e:
            logger.error(f"‚ùå Erreur generate_response_with_entities: {e}")
            self.optimization_stats["errors_count"] += 1
            return RAGResult(
                source=RAGSource.INTERNAL_ERROR,
                metadata={"error": str(e)},
            )

    async def _process_query(
        self,
        query: str,
        language: str,
        tenant_id: str,
        start_time: float,
        conversation_context: Dict = None,
        contextual_history: List[Dict] = None,
    ) -> RAGResult:
        """Pipeline de traitement avec QueryRouter

        Args:
            query: Requ√™te utilisateur
            language: Langue de la requ√™te
            tenant_id: Identifiant du tenant
            start_time: Timestamp de d√©but
            conversation_context: Contexte conversationnel (format dict)
            contextual_history: Historique contextuel r√©cup√©r√© par ConversationMemory
        """

        logger.info(f"üåê _process_query traite avec langue: {language}")

        # 1. ROUTAGE VIA QUERY ROUTER
        route = self.query_router.route(
            query=query, user_id=tenant_id, language=language
        )

        logger.info(
            f"üéØ QueryRouter ‚Üí destination: {route.destination}, confiance: {route.confidence:.2%}"
        )

        # 2. V√âRIFIER CLARIFICATION N√âCESSAIRE
        if route.destination == "needs_clarification":
            self.optimization_stats["clarification_needed"] += 1
            logger.info(
                f"‚ö†Ô∏è Clarification n√©cessaire - champs manquants: {route.missing_fields}"
            )

            return RAGResult(
                source=RAGSource.NEEDS_CLARIFICATION,
                answer=self._build_clarification_message(
                    route.missing_fields, language
                ),
                metadata={
                    "needs_clarification": True,
                    "missing_fields": route.missing_fields,
                    "entities": route.entities,
                    "validation_details": route.validation_details,
                    "language": language,
                },
            )

        # 3. D√âTERMINER QUERY_TYPE DEPUIS DESTINATION
        if route.destination == "postgresql":
            query_type = "standard"
        elif route.destination == "weaviate":
            query_type = "diagnostic"
        else:  # hybrid
            query_type = "standard"

        # 4. CR√âER PREPROCESSED_DATA DEPUIS ROUTE
        preprocessed_data = {
            "normalized_query": query,
            "original_query": query,
            "entities": route.entities,
            "language": language,
            "routing_hint": route.destination,
            "is_comparative": False,
            "comparison_entities": [],
            "query_type": query_type,
            "metadata": {
                "original_query": query,
                "normalized_query": query,
                "routing_hint": route.destination,
                "is_comparative": False,
                "routing_applied": True,
                "confidence": route.confidence,
                "language_detected": language,
                "validation_details": route.validation_details,
            },
        }

        # ‚úÖ AJOUTER le contexte conversationnel
        if conversation_context:
            preprocessed_data["conversation_context"] = conversation_context
            logger.info(
                f"üìù Contexte conversationnel ajout√©: {list(conversation_context.keys())}"
            )

        # ‚úÖ NOUVEAU: AJOUTER l'historique contextuel
        if contextual_history:
            preprocessed_data["contextual_history"] = contextual_history
            preprocessed_data["metadata"]["contextual_history_count"] = len(
                contextual_history
            )
            logger.info(
                f"üìö Historique contextuel ajout√©: {len(contextual_history)} √©l√©ments"
            )

        # 5. MISE √Ä JOUR DES STATS (bas√© sur query_type d√©termin√©)
        if query_type == "comparative":
            self.optimization_stats["comparative_queries"] += 1
        elif query_type == "temporal_range":
            self.optimization_stats["temporal_queries"] += 1
        elif query_type == "optimization":
            self.optimization_stats["optimization_queries"] += 1
        elif query_type == "calculation":
            self.optimization_stats["calculation_queries"] += 1
        elif query_type == "economic":
            self.optimization_stats["economic_queries"] += 1
        elif query_type == "diagnostic":
            self.optimization_stats["diagnostic_queries"] += 1

        # 6. ROUTAGE VERS HANDLER
        result = await self._route_to_handler(
            query_type, preprocessed_data, start_time, language
        )

        # ‚úÖ CORRECTION CRITIQUE: G√©n√©rer r√©ponse LLM si n√©cessaire
        result = await self._ensure_answer_generated(
            result, preprocessed_data, query, language
        )

        # 7. ENRICHIR M√âTADONN√âES
        result.metadata.update(preprocessed_data["metadata"])
        result.metadata["route_confidence"] = route.confidence
        result.metadata["route_destination"] = route.destination

        self.optimization_stats["routing_success"] += 1

        return result

    async def _process_query_with_entities(
        self,
        query: str,
        entities: Dict[str, Any],
        language: str,
        tenant_id: str,
        start_time: float,
        conversation_context: Dict = None,
        contextual_history: List[Dict] = None,
    ) -> RAGResult:
        """
        Pipeline de traitement avec entit√©s pr√©-extraites

        Similaire √† _process_query mais utilise les entit√©s fournies
        au lieu de les extraire via le QueryRouter

        Args:
            query: Requ√™te utilisateur
            entities: Entit√©s pr√©-extraites
            language: Langue de la requ√™te
            tenant_id: Identifiant du tenant
            start_time: Timestamp de d√©but
            conversation_context: Contexte conversationnel (format dict)
            contextual_history: Historique contextuel r√©cup√©r√© par ConversationMemory
        """

        logger.info(f"üåê _process_query_with_entities traite avec langue: {language}")
        logger.info(f"üìã Utilisation des entit√©s pr√©-extraites: {entities}")

        # 1. ROUTAGE VIA QUERY ROUTER (qui utilisera les entit√©s si fournies)
        route = self.query_router.route(
            query=query,
            user_id=tenant_id,
            language=language,
            preextracted_entities=entities,  # Passer les entit√©s pr√©-extraites
        )

        logger.info(
            f"üéØ QueryRouter ‚Üí destination: {route.destination}, confiance: {route.confidence:.2%}"
        )

        # 2. V√âRIFIER CLARIFICATION (m√™me avec entit√©s pr√©-extraites)
        if route.destination == "needs_clarification":
            self.optimization_stats["clarification_needed"] += 1
            logger.info(
                f"‚ö†Ô∏è Clarification n√©cessaire malgr√© entit√©s - champs: {route.missing_fields}"
            )

            return RAGResult(
                source=RAGSource.NEEDS_CLARIFICATION,
                answer=self._build_clarification_message(
                    route.missing_fields, language
                ),
                metadata={
                    "needs_clarification": True,
                    "missing_fields": route.missing_fields,
                    "entities": route.entities,
                    "validation_details": route.validation_details,
                    "language": language,
                    "entities_preextracted": True,
                },
            )

        # 3. D√âTERMINER QUERY_TYPE DEPUIS DESTINATION
        if route.destination == "postgresql":
            query_type = "standard"
        elif route.destination == "weaviate":
            query_type = "diagnostic"
        else:  # hybrid
            query_type = "standard"

        # 4. CR√âER PREPROCESSED_DATA
        preprocessed_data = {
            "normalized_query": query,
            "original_query": query,
            "entities": route.entities,  # Utiliser les entit√©s valid√©es par le router
            "language": language,
            "routing_hint": route.destination,
            "is_comparative": False,
            "comparison_entities": [],
            "query_type": query_type,
            "metadata": {
                "original_query": query,
                "normalized_query": query,
                "routing_hint": route.destination,
                "is_comparative": False,
                "routing_applied": True,
                "entities_preextracted": True,
                "confidence": route.confidence,
                "language_detected": language,
                "validation_details": route.validation_details,
            },
        }

        # ‚úÖ AJOUTER le contexte conversationnel
        if conversation_context:
            preprocessed_data["conversation_context"] = conversation_context
            logger.info(
                f"üìù Contexte conversationnel ajout√©: {list(conversation_context.keys())}"
            )

        # ‚úÖ NOUVEAU: AJOUTER l'historique contextuel
        if contextual_history:
            preprocessed_data["contextual_history"] = contextual_history
            preprocessed_data["metadata"]["contextual_history_count"] = len(
                contextual_history
            )
            logger.info(
                f"üìö Historique contextuel ajout√©: {len(contextual_history)} √©l√©ments"
            )

        # 5. MISE √Ä JOUR DES STATS
        if query_type == "comparative":
            self.optimization_stats["comparative_queries"] += 1
        elif query_type == "temporal_range":
            self.optimization_stats["temporal_queries"] += 1
        elif query_type == "optimization":
            self.optimization_stats["optimization_queries"] += 1
        elif query_type == "calculation":
            self.optimization_stats["calculation_queries"] += 1
        elif query_type == "economic":
            self.optimization_stats["economic_queries"] += 1
        elif query_type == "diagnostic":
            self.optimization_stats["diagnostic_queries"] += 1

        # 6. ROUTAGE VERS HANDLER (force standard pour PostgreSQL)
        result = await self.standard_handler.handle(
            preprocessed_data, start_time, language=language
        )

        # ‚úÖ CORRECTION CRITIQUE: G√©n√©rer r√©ponse LLM si n√©cessaire
        result = await self._ensure_answer_generated(
            result, preprocessed_data, query, language
        )

        # 7. ENRICHIR M√âTADONN√âES
        result.metadata.update(preprocessed_data["metadata"])
        result.metadata["route_confidence"] = route.confidence
        result.metadata["route_destination"] = route.destination
        result.metadata["entities_source"] = "preextracted_from_session"

        self.optimization_stats["routing_success"] += 1

        return result

    async def _ensure_answer_generated(
        self,
        result: RAGResult,
        preprocessed_data: Dict[str, Any],
        original_query: str,
        language: str,
    ) -> RAGResult:
        """
        ‚úÖ NOUVELLE M√âTHODE CRITIQUE: G√©n√®re la r√©ponse LLM avec contexte conversationnel

        V√©rifie si le RAGResult contient des documents mais pas de r√©ponse,
        et dans ce cas appelle le g√©n√©rateur LLM pour cr√©er la r√©ponse.

        Args:
            result: RAGResult du handler
            preprocessed_data: Donn√©es preprocess√©es (contient contextual_history)
            original_query: Requ√™te originale
            language: Langue de la requ√™te

        Returns:
            RAGResult avec answer g√©n√©r√©
        """
        # Si on a d√©j√† une r√©ponse, on ne fait rien
        if result.answer and result.answer.strip():
            logger.debug("‚úÖ R√©ponse d√©j√† pr√©sente, g√©n√©ration LLM non n√©cessaire")
            return result

        # Si on a des documents mais pas de r√©ponse, g√©n√©rer via LLM
        if result.context_docs and len(result.context_docs) > 0:
            if not self.core.generator:
                logger.warning(
                    "‚ö†Ô∏è G√©n√©rateur LLM non disponible, impossible de g√©n√©rer r√©ponse"
                )
                result.answer = "Data retrieved but response generation unavailable."
                return result

            logger.info(
                f"üîß G√©n√©ration r√©ponse LLM pour {len(result.context_docs)} documents PostgreSQL"
            )

            # ‚úÖ CORRECTION : R√©cup√©rer le contexte conversationnel
            contextual_history = preprocessed_data.get("contextual_history", "")

            # DEBUG CRITIQUE - AJOUTER CES LOGS
            logger.info(
                f"üîç ENSURE - contextual_history type: {type(contextual_history)}"
            )
            logger.info(
                f"üîç ENSURE - contextual_history length: {len(contextual_history) if contextual_history else 0}"
            )
            logger.info(
                f"üîç ENSURE - contextual_history preview: {contextual_history[:200] if contextual_history else 'VIDE'}"
            )

            # Formater l'historique pour le g√©n√©rateur
            conversation_context = ""
            if contextual_history:
                # Le contexte est d√©j√† format√© en string
                conversation_context = str(contextual_history)
                logger.info(
                    f"üìö Contexte conversationnel transmis au g√©n√©rateur: {len(conversation_context)} chars"
                )
                logger.info(f"üìö Preview contexte: {conversation_context[:200]}")
            else:
                logger.warning("‚ö†Ô∏è ENSURE - Pas d'historique dans preprocessed_data!")

            try:
                # DEBUG : V√©rifier ce qu'on envoie au g√©n√©rateur
                logger.info(
                    f"üîß ENSURE - Appel generate_response avec conversation_context length: {len(conversation_context)}"
                )

                # Appel du g√©n√©rateur avec les documents r√©cup√©r√©s ET le contexte conversationnel
                generated_answer = await self.core.generator.generate_response(
                    query=preprocessed_data.get("original_query", original_query),
                    context_docs=result.context_docs,
                    conversation_context=conversation_context,  # ‚úÖ CORRECTION - DOIT CONTENIR LE CONTEXTE
                    language=language,
                    intent_result=None,
                )

                result.answer = generated_answer
                result.metadata["llm_generation_applied"] = True
                result.metadata["llm_input_docs_count"] = len(result.context_docs)
                result.metadata["conversation_context_used"] = bool(
                    conversation_context
                )
                result.metadata["conversation_context_length"] = len(
                    conversation_context
                )
                self.optimization_stats["llm_generations"] += 1

                logger.info(
                    f"‚úÖ R√©ponse LLM g√©n√©r√©e ({len(generated_answer)} caract√®res)"
                )

            except Exception as e:
                logger.error(f"‚ùå Erreur g√©n√©ration LLM: {e}", exc_info=True)
                result.answer = "Unable to generate response from the retrieved data."
                result.metadata["llm_generation_error"] = str(e)

        return result

    def _build_clarification_message(
        self, missing_fields: List[str], language: str = "fr"
    ) -> str:
        """
        Construit un message de clarification en fran√ßais ou anglais

        Args:
            missing_fields: Liste des champs manquants
            language: Langue du message ('fr' ou 'en')

        Returns:
            Message de clarification format√©
        """
        if language == "en":
            if len(missing_fields) == 1:
                return f"Please specify the {missing_fields[0]} to continue."
            else:
                fields = ", ".join(missing_fields[:-1]) + f" and {missing_fields[-1]}"
                return f"Please specify the following information: {fields}."
        else:  # fran√ßais par d√©faut
            if len(missing_fields) == 1:
                field_fr = self._translate_field_name(missing_fields[0])
                return f"Veuillez pr√©ciser {field_fr} pour continuer."
            else:
                fields_fr = [self._translate_field_name(f) for f in missing_fields]
                fields_str = ", ".join(fields_fr[:-1]) + f" et {fields_fr[-1]}"
                return f"Veuillez pr√©ciser les informations suivantes : {fields_str}."

    def _translate_field_name(self, field: str) -> str:
        """Traduit un nom de champ en fran√ßais"""
        translations = {
            "breed": "la race",
            "age": "l'√¢ge",
            "gender": "le sexe",
            "weight": "le poids",
            "metric": "la m√©trique",
            "period": "la p√©riode",
            "date": "la date",
            "location": "le lieu",
            "building": "le b√¢timent",
            "batch": "le lot",
        }
        return translations.get(field, field)

    async def _route_to_handler(
        self,
        query_type: str,
        preprocessed_data: Dict[str, Any],
        start_time: float,
        language: str,
    ) -> RAGResult:
        """Route vers le handler appropri√©"""

        logger.info(f"üåê _route_to_handler avec langue: {language}")

        if query_type == "temporal_range":
            logger.debug("‚Üí Routage vers TemporalQueryHandler")
            return await self.temporal_handler.handle(preprocessed_data, start_time)

        elif query_type == "comparative":
            logger.debug("‚Üí Routage vers ComparativeQueryHandler")
            return await self.comparative_handler.handle(preprocessed_data, start_time)

        elif query_type in ["optimization", "calculation"]:
            logger.debug(f"‚Üí Routage vers StandardHandler (type={query_type})")
            preprocessed_data["is_optimization"] = query_type == "optimization"
            preprocessed_data["is_calculation"] = query_type == "calculation"
            return await self.standard_handler.handle(
                preprocessed_data, start_time, language=language
            )

        elif query_type == "economic":
            logger.debug("‚Üí Requ√™te √©conomique d√©tect√©e")
            return RAGResult(
                source=RAGSource.ERROR,
                answer="Les donn√©es √©conomiques ne sont pas disponibles.",
                metadata={"query_type": "economic"},
            )

        elif query_type == "diagnostic":
            logger.debug("‚Üí Routage vers StandardHandler (diagnostic)")
            preprocessed_data["routing_hint"] = "weaviate"
            return await self.standard_handler.handle(
                preprocessed_data, start_time, language=language
            )

        else:  # standard
            logger.debug("‚Üí Routage vers StandardHandler (standard)")
            return await self.standard_handler.handle(
                preprocessed_data, start_time, language=language
            )

    def get_status(self) -> Dict:
        """Status syst√®me complet"""
        return {
            "rag_enabled": RAG_ENABLED,
            "initialized": self.is_initialized,
            "degraded_mode": self.degraded_mode,
            "version": "v4.8.2_query_enrichment",
            "architecture": "modular_query_router_with_memory_and_enrichment",
            "modules": {
                "core": True,
                "rag_engine": True,
                "query_router": bool(self.query_router),
                "entity_extractor": bool(self.entity_extractor),
                "temporal_handler": True,
                "comparative_handler": True,
                "standard_handler": True,
                "postgresql_retriever": bool(self.postgresql_retriever),
                "weaviate_core": bool(self.weaviate_core),
                "comparison_handler": bool(self.comparison_handler),
                "llm_generator": bool(self.core.generator),
                "conversation_memory": bool(self.conversation_memory),
            },
            "optimization_stats": self.optimization_stats.copy(),
            "initialization_errors": self.initialization_errors,
        }

    async def close(self):
        """Fermeture propre de tous les modules"""
        logger.info("üîí Fermeture RAG Engine...")

        try:
            if self.postgresql_retriever:
                await self.postgresql_retriever.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture PostgreSQL Retriever: {e}")

        try:
            if self.weaviate_core:
                await self.weaviate_core.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture Weaviate Core: {e}")

        try:
            await self.core.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture Core: {e}")

        logger.info("‚úÖ RAG Engine ferm√© compl√®tement")


# Factory function
def create_rag_engine(openai_client=None) -> InteliaRAGEngine:
    """Factory pour cr√©er une instance RAG Engine"""
    return InteliaRAGEngine(openai_client)


# Fonction de test
async def test_clarification_query():
    """Test d'une requ√™te n√©cessitant clarification"""
    engine = InteliaRAGEngine()

    try:
        await engine.initialize()

        test_query = "Quel est le poids pour du Ross 308 ?"

        logger.info(f"\n{'='*60}")
        logger.info(f"Testing: {test_query}")
        logger.info(f"{'='*60}")

        result = await engine.generate_response(test_query, language="fr")

        print(f"Source: {result.source}")
        print(f"Answer: {result.answer}")
        print(f"Metadata: {result.metadata}")

    except Exception as e:
        logger.error(f"‚ùå Test error: {e}")
    finally:
        await engine.close()


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
    asyncio.run(test_clarification_query())
