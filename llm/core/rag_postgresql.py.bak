# -*- coding: utf-8 -*-
"""
rag_postgresql.py - PostgreSQL System for RAG
VERSION WITH OPENAI GPT-4O-MINI - Natural response generation
Complete rewrite with JSON-based terminology loading
"""

import os
import json
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum

# Safe conditional imports
try:
    import asyncpg

    ASYNCPG_AVAILABLE = True
except ImportError:
    ASYNCPG_AVAILABLE = False
    asyncpg = None

try:
    import openai

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

from .data_models import RAGResult, RAGSource, Document

logger = logging.getLogger(__name__)

# PostgreSQL configuration with secure defaults
POSTGRESQL_CONFIG = {
    "user": os.getenv("DB_USER", "doadmin"),
    "password": os.getenv("DB_PASSWORD", ""),
    "host": os.getenv("DB_HOST", "localhost"),
    "port": int(os.getenv("DB_PORT", 25060)),
    "database": os.getenv("DB_NAME", "defaultdb"),
    "ssl": os.getenv("DB_SSL", "require"),
}

# OpenAI configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = "gpt-4o-mini"  # Cost-effective model for simple tasks


class QueryType(Enum):
    """Query types for intelligent routing"""

    KNOWLEDGE = "knowledge"
    METRICS = "metrics"
    HYBRID = "hybrid"
    UNKNOWN = "unknown"


@dataclass
class MetricResult:
    """Result of a PostgreSQL metrics query"""

    company: str
    breed: str
    strain: str
    species: str
    metric_name: str
    value_numeric: Optional[float] = None
    value_text: Optional[str] = None
    unit: Optional[str] = None
    age_min: Optional[int] = None
    age_max: Optional[int] = None
    sheet_name: str = ""
    category: str = ""
    confidence: float = 1.0
    sex: Optional[str] = None
    housing_system: Optional[str] = None
    data_type: Optional[str] = None

    def __post_init__(self):
        """Data validation and cleaning"""
        self.company = str(self.company) if self.company is not None else "Unknown"
        self.breed = str(self.breed) if self.breed is not None else "Unknown"
        self.strain = str(self.strain) if self.strain is not None else "Unknown"
        self.species = str(self.species) if self.species is not None else "Unknown"
        self.metric_name = (
            str(self.metric_name) if self.metric_name is not None else "Unknown"
        )
        self.sheet_name = str(self.sheet_name) if self.sheet_name is not None else ""
        self.category = str(self.category) if self.category is not None else ""

        # Sex normalization
        if self.sex:
            self.sex = str(self.sex).lower()
            if self.sex in ["male", "mâle", "m", "masculin"]:
                self.sex = "male"
            elif self.sex in ["female", "femelle", "f", "féminin"]:
                self.sex = "female"
            elif self.sex in [
                "mixed",
                "mixte",
                "as_hatched",
                "as-hatched",
                "straight_run",
            ]:
                self.sex = "as_hatched"
            else:
                self.sex = "as_hatched"

        self.confidence = max(0.0, min(1.0, float(self.confidence)))


class SQLQueryNormalizer:
    """Multilingual normalizer for converting user concepts to searchable database terms

    This class loads terminology from JSON configuration files and provides methods
    to normalize queries, extract search terms, and detect sex information.
    """

    def __init__(self):
        """Initialize normalizer with terminology from JSON files"""
        self.terminology = self._load_terminology()
        self.CONCEPT_MAPPINGS = self._build_concept_mappings()
        logger.info(
            f"SQLQueryNormalizer initialized with {len(self.CONCEPT_MAPPINGS)} concept mappings"
        )

    def _load_terminology(self) -> Dict[str, Any]:
        """Load terminology from JSON configuration files

        Loads terminology files for supported languages (en, fr, es) from the config directory.
        If a file is not found or cannot be loaded, logs a warning and continues with empty dict.

        Returns:
            Dict[str, Any]: Dictionary with language codes as keys and terminology as values
        """
        config_dir = os.path.join(os.path.dirname(__file__), "..", "config")
        terms = {}

        supported_languages = ["en", "fr", "es"]

        for lang in supported_languages:
            file_path = os.path.join(config_dir, f"universal_terms_{lang}.json")
            try:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        terms[lang] = json.load(f)
                        logger.info(
                            f"Terminology loaded successfully for language: {lang}"
                        )
                else:
                    logger.warning(f"Terminology file not found: {file_path}")
                    terms[lang] = {}
            except Exception as e:
                logger.error(f"Error loading terminology for {lang}: {e}")
                terms[lang] = {}

        return terms

    def _build_concept_mappings(self) -> Dict[str, List[str]]:
        """Build concept mappings from loaded terminology

        Aggregates terms from all loaded language files into a unified mapping
        where each concept key maps to all its possible terms across languages.

        Returns:
            Dict[str, List[str]]: Mapping of concept keys to lists of searchable terms
        """
        mappings = {}

        # Aggregate terms from all languages
        for lang, lang_terms in self.terminology.items():
            if "performance_metrics" not in lang_terms:
                continue

            perf_metrics = lang_terms["performance_metrics"]

            for metric_key, metric_terms in perf_metrics.items():
                # Normalize metric key (e.g., "body_weight" -> "weight")
                base_key = metric_key.split("_")[0] if "_" in metric_key else metric_key

                if base_key not in mappings:
                    mappings[base_key] = []

                # Add all terms for this metric
                if isinstance(metric_terms, list):
                    mappings[base_key].extend(metric_terms)

                # Also map the full metric key
                if metric_key not in mappings:
                    mappings[metric_key] = []
                if isinstance(metric_terms, list):
                    mappings[metric_key].extend(metric_terms)

        # Remove duplicates
        for key in mappings:
            mappings[key] = list(set(mappings[key]))

        logger.info(f"Built concept mappings for {len(mappings)} concepts")
        return mappings

    def get_metric_patterns(self, query: str, language: str = "fr") -> List[str]:
        """Get search patterns based on configured terms

        Args:
            query: User query string
            language: Target language code (default: 'fr')

        Returns:
            List[str]: List of matching search patterns for the query
        """
        query_lower = query.lower()
        patterns = []

        if language not in self.terminology:
            logger.warning(f"Language {language} not found in terminology")
            return patterns

        lang_terms = self.terminology[language]

        if "performance_metrics" not in lang_terms:
            return patterns

        perf_metrics = lang_terms["performance_metrics"]

        # Check each metric type
        for metric_key, metric_terms in perf_metrics.items():
            if isinstance(metric_terms, list):
                if any(term.lower() in query_lower for term in metric_terms):
                    patterns.extend(metric_terms)

        return list(set(patterns))  # Remove duplicates

    def normalize_query_concepts(self, query: str) -> List[str]:
        """Converts user query to normalized concept terms

        Args:
            query: User query string

        Returns:
            List[str]: List of unique normalized concept terms found in query
        """
        query_lower = query.lower()
        normalized_concepts = []

        for concept, terms in self.CONCEPT_MAPPINGS.items():
            if any(term.lower() in query_lower for term in terms):
                normalized_concepts.extend(terms)

        seen = set()
        unique_concepts = []
        for concept in normalized_concepts:
            if concept not in seen:
                seen.add(concept)
                unique_concepts.append(concept)

        return unique_concepts

    def get_search_terms(self, query: str) -> Tuple[List[str], List[str]]:
        """Returns (normalized_concepts, raw_words) for SQL search

        Args:
            query: User query string

        Returns:
            Tuple containing:
                - List of normalized concept terms
                - List of raw words from query (length > 3)
        """
        normalized = self.normalize_query_concepts(query)
        raw_words = [word for word in query.lower().split() if len(word) > 3]
        return normalized, raw_words

    def extract_sex_from_query(self, query: str) -> Optional[str]:
        """Extract sex from query - returns 'male', 'female', 'as_hatched', or None

        Args:
            query: User query string

        Returns:
            Optional[str]: Detected sex ('male', 'female', 'as_hatched') or None
        """
        query_lower = query.lower()

        male_patterns = ["male", "mâle", "mâles", "masculin", "coq", "coqs", "rooster"]
        if any(pattern in query_lower for pattern in male_patterns):
            return "male"

        female_patterns = [
            "female",
            "femelle",
            "femelles",
            "féminin",
            "poule",
            "poules",
            "hen",
        ]
        if any(pattern in query_lower for pattern in female_patterns):
            return "female"

        mixed_patterns = [
            "as-hatched",
            "ashatched",
            "mixed",
            "mixte",
            "mélangé",
            "non sexé",
            "straight run",
        ]
        if any(pattern in query_lower for pattern in mixed_patterns):
            return "as_hatched"

        return None


class QueryRouter:
    """Intelligent router to direct queries to the right source"""

    def __init__(self):
        self.metric_keywords = {
            "performance",
            "metrics",
            "donnees",
            "chiffres",
            "resultats",
            "weight",
            "poids",
            "egg",
            "oeuf",
            "production",
            "feed",
            "alimentation",
            "mortality",
            "mortalite",
            "growth",
            "croissance",
            "nutrition",
            "age",
            "semaine",
            "week",
            "day",
            "jour",
            "phase",
            "temperature",
            "humidity",
            "humidite",
            "housing",
            "logement",
            "density",
            "densite",
            "fcr",
            "icg",
            "conversion",
            "efficacite",
            "ross",
            "cobb",
            "hubbard",
        }

        self.knowledge_keywords = {
            "comment",
            "pourquoi",
            "qu'est-ce",
            "expliquer",
            "definir",
            "maladie",
            "disease",
            "traitement",
            "treatment",
            "symptom",
            "symptome",
            "prevention",
            "biosecurite",
            "biosecurity",
            "management",
            "gestion",
            "guide",
            "protocol",
            "protocole",
            "conseil",
            "advice",
            "recommendation",
            "recommandation",
        }

    def route_query(self, query: str, intent_result=None) -> QueryType:
        """Determines query type and appropriate source

        Args:
            query: User query string
            intent_result: Optional intent analysis result

        Returns:
            QueryType: Determined query type (METRICS, KNOWLEDGE, HYBRID, or UNKNOWN)
        """
        query_lower = query.lower()

        metric_score = sum(
            1 for keyword in self.metric_keywords if keyword in query_lower
        )
        knowledge_score = sum(
            1 for keyword in self.knowledge_keywords if keyword in query_lower
        )

        if intent_result:
            if hasattr(intent_result, "genetic_line") and intent_result.genetic_line:
                metric_score += 2
            if hasattr(intent_result, "age") and intent_result.age:
                metric_score += 1

        comparison_indicators = [
            "vs",
            "versus",
            "compare",
            "comparaison",
            "difference",
            "mieux",
        ]
        has_comparison = any(
            indicator in query_lower for indicator in comparison_indicators
        )

        if metric_score > knowledge_score + 1:
            return QueryType.METRICS
        elif knowledge_score > metric_score + 1:
            return QueryType.KNOWLEDGE
        elif has_comparison or (metric_score > 0 and knowledge_score > 0):
            return QueryType.HYBRID
        else:
            return QueryType.UNKNOWN


class PostgreSQLRetriever:
    """PostgreSQL data retriever for poultry metrics"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.pool = None
        self.query_normalizer = SQLQueryNormalizer()
        self.is_initialized = False

    async def initialize(self):
        """Initialize PostgreSQL connection"""
        if not ASYNCPG_AVAILABLE:
            logger.error("asyncpg not available - PostgreSQL disabled")
            raise ImportError("asyncpg required for PostgreSQL")

        if self.is_initialized:
            return

        try:
            if not self.config.get("password"):
                logger.warning("DB_PASSWORD not defined - PostgreSQL may fail")

            if not self.config.get("host"):
                logger.warning("DB_HOST not defined - PostgreSQL may fail")

            self.pool = await asyncpg.create_pool(
                user=self.config["user"],
                password=self.config["password"],
                host=self.config["host"],
                port=self.config["port"],
                database=self.config["database"],
                ssl=self.config["ssl"],
                min_size=2,
                max_size=10,
                command_timeout=30,
            )

            async with self.pool.acquire() as conn:
                await conn.execute("SELECT 1")

            self.is_initialized = True
            logger.info("PostgreSQL Retriever initialized successfully")

        except Exception as e:
            logger.error(f"PostgreSQL initialization error: {e}")
            self.pool = None
            self.is_initialized = False
            raise

    async def search_metrics(
        self,
        query: str,
        entities: Dict[str, Any] = None,  # ✅ Type changé de str à Any
        top_k: int = 10,
    ) -> List[MetricResult]:
        """Search metrics in PostgreSQL with sex/as-hatched logic and entity support

        Args:
            query: User query string
            entities: Preprocessed entities from intent analysis (can contain objects, not just strings)
            top_k: Maximum number of results to return

        Returns:
            List[MetricResult]: List of matching metrics
        """

        if not self.is_initialized or not self.pool:
            logger.warning("PostgreSQL not initialized - attempting initialization")
            try:
                await self.initialize()
            except Exception as e:
                logger.error(f"PostgreSQL initialization failed: {e}")
                return []

        try:
            # ✅ NOUVEAU: Normaliser les entités si elles proviennent de l'analyse d'intent
            normalized_entities = self._normalize_entities(entities)

            # ✅ NOUVEAU: Log des entités reçues pour debug
            logger.debug(f"Entities received: {entities}")
            logger.debug(f"Normalized entities: {normalized_entities}")

            sql_query, params = self._build_sex_aware_sql_query(
                query, normalized_entities, top_k
            )

            logger.debug(f"SQL Query: {sql_query}")
            logger.debug(f"Parameters: {params}")

            async with self.pool.acquire() as conn:
                rows = await conn.fetch(sql_query, *params)

            results = []
            for i, row in enumerate(rows):
                try:
                    result = MetricResult(
                        company=row.get("company_name", "Unknown"),
                        breed=row.get("breed_name", "Unknown"),
                        strain=row.get("strain_name", "Unknown"),
                        species=row.get("species", "Unknown"),
                        metric_name=row.get("metric_name", "Unknown"),
                        value_numeric=row.get("value_numeric"),
                        value_text=row.get("value_text"),
                        unit=row.get("unit"),
                        age_min=row.get("age_min"),
                        age_max=row.get("age_max"),
                        sheet_name=row.get("sheet_name", ""),
                        category=row.get("category_name", ""),
                        sex=row.get("sex"),
                        housing_system=row.get("housing_system"),
                        data_type=row.get("data_type"),
                        confidence=self._calculate_sex_aware_relevance(
                            query,
                            row,
                            normalized_entities,  # ✅ Utilise les entités normalisées
                        ),
                    )
                    results.append(result)
                except Exception as row_error:
                    logger.error(f"Row conversion error {i}: {row_error}")
                    continue

            logger.info(
                f"PostgreSQL: {len(results)} metrics found from {len(rows)} rows"
            )
            return results

        except Exception as e:
            logger.error(f"PostgreSQL search error: {e}")
            return []

        def _normalize_entities(
            self, entities: Dict[str, Any] = None
        ) -> Dict[str, str]:
            """Normalize entities from intent analysis to simple string dict

            Args:
                entities: Raw entities dict (may contain objects or complex types)

            Returns:
                Dict[str, str]: Normalized entities with string values only
            """
            if not entities:
                return {}

            normalized = {}

            for key, value in entities.items():
                if value is None:
                    continue

                # Si c'est déjà une string, on la garde
                if isinstance(value, str):
                    normalized[key] = value
                # Si c'est un bool, on le convertit en string
                elif isinstance(value, bool):
                    normalized[key] = "true" if value else "false"
                # Si c'est un nombre, on le convertit en string
                elif isinstance(value, (int, float)):
                    normalized[key] = str(value)
                # Si c'est un objet avec un attribut 'value', on l'extrait
                elif hasattr(value, "value"):
                    normalized[key] = str(value.value)
                # Sinon, on convertit en string
                else:
                    normalized[key] = str(value)

            return normalized

    def _build_sex_aware_sql_query(
        self, query: str, entities: Dict[str, str] = None, top_k: int = 10
    ) -> Tuple[str, List]:
        """Build SQL query with sex/as-hatched logic"""

        base_query = """
        SELECT 
            c.company_name,
            b.breed_name,
            s.strain_name,
            s.species,
            m.metric_name,
            m.value_numeric,
            m.value_text,
            m.unit,
            m.age_min,
            m.age_max,
            m.sheet_name,
            dc.category_name,
            d.sex,
            d.housing_system,
            d.data_type,
            m.metadata
        FROM companies c
        JOIN breeds b ON c.id = b.company_id
        JOIN strains s ON b.id = s.breed_id  
        JOIN documents d ON s.id = d.strain_id
        JOIN metrics m ON d.id = m.document_id
        JOIN data_categories dc ON m.category_id = dc.id
        WHERE 1=1
        """

        params = []
        conditions = []
        param_count = 0

        # Sex logic with fallback
        sex_from_query = self.query_normalizer.extract_sex_from_query(query)
        sex_from_entities = entities.get("sex") if entities else None
        sex_specified = entities.get("sex_specified") == "true" if entities else False

        target_sex = sex_from_entities or sex_from_query
        actual_sex_specified = sex_specified or (sex_from_query is not None)

        if target_sex and actual_sex_specified:
            logger.debug(
                f"Sex specified: {target_sex}, searching with as_hatched fallback"
            )
            param_count += 1

            sex_priority_case = f"""
                CASE 
                    WHEN LOWER(COALESCE(d.sex, 'as_hatched')) = ${param_count} THEN 1
                    WHEN LOWER(COALESCE(d.sex, 'as_hatched')) IN ('as_hatched', 'mixed', 'as-hatched') THEN 2
                    ELSE 3
                END
            """

            conditions.append(
                f"""
                (LOWER(COALESCE(d.sex, 'as_hatched')) = ${param_count} 
                 OR LOWER(COALESCE(d.sex, 'as_hatched')) IN ('as_hatched', 'mixed', 'as-hatched', 'straight_run'))
            """
            )

            params.append(target_sex.lower())

        else:
            logger.debug(
                "No sex specified, defaulting to as_hatched with other sexes included"
            )

            sex_priority_case = """
                CASE 
                    WHEN LOWER(COALESCE(d.sex, 'as_hatched')) IN ('as_hatched', 'mixed', 'as-hatched') THEN 1
                    WHEN LOWER(COALESCE(d.sex, 'as_hatched')) = 'male' THEN 2
                    WHEN LOWER(COALESCE(d.sex, 'as_hatched')) = 'female' THEN 3
                    ELSE 4
                END
            """

        # Concept normalization using JSON-based terminology
        normalized_concepts, raw_words = self.query_normalizer.get_search_terms(query)
        logger.debug(f"Normalized concepts: {normalized_concepts[:5]}")
        logger.debug(f"Raw words: {raw_words[:3]}")

        # Age extraction
        age_extracted = self._extract_age_from_query(query)
        if age_extracted:
            logger.debug(f"Age extracted from query: {age_extracted} days")
            age_tolerance = 3

            param_count += 1
            param_count_age2 = param_count + 1
            param_count_tolerance = param_count + 2

            conditions.append(
                f"""
                ((m.age_min <= ${param_count} AND m.age_max >= ${param_count_age2}) 
                 OR ABS(COALESCE(m.age_min, 0) - ${param_count}) <= ${param_count_tolerance}
                 OR ABS(COALESCE(m.age_max, 0) - ${param_count_age2}) <= ${param_count_tolerance})
            """
            )

            params.extend([age_extracted, age_extracted, age_tolerance])
            param_count += 2

        # Entity filters
        if entities:
            if entities.get("line"):
                param_count += 1
                conditions.append(f"LOWER(s.strain_name) ILIKE ${param_count}")
                params.append(f"%{entities['line'].lower()}%")

            if entities.get("age_days") and not age_extracted:
                age_days = int(entities["age_days"])
                param_count += 1
                param_count_age2 = param_count + 1
                conditions.append(
                    f"""
                    (m.age_min <= ${param_count} AND m.age_max >= ${param_count_age2}) 
                    OR (m.age_min IS NULL AND m.age_max IS NULL)
                """
                )
                params.extend([age_days, age_days])
                param_count += 1

        # Metric search with normalized concepts
        metric_search_conditions = []

        for concept in normalized_concepts[:8]:
            param_count += 1
            metric_search_conditions.append(
                f"LOWER(m.metric_name) ILIKE ${param_count}"
            )
            params.append(f"%{concept}%")

        for word in raw_words[:3]:
            param_count += 1
            param_count_word2 = param_count + 1
            metric_search_conditions.extend(
                [
                    f"LOWER(m.metric_name) ILIKE ${param_count}",
                    f"LOWER(m.value_text) ILIKE ${param_count_word2}",
                ]
            )
            params.extend([f"%{word}%", f"%{word}%"])
            param_count += 1

        if metric_search_conditions:
            conditions.append(f"({' OR '.join(metric_search_conditions)})")

        if conditions:
            base_query += " AND " + " AND ".join(conditions)

        # Sorting with sex prioritization
        order_clauses = [sex_priority_case]

        if age_extracted:
            order_clauses.append(f"ABS(COALESCE(m.age_min, 999) - {age_extracted})")

        order_clauses.extend(["m.value_numeric DESC NULLS LAST", "m.metric_name"])

        base_query += f" ORDER BY {', '.join(order_clauses)}"
        base_query += f" LIMIT {top_k}"

        return base_query, params

    def _calculate_sex_aware_relevance(
        self, query: str, row: Dict, entities: Dict[str, str] = None
    ) -> float:
        """Calculate relevance score considering sex matching"""
        score = 0.5

        sex_from_query = self.query_normalizer.extract_sex_from_query(query)
        sex_from_entities = entities.get("sex") if entities else None
        sex_specified = entities.get("sex_specified") == "true" if entities else False

        target_sex = sex_from_entities or sex_from_query
        row_sex = (row.get("sex") or "as_hatched").lower()

        if target_sex and sex_specified:
            if row_sex == target_sex.lower():
                score += 0.3
            elif row_sex in ["as_hatched", "mixed", "as-hatched"]:
                score += 0.1
        else:
            if row_sex in ["as_hatched", "mixed", "as-hatched"]:
                score += 0.2
            else:
                score += 0.05

        normalized_concepts, _ = self.query_normalizer.get_search_terms(query)
        metric_name_lower = (row.get("metric_name") or "").lower()

        for concept in normalized_concepts:
            if concept in metric_name_lower:
                score += 0.3
                break

        query_lower = query.lower()
        if query_lower in metric_name_lower:
            score += 0.2

        if row.get("value_numeric") is not None:
            score += 0.1

        if row.get("age_min") is not None and row.get("age_max") is not None:
            score += 0.1

        return min(1.0, score)

    def _extract_age_from_query(self, query: str) -> Optional[int]:
        """Extract age in days from query"""
        import re

        patterns = [
            r"day\s+(\d+)",
            r"jour\s+(\d+)",
            r"j\s*(\d+)",
            r"(\d+)\s*day",
            r"(\d+)\s*jour",
            r"a\s+(\d+)\s+jours?",
            r"at\s+day\s+(\d+)",
            r"age\s+(\d+)",
            r"(\d+)\s*j\b",
            r"d(\d+)",
            r"age_day_(\d+)",
        ]

        query_lower = query.lower()
        for pattern in patterns:
            match = re.search(pattern, query_lower)
            if match:
                try:
                    age = int(match.group(1))
                    if 0 <= age <= 150:
                        logger.debug(
                            f"Age detected: {age} days via pattern '{pattern}'"
                        )
                        return age
                except ValueError:
                    continue

        implicit_patterns = [
            r"à\s+(\d+)\s+jours?",
            r"at\s+(\d+)\s+days?",
            r"(\d+)\s+jours?\s+de",
            r"(\d+)\s+days?\s+of",
        ]

        for pattern in implicit_patterns:
            match = re.search(pattern, query_lower)
            if match:
                try:
                    age = int(match.group(1))
                    if 0 <= age <= 150:
                        logger.debug(
                            f"Implicit age detected: {age} days via pattern '{pattern}'"
                        )
                        return age
                except ValueError:
                    continue

        return None

    async def close(self):
        """Close PostgreSQL connection"""
        if self.pool:
            try:
                await self.pool.close()
                logger.info("PostgreSQL connection closed")
            except Exception as e:
                logger.error(f"PostgreSQL close error: {e}")
            finally:
                self.pool = None
                self.is_initialized = False


class PostgreSQLSystem:
    """Main PostgreSQL system with OpenAI response generation"""

    def __init__(self):
        self.query_router = None
        self.postgres_retriever = None
        self.is_initialized = False
        self.openai_client = None

    async def initialize(self):
        """Initialize PostgreSQL system"""
        if self.is_initialized:
            return

        if not ASYNCPG_AVAILABLE:
            logger.error("asyncpg not available - PostgreSQL disabled")
            raise ImportError("asyncpg required for PostgreSQL")

        try:
            self.query_router = QueryRouter()
            self.postgres_retriever = PostgreSQLRetriever(POSTGRESQL_CONFIG)
            await self.postgres_retriever.initialize()

            # Initialize OpenAI client if available
            if OPENAI_AVAILABLE and OPENAI_API_KEY:
                self.openai_client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
                logger.info("OpenAI client initialized with gpt-4o-mini")
            else:
                logger.warning("OpenAI not available - using fallback responses")

            self.is_initialized = True
            logger.info("PostgreSQL System initialized with OpenAI response generation")

        except Exception as e:
            logger.error(f"PostgreSQL System initialization error: {e}")
            self.is_initialized = False
            raise

    def route_query(self, query: str, intent_result=None) -> QueryType:
        """Route a query to the appropriate source"""
        if not self.query_router:
            return QueryType.KNOWLEDGE
        return self.query_router.route_query(query, intent_result)

    async def _generate_natural_response_with_openai(
        self,
        query: str,
        metric: MetricResult,
        age_requested: Optional[int],
        target_sex: Optional[str],
    ) -> str:
        """Generate natural response using OpenAI gpt-4o-mini"""

        # Prepare structured context
        context = {
            "question": query,
            "strain": metric.strain,
            "sex": metric.sex,
            "age": metric.age_min,
            "metric": metric.metric_name,
            "value": metric.value_numeric,
            "unit": metric.unit,
        }

        # System prompt
        system_prompt = """Tu es un assistant expert en aviculture. 
Tu dois répondre aux questions sur les performances des volailles de manière naturelle et professionnelle.
Reprends les éléments de la question dans ta réponse.
Sois concis et précis. Réponds en français."""

        # User prompt
        user_prompt = f"""Question: {query}

Données trouvées:
- Souche: {context['strain']}
- Sexe: {context['sex']}
- Âge: {context['age']} jours
- Métrique: {context['metric']}
- Valeur: {context['value']} {context['unit']}

Génère une réponse naturelle en français qui reprend la question et donne l'information de manière claire."""

        try:
            if not self.openai_client:
                raise Exception("OpenAI client not initialized")

            response = await self.openai_client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.3,
                max_tokens=150,
            )

            generated_text = response.choices[0].message.content.strip()
            logger.info(
                f"OpenAI response generated successfully: {len(generated_text)} chars"
            )
            return generated_text

        except Exception as e:
            logger.error(f"OpenAI error: {e}")
            # Fallback to structured response
            sex_display = {
                "male": "mâles",
                "female": "femelles",
                "as_hatched": "as-hatched (sexes mélangés)",
            }.get(context["sex"], context["sex"])

            return f"Le poids d'un {context['strain']} {sex_display} de {context['age']} jours est de {context['value']} {context['unit']}."

    async def search_metrics(
        self, query: str, entities: Dict[str, str] = None, top_k: int = 10
    ) -> RAGResult:
        """Main search method with OpenAI-powered response generation"""

        if not self.is_initialized or not self.postgres_retriever:
            return RAGResult(
                source=RAGSource.NO_RESULTS,
                metadata={"error": "PostgreSQL not available"},
            )

        try:
            # Search metrics
            metric_results = await self.postgres_retriever.search_metrics(
                query, entities, top_k
            )

            if not metric_results:
                return RAGResult(
                    source=RAGSource.NO_RESULTS,
                    metadata={
                        "source_type": "metrics",
                        "data_source": "postgresql",
                        "sex_logic_applied": True,
                    },
                )

            # Convert to Documents
            documents = []
            logger.debug(f"Converting {len(metric_results)} metrics to documents")

            for i, metric in enumerate(metric_results):
                try:
                    doc_content = self._format_metric_content_with_sex(metric)

                    doc = Document(
                        content=doc_content,
                        metadata={
                            "company": metric.company,
                            "breed": metric.breed,
                            "strain": metric.strain,
                            "species": metric.species,
                            "metric_name": metric.metric_name,
                            "category": metric.category,
                            "sheet_name": metric.sheet_name,
                            "sex": metric.sex,
                            "housing_system": metric.housing_system,
                            "data_type": metric.data_type,
                            "source_type": "metrics",
                            "data_source": "postgresql",
                            "sex_aware_search": True,
                        },
                        score=metric.confidence,
                        source_type="metrics",
                        retrieval_method="postgresql_sex_aware",
                    )
                    documents.append(doc)

                except Exception as doc_error:
                    logger.error(f"Document creation error for metric {i}: {doc_error}")
                    continue

            if not documents:
                logger.warning("No documents created from found metrics")
                return RAGResult(
                    source=RAGSource.NO_RESULTS,
                    metadata={
                        "source_type": "metrics",
                        "data_source": "postgresql",
                        "error": "No valid documents created",
                        "sex_logic_applied": True,
                    },
                )

            # Generate OpenAI-powered response
            answer_text = await self._generate_sex_aware_response(
                query, documents, metric_results, entities
            )

            # Calculate confidence
            avg_confidence = sum(m.confidence for m in metric_results) / len(
                metric_results
            )

            sex_from_entities = entities.get("sex") if entities else None
            if sex_from_entities:
                matching_sex_results = [
                    m for m in metric_results if m.sex == sex_from_entities
                ]
                if matching_sex_results:
                    avg_confidence = min(1.0, avg_confidence + 0.1)

            logger.info(
                f"PostgreSQL SUCCESS: {len(documents)} documents with OpenAI response"
            )

            return RAGResult(
                source=RAGSource.RAG_SUCCESS,
                answer=answer_text,
                context_docs=[doc.to_dict() for doc in documents],
                confidence=avg_confidence,
                metadata={
                    "source_type": "metrics",
                    "data_source": "postgresql",
                    "metric_count": len(metric_results),
                    "document_count": len(documents),
                    "avg_confidence": avg_confidence,
                    "sex_logic_applied": True,
                    "sex_specified": (
                        entities.get("sex_specified") == "true" if entities else False
                    ),
                    "target_sex": entities.get("sex") if entities else "as_hatched",
                    "response_generated": True,
                    "openai_model": OPENAI_MODEL,
                },
            )

        except Exception as e:
            logger.error(f"PostgreSQL search error: {e}")
            import traceback

            logger.error(f"Stack trace: {traceback.format_exc()}")
            return RAGResult(
                source=RAGSource.ERROR,
                metadata={
                    "error": str(e),
                    "source_type": "metrics",
                    "sex_logic_applied": True,
                },
            )

    def _format_metric_content_with_sex(self, metric: MetricResult) -> str:
        """Format a metric into text content with sex information"""
        try:
            content_parts = [
                f"**{metric.metric_name}**",
                f"Company: {metric.company}",
                f"Breed: {metric.breed}",
                f"Strain: {metric.strain}",
                f"Species: {metric.species}",
                f"Category: {metric.category}",
            ]

            if metric.sex:
                sex_display = {
                    "male": "Male",
                    "female": "Female",
                    "as_hatched": "As-hatched (mixed sexes)",
                    "mixed": "Mixed sexes",
                }.get(metric.sex, metric.sex.title())
                content_parts.append(f"Sex: {sex_display}")

            if metric.value_numeric is not None:
                value_str = f"{metric.value_numeric}"
                if metric.unit:
                    value_str += f" {metric.unit}"
                content_parts.append(f"Value: {value_str}")
            elif metric.value_text:
                content_parts.append(f"Value: {metric.value_text}")

            if metric.age_min is not None and metric.age_max is not None:
                if metric.age_min == metric.age_max:
                    content_parts.append(f"Age: {metric.age_min} days")
                else:
                    content_parts.append(f"Age: {metric.age_min}-{metric.age_max} days")

            if metric.sheet_name:
                content_parts.append(f"Source: {metric.sheet_name}")

            return "\n".join(content_parts)

        except Exception as e:
            logger.error(f"Metric formatting error: {e}")
            return f"Metric: {getattr(metric, 'metric_name', 'Unknown name')}"

    async def _generate_sex_aware_response(
        self,
        query: str,
        documents: List[Document],
        metric_results: List[MetricResult],
        entities: Dict[str, str] = None,
    ) -> str:
        """Generate intelligent response using OpenAI"""
        try:
            age_requested = self._extract_age_from_query(query)
            sex_from_entities = entities.get("sex") if entities else None
            sex_specified = (
                entities.get("sex_specified") == "true" if entities else False
            )

            # Analyze query for metric type
            query_lower = query.lower()
            metric_type = None
            if any(word in query_lower for word in ["weight", "poids", "body"]):
                metric_type = "weight"
            elif any(
                word in query_lower for word in ["fcr", "conversion", "efficacite"]
            ):
                metric_type = "fcr"
            elif any(word in query_lower for word in ["gain", "croissance", "growth"]):
                metric_type = "gain"

            # Select best metric
            best_metric = self._select_best_metric_with_sex_logic(
                metric_results,
                age_requested,
                metric_type,
                sex_from_entities,
                sex_specified,
            )

            if not best_metric:
                return f"Aucune donnée trouvée pour '{query}'."

            # Use OpenAI to generate natural response
            response = await self._generate_natural_response_with_openai(
                query, best_metric, age_requested, sex_from_entities
            )

            # Add info about multiple results if relevant
            if len(metric_results) > 1:
                sex_breakdown = self._analyze_sex_distribution(metric_results)
                if sex_breakdown:
                    response += (
                        f"\n\n*Données additionnelles disponibles: {sex_breakdown}*"
                    )

            return response

        except Exception as e:
            logger.error(f"Response generation error: {e}")
            if metric_results:
                best = metric_results[0]
                sex_info = (
                    f" pour {best.sex}"
                    if best.sex and best.sex != "as_hatched"
                    else " (as-hatched)"
                )
                return f"Données trouvées{sex_info}: {best.metric_name} = {best.value_numeric or best.value_text or 'valeur non disponible'} pour {best.strain}."
            return f"Erreur lors de la génération de la réponse pour '{query}'."

    def _select_best_metric_with_sex_logic(
        self,
        metric_results: List[MetricResult],
        age_requested: Optional[int],
        metric_type: Optional[str],
        target_sex: Optional[str],
        sex_specified: bool,
    ) -> Optional[MetricResult]:
        """Select best metric with sex logic"""
        if not metric_results:
            return None

        # Filter by sex if specified
        if target_sex and sex_specified:
            exact_sex_matches = [m for m in metric_results if m.sex == target_sex]
            if exact_sex_matches:
                candidate_results = exact_sex_matches
                logger.debug(
                    f"Sex specified found: {len(exact_sex_matches)} results for {target_sex}"
                )
            else:
                as_hatched_matches = [
                    m for m in metric_results if m.sex in ["as_hatched", "mixed"]
                ]
                if as_hatched_matches:
                    candidate_results = as_hatched_matches
                    logger.debug(
                        f"Fallback as_hatched: {len(as_hatched_matches)} results"
                    )
                else:
                    candidate_results = metric_results
        else:
            as_hatched_first = [
                m for m in metric_results if m.sex in ["as_hatched", "mixed"]
            ]
            other_sexes = [
                m for m in metric_results if m.sex not in ["as_hatched", "mixed"]
            ]
            candidate_results = as_hatched_first + other_sexes
            logger.debug(
                f"Prioritizing as_hatched: {len(as_hatched_first)} as_hatched + {len(other_sexes)} others"
            )

        # Filter by age if specified
        if age_requested:
            exact_age_matches = [
                m for m in candidate_results if m.age_min == age_requested
            ]
            if exact_age_matches:
                candidate_results = exact_age_matches
            else:
                close_age_matches = [
                    m
                    for m in candidate_results
                    if m.age_min and abs(m.age_min - age_requested) <= 3
                ]
                if close_age_matches:
                    candidate_results = sorted(
                        close_age_matches,
                        key=lambda m: abs((m.age_min or 0) - age_requested),
                    )

        # Filter by metric type if detected
        if metric_type:
            type_matches = [
                m for m in candidate_results if metric_type in m.metric_name.lower()
            ]
            if type_matches:
                candidate_results = type_matches

        return candidate_results[0] if candidate_results else metric_results[0]

    def _analyze_sex_distribution(self, metric_results: List[MetricResult]) -> str:
        """Analyze sex distribution in results"""
        sex_counts = {}
        for metric in metric_results:
            sex = metric.sex or "as_hatched"
            sex_counts[sex] = sex_counts.get(sex, 0) + 1

        if len(sex_counts) <= 1:
            return ""

        sex_labels = {
            "male": "mâles",
            "female": "femelles",
            "as_hatched": "as-hatched",
            "mixed": "mixte",
        }

        breakdown_parts = []
        for sex, count in sex_counts.items():
            label = sex_labels.get(sex, sex)
            breakdown_parts.append(f"{count} {label}")

        return ", ".join(breakdown_parts)

    def _extract_age_from_query(self, query: str) -> Optional[int]:
        """Extract age in days from query"""
        if self.postgres_retriever:
            return self.postgres_retriever._extract_age_from_query(query)
        return None

    async def close(self):
        """Close PostgreSQL system"""
        if self.postgres_retriever:
            await self.postgres_retriever.close()
        self.is_initialized = False

    def get_sex_logic_status(self) -> Dict[str, Any]:
        """Return sex/as-hatched logic system status"""
        if not self.postgres_retriever:
            return {"available": False, "reason": "retriever_not_initialized"}

        return {
            "available": True,
            "sex_aware_search": True,
            "openai_enabled": self.openai_client is not None,
            "openai_model": OPENAI_MODEL if self.openai_client else None,
            "supported_sexes": ["male", "female", "as_hatched", "mixed"],
            "fallback_behavior": "as_hatched",
            "sex_detection_patterns": 3,
            "normalization_concepts": len(
                self.postgres_retriever.query_normalizer.CONCEPT_MAPPINGS
            ),
            "terminology_loaded": len(
                self.postgres_retriever.query_normalizer.terminology
            )
            > 0,
        }
