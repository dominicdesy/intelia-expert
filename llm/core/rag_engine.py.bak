# -*- coding: utf-8 -*-
"""
rag_engine.py - RAG Engine Principal Refactoris√©
Point d'entr√©e principal avec d√©l√©gation vers modules sp√©cialis√©s
VERSION 4.7.0 - CORRECTION CRITIQUE: G√âN√âRATION LLM POUR POSTGRESQL:
- ‚úÖ NOUVEAU: G√©n√©ration automatique de r√©ponse LLM apr√®s r√©cup√©ration documents
- ‚úÖ Appel generator.generate_response() si context_docs pr√©sents mais answer vide
- ‚úÖ Import automatique de POSTGRESQL_CONFIG dans _initialize_external_modules()
- ‚úÖ Instanciation PostgreSQLRetriever avec config centralis√©e
- ‚úÖ Plus besoin de passer config depuis monitoring.py
- ‚úÖ S√©paration PostgreSQLRetriever (search_metrics) et PostgreSQLValidator (validation)
- ‚úÖ Transmission correcte du param√®tre language √† tous les handlers
- ‚úÖ Support des entit√©s pr√©-extraites pour fusion conversationnelle
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any

from config.config import RAG_ENABLED

try:
    from .data_models import RAGResult, RAGSource
except ImportError as e:
    logging.error(f"Erreur import data_models: {e}")
    raise

try:
    from utils.imports_and_dependencies import OPENAI_AVAILABLE, AsyncOpenAI
except ImportError:
    OPENAI_AVAILABLE = False
    AsyncOpenAI = None

# Import des modules refactoris√©s
from .rag_engine_core import RAGEngineCore
from .rag_engine_handlers import (
    TemporalQueryHandler,
    ComparativeQueryHandler,
    StandardQueryHandler,
)

# NOUVEAUX IMPORTS - Modules centralis√©s
from .query_classifier import UnifiedQueryClassifier, QueryType
from .entity_extractor import EntityExtractor
from .validation_core import ValidationCore

logger = logging.getLogger(__name__)

# Imports conditionnels des modules externes
POSTGRESQL_RETRIEVER_AVAILABLE = False
POSTGRESQL_VALIDATOR_AVAILABLE = False
QUERY_PREPROCESSOR_AVAILABLE = False
COMPARISON_HANDLER_AVAILABLE = False
WEAVIATE_CORE_AVAILABLE = False

PostgreSQLRetriever = None
PostgreSQLValidator = None
QueryPreprocessor = None
ComparisonHandler = None
WeaviateCore = None

# Import s√©par√© du Retriever et Validator
try:
    from .rag_postgresql_retriever import PostgreSQLRetriever

    POSTGRESQL_RETRIEVER_AVAILABLE = True
    logger.info("‚úÖ PostgreSQL Retriever import√©")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è PostgreSQL Retriever non disponible: {e}")

try:
    from .rag_postgresql_validator import PostgreSQLValidator

    POSTGRESQL_VALIDATOR_AVAILABLE = True
    logger.info("‚úÖ PostgreSQL Validator import√©")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è PostgreSQL Validator non disponible: {e}")

try:
    from .query_preprocessor import QueryPreprocessor

    QUERY_PREPROCESSOR_AVAILABLE = True
    logger.info("‚úÖ Query Preprocessor import√©")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Query Preprocessor non disponible: {e}")

try:
    from .comparison_handler import ComparisonHandler

    COMPARISON_HANDLER_AVAILABLE = True
    logger.info("‚úÖ Comparison Handler import√© (wrapper)")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Comparison Handler non disponible: {e}")

try:
    from .rag_weaviate_core import WeaviateCore

    WEAVIATE_CORE_AVAILABLE = True
    logger.info("‚úÖ Weaviate Core import√©")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Weaviate Core non disponible: {e}")


class InteliaRAGEngine:
    """
    RAG Engine principal avec architecture modulaire refactoris√©e

    VERSION 4.7.0 - G√âN√âRATION LLM AUTOMATIQUE:
    - Configuration PostgreSQL charg√©e automatiquement depuis rag_postgresql_config.py
    - Instanciation PostgreSQLRetriever avec config centralis√©e
    - Initialisation compl√®te du PostgreSQLValidator
    - Transmission du validator au StandardHandler
    - S√©paration PostgreSQLRetriever (search_metrics) et PostgreSQLValidator (validation)
    - Transmission correcte du param√®tre language √† tous les handlers
    - ‚úÖ CORRECTION CRITIQUE: G√©n√©ration LLM automatique apr√®s r√©cup√©ration documents
    - ‚úÖ NOUVEAU: M√©thode generate_response_with_entities() pour fusion conversationnelle
    - Utilise UnifiedQueryClassifier au lieu de QueryClassifier legacy
    - Int√®gre EntityExtractor pour extraction centralis√©e
    - Utilise ValidationCore pour validation unifi√©e
    - ComparisonHandler est maintenant un wrapper vers ComparisonEngine
    """

    def __init__(self, openai_client: AsyncOpenAI = None):
        """Initialisation avec nouveaux modules centralis√©s"""
        # Core engine
        self.core = RAGEngineCore(openai_client)

        # NOUVEAUX MODULES CENTRALIS√âS
        self.query_classifier = UnifiedQueryClassifier()
        self.entity_extractor = EntityExtractor()
        self.validator = ValidationCore()

        # Handlers sp√©cialis√©s
        self.temporal_handler = TemporalQueryHandler()
        self.comparative_handler = ComparativeQueryHandler()
        self.standard_handler = StandardQueryHandler()

        # Modules externes avec Retriever ET Validator s√©par√©s
        self.postgresql_retriever = None
        self.postgresql_validator = None
        self.query_preprocessor = None
        self.comparison_handler = None
        self.weaviate_core = None

        # √âtat
        self.is_initialized = False
        self.degraded_mode = False
        self.initialization_errors = []

        # Stats
        self.optimization_stats = {
            "requests_total": 0,
            "preprocessing_success": 0,
            "preprocessing_failures": 0,
            "comparative_queries": 0,
            "comparative_success": 0,
            "comparative_failures": 0,
            "comparative_fallbacks": 0,
            "temporal_queries": 0,
            "optimization_queries": 0,
            "calculation_queries": 0,
            "economic_queries": 0,
            "diagnostic_queries": 0,
            "postgresql_queries": 0,
            "llm_generations": 0,
            "errors_count": 0,
            "preextracted_entities_queries": 0,
        }

    async def initialize(self):
        """Initialisation modulaire avec nouveaux composants"""
        if self.is_initialized:
            return

        logger.info("üöÄ Initialisation RAG Engine v4.7.0 (G√©n√©ration LLM Automatique)")
        self.initialization_errors = []

        try:
            # Initialiser le core
            await self.core.initialize()

            # Initialiser les modules externes
            await self._initialize_external_modules()

            # Configurer les handlers avec les modules
            await self._configure_handlers()

            self.is_initialized = True

            active_modules = [
                name
                for name, module in [
                    ("Preprocessor", self.query_preprocessor),
                    ("PostgreSQLRetriever", self.postgresql_retriever),
                    ("PostgreSQLValidator", self.postgresql_validator),
                    ("WeaviateCore", self.weaviate_core),
                    ("ComparisonHandler", self.comparison_handler),
                    ("QueryClassifier", self.query_classifier),
                    ("EntityExtractor", self.entity_extractor),
                    ("ValidationCore", self.validator),
                    ("LLMGenerator", self.core.generator),
                ]
                if module is not None
            ]

            logger.info(
                f"‚úÖ RAG Engine initialis√© - Modules: {', '.join(active_modules)}"
            )

            if self.initialization_errors:
                logger.warning(
                    f"‚ö†Ô∏è Erreurs d'initialisation: {self.initialization_errors}"
                )

        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation critique: {e}")
            self.degraded_mode = True
            self.is_initialized = True
            self.initialization_errors.append(str(e))

    async def _initialize_external_modules(self):
        """Initialise Retriever et Validator avec config centralis√©e"""

        # Query Preprocessor
        if QUERY_PREPROCESSOR_AVAILABLE and QueryPreprocessor:
            try:
                self.query_preprocessor = QueryPreprocessor()
                await self.query_preprocessor.initialize()
                logger.info("‚úÖ Query Preprocessor initialis√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Query Preprocessor √©chou√©: {e}")
                self.initialization_errors.append(f"Preprocessor: {e}")

        # PostgreSQL Retriever (pour search_metrics)
        if POSTGRESQL_RETRIEVER_AVAILABLE and PostgreSQLRetriever:
            try:
                # Import de la configuration centralis√©e
                from .rag_postgresql_config import POSTGRESQL_CONFIG

                # Validation de la config
                if not POSTGRESQL_CONFIG.get("password"):
                    logger.warning(
                        "‚ö†Ô∏è PostgreSQL config incompl√®te - variables d'environnement manquantes"
                    )
                    raise ValueError(
                        "PostgreSQL password manquant dans la configuration"
                    )

                # Instanciation avec config centralis√©e
                self.postgresql_retriever = PostgreSQLRetriever(
                    config=POSTGRESQL_CONFIG,
                    intents_file_path="/app/config/intents.json",
                )
                await self.postgresql_retriever.initialize()
                logger.info(
                    "‚úÖ PostgreSQL Retriever initialis√© avec config centralis√©e"
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è PostgreSQL Retriever √©chou√©: {e}")
                self.initialization_errors.append(f"PostgreSQLRetriever: {e}")

        # PostgreSQL Validator (pour validation)
        if POSTGRESQL_VALIDATOR_AVAILABLE and PostgreSQLValidator:
            try:
                self.postgresql_validator = PostgreSQLValidator(
                    openai_client=self.core.openai_client
                )
                # Appeler initialize() si la m√©thode existe
                if hasattr(self.postgresql_validator, "initialize"):
                    await self.postgresql_validator.initialize()
                logger.info("‚úÖ PostgreSQL Validator initialis√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è PostgreSQL Validator √©chou√©: {e}")
                self.initialization_errors.append(f"PostgreSQLValidator: {e}")

        # Weaviate Core
        if WEAVIATE_CORE_AVAILABLE and WeaviateCore and self.core.openai_client:
            try:
                self.weaviate_core = WeaviateCore(self.core.openai_client)
                await self.weaviate_core.initialize()
                logger.info("‚úÖ Weaviate Core initialis√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Weaviate Core √©chou√©: {e}")
                self.initialization_errors.append(f"WeaviateCore: {e}")

        # Comparison Handler (utilise le Retriever)
        if COMPARISON_HANDLER_AVAILABLE and ComparisonHandler:
            try:
                self.comparison_handler = ComparisonHandler(self.postgresql_retriever)
                if not self.postgresql_retriever:
                    logger.warning(
                        "‚ö†Ô∏è Comparison Handler en mode d√©grad√© (pas de PostgreSQL)"
                    )
                else:
                    logger.info("‚úÖ Comparison Handler initialis√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Comparison Handler √©chou√©: {e}")
                self.initialization_errors.append(f"ComparisonHandler: {e}")

    async def _configure_handlers(self):
        """Configure handlers avec Retriever ET Validator"""

        # Configuration temporal handler (utilise le Retriever)
        self.temporal_handler.configure(postgresql_system=self.postgresql_retriever)

        # Configuration comparative handler (utilise le Retriever)
        self.comparative_handler.configure(
            comparison_handler=self.comparison_handler,
            weaviate_core=self.weaviate_core,
            postgresql_system=self.postgresql_retriever,
        )

        # Configuration standard handler (utilise RETRIEVER + VALIDATOR)
        self.standard_handler.configure(
            postgresql_system=self.postgresql_retriever,
            weaviate_core=self.weaviate_core,
            postgresql_validator=self.postgresql_validator,
        )

        logger.debug(
            f"üîç HANDLER CONFIGURED - postgresql_system type: {type(self.standard_handler.postgresql_system)}"
        )
        logger.debug(
            f"üîç HANDLER CONFIGURED - postgresql_system is None: {self.standard_handler.postgresql_system is None}"
        )

    async def generate_response(
        self,
        query: str,
        tenant_id: str = "default",
        conversation_context: List[Dict] = None,
        language: Optional[str] = None,
        enable_preprocessing: bool = True,
        **kwargs,
    ) -> RAGResult:
        """Point d'entr√©e principal avec routage intelligent"""

        if not self.is_initialized:
            logger.warning("‚ö†Ô∏è RAG Engine non initialis√©, tentative d'initialisation")
            try:
                await self.initialize()
            except Exception as e:
                logger.error(f"‚ùå √âchec initialisation: {e}")

        start_time = time.time()
        self.optimization_stats["requests_total"] += 1

        # Validation
        if not query or not query.strip():
            return RAGResult(
                source=RAGSource.ERROR,
                metadata={"error": "Query vide"},
            )

        effective_language = language or "fr"
        logger.info(f"üåê generate_response re√ßoit langue: {effective_language}")

        # Fallback si syst√®me indisponible
        if self.degraded_mode and not self.postgresql_retriever:
            return RAGResult(
                source=RAGSource.FALLBACK_NEEDED,
                answer="Le syst√®me RAG n'est pas disponible.",
                metadata={"reason": "syst√®me_indisponible"},
            )

        try:
            return await self._process_query(
                query, effective_language, enable_preprocessing, start_time
            )
        except Exception as e:
            logger.error(f"‚ùå Erreur generate_response: {e}")
            self.optimization_stats["errors_count"] += 1
            return RAGResult(
                source=RAGSource.INTERNAL_ERROR,
                metadata={"error": str(e)},
            )

    async def generate_response_with_entities(
        self,
        query: str,
        entities: Dict[str, Any],
        tenant_id: str = "default",
        language: Optional[str] = None,
        **kwargs,
    ) -> RAGResult:
        """
        Point d'entr√©e sp√©cial pour requ√™tes avec entit√©s pr√©-extraites

        UTILIS√â POUR LA M√âMOIRE CONVERSATIONNELLE:
        - Permet de passer directement les entit√©s fusionn√©es depuis la session
        - Bypass l'extraction normale du preprocessing
        - Garantit que les entit√©s accumul√©es sont utilis√©es

        Args:
            query: Requ√™te utilisateur (peut √™tre accumul√©e)
            entities: Entit√©s pr√©-extraites et fusionn√©es
            tenant_id: Identifiant du tenant
            language: Langue de la requ√™te

        Returns:
            RAGResult avec r√©ponse g√©n√©r√©e
        """

        if not self.is_initialized:
            logger.warning("‚ö†Ô∏è RAG Engine non initialis√©, tentative d'initialisation")
            try:
                await self.initialize()
            except Exception as e:
                logger.error(f"‚ùå √âchec initialisation: {e}")

        start_time = time.time()
        self.optimization_stats["requests_total"] += 1
        self.optimization_stats["preextracted_entities_queries"] += 1

        # Validation
        if not query or not query.strip():
            return RAGResult(
                source=RAGSource.ERROR,
                metadata={"error": "Query vide"},
            )

        effective_language = language or "fr"
        logger.info(
            f"üåê generate_response_with_entities re√ßoit langue: {effective_language}"
        )
        logger.info(f"üîÑ Entit√©s pr√©-extraites fournies: {entities}")

        # Fallback si syst√®me indisponible
        if self.degraded_mode and not self.postgresql_retriever:
            return RAGResult(
                source=RAGSource.FALLBACK_NEEDED,
                answer="Le syst√®me RAG n'est pas disponible.",
                metadata={"reason": "syst√®me_indisponible"},
            )

        try:
            return await self._process_query_with_entities(
                query, entities, effective_language, start_time
            )
        except Exception as e:
            logger.error(f"‚ùå Erreur generate_response_with_entities: {e}")
            self.optimization_stats["errors_count"] += 1
            return RAGResult(
                source=RAGSource.INTERNAL_ERROR,
                metadata={"error": str(e)},
            )

    async def _process_query(
        self,
        query: str,
        language: str,
        enable_preprocessing: bool,
        start_time: float,
    ) -> RAGResult:
        """Pipeline de traitement modulaire"""

        logger.info(f"üåê _process_query traite avec langue: {language}")

        # 1. Preprocessing
        preprocessed_data = await self._apply_preprocessing(
            query, language, enable_preprocessing
        )

        if "language" not in preprocessed_data:
            preprocessed_data["language"] = language
            logger.info(f"üåê Langue ajout√©e √† preprocessed_data: {language}")

        # 2. Classification
        classification = self.query_classifier.classify(
            preprocessed_data["normalized_query"]
        )

        query_type = classification.query_type.value
        logger.info(
            f"üéØ Type de requ√™te d√©tect√©: {query_type} (confiance: {classification.confidence:.2%})"
        )

        # Mise √† jour des stats
        if classification.query_type == QueryType.COMPARATIVE:
            self.optimization_stats["comparative_queries"] += 1
        elif classification.query_type == QueryType.TEMPORAL_RANGE:
            self.optimization_stats["temporal_queries"] += 1
        elif classification.query_type == QueryType.OPTIMIZATION:
            self.optimization_stats["optimization_queries"] += 1
        elif classification.query_type == QueryType.CALCULATION:
            self.optimization_stats["calculation_queries"] += 1
        elif classification.query_type == QueryType.ECONOMIC:
            self.optimization_stats["economic_queries"] += 1
        elif classification.query_type == QueryType.DIAGNOSTIC:
            self.optimization_stats["diagnostic_queries"] += 1

        # 3. Enrichir preprocessed_data
        preprocessed_data["query_type"] = query_type
        preprocessed_data["classification"] = classification.to_dict()

        # 4. Routage vers handler
        result = await self._route_to_handler(
            query_type, preprocessed_data, start_time, language
        )

        # ‚úÖ CORRECTION CRITIQUE: G√©n√©rer r√©ponse LLM si n√©cessaire
        result = await self._ensure_answer_generated(
            result, preprocessed_data, query, language
        )

        # 5. Enrichir m√©tadonn√©es
        result.metadata.update(preprocessed_data["metadata"])
        result.metadata["classification"] = classification.to_dict()

        return result

    async def _process_query_with_entities(
        self,
        query: str,
        entities: Dict[str, Any],
        language: str,
        start_time: float,
    ) -> RAGResult:
        """
        Pipeline de traitement avec entit√©s pr√©-extraites

        Similaire √† _process_query mais utilise les entit√©s fournies
        au lieu de les extraire via le preprocessing
        """

        logger.info(f"üåê _process_query_with_entities traite avec langue: {language}")
        logger.info(f"üîÑ Utilisation des entit√©s pr√©-extraites: {entities}")

        # 1. Cr√©er preprocessed_data avec les entit√©s fournies
        preprocessed_data = {
            "normalized_query": query,
            "original_query": query,
            "entities": entities,
            "language": language,
            "routing_hint": "postgresql",  # Force PostgreSQL car entit√©s disponibles
            "is_comparative": False,
            "comparison_entities": [],
            "metadata": {
                "preprocessing_applied": True,
                "entities_preextracted": True,
                "extraction_confidence": entities.get("confidence", 1.0),
                "entities_found": len([k for k in entities.keys() if entities.get(k)]),
                "language_detected": language,
            },
        }

        # 2. Classification
        classification = self.query_classifier.classify(query)
        query_type = classification.query_type.value

        logger.info(
            f"üéØ Type de requ√™te d√©tect√©: {query_type} (confiance: {classification.confidence:.2%})"
        )

        # Mise √† jour des stats
        if classification.query_type == QueryType.COMPARATIVE:
            self.optimization_stats["comparative_queries"] += 1
        elif classification.query_type == QueryType.TEMPORAL_RANGE:
            self.optimization_stats["temporal_queries"] += 1
        elif classification.query_type == QueryType.OPTIMIZATION:
            self.optimization_stats["optimization_queries"] += 1
        elif classification.query_type == QueryType.CALCULATION:
            self.optimization_stats["calculation_queries"] += 1
        elif classification.query_type == QueryType.ECONOMIC:
            self.optimization_stats["economic_queries"] += 1
        elif classification.query_type == QueryType.DIAGNOSTIC:
            self.optimization_stats["diagnostic_queries"] += 1

        # 3. Enrichir preprocessed_data
        preprocessed_data["query_type"] = query_type
        preprocessed_data["classification"] = classification.to_dict()

        # 4. Routage vers handler (force standard pour PostgreSQL)
        result = await self.standard_handler.handle(
            preprocessed_data, start_time, language=language
        )

        # ‚úÖ CORRECTION CRITIQUE: G√©n√©rer r√©ponse LLM si n√©cessaire
        result = await self._ensure_answer_generated(
            result, preprocessed_data, query, language
        )

        # 5. Enrichir m√©tadonn√©es
        result.metadata.update(preprocessed_data["metadata"])
        result.metadata["classification"] = classification.to_dict()
        result.metadata["entities_source"] = "preextracted_from_session"

        return result

    async def _ensure_answer_generated(
        self,
        result: RAGResult,
        preprocessed_data: Dict[str, Any],
        original_query: str,
        language: str,
    ) -> RAGResult:
        """
        ‚úÖ NOUVELLE M√âTHODE CRITIQUE: G√©n√®re la r√©ponse LLM si n√©cessaire

        V√©rifie si le RAGResult contient des documents mais pas de r√©ponse,
        et dans ce cas appelle le g√©n√©rateur LLM pour cr√©er la r√©ponse.

        Args:
            result: RAGResult du handler
            preprocessed_data: Donn√©es preprocess√©es
            original_query: Requ√™te originale
            language: Langue de la requ√™te

        Returns:
            RAGResult avec answer g√©n√©r√©
        """
        # Si on a d√©j√† une r√©ponse, on ne fait rien
        if result.answer and result.answer.strip():
            logger.debug("‚úÖ R√©ponse d√©j√† pr√©sente, g√©n√©ration LLM non n√©cessaire")
            return result

        # Si on a des documents mais pas de r√©ponse, g√©n√©rer via LLM
        if result.context_docs and len(result.context_docs) > 0:
            if not self.core.generator:
                logger.warning(
                    "‚ö†Ô∏è G√©n√©rateur LLM non disponible, impossible de g√©n√©rer r√©ponse"
                )
                result.answer = "Data retrieved but response generation unavailable."
                return result

            logger.info(
                f"üìù G√©n√©ration r√©ponse LLM pour {len(result.context_docs)} documents PostgreSQL"
            )

            try:
                # Appel du g√©n√©rateur avec les documents r√©cup√©r√©s
                generated_answer = await self.core.generator.generate_response(
                    query=preprocessed_data.get("original_query", original_query),
                    context_docs=result.context_docs,
                    conversation_context="",
                    language=language,
                    intent_result=None,
                )

                result.answer = generated_answer
                result.metadata["llm_generation_applied"] = True
                result.metadata["llm_input_docs_count"] = len(result.context_docs)
                self.optimization_stats["llm_generations"] += 1

                logger.info(
                    f"‚úÖ R√©ponse LLM g√©n√©r√©e ({len(generated_answer)} caract√®res)"
                )

            except Exception as e:
                logger.error(f"‚ùå Erreur g√©n√©ration LLM: {e}")
                result.answer = "Unable to generate response from the retrieved data."
                result.metadata["llm_generation_error"] = str(e)

        return result

    async def _apply_preprocessing(
        self, query: str, language: str, enable_preprocessing: bool
    ) -> Dict[str, Any]:
        """Applique le preprocessing"""

        logger.debug(f"üåê _apply_preprocessing avec langue: {language}")

        if not enable_preprocessing or not self.query_preprocessor:
            logger.debug("üìã Preprocessing minimal")

            extracted = self.entity_extractor.extract(query)
            entities_dict = extracted.to_dict()

            return {
                "normalized_query": query,
                "original_query": query,
                "entities": entities_dict,
                "language": language,
                "routing_hint": None,
                "is_comparative": False,
                "comparison_entities": [],
                "metadata": {
                    "preprocessing_applied": False,
                    "extraction_confidence": extracted.confidence,
                    "entities_found": extracted.get_entity_count(),
                    "language_detected": language,
                },
            }

        try:
            logger.debug("üîß Application du preprocessing complet")
            preprocessed = await self.query_preprocessor.preprocess_query(
                query=query, language=language
            )

            self.optimization_stats["preprocessing_success"] += 1

            return {
                "normalized_query": preprocessed.get("normalized_query", query),
                "original_query": query,
                "entities": preprocessed.get("entities", {}),
                "language": language,
                "routing_hint": preprocessed.get("routing"),
                "is_comparative": preprocessed.get("is_comparative", False),
                "comparison_entities": preprocessed.get("comparison_entities", []),
                "temporal_range": preprocessed.get("temporal_range"),
                "metadata": {
                    "original_query": query,
                    "normalized_query": preprocessed.get("normalized_query", query),
                    "routing_hint": preprocessed.get("routing"),
                    "is_comparative": preprocessed.get("is_comparative", False),
                    "preprocessing_applied": True,
                    "confidence": preprocessed.get("confidence", 1.0),
                    "language_detected": language,
                },
            }

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Preprocessing √©chou√©: {e}, fallback basique")
            self.optimization_stats["preprocessing_failures"] += 1

            extracted = self.entity_extractor.extract(query)
            entities_dict = extracted.to_dict()

            return {
                "normalized_query": query,
                "original_query": query,
                "entities": entities_dict,
                "language": language,
                "routing_hint": None,
                "is_comparative": False,
                "comparison_entities": [],
                "metadata": {
                    "preprocessing_applied": False,
                    "preprocessing_error": str(e),
                    "fallback_extraction": True,
                    "extraction_confidence": extracted.confidence,
                    "language_detected": language,
                },
            }

    async def _route_to_handler(
        self,
        query_type: str,
        preprocessed_data: Dict[str, Any],
        start_time: float,
        language: str,
    ) -> RAGResult:
        """Route vers le handler appropri√©"""

        logger.info(f"üåê _route_to_handler avec langue: {language}")

        if query_type == "temporal_range":
            logger.debug("‚Üí Routage vers TemporalQueryHandler")
            return await self.temporal_handler.handle(preprocessed_data, start_time)

        elif query_type == "comparative":
            logger.debug("‚Üí Routage vers ComparativeQueryHandler")
            return await self.comparative_handler.handle(preprocessed_data, start_time)

        elif query_type in ["optimization", "calculation"]:
            logger.debug(f"‚Üí Routage vers StandardHandler (type={query_type})")
            preprocessed_data["is_optimization"] = query_type == "optimization"
            preprocessed_data["is_calculation"] = query_type == "calculation"
            return await self.standard_handler.handle(
                preprocessed_data, start_time, language=language
            )

        elif query_type == "economic":
            logger.debug("‚Üí Requ√™te √©conomique d√©tect√©e")
            return RAGResult(
                source=RAGSource.ERROR,
                answer="Les donn√©es √©conomiques ne sont pas disponibles.",
                metadata={"query_type": "economic"},
            )

        elif query_type == "diagnostic":
            logger.debug("‚Üí Routage vers StandardHandler (diagnostic)")
            preprocessed_data["routing_hint"] = "weaviate"
            return await self.standard_handler.handle(
                preprocessed_data, start_time, language=language
            )

        else:  # standard
            logger.debug("‚Üí Routage vers StandardHandler (standard)")
            return await self.standard_handler.handle(
                preprocessed_data, start_time, language=language
            )

    def get_status(self) -> Dict:
        """Status syst√®me complet"""
        return {
            "rag_enabled": RAG_ENABLED,
            "initialized": self.is_initialized,
            "degraded_mode": self.degraded_mode,
            "version": "v4.7.0_llm_generation_fix",
            "architecture": "modular_centralized",
            "modules": {
                "core": True,
                "rag_engine": True,
                "query_classifier": bool(self.query_classifier),
                "entity_extractor": bool(self.entity_extractor),
                "validation_core": bool(self.validator),
                "temporal_handler": True,
                "comparative_handler": True,
                "standard_handler": True,
                "query_preprocessor": bool(self.query_preprocessor),
                "postgresql_retriever": bool(self.postgresql_retriever),
                "postgresql_validator": bool(self.postgresql_validator),
                "weaviate_core": bool(self.weaviate_core),
                "comparison_handler": bool(self.comparison_handler),
                "llm_generator": bool(self.core.generator),
            },
            "optimization_stats": self.optimization_stats.copy(),
            "initialization_errors": self.initialization_errors,
        }

    async def close(self):
        """Fermeture propre de tous les modules"""
        logger.info("üîí Fermeture RAG Engine...")

        try:
            if self.query_preprocessor:
                await self.query_preprocessor.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture Preprocessor: {e}")

        try:
            if self.postgresql_retriever:
                await self.postgresql_retriever.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture PostgreSQL Retriever: {e}")

        try:
            if self.postgresql_validator and hasattr(
                self.postgresql_validator, "close"
            ):
                await self.postgresql_validator.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture PostgreSQL Validator: {e}")

        try:
            if self.weaviate_core:
                await self.weaviate_core.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture Weaviate Core: {e}")

        try:
            await self.core.close()
        except Exception as e:
            logger.error(f"‚ùå Erreur fermeture Core: {e}")

        logger.info("‚úÖ RAG Engine ferm√© compl√®tement")


# Factory function
def create_rag_engine(openai_client=None) -> InteliaRAGEngine:
    """Factory pour cr√©er une instance RAG Engine"""
    return InteliaRAGEngine(openai_client)


# Fonction de test
async def test_clarification_query():
    """Test d'une requ√™te n√©cessitant clarification"""
    engine = InteliaRAGEngine()

    try:
        await engine.initialize()

        test_query = "Quel est le poids pour du Ross 308 ?"

        logger.info(f"\n{'='*60}")
        logger.info(f"Testing: {test_query}")
        logger.info(f"{'='*60}")

        result = await engine.generate_response(test_query, language="fr")

        print(f"Source: {result.source}")
        print(f"Answer: {result.answer}")
        print(f"Metadata: {result.metadata}")

    except Exception as e:
        logger.error(f"‚ùå Test error: {e}")
    finally:
        await engine.close()


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
    asyncio.run(test_clarification_query())
