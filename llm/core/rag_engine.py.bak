# -*- coding: utf-8 -*-
"""
rag_engine.py - RAG Engine Enhanced avec SystÃ¨me RAG JSON IntÃ©grÃ© + PostgreSQL
Version 5.0 - IntÃ©gration hybride Weaviate + PostgreSQL (conservatrice)
"""

import os
import asyncio
import logging
import time
import numpy as np
import httpx
from typing import Dict, List, Optional, Any, Tuple
from collections import defaultdict
from enum import Enum
from dataclasses import dataclass
from utils.utilities import validate_intent_result

# CORRECTION CRITIQUE: DÃ©finir logger AVANT toute utilisation
logger = logging.getLogger(__name__)

# NOUVEAUX IMPORTS: SystÃ¨me RAG JSON
try:
    from rag.extractors.json_extractor import JSONExtractor
    from rag.extractors.table_extractor import TableExtractor
    from rag.extractors.genetic_line_extractor import GeneticLineExtractor
    from rag.models.validation import JSONValidator, ValidationRequest
    from rag.models.ingestion import IngestionPipeline, IngestionRequest
    from rag.core.hybrid_search import HybridSearchEngine
    from rag.core.document_processor import DocumentProcessor
    from rag.core.cache_manager import EnhancedCacheManager

    RAG_JSON_SYSTEM_AVAILABLE = True
    logger.info("âœ… SystÃ¨me RAG JSON importÃ© avec succÃ¨s")
except ImportError as e:
    RAG_JSON_SYSTEM_AVAILABLE = False
    logger.warning(f"âš ï¸ SystÃ¨me RAG JSON non disponible: {e}")

# NOUVEAU: Support PostgreSQL hybride (optionnel)
try:
    import asyncpg
    from enum import Enum

    # Configuration PostgreSQL
    POSTGRESQL_CONFIG = {
        "user": os.getenv("DB_USER", "doadmin"),
        "password": os.getenv("DB_PASSWORD"),
        "host": os.getenv("DB_HOST"),
        "port": int(os.getenv("DB_PORT", 25060)),
        "database": os.getenv("DB_NAME", "defaultdb"),
        "ssl": os.getenv("DB_SSL", "require"),
    }

    POSTGRESQL_INTEGRATION_AVAILABLE = True
    logger.info("âœ… Support PostgreSQL disponible")
except ImportError as e:
    POSTGRESQL_INTEGRATION_AVAILABLE = False
    logger.warning(f"âš ï¸ Support PostgreSQL non disponible: {e}")

# CORRECTION: Imports explicites au lieu des star imports dangereux
try:
    from config.config import (
        # Core config
        RAG_ENABLED,
        CACHE_ENABLED,
        EXTERNAL_CACHE_AVAILABLE,
        # API Keys
        OPENAI_API_KEY,
        LANGSMITH_ENABLED,
        LANGSMITH_API_KEY,
        LANGSMITH_PROJECT,
        # RRF Intelligent
        ENABLE_INTELLIGENT_RRF,
        RAG_SIMILARITY_TOP_K,
        RAG_CONFIDENCE_THRESHOLD,
        HYBRID_SEARCH_ENABLED,
        DEFAULT_ALPHA,
        MAX_CONVERSATION_CONTEXT,
        RAG_VERIFICATION_ENABLED,
        # Entity Enrichment
        ENTITY_ENRICHMENT_ENABLED,
        # Guardrails
        GUARDRAILS_AVAILABLE,
        GUARDRAILS_LEVEL,
        # API Diagnostics
        ENABLE_API_DIAGNOSTICS,
    )

    logger.debug("Config importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import config: {e}")
    raise

try:
    from utils.imports_and_dependencies import (
        # Availability flags
        OPENAI_AVAILABLE,
        WEAVIATE_AVAILABLE,
        AsyncOpenAI,
    )

    logger.debug("Imports_and_dependencies importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import imports_and_dependencies: {e}")
    raise

try:
    from .data_models import RAGResult, RAGSource, Document

    logger.debug("Data_models importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import data_models: {e}")
    raise

try:
    from utils.utilities import (
        METRICS,
        detect_language_enhanced,
        build_where_filter,
        get_out_of_domain_message,
    )

    logger.debug("Utilities importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import utilities: {e}")
    raise

try:
    from retrieval.embedder import OpenAIEmbedder

    logger.debug("Embedder importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import embedder: {e}")
    raise

try:
    from retrieval.retriever import HybridWeaviateRetriever

    logger.debug("Retriever importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import retriever: {e}")
    raise

try:
    from generation.generators import EnhancedResponseGenerator

    logger.debug("Generators importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import generators: {e}")
    raise

try:
    from security.ood_detector import EnhancedOODDetector

    logger.debug("OOD_detector importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import ood_detector: {e}")
    raise

try:
    from .memory import ConversationMemory

    logger.debug("Memory importÃ© avec succÃ¨s")
except Exception as e:
    logger.error(f"Erreur import memory: {e}")
    raise

# === NOUVEAU: IMPORTS LANGSMITH ===
if LANGSMITH_ENABLED:
    try:
        from langsmith import Client

        LANGSMITH_AVAILABLE = True
        logger.info("LangSmith importÃ© avec succÃ¨s")
    except ImportError as e:
        LANGSMITH_AVAILABLE = False
        logger.warning(f"LangSmith non disponible: {e}")
else:
    LANGSMITH_AVAILABLE = False

# === NOUVEAU: IMPORT RRF INTELLIGENT ===
try:
    from retrieval.enhanced_rrf_fusion import IntelligentRRFFusion

    INTELLIGENT_RRF_AVAILABLE = True
    logger.info("RRF Intelligent importÃ© avec succÃ¨s")
except ImportError as e:
    INTELLIGENT_RRF_AVAILABLE = False
    logger.warning(f"RRF Intelligent non disponible: {e}")

# === NOUVEAUX COMPOSANTS POSTGRESQL ===
if POSTGRESQL_INTEGRATION_AVAILABLE:

    class QueryType(Enum):
        """Types de requÃªtes pour routage intelligent"""

        KNOWLEDGE = "knowledge"  # Connaissances gÃ©nÃ©rales â†’ Weaviate
        METRICS = "metrics"  # DonnÃ©es de performance â†’ PostgreSQL
        HYBRID = "hybrid"  # Combinaison des deux
        UNKNOWN = "unknown"  # Type indÃ©terminÃ©

    @dataclass
    class MetricResult:
        """RÃ©sultat d'une requÃªte de mÃ©triques PostgreSQL"""

        company: str
        breed: str
        strain: str
        species: str
        metric_name: str
        value_numeric: Optional[float]
        value_text: Optional[str]
        unit: Optional[str]
        age_min: Optional[int]
        age_max: Optional[int]
        sheet_name: str
        category: str
        confidence: float = 1.0

    class QueryRouter:
        """Routeur intelligent pour diriger les requÃªtes vers la bonne source"""

        def __init__(self):
            # Mots-clÃ©s pour PostgreSQL (mÃ©triques/performance)
            self.metric_keywords = {
                "performance",
                "metrics",
                "donnÃ©es",
                "chiffres",
                "rÃ©sultats",
                "weight",
                "poids",
                "egg",
                "oeuf",
                "production",
                "feed",
                "alimentation",
                "mortality",
                "mortalitÃ©",
                "growth",
                "croissance",
                "nutrition",
                "age",
                "semaine",
                "week",
                "day",
                "jour",
                "phase",
                "temperature",
                "tempÃ©rature",
                "humidity",
                "humiditÃ©",
                "housing",
                "logement",
                "density",
                "densitÃ©",
            }

            # Mots-clÃ©s pour Weaviate (connaissances)
            self.knowledge_keywords = {
                "comment",
                "pourquoi",
                "qu'est-ce",
                "expliquer",
                "dÃ©finir",
                "maladie",
                "disease",
                "traitement",
                "treatment",
                "symptom",
                "symptÃ´me",
                "prÃ©vention",
                "prevention",
                "biosÃ©curitÃ©",
                "biosecurity",
                "management",
                "gestion",
                "guide",
                "protocol",
                "protocole",
                "conseil",
                "advice",
                "recommendation",
                "recommandation",
            }

        def route_query(self, query: str, intent_result=None) -> QueryType:
            """DÃ©termine le type de requÃªte et la source appropriÃ©e"""

            query_lower = query.lower()

            # Compteurs de mots-clÃ©s
            metric_score = sum(
                1 for keyword in self.metric_keywords if keyword in query_lower
            )
            knowledge_score = sum(
                1 for keyword in self.knowledge_keywords if keyword in query_lower
            )

            # Analyse des entitÃ©s si intent_result disponible
            if intent_result:
                # Boost pour mÃ©triques si strain/breed spÃ©cifiÃ©
                if (
                    hasattr(intent_result, "genetic_line")
                    and intent_result.genetic_line
                ):
                    metric_score += 2

                # Boost pour mÃ©triques si Ã¢ge mentionnÃ©
                if hasattr(intent_result, "age") and intent_result.age:
                    metric_score += 1

            # DÃ©tection de comparaisons (souvent hybride)
            comparison_indicators = [
                "vs",
                "versus",
                "compare",
                "comparaison",
                "diffÃ©rence",
                "mieux",
            ]
            has_comparison = any(
                indicator in query_lower for indicator in comparison_indicators
            )

            # RÃ¨gles de dÃ©cision
            if metric_score > knowledge_score + 1:
                return QueryType.METRICS
            elif knowledge_score > metric_score + 1:
                return QueryType.KNOWLEDGE
            elif has_comparison or (metric_score > 0 and knowledge_score > 0):
                return QueryType.HYBRID
            else:
                return QueryType.UNKNOWN

    class PostgreSQLRetriever:
        """RÃ©cupÃ©rateur de donnÃ©es PostgreSQL pour mÃ©triques avicoles"""

        def __init__(self, config: Dict[str, Any]):
            self.config = config
            self.pool = None

        async def initialize(self):
            """Initialise la connexion PostgreSQL"""
            try:
                self.pool = await asyncpg.create_pool(
                    user=self.config["user"],
                    password=self.config["password"],
                    host=self.config["host"],
                    port=self.config["port"],
                    database=self.config["database"],
                    ssl=self.config["ssl"],
                    min_size=2,
                    max_size=10,
                )
                logger.info("âœ… PostgreSQL Retriever initialisÃ©")
            except Exception as e:
                logger.error(f"âŒ Erreur PostgreSQL Retriever: {e}")
                raise

        async def search_metrics(
            self, query: str, intent_result=None, top_k: int = 10
        ) -> List[MetricResult]:
            """Recherche de mÃ©triques dans PostgreSQL"""

            if not self.pool:
                await self.initialize()

            try:
                # Construction de la requÃªte SQL dynamique
                sql_query, params = self._build_sql_query(query, intent_result, top_k)

                async with self.pool.acquire() as conn:
                    rows = await conn.fetch(sql_query, *params)

                # Conversion en MetricResult
                results = []
                for row in rows:
                    result = MetricResult(
                        company=row["company_name"],
                        breed=row["breed_name"],
                        strain=row["strain_name"],
                        species=row["species"],
                        metric_name=row["metric_name"],
                        value_numeric=row["value_numeric"],
                        value_text=row["value_text"],
                        unit=row["unit"],
                        age_min=row["age_min"],
                        age_max=row["age_max"],
                        sheet_name=row["sheet_name"],
                        category=row["category_name"],
                        confidence=self._calculate_relevance_score(query, row),
                    )
                    results.append(result)

                logger.info(f"PostgreSQL: {len(results)} mÃ©triques trouvÃ©es")
                return results

            except Exception as e:
                logger.error(f"Erreur recherche PostgreSQL: {e}")
                return []

        def _build_sql_query(
            self, query: str, intent_result=None, top_k: int = 10
        ) -> Tuple[str, List]:
            """Construction dynamique de la requÃªte SQL"""

            base_query = """
            SELECT 
                c.company_name,
                b.breed_name,
                s.strain_name,
                s.species,
                m.metric_name,
                m.value_numeric,
                m.value_text,
                m.unit,
                m.age_min,
                m.age_max,
                m.sheet_name,
                dc.category_name,
                m.metadata
            FROM companies c
            JOIN breeds b ON c.id = b.company_id
            JOIN strains s ON b.id = s.breed_id  
            JOIN documents d ON s.id = d.strain_id
            JOIN metrics m ON d.id = m.document_id
            JOIN data_categories dc ON m.category_id = dc.id
            WHERE 1=1
            """

            params = []
            conditions = []
            param_count = 0

            # Filtres selon intent_result
            if intent_result:
                if (
                    hasattr(intent_result, "genetic_line")
                    and intent_result.genetic_line
                ):
                    param_count += 1
                    conditions.append(f"LOWER(s.strain_name) ILIKE ${param_count}")
                    params.append(f"%{intent_result.genetic_line.lower()}%")

                if hasattr(intent_result, "age") and intent_result.age:
                    param_count += 1
                    conditions.append(
                        f"(m.age_min <= ${param_count} AND m.age_max >= ${param_count}) OR (m.age_min IS NULL AND m.age_max IS NULL)"
                    )
                    params.append(intent_result.age)
                    params.append(intent_result.age)
                    param_count += 1

            # Recherche textuelle sur les mÃ©triques
            query_words = query.lower().split()
            for word in query_words[
                :3
            ]:  # Limite Ã  3 mots pour Ã©viter la sur-spÃ©cification
                if len(word) > 3:  # Ignorer mots trop courts
                    param_count += 1
                    conditions.append(
                        f"(LOWER(m.metric_name) ILIKE ${param_count} OR LOWER(m.value_text) ILIKE ${param_count})"
                    )
                    params.append(f"%{word}%")
                    params.append(f"%{word}%")
                    param_count += 1

            # Ajout des conditions
            if conditions:
                base_query += " AND (" + " OR ".join(conditions) + ")"

            # Tri par pertinence et limite
            base_query += f" ORDER BY m.value_numeric DESC NULLS LAST LIMIT {top_k}"

            return base_query, params

        def _calculate_relevance_score(self, query: str, row: Dict) -> float:
            """Calcule un score de pertinence pour un rÃ©sultat"""

            score = 0.5  # Score de base
            query_lower = query.lower()

            # Boost si mÃ©trique correspond au nom
            if row["metric_name"] and query_lower in row["metric_name"].lower():
                score += 0.3

            # Boost si valeur numÃ©rique disponible
            if row["value_numeric"] is not None:
                score += 0.1

            # Boost si Ã¢ge spÃ©cifique
            if row["age_min"] is not None and row["age_max"] is not None:
                score += 0.1

            return min(1.0, score)

        async def close(self):
            """Ferme la connexion PostgreSQL"""
            if self.pool:
                await self.pool.close()


class InteliaRAGEngine:
    """RAG Engine principal avec systÃ¨me JSON avicole intÃ©grÃ© + PostgreSQL hybride"""

    def __init__(self, openai_client: AsyncOpenAI = None):
        self.openai_client = openai_client or self._build_openai_client()

        # Composants principaux existants
        self.cache_manager = None
        self.embedder = None
        self.retriever = None
        self.generator = None
        self.verifier = None
        self.memory = None
        self.intent_processor = None
        self.ood_detector = None
        self.guardrails = None
        self.weaviate_client = None

        # === NOUVEAUX COMPOSANTS RAG JSON ===
        self.json_extractor = None
        self.table_extractor = None
        self.genetic_line_extractor = None
        self.json_validator = None
        self.ingestion_pipeline = None
        self.hybrid_search_engine = None
        self.document_processor = None
        self.enhanced_cache_manager = None

        # === NOUVEAUX COMPOSANTS POSTGRESQL ===
        self.postgres_retriever = None
        self.query_router = None

        # === NOUVEAU: LANGSMITH CLIENT ===
        self.langsmith_client = None
        if LANGSMITH_AVAILABLE and LANGSMITH_ENABLED and LANGSMITH_API_KEY:
            try:
                self.langsmith_client = Client(
                    api_key=LANGSMITH_API_KEY, api_url="https://api.smith.langchain.com"
                )
                logger.info(f"LangSmith initialisÃ© - Projet: {LANGSMITH_PROJECT}")
            except Exception as e:
                logger.error(f"Erreur initialisation LangSmith: {e}")
                self.langsmith_client = None

        # === NOUVEAU: RRF INTELLIGENT ===
        self.intelligent_rrf = None

        # Ã‰tat
        self.is_initialized = False
        self.degraded_mode = False

        # Stats Ã©tendues avec systÃ¨me JSON et PostgreSQL
        self.optimization_stats = {
            "cache_hits": 0,
            "cache_misses": 0,
            "semantic_cache_hits": 0,
            "fallback_cache_hits": 0,
            "hybrid_searches": 0,
            "guardrail_violations": 0,
            "entity_enrichments": 0,
            "api_corrections": 0,
            "external_cache_used": False,
            "semantic_debug_requests": 0,
            "explain_score_extractions": 0,
            # NOUVEAU: Stats LangSmith
            "langsmith_traces": 0,
            "langsmith_errors": 0,
            "prompt_optimizations": 0,
            # NOUVEAU: Stats RRF Intelligent
            "intelligent_rrf_used": 0,
            "genetic_boosts_applied": 0,
            "rrf_learning_updates": 0,
            "semantic_reasoning_failures": 0,
            "intent_coverage_stats": defaultdict(int),
            "weaviate_capabilities": {},
            "dynamic_ood_threshold_adjustments": 0,
            "conversation_context_usage": 0,
            # NOUVEAU: Stats systÃ¨me JSON
            "json_validations": 0,
            "json_ingestions": 0,
            "table_extractions": 0,
            "genetic_line_detections": 0,
            "performance_metrics_processed": 0,
            "cache_sets": 0,
            # NOUVEAU: Stats PostgreSQL
            "postgresql_queries": 0,
            "postgresql_fallbacks": 0,
            "hybrid_queries": 0,
            "query_routing": defaultdict(int),
        }

    def _build_openai_client(self) -> AsyncOpenAI:
        """Construit le client OpenAI"""
        try:
            http_client = httpx.AsyncClient(timeout=30.0)
            return AsyncOpenAI(api_key=OPENAI_API_KEY, http_client=http_client)
        except Exception as e:
            logger.warning(f"Erreur client OpenAI: {e}")
            return AsyncOpenAI(api_key=OPENAI_API_KEY)

    async def initialize(self):
        """Initialisation complÃ¨te avec systÃ¨me JSON intÃ©grÃ© + PostgreSQL"""
        if self.is_initialized:
            return

        logger.info(
            "ðŸš€ Initialisation RAG Engine v5.0 avec systÃ¨me JSON avicole + PostgreSQL"
        )

        if not OPENAI_AVAILABLE or not WEAVIATE_AVAILABLE:
            self.degraded_mode = True
            logger.warning("Mode dÃ©gradÃ© activÃ©")
            self.is_initialized = True
            return

        try:
            # === Ã‰TAPE 1: SYSTÃˆME JSON AVICOLE ===
            if RAG_JSON_SYSTEM_AVAILABLE:
                await self._initialize_json_system()
            else:
                logger.warning(
                    "âš ï¸ SystÃ¨me JSON non disponible, fonctionnalitÃ©s limitÃ©es"
                )

            # === Ã‰TAPE 1.5: SYSTÃˆME POSTGRESQL (NOUVEAU) ===
            if POSTGRESQL_INTEGRATION_AVAILABLE:
                await self._initialize_postgresql_system()
            else:
                logger.warning(
                    "âš ï¸ SystÃ¨me PostgreSQL non disponible, utilisation Weaviate seul"
                )

            # === Ã‰TAPE 2: CACHE SYSTÃˆME ===
            logger.debug("Ã‰tape 2: Initialisation Cache Redis externe...")
            await self._initialize_cache_system()

            # === Ã‰TAPE 3: CONNEXION WEAVIATE ===
            logger.debug("Ã‰tape 3: Connexion Weaviate...")
            await self._connect_weaviate()

            # === Ã‰TAPE 4: COMPOSANTS DE BASE ===
            logger.debug("Ã‰tape 4: Composants de base...")
            await self._initialize_base_components()

            # === Ã‰TAPE 5: RETRIEVER HYBRIDE ===
            logger.debug("Ã‰tape 5: Retriever hybride...")
            await self._initialize_hybrid_retriever()

            # === Ã‰TAPE 6: GÃ‰NÃ‰RATEUR DE RÃ‰PONSES ===
            logger.debug("Ã‰tape 6: GÃ©nÃ©rateur de rÃ©ponses...")
            await self._initialize_generator()

            # === Ã‰TAPE 7: INTENT PROCESSOR ===
            logger.debug("Ã‰tape 7: Intent processor...")
            await self._initialize_intent_processor()

            # === Ã‰TAPE 8: GUARDRAILS ===
            if GUARDRAILS_AVAILABLE:
                await self._initialize_guardrails()

            self.is_initialized = True
            logger.info("âœ… RAG Engine v5.0 initialisÃ© avec succÃ¨s")

        except Exception as e:
            logger.error(f"âŒ Erreur initialisation RAG Engine: {e}")
            logger.error(f"Type d'erreur: {type(e).__name__}")
            import traceback

            logger.error(f"Traceback: {traceback.format_exc()}")
            self.degraded_mode = True
            self.is_initialized = True

    async def _initialize_postgresql_system(self):
        """Initialise le systÃ¨me PostgreSQL (NOUVEAU)"""
        try:
            logger.info("ðŸ”§ Initialisation systÃ¨me PostgreSQL...")

            # Routeur de requÃªtes
            if POSTGRESQL_INTEGRATION_AVAILABLE:
                self.query_router = QueryRouter()
                logger.info("âœ… Query Router initialisÃ©")

                # PostgreSQL Retriever
                try:
                    self.postgres_retriever = PostgreSQLRetriever(POSTGRESQL_CONFIG)
                    await self.postgres_retriever.initialize()
                    logger.info("âœ… PostgreSQL Retriever initialisÃ©")
                except Exception as e:
                    logger.warning(f"PostgreSQL Retriever Ã©chouÃ©: {e}")
                    self.postgres_retriever = None

            logger.info("âœ… SystÃ¨me PostgreSQL initialisÃ©")

        except Exception as e:
            logger.error(f"âŒ Erreur initialisation systÃ¨me PostgreSQL: {e}")
            # Continue sans PostgreSQL
            self.query_router = None
            self.postgres_retriever = None

    async def _initialize_json_system(self):
        """Initialise le systÃ¨me RAG JSON complet"""
        try:
            logger.info("ðŸ”§ Initialisation systÃ¨me RAG JSON...")

            # Extracteurs spÃ©cialisÃ©s
            self.json_extractor = JSONExtractor()
            self.table_extractor = TableExtractor()
            self.genetic_line_extractor = GeneticLineExtractor()

            # Validateur JSON
            self.json_validator = JSONValidator()

            # Pipeline d'ingestion
            self.ingestion_pipeline = IngestionPipeline(
                json_extractor=self.json_extractor,
                table_extractor=self.table_extractor,
                genetic_line_extractor=self.genetic_line_extractor,
                validator=self.json_validator,
            )

            # Processeur de documents
            self.document_processor = DocumentProcessor(
                extractors={
                    "json": self.json_extractor,
                    "table": self.table_extractor,
                    "genetic_line": self.genetic_line_extractor,
                }
            )

            logger.info("âœ… SystÃ¨me RAG JSON initialisÃ©")

        except Exception as e:
            logger.error(f"âŒ Erreur initialisation systÃ¨me JSON: {e}")
            raise

    async def _initialize_cache_system(self):
        """Initialise le systÃ¨me de cache amÃ©liorÃ©"""
        try:
            if CACHE_ENABLED and EXTERNAL_CACHE_AVAILABLE:
                # Cache Redis externe existant
                try:
                    from cache.redis_cache_manager import RAGCacheManager

                    self.cache_manager = RAGCacheManager()
                    await self.cache_manager.initialize()
                    if self.cache_manager.enabled:
                        self.optimization_stats["external_cache_used"] = True
                        logger.info("âœ… Cache Redis externe activÃ©")
                except ImportError as e:
                    logger.warning(f"RAGCacheManager non disponible: {e}")
                    self.cache_manager = None
                except Exception as e:
                    logger.warning(f"Cache Redis externe Ã©chouÃ©: {e}")
                    self.cache_manager = None

                # Cache amÃ©liorÃ© pour systÃ¨me JSON
                if RAG_JSON_SYSTEM_AVAILABLE:
                    try:
                        self.enhanced_cache_manager = EnhancedCacheManager()
                        await self.enhanced_cache_manager.initialize()
                        logger.info("âœ… Cache systÃ¨me JSON activÃ©")
                    except Exception as e:
                        logger.warning(f"Cache systÃ¨me JSON Ã©chouÃ©: {e}")
                        self.enhanced_cache_manager = None

        except Exception as e:
            logger.error(f"Erreur initialisation cache: {e}")

    async def _initialize_base_components(self):
        """Initialise les composants de base"""
        try:
            self.embedder = OpenAIEmbedder(self.openai_client, self.cache_manager)
            self.memory = ConversationMemory(self.openai_client)
            # CORRECTION: Passer le client OpenAI pour la traduction multilingue
            self.ood_detector = EnhancedOODDetector(
                blocked_terms_path=None, openai_client=self.openai_client
            )
            logger.debug("âœ… Composants de base initialisÃ©s")
        except Exception as e:
            logger.error(f"Erreur composants de base: {e}")
            raise

    async def _initialize_hybrid_retriever(self):
        """Initialise le retriever hybride avec RRF intelligent"""
        if self.weaviate_client:
            try:
                self.retriever = HybridWeaviateRetriever(self.weaviate_client)

                # Moteur de recherche hybride pour systÃ¨me JSON
                if RAG_JSON_SYSTEM_AVAILABLE:
                    self.hybrid_search_engine = HybridSearchEngine(
                        weaviate_client=self.weaviate_client,
                        cache_manager=self.enhanced_cache_manager,
                    )

                # === RRF INTELLIGENT ===
                if (
                    INTELLIGENT_RRF_AVAILABLE
                    and ENABLE_INTELLIGENT_RRF
                    and self.cache_manager
                    and self.cache_manager.enabled
                ):
                    try:
                        self.intelligent_rrf = IntelligentRRFFusion(
                            redis_client=self.cache_manager.client,
                            intent_processor=None,  # Sera dÃ©fini plus tard
                        )
                        logger.info("âœ… RRF Intelligent initialisÃ©")
                        if hasattr(self.retriever, "set_intelligent_rrf"):
                            self.retriever.set_intelligent_rrf(self.intelligent_rrf)
                            logger.info("âœ… RRF Intelligent liÃ© au retriever")
                    except Exception as e:
                        logger.error(f"Erreur RRF Intelligent: {e}")

                # Diagnostic API Weaviate
                if ENABLE_API_DIAGNOSTICS:
                    try:
                        await self.retriever.diagnose_weaviate_api()
                        self.optimization_stats["weaviate_capabilities"] = (
                            self.retriever.api_capabilities.copy()
                        )
                    except Exception as e:
                        logger.warning(f"Diagnostic Weaviate Ã©chouÃ©: {e}")

            except Exception as e:
                logger.warning(f"Retriever hybride Ã©chouÃ©: {e}")

    async def _initialize_generator(self):
        """Initialise le gÃ©nÃ©rateur de rÃ©ponses"""
        try:
            self.generator = EnhancedResponseGenerator(
                self.openai_client, self.cache_manager
            )
        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©rateur: {e}")
            raise

    async def _initialize_intent_processor(self):
        """Initialise l'intent processor"""
        try:
            from processing.intent_processor import create_intent_processor
            import os
            from pathlib import Path

            # Tentative de rÃ©solution du chemin de configuration
            config_paths = [
                "config/intents.json",
                Path(__file__).parent.parent / "config" / "intents.json",
                Path.cwd() / "config" / "intents.json",
                os.path.join(os.path.dirname(__file__), "..", "config", "intents.json"),
            ]

            config_found = None
            for path in config_paths:
                path_obj = Path(path)
                if path_obj.exists():
                    config_found = str(path_obj.resolve())
                    logger.debug(f"Configuration intents trouvÃ©e: {config_found}")
                    break

            if config_found:
                self.intent_processor = create_intent_processor(config_found)
                logger.info(
                    f"Intent processor initialisÃ© avec configuration: {config_found}"
                )
            else:
                logger.warning(
                    f"Aucun fichier intents.json trouvÃ© dans {[str(p) for p in config_paths]}"
                )
                logger.info("Utilisation de la configuration par dÃ©faut intÃ©grÃ©e")
                self.intent_processor = create_intent_processor()

            # Connecter RRF Intelligent Ã  Intent Processor
            if self.intelligent_rrf:
                self.intelligent_rrf.intent_processor = self.intent_processor

            logger.info("âœ… Intent processor initialisÃ© avec succÃ¨s")

        except Exception as e:
            logger.warning(f"Intent processor non disponible: {e}")
            self.intent_processor = None

    async def _initialize_guardrails(self):
        """Initialise les guardrails"""
        try:
            from security.advanced_guardrails import (
                create_response_guardrails,
            )

            self.guardrails = create_response_guardrails(
                self.openai_client, GUARDRAILS_LEVEL
            )
        except Exception as e:
            logger.warning(f"Guardrails Ã©chouÃ©: {e}")

    # === NOUVELLES MÃ‰THODES POSTGRESQL ===

    def _route_query(self, query: str, intent_result=None) -> "QueryType":
        """Route une requÃªte vers la source appropriÃ©e (NOUVEAU)"""
        if not POSTGRESQL_INTEGRATION_AVAILABLE or not self.query_router:
            return QueryType.KNOWLEDGE if "QueryType" in globals() else "knowledge"

        try:
            route_result = self.query_router.route_query(query, intent_result)
            self.optimization_stats["query_routing"][route_result.value] += 1
            logger.debug(f"Query routÃ©e vers: {route_result.value}")
            return route_result
        except Exception as e:
            logger.warning(f"Erreur routage de requÃªte: {e}")
            return QueryType.KNOWLEDGE if "QueryType" in globals() else "knowledge"

    async def _search_postgresql_metrics(
        self, query: str, intent_result=None, **kwargs
    ) -> RAGResult:
        """Recherche dans PostgreSQL pour les mÃ©triques (NOUVEAU)"""

        self.optimization_stats["postgresql_queries"] += 1

        if not self.postgres_retriever:
            logger.warning("PostgreSQL non disponible, fallback vers Weaviate")
            self.optimization_stats["postgresql_fallbacks"] += 1
            return await self._search_weaviate_knowledge(query, intent_result, **kwargs)

        try:
            # Recherche des mÃ©triques
            metric_results = await self.postgres_retriever.search_metrics(
                query, intent_result, kwargs.get("top_k", RAG_SIMILARITY_TOP_K)
            )

            if not metric_results:
                return RAGResult(
                    source=RAGSource.NO_RESULTS,
                    metadata={"source_type": "metrics", "data_source": "postgresql"},
                )

            # Conversion en Documents pour compatibilitÃ©
            documents = []
            for metric in metric_results:
                doc_content = self._format_metric_content(metric)

                doc = Document(
                    content=doc_content,
                    metadata={
                        "company": metric.company,
                        "breed": metric.breed,
                        "strain": metric.strain,
                        "species": metric.species,
                        "metric_name": metric.metric_name,
                        "category": metric.category,
                        "sheet_name": metric.sheet_name,
                        "source_type": "metrics",
                        "data_source": "postgresql",
                    },
                    score=metric.confidence,
                )
                documents.append(doc)

            # Calcul confiance globale
            avg_confidence = sum(m.confidence for m in metric_results) / len(
                metric_results
            )

            return RAGResult(
                documents=documents,
                source=RAGSource.RETRIEVAL_SUCCESS,
                confidence=avg_confidence,
                metadata={
                    "source_type": "metrics",
                    "data_source": "postgresql",
                    "metric_count": len(metric_results),
                    "avg_confidence": avg_confidence,
                },
            )

        except Exception as e:
            logger.error(f"Erreur recherche mÃ©triques PostgreSQL: {e}")
            self.optimization_stats["postgresql_fallbacks"] += 1
            return await self._search_weaviate_knowledge(query, intent_result, **kwargs)

    async def _search_hybrid_sources(
        self, query: str, intent_result=None, **kwargs
    ) -> RAGResult:
        """Recherche hybride combinant Weaviate et PostgreSQL (NOUVEAU)"""

        self.optimization_stats["hybrid_queries"] += 1

        try:
            # Recherche parallÃ¨le dans les deux sources
            weaviate_task = asyncio.create_task(
                self._search_weaviate_knowledge(query, intent_result, **kwargs)
            )
            postgres_task = asyncio.create_task(
                self._search_postgresql_metrics(query, intent_result, **kwargs)
            )

            # Attendre les rÃ©sultats
            weaviate_result, postgres_result = await asyncio.gather(
                weaviate_task, postgres_task, return_exceptions=True
            )

            # Fusion des rÃ©sultats
            return self._merge_weaviate_postgresql_results(
                weaviate_result, postgres_result, query
            )

        except Exception as e:
            logger.error(f"Erreur recherche hybride: {e}")
            return RAGResult(
                source=RAGSource.ERROR,
                metadata={"error": str(e), "source_type": "hybrid"},
            )

    async def _search_weaviate_knowledge(
        self, query: str, intent_result=None, **kwargs
    ) -> RAGResult:
        """Recherche dans Weaviate (connaissances) - utilise la logique existante"""
        # Cette mÃ©thode encapsule la logique Weaviate existante
        # Pour l'instant, on dÃ©lÃ¨gue vers la mÃ©thode principale
        # (sera refactorisÃ© dans une prochaine version)
        return await self._generate_response_core_weaviate_only(
            query, intent_result, **kwargs
        )

    def _merge_weaviate_postgresql_results(
        self, weaviate_result: RAGResult, postgres_result: RAGResult, query: str
    ) -> RAGResult:
        """Fusion intelligente des rÃ©sultats Weaviate + PostgreSQL (NOUVEAU)"""

        merged_documents = []
        merged_metadata = {"source_type": "hybrid", "sources": []}

        # Ajouter documents de connaissance
        if isinstance(weaviate_result, RAGResult) and weaviate_result.documents:
            for doc in weaviate_result.documents:
                doc.metadata["result_type"] = "knowledge"
                merged_documents.append(doc)
            merged_metadata["sources"].append("weaviate")
            merged_metadata["knowledge_count"] = len(weaviate_result.documents)

        # Ajouter mÃ©triques
        if isinstance(postgres_result, RAGResult) and postgres_result.documents:
            for doc in postgres_result.documents:
                doc.metadata["result_type"] = "metrics"
                merged_documents.append(doc)
            merged_metadata["sources"].append("postgresql")
            merged_metadata["metrics_count"] = len(postgres_result.documents)

        if not merged_documents:
            return RAGResult(source=RAGSource.NO_RESULTS, metadata=merged_metadata)

        # Tri par pertinence (mÃ©triques en premier si requÃªte orientÃ©e donnÃ©es)
        query_lower = query.lower()
        if any(
            keyword in query_lower
            for keyword in ["chiffre", "donnÃ©es", "rÃ©sultat", "performance"]
        ):
            # Prioriser les mÃ©triques
            merged_documents.sort(
                key=lambda x: (x.metadata.get("result_type") != "metrics", -x.score)
            )
        else:
            # Tri standard par score
            merged_documents.sort(key=lambda x: -x.score)

        # Calcul confiance hybride
        total_confidence = (
            sum(doc.score for doc in merged_documents) / len(merged_documents)
            if merged_documents
            else 0
        )

        return RAGResult(
            documents=merged_documents,
            source=RAGSource.RETRIEVAL_SUCCESS,
            confidence=total_confidence,
            metadata=merged_metadata,
        )

    def _format_metric_content(self, metric: "MetricResult") -> str:
        """Formate une mÃ©trique en contenu texte pour le LLM (NOUVEAU)"""

        content_parts = [
            f"**{metric.metric_name}**",
            f"Entreprise: {metric.company}",
            f"Race: {metric.breed}",
            f"LignÃ©e: {metric.strain}",
            f"EspÃ¨ce: {metric.species}",
            f"CatÃ©gorie: {metric.category}",
        ]

        # Valeur
        if metric.value_numeric is not None:
            value_str = f"{metric.value_numeric}"
            if metric.unit:
                value_str += f" {metric.unit}"
            content_parts.append(f"Valeur: {value_str}")
        elif metric.value_text:
            content_parts.append(f"Valeur: {metric.value_text}")

        # Ã‚ge si disponible
        if metric.age_min is not None and metric.age_max is not None:
            if metric.age_min == metric.age_max:
                content_parts.append(f"Ã‚ge: {metric.age_min} semaines")
            else:
                content_parts.append(f"Ã‚ge: {metric.age_min}-{metric.age_max} semaines")

        content_parts.append(f"Source: {metric.sheet_name}")

        return "\n".join(content_parts)

    # === NOUVELLES MÃ‰THODES JSON (conservÃ©es) ===

    async def validate_json_document(
        self, json_data: Dict[str, Any], strict_mode: bool = False
    ) -> Dict[str, Any]:
        """Valide un document JSON selon les schÃ©mas avicoles"""
        if not RAG_JSON_SYSTEM_AVAILABLE or not self.json_validator:
            return {"valid": False, "error": "SystÃ¨me JSON non disponible"}

        try:
            self.optimization_stats["json_validations"] += 1

            validation_request = ValidationRequest(
                json_data=json_data, strict_mode=strict_mode, auto_enrich=True
            )

            result = await self.json_validator.validate_document(validation_request)

            logger.info(
                f"Validation JSON: {'âœ… Valide' if result.is_valid else 'âŒ Invalide'}"
            )

            return {
                "valid": result.is_valid,
                "enriched_data": result.enriched_data,
                "metadata": result.metadata,
                "errors": result.errors,
                "warnings": result.warnings,
            }

        except Exception as e:
            logger.error(f"Erreur validation JSON: {e}")
            return {"valid": False, "error": str(e)}

    async def ingest_json_documents(
        self, json_files: List[Dict[str, Any]], batch_size: int = 5
    ) -> Dict[str, Any]:
        """IngÃ¨re des documents JSON dans le systÃ¨me"""
        if not RAG_JSON_SYSTEM_AVAILABLE or not self.ingestion_pipeline:
            return {"success": False, "error": "SystÃ¨me JSON non disponible"}

        try:
            self.optimization_stats["json_ingestions"] += 1

            ingestion_request = IngestionRequest(
                json_files=json_files, batch_size=batch_size, force_reprocess=False
            )

            result = await self.ingestion_pipeline.process_documents(ingestion_request)

            logger.info(
                f"Ingestion JSON: {result.processed_count}/{result.total_count} documents traitÃ©s"
            )

            return {
                "success": True,
                "processed_count": result.processed_count,
                "total_count": result.total_count,
                "errors": result.errors,
                "warnings": result.warnings,
                "metadata": result.metadata,
            }

        except Exception as e:
            logger.error(f"Erreur ingestion JSON: {e}")
            return {"success": False, "error": str(e)}

    async def search_json_enhanced(
        self,
        query: str,
        genetic_line: Optional[str] = None,
        performance_metrics: Optional[List[str]] = None,
        age_range: Optional[Dict[str, int]] = None,
    ) -> List[Dict[str, Any]]:
        """Recherche avancÃ©e dans les documents JSON avec filtres avicoles"""
        if not RAG_JSON_SYSTEM_AVAILABLE or not self.hybrid_search_engine:
            logger.warning(
                "Recherche JSON non disponible, utilisation du systÃ¨me classique"
            )
            return []

        try:
            # Construction des filtres avicoles
            filters = {}
            if genetic_line:
                filters["genetic_line"] = genetic_line
            if performance_metrics:
                filters["performance_metrics"] = performance_metrics
            if age_range:
                filters["age_range"] = age_range

            # Recherche hybride spÃ©cialisÃ©e
            results = await self.hybrid_search_engine.search_with_filters(
                query=query, filters=filters, top_k=RAG_SIMILARITY_TOP_K
            )

            logger.info(f"Recherche JSON: {len(results)} rÃ©sultats trouvÃ©s")

            return results

        except Exception as e:
            logger.error(f"Erreur recherche JSON: {e}")
            return []

    # === MÃ‰THODE PRINCIPALE MISE Ã€ JOUR ===

    async def generate_response(
        self,
        query: str,
        tenant_id: str = "default",
        conversation_context: List[Dict] = None,
        language: Optional[str] = None,
        explain_score: Optional[float] = None,
        # NOUVEAUX PARAMÃˆTRES JSON
        use_json_search: bool = True,
        genetic_line_filter: Optional[str] = None,
        performance_context: Optional[Dict[str, Any]] = None,
    ) -> RAGResult:
        """Point d'entrÃ©e principal avec systÃ¨me JSON intÃ©grÃ© + PostgreSQL"""

        if LANGSMITH_AVAILABLE and self.langsmith_client and LANGSMITH_ENABLED:
            return await self._generate_response_with_langsmith(
                query,
                tenant_id,
                conversation_context,
                language,
                explain_score,
                use_json_search,
                genetic_line_filter,
                performance_context,
            )
        else:
            return await self._generate_response_core(
                query,
                tenant_id,
                conversation_context,
                language,
                explain_score,
                use_json_search,
                genetic_line_filter,
                performance_context,
            )

    async def _generate_response_core(
        self,
        query: str,
        tenant_id: str,
        conversation_context: List[Dict],
        language: Optional[str],
        explain_score: Optional[float],
        use_json_search: bool,
        genetic_line_filter: Optional[str],
        performance_context: Optional[Dict[str, Any]],
    ) -> RAGResult:
        """MÃ©thode core avec recherche JSON intÃ©grÃ©e + PostgreSQL"""

        if self.degraded_mode:
            return RAGResult(
                source=RAGSource.FALLBACK_NEEDED, metadata={"reason": "degraded_mode"}
            )

        start_time = time.time()
        METRICS.inc("requests_total")

        try:
            # DÃ©tection langue
            if not language:
                language = detect_language_enhanced(query, default="fr")

            # === NOUVEAU: ROUTAGE INTELLIGENT DES REQUÃŠTES ===
            if POSTGRESQL_INTEGRATION_AVAILABLE and self.query_router:
                query_type = self._route_query(
                    query, None
                )  # intent_result sera traitÃ© plus tard

                # Intent processing pour enrichir le contexte
                intent_result = None
                if self.intent_processor:
                    try:
                        intent_result = self.intent_processor.process_query(query)
                        if intent_result:
                            METRICS.intent_detected(
                                intent_result.intent_type,
                                getattr(intent_result, "confidence", 0.8),
                            )
                            self.optimization_stats["intent_coverage_stats"][
                                intent_result.intent_type
                            ] += 1
                    except Exception as e:
                        logger.warning(f"Erreur intent processor: {e}")
                        intent_result = None

                # Re-routage avec intent_result enrichi
                query_type = self._route_query(query, intent_result)

                # Routage vers la source appropriÃ©e
                if query_type == QueryType.METRICS:
                    logger.info("ðŸŽ¯ RequÃªte routÃ©e vers PostgreSQL (mÃ©triques)")
                    return await self._search_postgresql_metrics(
                        query,
                        intent_result,
                        conversation_context=conversation_context,
                        language=language,
                        tenant_id=tenant_id,
                    )

                elif query_type == QueryType.HYBRID:
                    logger.info("ðŸ”„ RequÃªte routÃ©e vers recherche hybride")
                    return await self._search_hybrid_sources(
                        query,
                        intent_result,
                        conversation_context=conversation_context,
                        language=language,
                        tenant_id=tenant_id,
                    )

                # Sinon: QueryType.KNOWLEDGE ou UNKNOWN â†’ Continue vers Weaviate
                logger.info("ðŸ“š RequÃªte routÃ©e vers Weaviate (connaissances)")

            # === RECHERCHE JSON PRIORITAIRE (conservÃ©e) ===
            json_results = []
            if use_json_search and RAG_JSON_SYSTEM_AVAILABLE:
                try:
                    json_results = await self.search_json_enhanced(
                        query=query,
                        genetic_line=genetic_line_filter,
                        performance_metrics=(
                            performance_context.get("metrics")
                            if performance_context
                            else None
                        ),
                        age_range=(
                            performance_context.get("age_range")
                            if performance_context
                            else None
                        ),
                    )

                    if json_results:
                        logger.info(f"ðŸŽ¯ RÃ©sultats JSON trouvÃ©s: {len(json_results)}")

                        # Si on a de bons rÃ©sultats JSON, les utiliser directement
                        if len(json_results) >= 3:
                            return await self._generate_response_from_json_results(
                                query,
                                json_results,
                                language,
                                conversation_context,
                                start_time,
                            )
                except Exception as e:
                    logger.warning(f"Erreur recherche JSON: {e}")

            # === FALLBACK VERS RECHERCHE CLASSIQUE WEAVIATE ===
            logger.info("ðŸ“š Utilisation recherche Weaviate (fallback ou complÃ©ment)")

            return await self._generate_response_core_weaviate_only(
                query,
                intent_result,
                conversation_context,
                language,
                start_time,
                tenant_id,
            )

        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration rÃ©ponse core: {e}")
            return RAGResult(
                source=RAGSource.INTERNAL_ERROR,
                metadata={"error": str(e), "processing_time": time.time() - start_time},
            )

    async def _generate_response_core_weaviate_only(
        self,
        query: str,
        intent_result,
        conversation_context: List[Dict],
        language: str,
        start_time: float,
        tenant_id: str,
    ) -> RAGResult:
        """MÃ©thode Weaviate classique (LOGIQUE ORIGINALE CONSERVÃ‰E)"""

        try:
            # NOUVEAU: VÃ©rification cache AVANT traitement
            cache_key = None
            if self.cache_manager and self.cache_manager.enabled:
                try:
                    # CrÃ©er une clÃ© de cache unique
                    import hashlib

                    context_hash = ""
                    if conversation_context:
                        context_str = str(conversation_context)
                        context_hash = hashlib.md5(context_str.encode()).hexdigest()[:8]

                    cache_key = f"{tenant_id}:{hashlib.md5(query.encode()).hexdigest()}:{language}:{context_hash}"

                    # Utiliser la mÃ©thode get_response du cache sÃ©mantique si disponible
                    if hasattr(self.cache_manager, "semantic_cache"):
                        cached_response = (
                            await self.cache_manager.semantic_cache.get_response(
                                query, context_hash, language
                            )
                        )
                    else:
                        # Fallback vers cache simple
                        cached_response = await self.cache_manager.get(cache_key)
                        if cached_response and isinstance(cached_response, bytes):
                            cached_response = cached_response.decode("utf-8")

                    if cached_response:
                        self.optimization_stats["cache_hits"] += 1
                        logger.info(f"Cache HIT pour requÃªte: {query[:50]}...")

                        # Si c'est une chaÃ®ne, crÃ©er la structure attendue
                        if isinstance(cached_response, str):
                            return RAGResult(
                                source=RAGSource.RAG_SUCCESS,
                                answer=cached_response,
                                confidence=0.85,  # Confiance Ã©levÃ©e pour cache
                                metadata={
                                    "cache_hit": True,
                                    "processing_time": time.time() - start_time,
                                    "cache_type": (
                                        "semantic"
                                        if hasattr(self.cache_manager, "semantic_cache")
                                        else "simple"
                                    ),
                                },
                            )
                        # Si c'est un dict avec la structure complÃ¨te
                        elif isinstance(cached_response, dict):
                            return RAGResult(
                                source=RAGSource.RAG_SUCCESS,
                                answer=cached_response.get("answer", ""),
                                confidence=cached_response.get("confidence", 0.85),
                                metadata={
                                    "cache_hit": True,
                                    "processing_time": time.time() - start_time,
                                    "cache_type": (
                                        "semantic"
                                        if hasattr(self.cache_manager, "semantic_cache")
                                        else "simple"
                                    ),
                                    **cached_response.get("metadata", {}),
                                },
                            )
                    else:
                        self.optimization_stats["cache_misses"] += 1

                except Exception as e:
                    logger.warning(f"Erreur consultation cache: {e}")
                    self.optimization_stats["cache_misses"] += 1

            # Intent processing avec gestion d'erreurs robuste (si pas dÃ©jÃ  fait)
            if intent_result is None and self.intent_processor:
                try:
                    intent_result = self.intent_processor.process_query(query)
                    if intent_result:
                        METRICS.intent_detected(
                            intent_result.intent_type,
                            getattr(intent_result, "confidence", 0.8),
                        )
                        self.optimization_stats["intent_coverage_stats"][
                            intent_result.intent_type
                        ] += 1
                except Exception as e:
                    logger.warning(f"Erreur intent processor: {e}")
                    intent_result = None

            # CORRECTION CRITIQUE: OOD detection avec nouvelle API
            if self.ood_detector:
                try:
                    # NOUVEAU: Utiliser calculate_ood_score_multilingual() synchrone
                    is_in_domain, domain_score, score_details = (
                        self.ood_detector.calculate_ood_score_multilingual(
                            query, intent_result, language
                        )
                    )

                    if not is_in_domain:
                        return RAGResult(
                            source=RAGSource.OOD_FILTERED,
                            answer=get_out_of_domain_message(language),
                            confidence=0.0,
                            metadata={
                                "ood_score": domain_score,
                                "reason": "out_of_domain",
                                "language": language,
                                "translation_details": score_details,
                            },
                        )
                except Exception as e:
                    logger.warning(f"Erreur OOD multilingue: {e}")
                    # Fallback vers mÃ©thode standard si multilingue Ã©choue
                    try:
                        is_in_domain, domain_score, score_details = (
                            self.ood_detector.calculate_ood_score(query, intent_result)
                        )
                        if not is_in_domain:
                            return RAGResult(
                                source=RAGSource.OOD_FILTERED,
                                answer=get_out_of_domain_message(language),
                                confidence=0.0,
                                metadata={
                                    "ood_score": domain_score,
                                    "reason": "out_of_domain",
                                    "language": language,
                                    "fallback_used": True,
                                },
                            )
                    except Exception as fallback_error:
                        logger.error(f"Erreur OOD fallback: {fallback_error}")
                        # Continuer sans OOD si tout Ã©choue

            # PrÃ©paration contexte conversation
            conversation_context_str = ""
            if conversation_context and len(conversation_context) > 0:
                self.optimization_stats["conversation_context_usage"] += 1
                recent_context = conversation_context[-MAX_CONVERSATION_CONTEXT:]
                conversation_context_str = "\n".join(
                    [
                        f"Q: {ctx.get('question', '')}\nR: {ctx.get('answer', '')[:200]}..."
                        for ctx in recent_context
                    ]
                )

            # GÃ©nÃ©ration embedding
            search_query = (
                getattr(intent_result, "expanded_query", query)
                if intent_result
                else query
            )
            if self.embedder:
                try:
                    query_vector = await self.embedder.get_embedding(search_query)
                except Exception as e:
                    logger.error(f"Erreur embedding: {e}")
                    query_vector = None
            else:
                query_vector = None

            if not query_vector:
                return RAGResult(
                    source=RAGSource.EMBEDDING_FAILED,
                    metadata={"error": "embedding_failed"},
                )

            # Construction filtres Weaviate
            where_filter = build_where_filter(intent_result)

            # Recherche de documents
            documents = []
            if self.retriever:
                try:
                    search_alpha = (
                        getattr(intent_result, "preferred_alpha", DEFAULT_ALPHA)
                        if intent_result
                        else DEFAULT_ALPHA
                    )

                    # Utilisation RRF intelligent si disponible
                    if (
                        self.intelligent_rrf
                        and hasattr(self.intelligent_rrf, "enabled")
                        and self.intelligent_rrf.enabled
                        and ENABLE_INTELLIGENT_RRF
                    ):

                        documents = await self._enhanced_hybrid_search_with_rrf(
                            query_vector,
                            search_query,
                            RAG_SIMILARITY_TOP_K,
                            where_filter,
                            search_alpha,
                            query,
                            intent_result,
                        )
                        self.optimization_stats["intelligent_rrf_used"] += 1

                    else:
                        # Recherche hybride classique
                        documents = await self.retriever.adaptive_search(
                            query_vector,
                            search_query,
                            RAG_SIMILARITY_TOP_K,
                            where_filter,
                            alpha=search_alpha,
                        )

                    # Statistiques recherche
                    if any(doc.metadata.get("hybrid_used") for doc in documents):
                        self.optimization_stats["hybrid_searches"] += 1

                except Exception as e:
                    logger.error(f"Erreur recherche hybride: {e}")
                    return RAGResult(
                        source=RAGSource.SEARCH_FAILED, metadata={"error": str(e)}
                    )

            if not documents:
                return RAGResult(source=RAGSource.NO_DOCUMENTS_FOUND)

            # âœ… CORRECTION: Logs de debug AVANT le filtrage et la vÃ©rification
            effective_threshold = RAG_CONFIDENCE_THRESHOLD
            filtered_docs = [
                doc for doc in documents if doc.score >= effective_threshold
            ]

            # Logs de diagnostic pour debugging - CHANGEMENT: debug au lieu d'error
            logger.debug(f"ðŸ” DEBUG RAG: documents trouvÃ©s: {len(documents)}")
            logger.debug(f"ðŸ” DEBUG RAG: seuil appliquÃ©: {effective_threshold}")
            if documents:
                scores = [doc.score for doc in documents]
                logger.debug(f"ðŸ” DEBUG RAG: scores des documents: {scores}")
                logger.debug(f"ðŸ” DEBUG RAG: score max: {max(scores)}")
            logger.debug(f"ðŸ” DEBUG RAG: documents filtrÃ©s: {len(filtered_docs)}")

            # VÃ©rification et retour LOW_CONFIDENCE si nÃ©cessaire
            if not filtered_docs:
                logger.debug(
                    "ðŸš¨ DEBUG RAG: RETOURNE LOW_CONFIDENCE - aucun document ne passe le seuil"
                )
                return RAGResult(
                    source=RAGSource.LOW_CONFIDENCE,
                    metadata={
                        "threshold": effective_threshold,
                        "max_score": (
                            max([d.score for d in documents]) if documents else 0
                        ),
                        "documents_found": len(documents),
                        "reason": "all_documents_below_threshold",
                    },
                )

            # GÃ©nÃ©ration de la rÃ©ponse
            try:
                if self.generator:
                    response_text = await self.generator.generate_response(
                        query,
                        filtered_docs,
                        conversation_context_str,
                        language,
                        intent_result,
                    )

                    if not response_text or not isinstance(response_text, str):
                        return RAGResult(source=RAGSource.GENERATION_FAILED)

            except Exception as e:
                logger.error(f"Erreur gÃ©nÃ©ration rÃ©ponse: {e}")
                return RAGResult(
                    source=RAGSource.GENERATION_FAILED, metadata={"error": str(e)}
                )

            # Calcul confiance finale
            final_confidence = self._calculate_confidence(filtered_docs)

            # Construction mÃ©tadonnÃ©es complÃ¨tes
            try:
                from utils.imports_and_dependencies import dependency_manager

                dependencies_status = dependency_manager.get_legacy_status()
            except Exception:
                dependencies_status = {}

            metadata = {
                "approach": "enhanced_rag_v5_postgresql_integrated",
                "optimizations_enabled": {
                    "external_redis_cache": self.optimization_stats[
                        "external_cache_used"
                    ],
                    "json_system": RAG_JSON_SYSTEM_AVAILABLE,
                    "postgresql_integration": POSTGRESQL_INTEGRATION_AVAILABLE,
                    "semantic_cache": (
                        getattr(self.cache_manager, "ENABLE_SEMANTIC_CACHE", False)
                        if self.cache_manager
                        else False
                    ),
                    "hybrid_search": HYBRID_SEARCH_ENABLED,
                    "intelligent_rrf": ENABLE_INTELLIGENT_RRF
                    and bool(self.intelligent_rrf),
                    "langsmith_monitoring": LANGSMITH_ENABLED
                    and bool(self.langsmith_client),
                    "entity_enrichment": ENTITY_ENRICHMENT_ENABLED,
                    "advanced_guardrails": GUARDRAILS_AVAILABLE,
                    "api_diagnostics": ENABLE_API_DIAGNOSTICS,
                    "dynamic_ood_thresholds": True,
                },
                "postgresql_system": {
                    "available": POSTGRESQL_INTEGRATION_AVAILABLE,
                    "configured": bool(self.postgres_retriever),
                    "router_enabled": bool(self.query_router),
                },
                "json_system": {
                    "used": False,  # Dans cette branche Weaviate classique
                    "results_count": 0,
                },
                "langsmith": {
                    "enabled": LANGSMITH_ENABLED,
                    "project": LANGSMITH_PROJECT,
                    "traced": bool(self.langsmith_client),
                },
                "weaviate_version": dependencies_status.get("weaviate", False),
                "documents_found": len(documents),
                "documents_used": len(filtered_docs),
                "effective_threshold": effective_threshold,
                "query_expanded": search_query != query,
                "conversation_context_used": bool(conversation_context),
                "where_filter_applied": where_filter is not None,
                "verification_enabled": RAG_VERIFICATION_ENABLED,
                "language_target": language,
                "language_detected": detect_language_enhanced(query),
                "processing_time": time.time() - start_time,
                "optimization_stats": self.optimization_stats.copy(),
            }

            # Ajout entitÃ©s dÃ©tectÃ©es si disponibles
            if intent_result and hasattr(intent_result, "detected_entities"):
                metadata["detected_entities"] = intent_result.detected_entities
                metadata["intent_type"] = (
                    intent_result.intent_type.value
                    if hasattr(intent_result.intent_type, "value")
                    else str(intent_result.intent_type)
                )
                metadata["intent_confidence"] = intent_result.confidence

            # Construire le rÃ©sultat
            result = RAGResult(
                source=RAGSource.RAG_SUCCESS,
                answer=response_text,
                confidence=final_confidence,
                metadata=metadata,
            )

            # NOUVEAU: Stocker en cache aprÃ¨s gÃ©nÃ©ration rÃ©ussie
            if (
                self.cache_manager
                and self.cache_manager.enabled
                and cache_key
                and result.source == RAGSource.RAG_SUCCESS
            ):
                try:
                    cache_data = {
                        "answer": result.answer,
                        "confidence": result.confidence,
                        "timestamp": time.time(),
                        "metadata": {"cached_at": time.time(), "cache_version": "1.0"},
                    }

                    # Utiliser la mÃ©thode set_response du cache sÃ©mantique si disponible
                    if hasattr(self.cache_manager, "semantic_cache"):
                        context_hash = ""
                        if conversation_context:
                            import hashlib

                            context_str = str(conversation_context)
                            context_hash = hashlib.md5(
                                context_str.encode()
                            ).hexdigest()[:8]

                        await self.cache_manager.semantic_cache.set_response(
                            query, context_hash, result.answer, language
                        )
                    else:
                        # Fallback vers cache simple
                        import json

                        await self.cache_manager.set(
                            cache_key,
                            json.dumps(cache_data).encode("utf-8"),
                            ttl=3600,  # 1 heure
                        )

                    self.optimization_stats["cache_sets"] += 1
                    logger.debug(f"RÃ©ponse mise en cache avec clÃ©: {cache_key}")

                except Exception as e:
                    logger.warning(f"Erreur mise en cache: {e}")

            METRICS.observe_latency(time.time() - start_time)
            return result

        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration rÃ©ponse Weaviate: {e}")
            return RAGResult(
                source=RAGSource.INTERNAL_ERROR,
                metadata={"error": str(e), "processing_time": time.time() - start_time},
            )

    async def _generate_response_from_json_results(
        self,
        query: str,
        json_results: List[Dict[str, Any]],
        language: str,
        conversation_context: List[Dict],
        start_time: float,
    ) -> RAGResult:
        """GÃ©nÃ¨re une rÃ©ponse basÃ©e sur les rÃ©sultats JSON"""
        try:
            # GÃ©nÃ©ration de la rÃ©ponse avec le gÃ©nÃ©rateur existant
            if self.generator:
                # Conversion des rÃ©sultats JSON en Documents pour compatibilitÃ©
                documents = []
                for result in json_results:
                    doc = Document(
                        content=result.get("content", ""),
                        metadata=result.get("metadata", {}),
                        score=result.get("score", 0.8),
                    )
                    documents.append(doc)

                conversation_context_str = ""
                if conversation_context:
                    recent_context = conversation_context[-MAX_CONVERSATION_CONTEXT:]
                    conversation_context_str = "\n".join(
                        [
                            f"Q: {ctx.get('question', '')}\nR: {ctx.get('answer', '')[:200]}..."
                            for ctx in recent_context
                        ]
                    )

                response_text = await self.generator.generate_response(
                    query,
                    documents,
                    conversation_context_str,
                    language,
                    None,  # intent_result
                )

                return RAGResult(
                    source=RAGSource.RAG_SUCCESS,
                    answer=response_text,
                    confidence=0.9,  # Confiance Ã©levÃ©e pour rÃ©sultats JSON
                    metadata={
                        "json_system_used": True,
                        "json_results_count": len(json_results),
                        "genetic_lines_detected": list(
                            set(
                                r.get("metadata", {}).get("genetic_line")
                                for r in json_results
                                if r.get("metadata", {}).get("genetic_line")
                            )
                        ),
                        "processing_time": time.time() - start_time,
                        "system_version": "5.0_json_primary",
                    },
                )
            else:
                # Fallback simple si pas de gÃ©nÃ©rateur
                return RAGResult(
                    source=RAGSource.RAG_SUCCESS,
                    answer=f"RÃ©sultats trouvÃ©s dans la base de donnÃ©es avicole: {len(json_results)} documents pertinents.",
                    confidence=0.7,
                    metadata={
                        "json_system_used": True,
                        "fallback_simple": True,
                        "processing_time": time.time() - start_time,
                    },
                )

        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration rÃ©ponse JSON: {e}")
            raise

    async def _generate_response_with_langsmith(
        self,
        query: str,
        tenant_id: str,
        conversation_context: List[Dict],
        language: Optional[str],
        explain_score: Optional[float],
        use_json_search: bool,
        genetic_line_filter: Optional[str],
        performance_context: Optional[Dict[str, Any]],
    ) -> RAGResult:
        """GÃ©nÃ©ration de rÃ©ponse avec tracing LangSmith et JSON + PostgreSQL"""

        start_time = time.time()
        self.optimization_stats["langsmith_traces"] += 1

        try:
            # TraÃ§age contexte aviculture avec JSON et PostgreSQL
            langsmith_metadata = {
                "tenant_id": tenant_id,
                "query_length": len(query),
                "has_conversation_context": bool(conversation_context),
                "language_target": language,
                "system": "intelia_aviculture_rag_v5",
                "version": "postgresql_integrated_langsmith",
                "json_search_enabled": use_json_search,
                "postgresql_enabled": POSTGRESQL_INTEGRATION_AVAILABLE,
                "genetic_line_filter": genetic_line_filter,
                "performance_context": bool(performance_context),
            }

            # Traitement core avec JSON + PostgreSQL
            result = await self._generate_response_core(
                query,
                tenant_id,
                conversation_context,
                language,
                explain_score,
                use_json_search,
                genetic_line_filter,
                performance_context,
            )

            # Enrichissement mÃ©tadonnÃ©es LangSmith avec donnÃ©es JSON + PostgreSQL
            if hasattr(result, "metadata") and result.metadata:
                detected_entities = result.metadata.get("detected_entities", {})

                langsmith_metadata.update(
                    {
                        "genetic_line": detected_entities.get("line", "none"),
                        "age_days": detected_entities.get("age_days"),
                        "performance_metric": any(
                            metric in query.lower()
                            for metric in ["fcr", "poids", "mortalitÃ©", "ponte"]
                        ),
                        "intent_type": result.metadata.get("intent_type", "unknown"),
                        "intent_confidence": result.metadata.get(
                            "intent_confidence", 0.0
                        ),
                        "documents_used": result.metadata.get("documents_used", 0),
                        "json_system_used": result.metadata.get("json_system", {}).get(
                            "used", False
                        ),
                        "json_results_count": result.metadata.get(
                            "json_system", {}
                        ).get("results_count", 0),
                        "postgresql_used": result.metadata.get("source_type")
                        == "metrics",
                        "hybrid_search_used": result.metadata.get("source_type")
                        == "hybrid",
                        "processing_time": time.time() - start_time,
                        "confidence_score": result.confidence,
                    }
                )

            # Log mÃ©tadonnÃ©es dans LangSmith
            if self.langsmith_client:
                try:
                    await self._log_langsmith_alerts(query, result, langsmith_metadata)
                except Exception as e:
                    logger.warning(f"Erreur logging LangSmith: {e}")
                    self.optimization_stats["langsmith_errors"] += 1

            return result

        except Exception as e:
            self.optimization_stats["langsmith_errors"] += 1
            logger.error(f"Erreur LangSmith tracing: {e}")
            # Fallback sans LangSmith
            return await self._generate_response_core(
                query,
                tenant_id,
                conversation_context,
                language,
                explain_score,
                use_json_search,
                genetic_line_filter,
                performance_context,
            )

    # === MÃ‰THODES CRITIQUES CONSERVÃ‰ES ===

    async def _enhanced_hybrid_search_with_rrf(
        self,
        query_vector: List[float],
        query_text: str,
        top_k: int,
        where_filter: Dict,
        alpha: float,
        original_query: str,
        intent_result,
    ) -> List[Document]:
        """Recherche hybride utilisant le RRF intelligent - VERSION SÃ‰CURISÃ‰E CORRIGÃ‰E"""

        try:
            # VALIDATION CRITIQUE: S'assurer qu'intent_result est utilisable avec gestion robuste des types
            validated_intent = validate_intent_result(intent_result)

            # CORRECTION PRINCIPALE: Gestion robuste du type de validated_intent
            is_valid = False
            if isinstance(validated_intent, dict):
                is_valid = validated_intent.get("is_valid", False)
            elif isinstance(validated_intent, bool):
                is_valid = validated_intent
            else:
                logger.warning(
                    f"Type inattendu pour validated_intent: {type(validated_intent)}"
                )
                is_valid = False

            if not is_valid and intent_result is not None:
                logger.warning(f"Intent_result invalide dÃ©tectÃ©: {type(intent_result)}")

            # Recherche vectorielle et BM25 sÃ©parÃ©ment pour RRF intelligent
            # Utiliser la mÃ©thode fallback vectorielle existante
            vector_results = await self.retriever._vector_search_fallback(
                query_vector, top_k * 2, where_filter
            )

            # Pour BM25, recherche hybride avec alpha=0 (BM25 pur)
            bm25_results = await self.retriever._hybrid_search_v4_corrected(
                query_vector, query_text, top_k * 2, where_filter, alpha=0.0
            )

            # Conversion en format Dict pour RRF intelligent
            vector_dicts = [self._document_to_dict(doc) for doc in vector_results]
            bm25_dicts = [self._document_to_dict(doc) for doc in bm25_results]

            # Contexte pour RRF intelligent avec validation sÃ©curisÃ©e
            query_context = {
                "query": original_query,
                "alpha": alpha,
                "top_k": top_k,
                "intent_validated": is_valid,
            }

            # PASSAGE SÃ‰CURISÃ‰: Passer intent_result original mais avec validation robuste
            try:
                fused_results = await self.intelligent_rrf.enhanced_fusion(
                    vector_dicts, bm25_dicts, alpha, top_k, query_context, intent_result
                )
                logger.debug(
                    f"RRF intelligent rÃ©ussi avec {len(fused_results)} rÃ©sultats"
                )

            except Exception as rrf_error:
                logger.error(f"Erreur RRF avec intent_result: {rrf_error}")
                logger.debug(f"Type intent_result problÃ©matique: {type(intent_result)}")

                # Fallback: passer None au lieu d'un intent_result potentiellement dÃ©faillant
                try:
                    fused_results = await self.intelligent_rrf.enhanced_fusion(
                        vector_dicts, bm25_dicts, alpha, top_k, query_context, None
                    )
                    logger.warning(
                        "RRF intelligent rÃ©ussi en mode fallback (intent_result=None)"
                    )

                except Exception as fallback_error:
                    logger.error(f"Erreur RRF mÃªme en fallback: {fallback_error}")
                    # DerniÃ¨re option: RRF classique
                    fused_results = await self._classic_rrf_fallback(
                        vector_dicts, bm25_dicts, alpha, top_k
                    )
                    logger.warning("UtilisÃ© RRF classique en dernier recours")

            # Reconversion en Documents avec validation des donnÃ©es
            final_documents = []
            for result_dict in fused_results:
                try:
                    doc = Document(
                        content=result_dict.get("content", ""),
                        metadata=result_dict.get("metadata", {}),
                        score=result_dict.get("final_score", 0.0),
                        explain_score=result_dict.get("explain_score"),
                    )

                    # Ajout mÃ©tadonnÃ©es RRF intelligent avec validation
                    if "metadata" not in doc.metadata:
                        doc.metadata = {}

                    doc.metadata.update(
                        {
                            "intelligent_rrf_used": True,
                            "rrf_method": result_dict.get("metadata", {}).get(
                                "rrf_method", "intelligent"
                            ),
                            "intent_validated": is_valid,
                            "intent_result_type": str(type(intent_result)),
                            "rrf_processing_timestamp": time.time(),
                        }
                    )

                    final_documents.append(doc)

                except Exception as doc_error:
                    logger.warning(f"Erreur conversion document: {doc_error}")
                    continue

            logger.info(
                f"RRF intelligent terminÃ©: {len(final_documents)} documents finaux"
            )
            return final_documents

        except Exception as global_error:
            logger.error(f"Erreur globale dans RRF intelligent: {global_error}")
            logger.error(
                f"Type validated_intent: {type(validated_intent) if 'validated_intent' in locals() else 'non dÃ©fini'}"
            )
            logger.error(
                f"Type intent_result: {type(intent_result) if intent_result is not None else 'None'}"
            )

            # Fallback complet vers recherche classique
            try:
                classic_results = await self.retriever.adaptive_search(
                    query_vector,
                    query_text,
                    top_k,
                    where_filter,
                    alpha=alpha,
                )
                logger.warning("Fallback vers recherche classique rÃ©ussi")
                return classic_results

            except Exception as classic_error:
                logger.error(f"Erreur mÃªme en recherche classique: {classic_error}")
                return []

    async def _classic_rrf_fallback(self, vector_dicts, bm25_dicts, alpha, top_k):
        """Fallback RRF classique simple en cas d'erreur"""
        try:
            all_docs = {}
            rrf_k = 60

            # Traitement vectoriel
            for i, doc_dict in enumerate(vector_dicts):
                content_key = doc_dict.get("content", "")[:50]  # ClÃ© simple
                all_docs[content_key] = {
                    "doc": doc_dict,
                    "vector_rank": i + 1,
                    "bm25_rank": None,
                }

            # Traitement BM25
            for i, doc_dict in enumerate(bm25_dicts):
                content_key = doc_dict.get("content", "")[:50]
                if content_key in all_docs:
                    all_docs[content_key]["bm25_rank"] = i + 1
                else:
                    all_docs[content_key] = {
                        "doc": doc_dict,
                        "vector_rank": None,
                        "bm25_rank": i + 1,
                    }

            # Calcul RRF simple
            final_results = []
            for content_key, data in all_docs.items():
                rrf_score = 0.0

                if data["vector_rank"]:
                    rrf_score += alpha / (rrf_k + data["vector_rank"])
                if data["bm25_rank"]:
                    rrf_score += (1 - alpha) / (rrf_k + data["bm25_rank"])

                doc_dict = data["doc"].copy()
                doc_dict["final_score"] = rrf_score * 10
                doc_dict["metadata"] = doc_dict.get("metadata", {})
                doc_dict["metadata"]["rrf_method"] = "classic_fallback"

                final_results.append(doc_dict)

            return sorted(final_results, key=lambda x: x["final_score"], reverse=True)[
                :top_k
            ]

        except Exception as e:
            logger.error(f"Erreur mÃªme en RRF fallback: {e}")
            return []

    def _document_to_dict(self, doc: Document) -> Dict:
        """Convertit un Document en dictionnaire pour RRF intelligent"""
        return {
            "content": doc.content,
            "metadata": doc.metadata,
            "score": doc.score,
            "explain_score": doc.explain_score,
        }

    def _calculate_confidence(
        self, documents: List[Document], verification_result=None
    ) -> float:
        """Calcule la confiance finale"""
        if not documents:
            return 0.0

        scores = [doc.score for doc in documents if doc.score > 0]
        if not scores:
            return 0.5

        avg_score = sum(scores) / len(scores)
        coherence_factor = min(1.2, 1 + (len(scores) - 1) * 0.05)

        if len(scores) > 1:
            score_std = np.std(scores)
            distribution_factor = max(0.9, 1 - score_std * 0.5)
        else:
            distribution_factor = 1.0

        verification_factor = 1.0
        if (
            verification_result
            and hasattr(verification_result, "is_valid")
            and verification_result.is_valid
        ):
            verification_factor = 1.1

        final_confidence = (
            avg_score * coherence_factor * distribution_factor * verification_factor
        )
        return min(0.95, max(0.1, final_confidence))

    async def _connect_weaviate(self):
        """Connexion Weaviate corrigÃ©e avec authentification et configuration OpenAI"""
        try:
            import weaviate

            # Variables d'environnement Weaviate
            weaviate_url = os.getenv(
                "WEAVIATE_URL",
                "https://xmlc4jvtu6hfw9zrrmnw.c0.us-east1.gcp.weaviate.cloud",
            )
            weaviate_api_key = os.getenv("WEAVIATE_API_KEY", "")
            openai_api_key = os.getenv("OPENAI_API_KEY", "")

            logger.info(f"Tentative de connexion Weaviate: {weaviate_url}")
            logger.debug(
                f"Weaviate API Key configurÃ©e: {'Oui' if weaviate_api_key else 'Non'}"
            )
            logger.debug(
                f"OpenAI API Key configurÃ©e: {'Oui' if openai_api_key else 'Non'}"
            )

            # CORRECTION CRITIQUE: DÃ©finir OPENAI_APIKEY pour Weaviate si pas dÃ©jÃ  dÃ©finie
            if openai_api_key and "OPENAI_APIKEY" not in os.environ:
                os.environ["OPENAI_APIKEY"] = openai_api_key
                logger.debug(
                    "Variable OPENAI_APIKEY dÃ©finie pour compatibilitÃ© Weaviate"
                )

            # Pour une URL cloud Weaviate, utiliser connect_to_weaviate_cloud avec authentification
            if "weaviate.cloud" in weaviate_url:
                logger.debug(
                    "Utilisation connexion cloud Weaviate avec authentification"
                )

                if weaviate_api_key:
                    try:
                        # NOUVEAU: Client v4 avec API Key et headers OpenAI
                        import weaviate.classes as wvc_classes

                        # Headers personnalisÃ©s pour OpenAI
                        headers = {}
                        if openai_api_key:
                            headers["X-OpenAI-Api-Key"] = openai_api_key

                        self.weaviate_client = weaviate.connect_to_weaviate_cloud(
                            cluster_url=weaviate_url,
                            auth_credentials=wvc_classes.init.Auth.api_key(
                                weaviate_api_key
                            ),
                            headers=headers,
                        )
                        logger.info("Connexion Weaviate v4 avec API Key rÃ©ussie")

                    except ImportError:
                        logger.warning("Weaviate v4 non disponible, utilisation v3")
                        # Fallback vers client v3 avec authentification
                        self.weaviate_client = weaviate.Client(
                            url=weaviate_url,
                            auth_client_secret=weaviate.AuthApiKey(
                                api_key=weaviate_api_key
                            ),
                            additional_headers=(
                                {"X-OpenAI-Api-Key": openai_api_key}
                                if openai_api_key
                                else {}
                            ),
                        )
                        logger.info("Connexion Weaviate v3 avec API Key rÃ©ussie")

                    except Exception as auth_error:
                        logger.error(f"Erreur authentification Weaviate: {auth_error}")
                        # Tentative fallback v3
                        try:
                            self.weaviate_client = weaviate.Client(
                                url=weaviate_url,
                                auth_client_secret=weaviate.AuthApiKey(
                                    api_key=weaviate_api_key
                                ),
                                additional_headers=(
                                    {"X-OpenAI-Api-Key": openai_api_key}
                                    if openai_api_key
                                    else {}
                                ),
                            )
                            logger.info("Fallback Weaviate v3 avec API Key rÃ©ussi")
                        except Exception as fallback_error:
                            logger.error(
                                f"Fallback v3 Ã©galement Ã©chouÃ©: {fallback_error}"
                            )
                            self.weaviate_client = None
                            return
                else:
                    logger.error(
                        "WEAVIATE_API_KEY non configurÃ©e pour l'instance cloud"
                    )
                    self.weaviate_client = None
                    return
            else:
                # Connexion locale sans authentification
                host = weaviate_url.replace("http://", "").replace("https://", "")
                self.weaviate_client = weaviate.connect_to_local(host=host)
                logger.info("Connexion Weaviate locale configurÃ©e")

            # Test de connexion avec timeout
            if self.weaviate_client:
                try:
                    # Test asynchrone de la connexion
                    ready = await asyncio.wait_for(
                        asyncio.to_thread(lambda: self.weaviate_client.is_ready()),
                        timeout=15.0,
                    )

                    if ready:
                        logger.info(
                            f"Connexion Weaviate opÃ©rationnelle: {weaviate_url}"
                        )

                        # CORRECTION: Test de capacitÃ©s v4 compatible
                        try:
                            # Pour client v4, utiliser .collections au lieu de .schema
                            if hasattr(self.weaviate_client, "collections"):
                                await asyncio.to_thread(
                                    lambda: list(
                                        self.weaviate_client.collections.list_all()
                                    )
                                )
                                logger.info(
                                    "Permissions Weaviate vÃ©rifiÃ©es - accÃ¨s collections OK"
                                )
                            else:
                                # Fallback pour client v3
                                await asyncio.to_thread(
                                    lambda: self.weaviate_client.schema.get()
                                )
                                logger.info(
                                    "Permissions Weaviate vÃ©rifiÃ©es - accÃ¨s schÃ©ma OK"
                                )

                        except Exception as perm_error:
                            logger.warning(
                                f"Permissions limitÃ©es Weaviate: {perm_error}"
                            )
                            # Continue quand mÃªme, certaines opÃ©rations peuvent fonctionner

                    else:
                        logger.error("Weaviate connectÃ© mais pas prÃªt")
                        self.weaviate_client = None

                except asyncio.TimeoutError:
                    logger.error("Timeout lors du test de connexion Weaviate (15s)")
                    self.weaviate_client = None
                except Exception as test_error:
                    logger.error(f"Erreur test connexion Weaviate: {test_error}")
                    self.weaviate_client = None

        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©rale connexion Weaviate: {e}")
            self.weaviate_client = None

    async def _log_langsmith_alerts(
        self, query: str, result: RAGResult, metadata: Dict
    ):
        """Log des alertes spÃ©cialisÃ©es aviculture dans LangSmith"""

        alerts = []

        if not result.answer:
            return

        # DÃ©tection valeurs aberrantes aviculture
        answer_lower = result.answer.lower()

        # FCR aberrant
        import re

        fcr_matches = re.findall(r"fcr[:\s]*(\d+[.,]\d*)", answer_lower)
        for fcr_str in fcr_matches:
            try:
                fcr_value = float(fcr_str.replace(",", "."))
                if fcr_value > 3.0 or fcr_value < 0.8:
                    alerts.append(f"FCR_ABERRANT: {fcr_value}")
            except ValueError:
                continue

        # MortalitÃ© aberrante
        mort_matches = re.findall(r"mortalitÃ©[:\s]*(\d+)[%\s]", answer_lower)
        for mort_str in mort_matches:
            try:
                mort_value = float(mort_str)
                if mort_value > 20:
                    alerts.append(f"MORTALITE_ELEVEE: {mort_value}%")
            except ValueError:
                continue

        # Poids aberrant
        poids_matches = re.findall(r"poids[:\s]*(\d+)\s*g", answer_lower)
        for poids_str in poids_matches:
            try:
                poids_value = float(poids_str)
                if poids_value > 5000 or poids_value < 10:
                    alerts.append(f"POIDS_ABERRANT: {poids_value}g")
            except ValueError:
                continue

        # Log alertes si dÃ©tectÃ©es
        if alerts:
            logger.warning(f"Alertes aviculture dÃ©tectÃ©es: {alerts}")
            metadata["alerts_aviculture"] = alerts

        # Confiance faible
        if result.confidence < 0.3:
            alerts.append(f"CONFIANCE_FAIBLE: {result.confidence:.2f}")

    async def get_stats(self) -> Dict[str, Any]:
        """Statistiques du moteur hybride PostgreSQL + Weaviate"""

        base_stats = {
            "postgresql_available": POSTGRESQL_INTEGRATION_AVAILABLE,
            "postgresql_configured": bool(self.postgres_retriever),
            "query_routing_enabled": bool(self.query_router),
        }

        if POSTGRESQL_INTEGRATION_AVAILABLE:
            base_stats.update(
                {
                    "query_distribution": {
                        "knowledge_pct": round(
                            self.optimization_stats["query_routing"].get("knowledge", 0)
                            / max(
                                1,
                                sum(self.optimization_stats["query_routing"].values()),
                            )
                            * 100,
                            1,
                        ),
                        "metrics_pct": round(
                            self.optimization_stats["query_routing"].get("metrics", 0)
                            / max(
                                1,
                                sum(self.optimization_stats["query_routing"].values()),
                            )
                            * 100,
                            1,
                        ),
                        "hybrid_pct": round(
                            self.optimization_stats["query_routing"].get("hybrid", 0)
                            / max(
                                1,
                                sum(self.optimization_stats["query_routing"].values()),
                            )
                            * 100,
                            1,
                        ),
                    },
                    "postgresql_stats": {
                        "queries": self.optimization_stats["postgresql_queries"],
                        "fallbacks": self.optimization_stats["postgresql_fallbacks"],
                        "hybrid_queries": self.optimization_stats["hybrid_queries"],
                    },
                }
            )

        return base_stats

    def get_status(self) -> Dict:
        """Status enrichi avec systÃ¨me JSON intÃ©grÃ© + PostgreSQL"""
        try:
            weaviate_connected = False
            api_capabilities = {}

            if self.weaviate_client:
                try:
                    weaviate_connected = self.weaviate_client.is_ready()
                except Exception:
                    weaviate_connected = False

            if self.retriever and hasattr(self.retriever, "api_capabilities"):
                api_capabilities = self.retriever.api_capabilities

            # Import local de dependency_manager pour Ã©viter NameError
            from utils.imports_and_dependencies import dependency_manager

            dependencies_status = dependency_manager.get_legacy_status()

            status = {
                "rag_enabled": RAG_ENABLED,
                "initialized": self.is_initialized,
                "degraded_mode": self.degraded_mode,
                "approach": "enhanced_rag_v5_postgresql_json_integrated",
                "postgresql_system": {
                    "available": POSTGRESQL_INTEGRATION_AVAILABLE,
                    "components": {
                        "postgres_retriever": bool(self.postgres_retriever),
                        "query_router": bool(self.query_router),
                    },
                    "stats": {
                        "postgresql_queries": self.optimization_stats[
                            "postgresql_queries"
                        ],
                        "postgresql_fallbacks": self.optimization_stats[
                            "postgresql_fallbacks"
                        ],
                        "hybrid_queries": self.optimization_stats["hybrid_queries"],
                        "query_routing": dict(self.optimization_stats["query_routing"]),
                    },
                },
                "json_system": {
                    "available": RAG_JSON_SYSTEM_AVAILABLE,
                    "components": {
                        "json_extractor": bool(self.json_extractor),
                        "table_extractor": bool(self.table_extractor),
                        "genetic_line_extractor": bool(self.genetic_line_extractor),
                        "json_validator": bool(self.json_validator),
                        "ingestion_pipeline": bool(self.ingestion_pipeline),
                        "hybrid_search_engine": bool(self.hybrid_search_engine),
                        "document_processor": bool(self.document_processor),
                        "enhanced_cache_manager": bool(self.enhanced_cache_manager),
                    },
                    "stats": {
                        "json_validations": self.optimization_stats["json_validations"],
                        "json_ingestions": self.optimization_stats["json_ingestions"],
                        "table_extractions": self.optimization_stats[
                            "table_extractions"
                        ],
                        "genetic_line_detections": self.optimization_stats[
                            "genetic_line_detections"
                        ],
                        "performance_metrics_processed": self.optimization_stats[
                            "performance_metrics_processed"
                        ],
                    },
                },
                "optimizations": {
                    "external_cache_enabled": (
                        self.cache_manager.enabled if self.cache_manager else False
                    ),
                    "enhanced_cache_enabled": (
                        self.enhanced_cache_manager.enabled
                        if self.enhanced_cache_manager
                        else False
                    ),
                    "hybrid_search_enabled": HYBRID_SEARCH_ENABLED,
                    "intelligent_rrf_enabled": ENABLE_INTELLIGENT_RRF,
                    "langsmith_enabled": LANGSMITH_ENABLED,
                    "postgresql_integration_enabled": POSTGRESQL_INTEGRATION_AVAILABLE,
                    "semantic_cache_enabled": (
                        getattr(self.cache_manager, "ENABLE_SEMANTIC_CACHE", False)
                        if self.cache_manager
                        else False
                    ),
                    "entity_enrichment_enabled": ENTITY_ENRICHMENT_ENABLED,
                    "guardrails_level": GUARDRAILS_LEVEL,
                    "api_diagnostics_enabled": ENABLE_API_DIAGNOSTICS,
                },
                "langsmith": {
                    "available": LANGSMITH_AVAILABLE,
                    "enabled": LANGSMITH_ENABLED,
                    "configured": bool(self.langsmith_client),
                    "project": LANGSMITH_PROJECT,
                    "traces_count": self.optimization_stats["langsmith_traces"],
                    "errors_count": self.optimization_stats["langsmith_errors"],
                },
                "intelligent_rrf": {
                    "available": INTELLIGENT_RRF_AVAILABLE,
                    "enabled": ENABLE_INTELLIGENT_RRF,
                    "configured": bool(self.intelligent_rrf),
                    "learning_mode": getattr(self, "RRF_LEARNING_MODE", False),
                    "genetic_boost": getattr(self, "RRF_GENETIC_BOOST", False),
                    "usage_count": self.optimization_stats["intelligent_rrf_used"],
                    "performance_stats": (
                        self.intelligent_rrf.get_performance_stats()
                        if self.intelligent_rrf
                        else {}
                    ),
                },
                "components": dependencies_status,
                "weaviate_connected": weaviate_connected,
                "configuration": {
                    "similarity_top_k": RAG_SIMILARITY_TOP_K,
                    "confidence_threshold": RAG_CONFIDENCE_THRESHOLD,
                    "hybrid_default_alpha": DEFAULT_ALPHA,
                    "rrf_base_k": getattr(self, "RRF_BASE_K", 60),
                    "max_conversation_context": MAX_CONVERSATION_CONTEXT,
                },
                "optimization_stats": self.optimization_stats.copy(),
                "api_capabilities": api_capabilities,
                "metrics": METRICS.snapshot(),
            }

            return status

        except Exception as e:
            logger.error(f"Erreur get_status: {e}")
            return {"error": str(e), "initialized": self.is_initialized}

    async def close(self):
        """Ferme toutes les connexions (NOUVEAU)"""

        # Fermeture PostgreSQL
        if POSTGRESQL_INTEGRATION_AVAILABLE and self.postgres_retriever:
            try:
                await self.postgres_retriever.close()
                logger.info("PostgreSQL Retriever fermÃ©")
            except Exception as e:
                logger.warning(f"Erreur fermeture PostgreSQL: {e}")

        # Fermeture Weaviate et autres composants (si applicable)
        if hasattr(self.weaviate_client, "close"):
            try:
                await self.weaviate_client.close()
                logger.info("Weaviate client fermÃ©")
            except Exception as e:
                logger.warning(f"Erreur fermeture Weaviate: {e}")


# Factory function pour compatibilitÃ©
def create_rag_engine(openai_client=None) -> InteliaRAGEngine:
    """Factory pour crÃ©er une instance RAG Engine avec support PostgreSQL"""
    return InteliaRAGEngine(openai_client)
