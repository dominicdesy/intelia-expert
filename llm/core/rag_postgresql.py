# -*- coding: utf-8 -*-

"""

rag_postgresql.py - PostgreSQL System for RAG
Version modulaire avec int√©gration QueryValidator et DataAvailabilityChecker

"""

import os
import json
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum

# Safe conditional imports
try:
    import asyncpg

    ASYNCPG_AVAILABLE = True
except ImportError:
    ASYNCPG_AVAILABLE = False
    asyncpg = None

try:
    import openai

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    openai = None

from .data_models import RAGResult, RAGSource, Document
from .postgresql_query_builder import PostgreSQLQueryBuilder

# ‚úÖ PHASE 1: Import des nouveaux modules
try:
    from .query_validator import QueryValidator

    QUERY_VALIDATOR_AVAILABLE = True
except ImportError:
    QUERY_VALIDATOR_AVAILABLE = False
    QueryValidator = None
    logging.warning("QueryValidator non disponible")

try:
    from .data_availability_checker import DataAvailabilityChecker

    DATA_CHECKER_AVAILABLE = True
except ImportError:
    DATA_CHECKER_AVAILABLE = False
    DataAvailabilityChecker = None
    logging.warning("DataAvailabilityChecker non disponible")

logger = logging.getLogger(__name__)

# PostgreSQL configuration
POSTGRESQL_CONFIG = {
    "user": os.getenv("DB_USER", "doadmin"),
    "password": os.getenv("DB_PASSWORD", ""),
    "host": os.getenv("DB_HOST", "localhost"),
    "port": int(os.getenv("DB_PORT", 25060)),
    "database": os.getenv("DB_NAME", "defaultdb"),
    "ssl": os.getenv("DB_SSL", "require"),
}

# OpenAI configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = "gpt-4o-mini"


class QueryType(Enum):
    """Query types for intelligent routing"""

    KNOWLEDGE = "knowledge"
    METRICS = "metrics"
    HYBRID = "hybrid"
    UNKNOWN = "unknown"


@dataclass
class MetricResult:
    """Result of a PostgreSQL metrics query"""

    company: str
    breed: str
    strain: str
    species: str
    metric_name: str
    value_numeric: Optional[float] = None
    value_text: Optional[str] = None
    unit: Optional[str] = None
    age_min: Optional[int] = None
    age_max: Optional[int] = None
    sheet_name: str = ""
    category: str = ""
    confidence: float = 1.0
    sex: Optional[str] = None
    housing_system: Optional[str] = None
    data_type: Optional[str] = None

    def __post_init__(self):
        """Data validation and cleaning"""
        self.company = str(self.company) if self.company is not None else "Unknown"
        self.breed = str(self.breed) if self.breed is not None else "Unknown"
        self.strain = str(self.strain) if self.strain is not None else "Unknown"
        self.species = str(self.species) if self.species is not None else "Unknown"
        self.metric_name = (
            str(self.metric_name) if self.metric_name is not None else "Unknown"
        )
        self.sheet_name = str(self.sheet_name) if self.sheet_name is not None else ""
        self.category = str(self.category) if self.category is not None else ""

        # Sex normalization
        if self.sex:
            self.sex = str(self.sex).lower()
            if self.sex in ["male", "m√¢le", "m", "masculin"]:
                self.sex = "male"
            elif self.sex in ["female", "femelle", "f", "f√©minin"]:
                self.sex = "female"
            elif self.sex in [
                "mixed",
                "mixte",
                "as_hatched",
                "as-hatched",
                "straight_run",
            ]:
                self.sex = "as_hatched"
            else:
                self.sex = "as_hatched"

        self.confidence = max(0.0, min(1.0, float(self.confidence)))


class SQLQueryNormalizer:
    """Multilingual normalizer - Conserv√© du code original"""

    def __init__(self):
        self.terminology = self._load_terminology()
        self.CONCEPT_MAPPINGS = self._build_concept_mappings()
        logger.info(
            f"SQLQueryNormalizer initialized with {len(self.CONCEPT_MAPPINGS)} concept mappings"
        )

    def _load_terminology(self) -> Dict[str, Any]:
        """Load terminology from JSON configuration files"""
        config_dir = os.path.join(os.path.dirname(__file__), "..", "config")
        terms = {}
        supported_languages = ["en", "fr", "es"]

        for lang in supported_languages:
            file_path = os.path.join(config_dir, f"universal_terms_{lang}.json")
            try:
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        terms[lang] = json.load(f)
                        logger.info(
                            f"Terminology loaded successfully for language: {lang}"
                        )
                else:
                    logger.warning(f"Terminology file not found: {file_path}")
                    terms[lang] = {}
            except Exception as e:
                logger.error(f"Error loading terminology for {lang}: {e}")
                terms[lang] = {}

        return terms

    def _build_concept_mappings(self) -> Dict[str, List[str]]:
        """Build concept mappings from loaded terminology"""
        mappings = {}

        for lang, lang_terms in self.terminology.items():
            if "performance_metrics" not in lang_terms:
                continue

            perf_metrics = lang_terms["performance_metrics"]

            for metric_key, metric_terms in perf_metrics.items():
                base_key = metric_key.split("_")[0] if "_" in metric_key else metric_key

                if base_key not in mappings:
                    mappings[base_key] = []

                if isinstance(metric_terms, list):
                    mappings[base_key].extend(metric_terms)

                if metric_key not in mappings:
                    mappings[metric_key] = []
                if isinstance(metric_terms, list):
                    mappings[metric_key].extend(metric_terms)

        for key in mappings:
            mappings[key] = list(set(mappings[key]))

        logger.info(f"Built concept mappings for {len(mappings)} concepts")
        return mappings

    def get_search_terms(self, query: str) -> Tuple[List[str], List[str]]:
        """Returns (normalized_concepts, raw_words) for SQL search"""
        normalized = self.normalize_query_concepts(query)
        raw_words = [word for word in query.lower().split() if len(word) > 3]
        return normalized, raw_words

    def normalize_query_concepts(self, query: str) -> List[str]:
        """Converts user query to normalized concept terms"""
        query_lower = query.lower()
        normalized_concepts = []

        for concept, terms in self.CONCEPT_MAPPINGS.items():
            if any(term.lower() in query_lower for term in terms):
                normalized_concepts.extend(terms)

        seen = set()
        unique_concepts = []
        for concept in normalized_concepts:
            if concept not in seen:
                seen.add(concept)
                unique_concepts.append(concept)

        return unique_concepts

    def extract_sex_from_query(self, query: str) -> Optional[str]:
        """Extract sex from query"""
        query_lower = query.lower()

        male_patterns = ["male", "m√¢le", "m√¢les", "masculin", "coq", "coqs", "rooster"]
        if any(pattern in query_lower for pattern in male_patterns):
            return "male"

        female_patterns = [
            "female",
            "femelle",
            "femelles",
            "f√©minin",
            "poule",
            "poules",
            "hen",
        ]
        if any(pattern in query_lower for pattern in female_patterns):
            return "female"

        mixed_patterns = [
            "as-hatched",
            "ashatched",
            "mixed",
            "mixte",
            "m√©lang√©",
            "non sex√©",
            "straight run",
        ]
        if any(pattern in query_lower for pattern in mixed_patterns):
            return "as_hatched"

        return None


class QueryRouter:
    """Intelligent router - Conserv√© du code original"""

    def __init__(self):
        self.metric_keywords = {
            "performance",
            "metrics",
            "donnees",
            "chiffres",
            "resultats",
            "weight",
            "poids",
            "egg",
            "oeuf",
            "production",
            "feed",
            "alimentation",
            "mortality",
            "mortalite",
            "growth",
            "croissance",
            "fcr",
            "icg",
            "conversion",
            "ross",
            "cobb",
            "hubbard",
        }

        self.knowledge_keywords = {
            "comment",
            "pourquoi",
            "qu'est-ce",
            "expliquer",
            "definir",
            "maladie",
            "disease",
            "traitement",
            "prevention",
            "biosecurite",
        }

    def route_query(self, query: str, intent_result=None) -> QueryType:
        """Determines query type"""
        query_lower = query.lower()

        metric_score = sum(
            1 for keyword in self.metric_keywords if keyword in query_lower
        )
        knowledge_score = sum(
            1 for keyword in self.knowledge_keywords if keyword in query_lower
        )

        if metric_score > knowledge_score + 1:
            return QueryType.METRICS
        elif knowledge_score > metric_score + 1:
            return QueryType.KNOWLEDGE
        else:
            return QueryType.HYBRID


class PostgreSQLRetriever:
    """PostgreSQL data retriever - Simplifi√© avec QueryBuilder"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.pool = None
        self.query_normalizer = SQLQueryNormalizer()
        self.query_builder = PostgreSQLQueryBuilder(self.query_normalizer)
        self.is_initialized = False

    async def initialize(self):
        """Initialize PostgreSQL connection"""
        if not ASYNCPG_AVAILABLE:
            logger.error("asyncpg not available")
            raise ImportError("asyncpg required")

        if self.is_initialized:
            return

        try:
            self.pool = await asyncpg.create_pool(
                user=self.config["user"],
                password=self.config["password"],
                host=self.config["host"],
                port=self.config["port"],
                database=self.config["database"],
                ssl=self.config["ssl"],
                min_size=2,
                max_size=10,
                command_timeout=30,
            )

            async with self.pool.acquire() as conn:
                await conn.execute("SELECT 1")

            self.is_initialized = True
            logger.info("PostgreSQL Retriever initialized")

        except Exception as e:
            logger.error(f"PostgreSQL initialization error: {e}")
            self.pool = None
            self.is_initialized = False
            raise

    def _normalize_entities(self, entities: Dict[str, Any] = None) -> Dict[str, str]:
        """Normalize entities to simple string dict"""
        if not entities:
            return {}

        normalized = {}

        for key, value in entities.items():
            if value is None:
                continue

            if isinstance(value, str):
                normalized[key] = value
            elif isinstance(value, bool):
                normalized[key] = "true" if value else "false"
            elif isinstance(value, (int, float)):
                normalized[key] = str(value)
            elif hasattr(value, "value"):
                normalized[key] = str(value.value)
            else:
                normalized[key] = str(value)

        return normalized

    async def search_metrics(
        self,
        query: str,
        entities: Dict[str, Any] = None,
        top_k: int = 10,
        strict_sex_match: bool = False,
    ) -> List[MetricResult]:
        """
        Search metrics with optional strict sex matching

        Args:
            strict_sex_match: If True, only exact sex match (for comparisons)
        """

        if not self.is_initialized or not self.pool:
            logger.warning("PostgreSQL not initialized")
            try:
                await self.initialize()
            except Exception as e:
                logger.error(f"Initialization failed: {e}")
                return []

        try:
            normalized_entities = self._normalize_entities(entities)
            logger.debug(f"Entities: {entities}")
            logger.debug(f"Normalized: {normalized_entities}")

            sql_query, params = self.query_builder.build_sex_aware_sql_query(
                query, normalized_entities, top_k, strict_sex_match
            )

            logger.debug(f"SQL Query: {sql_query}")
            logger.debug(f"Parameters: {params}")

            async with self.pool.acquire() as conn:
                rows = await conn.fetch(sql_query, *params)

            results = []
            for i, row in enumerate(rows):
                try:
                    result = MetricResult(
                        company=row.get("company_name", "Unknown"),
                        breed=row.get("breed_name", "Unknown"),
                        strain=row.get("strain_name", "Unknown"),
                        species=row.get("species", "Unknown"),
                        metric_name=row.get("metric_name", "Unknown"),
                        value_numeric=row.get("value_numeric"),
                        value_text=row.get("value_text"),
                        unit=row.get("unit"),
                        age_min=row.get("age_min"),
                        age_max=row.get("age_max"),
                        sheet_name=row.get("sheet_name", ""),
                        category=row.get("category_name", ""),
                        sex=row.get("sex"),
                        housing_system=row.get("housing_system"),
                        data_type=row.get("data_type"),
                        confidence=self._calculate_relevance(
                            query, row, normalized_entities
                        ),
                    )
                    results.append(result)
                except Exception as row_error:
                    logger.error(f"Row conversion error {i}: {row_error}")
                    continue

            logger.info(
                f"PostgreSQL: {len(results)} metrics found from {len(rows)} rows"
            )
            return results

        except Exception as e:
            logger.error(f"PostgreSQL search error: {e}")
            return []

    def _calculate_relevance(
        self, query: str, row: Dict, entities: Dict[str, str] = None
    ) -> float:
        """Calculate relevance score"""
        score = 0.5

        sex_from_entities = entities.get("sex") if entities else None
        row_sex = (row.get("sex") or "as_hatched").lower()

        if sex_from_entities and sex_from_entities != "as_hatched":
            if row_sex == sex_from_entities.lower():
                score += 0.3
            elif row_sex in ["as_hatched", "mixed"]:
                score += 0.1
        else:
            if row_sex in ["as_hatched", "mixed"]:
                score += 0.2

        normalized_concepts, _ = self.query_normalizer.get_search_terms(query)
        metric_name_lower = (row.get("metric_name") or "").lower()

        for concept in normalized_concepts:
            if concept in metric_name_lower:
                score += 0.3
                break

        if row.get("value_numeric") is not None:
            score += 0.1

        return min(1.0, score)

    async def close(self):
        """Close PostgreSQL connection"""
        if self.pool:
            try:
                await self.pool.close()
                logger.info("PostgreSQL connection closed")
            except Exception as e:
                logger.error(f"PostgreSQL close error: {e}")
            finally:
                self.pool = None
                self.is_initialized = False


class PostgreSQLSystem:
    """Main PostgreSQL system - Interface simplifi√©e + Phase 1 modules"""

    def __init__(self):
        self.query_router = None
        self.postgres_retriever = None
        self.is_initialized = False
        self.openai_client = None

        # ‚úÖ PHASE 1: Initialisation des nouveaux modules
        self.query_validator = None
        self.data_availability_checker = None

    async def initialize(self):
        """Initialize PostgreSQL system + Phase 1 modules"""
        if self.is_initialized:
            return

        if not ASYNCPG_AVAILABLE:
            logger.error("asyncpg not available")
            raise ImportError("asyncpg required")

        try:
            self.query_router = QueryRouter()
            self.postgres_retriever = PostgreSQLRetriever(POSTGRESQL_CONFIG)
            await self.postgres_retriever.initialize()

            if OPENAI_AVAILABLE and OPENAI_API_KEY:
                self.openai_client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)
                logger.info("OpenAI client initialized")
            else:
                logger.warning("OpenAI not available")

            # ‚úÖ PHASE 1: Initialisation QueryValidator
            if QUERY_VALIDATOR_AVAILABLE and QueryValidator:
                try:
                    self.query_validator = QueryValidator()
                    logger.info("‚úÖ QueryValidator initialis√© (Phase 1)")
                except Exception as e:
                    logger.warning(f"QueryValidator init failed: {e}")
                    self.query_validator = None

            # ‚úÖ PHASE 1: Initialisation DataAvailabilityChecker
            if DATA_CHECKER_AVAILABLE and DataAvailabilityChecker:
                try:
                    self.data_availability_checker = DataAvailabilityChecker()
                    logger.info("‚úÖ DataAvailabilityChecker initialis√© (Phase 1)")
                except Exception as e:
                    logger.warning(f"DataAvailabilityChecker init failed: {e}")
                    self.data_availability_checker = None

            self.is_initialized = True
            logger.info("PostgreSQL System initialized with Phase 1 modules")

        except Exception as e:
            logger.error(f"PostgreSQL System initialization error: {e}")
            self.is_initialized = False
            raise

    def route_query(self, query: str, intent_result=None) -> QueryType:
        """Route a query"""
        if not self.query_router:
            return QueryType.KNOWLEDGE
        return self.query_router.route_query(query, intent_result)

    async def search_metrics(
        self,
        query: str,
        intent_result=None,
        top_k: int = 12,
        entities: Dict[str, Any] = None,
        strict_sex_match: bool = False,
    ) -> RAGResult:
        """
        AM√âLIOR√â: Recherche de m√©triques avec validation flexible
        """

        if not self.is_initialized or not self.postgres_retriever:
            logger.warning("PostgreSQL retriever non initialis√©")
            return RAGResult(
                source=RAGSource.ERROR, answer="Syst√®me de m√©triques non disponible."
            )

        import time

        start_time = time.time()

        try:
            # NOUVEAU: Validation flexible avec suggestions
            validation_result = self._flexible_query_validation(query, entities)

            if validation_result["status"] == "complete":
                # Requ√™te compl√®te - traitement normal
                logger.info("Query validation: complete")

            elif validation_result["status"] == "incomplete_but_processable":
                # Requ√™te incompl√®te mais traitable
                logger.info(f"üîß Correction: {validation_result['message']}")
                entities = validation_result["enhanced_entities"]

            elif validation_result["status"] == "needs_fallback":
                # Rediriger vers r√©ponse d'aide
                logger.info("Query validation: redirecting to helpful response")
                return RAGResult(
                    source=RAGSource.NO_RESULTS,
                    answer=validation_result["helpful_message"],
                    metadata={
                        "processing_time": time.time() - start_time,
                        "validation_status": "incomplete",
                        "missing_entities": validation_result["missing"],
                        "suggestions": validation_result["suggestions"],
                    },
                )

            # NOUVEAU: V√©rification disponibilit√© des donn√©es plus flexible
            if entities and entities.get("breed") and entities.get("age_days"):
                availability_check = self._check_data_availability_flexible(entities)
                if not availability_check["available"]:
                    logger.info(
                        f"Data availability check: {availability_check['message']}"
                    )

                    # Proposer alternatives au lieu de rejeter
                    if availability_check.get("alternatives"):
                        return RAGResult(
                            source=RAGSource.NO_RESULTS,
                            answer=availability_check["helpful_response"],
                            metadata={
                                "processing_time": time.time() - start_time,
                                "availability_status": "out_of_range",
                                "alternatives": availability_check["alternatives"],
                            },
                        )

            # Ex√©cution normale de la requ√™te
            metric_results = await self.postgres_retriever.search_metrics(
                query=query,
                entities=entities,
                top_k=top_k,
                strict_sex_match=strict_sex_match,
            )

            if not metric_results:
                return RAGResult(
                    source=RAGSource.NO_RESULTS,
                    answer="Aucune m√©trique trouv√©e pour cette requ√™te.",
                    metadata={"processing_time": time.time() - start_time},
                )

            documents = self._convert_metrics_to_documents(metric_results)

            if not documents:
                logger.warning("No documents created")
                return RAGResult(
                    source=RAGSource.NO_RESULTS,
                    metadata={"error": "No valid documents"},
                )

            answer_text = await self._generate_response(
                query, documents, metric_results, entities
            )

            avg_confidence = sum(m.confidence for m in metric_results) / len(
                metric_results
            )

            logger.info(f"PostgreSQL SUCCESS: {len(documents)} documents")

            return RAGResult(
                source=RAGSource.RAG_SUCCESS,
                answer=answer_text,
                context_docs=[doc.to_dict() for doc in documents],
                confidence=avg_confidence,
                metadata={
                    "source_type": "metrics",
                    "data_source": "postgresql",
                    "metric_count": len(metric_results),
                    "strict_sex_match": strict_sex_match,
                    "openai_model": OPENAI_MODEL,
                    "validation_passed": True,
                    "availability_passed": True,
                    "processing_time": time.time() - start_time,
                },
            )

        except Exception as e:
            logger.error(f"PostgreSQL search error: {e}")
            return RAGResult(
                source=RAGSource.ERROR,
                answer="Erreur lors de la recherche de m√©triques.",
                metadata={"error": str(e), "processing_time": time.time() - start_time},
            )

    def _flexible_query_validation(
        self, query: str, entities: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        NOUVEAU: Validation flexible qui essaie de compl√©ter les requ√™tes incompl√®tes
        """

        entities = entities or {}
        missing = []
        suggestions = []
        enhanced_entities = entities.copy()

        # V√©rifier breed
        if not entities.get("breed"):
            # Essayer d'extraire breed du texte de la requ√™te
            detected_breed = self._detect_breed_from_query(query)
            if detected_breed:
                enhanced_entities["breed"] = detected_breed
                logger.debug(f"Auto-detected breed: {detected_breed}")
            else:
                missing.append("breed")
                suggestions.append("Sp√©cifiez une race (Cobb 500, Ross 308, etc.)")

        # V√©rifier √¢ge
        if not entities.get("age_days"):
            # Essayer d'extraire √¢ge du texte
            detected_age = self._detect_age_from_query(query)
            if detected_age:
                enhanced_entities["age_days"] = detected_age
                logger.debug(f"Auto-detected age: {detected_age} days")
            else:
                # Pour certaines requ√™tes, l'√¢ge n'est pas critique
                if any(
                    word in query.lower()
                    for word in ["recommande", "meilleur", "compare", "g√©n√©ral"]
                ):
                    # Requ√™te g√©n√©rale - pas besoin d'√¢ge sp√©cifique
                    pass
                else:
                    missing.append("age")
                    suggestions.append("Pr√©cisez un √¢ge (21 jours, 42 jours, etc.)")

        # V√©rifier m√©trique
        if not entities.get("metric_type"):
            detected_metric = self._detect_metric_from_query(query)
            if detected_metric:
                enhanced_entities["metric_type"] = detected_metric
                logger.debug(f"Auto-detected metric: {detected_metric}")

        # D√©terminer le statut
        if not missing:
            return {"status": "complete", "enhanced_entities": enhanced_entities}

        elif len(missing) <= 1 and ("breed" not in missing):
            # Si juste l'√¢ge ou m√©trique manque, on peut souvent traiter
            return {
                "status": "incomplete_but_processable",
                "message": f"Autoriser la requ√™te sans {', '.join(missing)} sp√©cifique",
                "enhanced_entities": enhanced_entities,
                "missing": missing,
            }

        else:
            # Trop d'informations manquantes
            helpful_message = self._generate_validation_help_message(
                query, missing, suggestions
            )
            return {
                "status": "needs_fallback",
                "missing": missing,
                "suggestions": suggestions,
                "helpful_message": helpful_message,
            }

    def _detect_breed_from_query(self, query: str) -> Optional[str]:
        """D√©tecte la race dans le texte de la requ√™te"""
        query_lower = query.lower()

        # Patterns de d√©tection
        breed_patterns = {
            "cobb 500": ["cobb 500", "cobb500", "c500"],
            "ross 308": ["ross 308", "ross308", "r308"],
            "hubbard ja87": ["hubbard", "ja87", "j87"],
        }

        for canonical_breed, patterns in breed_patterns.items():
            for pattern in patterns:
                if pattern in query_lower:
                    return canonical_breed

        return None

    def _detect_age_from_query(self, query: str) -> Optional[int]:
        """D√©tecte l'√¢ge dans le texte de la requ√™te"""
        import re

        age_patterns = [
            r"√†\s+(\d+)\s+jours?",
            r"(\d+)\s+jours?",
            r"(\d+)\s*j\b",
            r"(\d+)\s+semaines?",  # Sera multipli√© par 7
        ]

        query_lower = query.lower()

        for pattern in age_patterns:
            match = re.search(pattern, query_lower)
            if match:
                age = int(match.group(1))
                # Convertir semaines en jours
                if "semaine" in pattern:
                    age *= 7
                if 0 <= age <= 150:  # Validation range
                    return age

        return None

    def _detect_metric_from_query(self, query: str) -> Optional[str]:
        """D√©tecte le type de m√©trique dans la requ√™te"""
        query_lower = query.lower()

        metric_keywords = {
            "weight": ["poids", "weight", "masse"],
            "fcr": ["fcr", "conversion", "indice", "ic"],
            "mortality": ["mortalit√©", "mortality", "mort"],
            "production": ["production", "ponte", "≈ìuf", "egg"],
            "feed": ["alimentation", "feed", "aliment"],
        }

        for metric_type, keywords in metric_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                return metric_type

        return None

    def _generate_validation_help_message(
        self, query: str, missing: List[str], suggestions: List[str]
    ) -> str:
        """G√©n√®re un message d'aide pour requ√™tes incompl√®tes"""

        if "recommande" in query.lower() or "meilleur" in query.lower():
            return """Pour une recommandation personnalis√©e, pr√©cisez :

**Races disponibles :**
‚Ä¢ Cobb 500 - Croissance rapide, bon FCR
‚Ä¢ Ross 308 - Excellent rendement, robustesse  
‚Ä¢ Hubbard JA87 - Adaptabilit√©, rusticit√©

**Contexte n√©cessaire :**
‚Ä¢ Type de production (chair, ponte)
‚Ä¢ Objectifs (croissance, conversion, mortalit√©)
‚Ä¢ Conditions d'√©levage

**Exemple :** "Recommande une race pour production intensive de chair"."""

        else:
            return f"""Informations manquantes : {', '.join(missing)}

**Suggestions :**
{chr(10).join(f'‚Ä¢ {s}' for s in suggestions)}

**Exemple de requ√™te compl√®te :**
"Quel est le poids du Cobb 500 √† 42 jours ?"

Reformulez avec plus de d√©tails pour des donn√©es pr√©cises."""

    def _check_data_availability_flexible(
        self, entities: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        V√©rification flexible de disponibilit√© avec alternatives
        """

        breed = entities.get("breed", "").lower()
        age_days = entities.get("age_days")

        if not age_days or not breed:
            return {"available": True}  # Skip si donn√©es incompl√®tes

        # Ranges de donn√©es connus
        data_ranges = {
            "cobb 500": {"min": 0, "max": 56},
            "ross 308": {"min": 0, "max": 56},
            "hubbard ja87": {"min": 0, "max": 49},
        }

        range_info = data_ranges.get(breed)
        if not range_info:
            return {"available": True}  # Breed inconnu - laisser passer

        if range_info["min"] <= age_days <= range_info["max"]:
            return {"available": True}

        # Hors plage - proposer alternatives
        alternatives = []
        if age_days > range_info["max"]:
            alternatives.append(
                f"Donn√©es disponibles jusqu'√† {range_info['max']} jours"
            )
            alternatives.append(f"Essayez: poids √† {range_info['max']} jours")

        helpful_response = f"""L'√¢ge demand√© ({age_days} jours) est hors de la plage de donn√©es disponibles pour {breed.title()} ({range_info['min']}-{range_info['max']} jours).

**Alternatives disponibles :**
{chr(10).join(f'‚Ä¢ {alt}' for alt in alternatives)}

**Donn√©es disponibles pour {breed.title()} :**
‚Ä¢ Poids corporel (0-{range_info['max']} jours)
‚Ä¢ FCR et conversion alimentaire  
‚Ä¢ Mortalit√© et performance"""

        return {
            "available": False,
            "message": f"L'√¢ge demand√© ({age_days} jours) est hors de la plage de donn√©es disponibles pour {breed} ({range_info['min']}-{range_info['max']} jours).",
            "alternatives": alternatives,
            "helpful_response": helpful_response,
        }

    def _check_data_availability_with_as_hatched_fix(
        self, query: str, entities: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        üîß CORRECTION CRITIQUE: Gestion correcte de as_hatched dans la validation des √¢ges

        Cette m√©thode corrige le probl√®me o√π 'as_hatched' √©tait trait√© comme un √¢ge invalide
        """
        # Obtenir la validation originale
        original_check = self.data_availability_checker.check_data_availability(
            query, entities
        )

        # Si la validation a √©chou√© √† cause d'un "√¢ge invalide"
        if not original_check.get("data_available", True):
            reason = original_check.get("reason", "")

            # üîß CORRECTION: V√©rifier si l'erreur concerne "as_hatched"
            if "invalide" in reason.lower() and "as_hatched" in str(
                entities.get("age_days", "")
            ):
                logger.info(
                    "üîß Correction as_hatched: Autoriser la requ√™te sans √¢ge sp√©cifique"
                )
                return {
                    "data_available": True,
                    "reason": "Age non sp√©cifi√© (as_hatched) - recherche g√©n√©rale autoris√©e",
                    "data_type": "metrics",
                    "corrected_as_hatched": True,
                }

            # üîß CORRECTION: Aussi pour les valeurs None ou "None"
            age_days = entities.get("age_days")
            if "invalide" in reason.lower() and (
                age_days is None or str(age_days).lower() in ["none", "null"]
            ):
                logger.info("üîß Correction: Autoriser la requ√™te sans √¢ge sp√©cifique")
                return {
                    "data_available": True,
                    "reason": "Age non sp√©cifi√© - recherche g√©n√©rale autoris√©e",
                    "data_type": "metrics",
                    "corrected_none_age": True,
                }

        # Retourner la validation originale si pas de probl√®me as_hatched
        return original_check

    def _convert_metrics_to_documents(
        self, metric_results: List[MetricResult]
    ) -> List[Document]:
        """Convert metrics to documents"""
        documents = []

        for metric in metric_results:
            try:
                content = self._format_metric_content(metric)
                doc = Document(
                    content=content,
                    metadata={
                        "strain": metric.strain,
                        "metric_name": metric.metric_name,
                        "sex": metric.sex,
                        "source_type": "metrics",
                    },
                    score=metric.confidence,
                    source_type="metrics",
                    retrieval_method="postgresql",
                )
                documents.append(doc)
            except Exception as e:
                logger.error(f"Document creation error: {e}")
                continue

        return documents

    def _format_metric_content(self, metric: MetricResult) -> str:
        """Format metric as text"""
        parts = [
            f"**{metric.metric_name}**",
            f"Strain: {metric.strain}",
        ]

        if metric.sex:
            parts.append(f"Sex: {metric.sex}")

        if metric.value_numeric is not None:
            parts.append(f"Value: {metric.value_numeric} {metric.unit or ''}")

        if metric.age_min is not None:
            if metric.age_min == metric.age_max:
                parts.append(f"Age: {metric.age_min} days")
            else:
                parts.append(f"Age: {metric.age_min}-{metric.age_max} days")

        return "\n".join(parts)

    async def _generate_response(
        self,
        query: str,
        documents: List[Document],
        metric_results: List[MetricResult],
        entities: Dict,
    ) -> str:
        """Generate response with OpenAI or fallback"""

        if not metric_results:
            return f"Aucune donn√©e trouv√©e pour '{query}'."

        best_metric = metric_results[0]

        sex_info = (
            f" pour {best_metric.sex}"
            if best_metric.sex and best_metric.sex != "as_hatched"
            else ""
        )
        return f"Donn√©es trouv√©es{sex_info}: {best_metric.metric_name} = {best_metric.value_numeric or best_metric.value_text} pour {best_metric.strain}."

    async def close(self):
        """Close system"""
        if self.postgres_retriever:
            await self.postgres_retriever.close()
        self.is_initialized = False

    def get_normalization_status(self) -> Dict[str, Any]:
        """Return normalization status + Phase 1 modules"""
        if not self.postgres_retriever:
            return {"available": False}

        return {
            "available": True,
            "sex_aware_search": True,
            "openai_enabled": self.openai_client is not None,
            "strict_sex_match_supported": True,
            # ‚úÖ PHASE 1: Status des nouveaux modules
            "phase_1_modules": {
                "query_validator": {
                    "available": self.query_validator is not None,
                    "status": "initialized" if self.query_validator else "unavailable",
                },
                "data_availability_checker": {
                    "available": self.data_availability_checker is not None,
                    "status": (
                        "initialized"
                        if self.data_availability_checker
                        else "unavailable"
                    ),
                },
            },
            "implementation_phase": "1_validation_availability",
            # üîß NOUVELLE INFO: Statut de la correction as_hatched
            "as_hatched_fix": {
                "applied": True,
                "description": "Correction pour traiter as_hatched comme √¢ge non sp√©cifi√©",
                "status": "active",
            },
            # üîß NOUVELLE INFO: Statut de la validation flexible
            "flexible_validation": {
                "applied": True,
                "description": "Validation flexible avec auto-d√©tection et alternatives",
                "features": [
                    "Auto-d√©tection breed/age/metric",
                    "Requ√™tes partiellement sp√©cifi√©es",
                    "Messages d'aide intelligents",
                    "Alternatives pour donn√©es hors plage",
                ],
                "status": "active",
            },
        }
